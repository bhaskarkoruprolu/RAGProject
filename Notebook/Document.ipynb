{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84fae11",
   "metadata": {},
   "source": [
    "### Data Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd92a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\india\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain_core\n",
      "  Using cached langchain_core-1.2.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain_core)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain_core)\n",
      "  Using cached langsmith-0.7.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_core) (26.0)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain_core)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain_core)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain_core)\n",
      "  Using cached tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain_core)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain_core)\n",
      "  Using cached uuid_utils-0.14.0-cp39-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain_core)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached orjson-3.11.7-cp313-cp313-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash>=3.0.0 (from langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached zstandard-0.25.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain_core)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain_core)\n",
      "  Using cached pydantic_core-2.41.5-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain_core)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain_core)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Using cached langchain_core-1.2.9-py3-none-any.whl (496 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.7.1-py3-none-any.whl (322 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Using cached tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached uuid_utils-0.14.0-cp39-abi3-win_amd64.whl (182 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.11.7-cp313-cp313-win_amd64.whl (124 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Using cached zstandard-0.25.0-cp313-cp313-win_amd64.whl (506 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: zstandard, xxhash, uuid-utils, urllib3, typing-extensions, tenacity, pyyaml, orjson, jsonpointer, idna, h11, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, requests-toolbelt, pydantic, httpx, langsmith, langchain_core\n",
      "\n",
      "   ----------------------------------------  0/25 [zstandard]\n",
      "   --- ------------------------------------  2/25 [uuid-utils]\n",
      "   ---- -----------------------------------  3/25 [urllib3]\n",
      "   ---- -----------------------------------  3/25 [urllib3]\n",
      "   ---- -----------------------------------  3/25 [urllib3]\n",
      "   ---- -----------------------------------  3/25 [urllib3]\n",
      "   ---- -----------------------------------  3/25 [urllib3]\n",
      "   ---- -----------------------------------  3/25 [urllib3]\n",
      "   ---- -----------------------------------  3/25 [urllib3]\n",
      "   ---- -----------------------------------  3/25 [urllib3]\n",
      "   ---- -----------------------------------  3/25 [urllib3]\n",
      "   ------ ---------------------------------  4/25 [typing-extensions]\n",
      "   ------ ---------------------------------  4/25 [typing-extensions]\n",
      "   -------- -------------------------------  5/25 [tenacity]\n",
      "   -------- -------------------------------  5/25 [tenacity]\n",
      "   --------- ------------------------------  6/25 [pyyaml]\n",
      "   --------- ------------------------------  6/25 [pyyaml]\n",
      "   --------- ------------------------------  6/25 [pyyaml]\n",
      "   --------- ------------------------------  6/25 [pyyaml]\n",
      "   --------- ------------------------------  6/25 [pyyaml]\n",
      "   ------------ ---------------------------  8/25 [jsonpointer]\n",
      "   -------------- -------------------------  9/25 [idna]\n",
      "   -------------- -------------------------  9/25 [idna]\n",
      "   -------------- -------------------------  9/25 [idna]\n",
      "   ---------------- ----------------------- 10/25 [h11]\n",
      "   ---------------- ----------------------- 10/25 [h11]\n",
      "   ---------------- ----------------------- 10/25 [h11]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   ----------------- ---------------------- 11/25 [charset_normalizer]\n",
      "   -------------------- ------------------- 13/25 [annotated-types]\n",
      "   ---------------------- ----------------- 14/25 [typing-inspection]\n",
      "   ------------------------ --------------- 15/25 [requests]\n",
      "   ------------------------ --------------- 15/25 [requests]\n",
      "   ------------------------ --------------- 15/25 [requests]\n",
      "   ------------------------ --------------- 15/25 [requests]\n",
      "   ------------------------- -------------- 16/25 [pydantic-core]\n",
      "   --------------------------- ------------ 17/25 [jsonpatch]\n",
      "   ---------------------------- ----------- 18/25 [httpcore]\n",
      "   ---------------------------- ----------- 18/25 [httpcore]\n",
      "   ---------------------------- ----------- 18/25 [httpcore]\n",
      "   ---------------------------- ----------- 18/25 [httpcore]\n",
      "   ---------------------------- ----------- 18/25 [httpcore]\n",
      "   ---------------------------- ----------- 18/25 [httpcore]\n",
      "   ---------------------------- ----------- 18/25 [httpcore]\n",
      "   ---------------------------- ----------- 18/25 [httpcore]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   ------------------------------ --------- 19/25 [anyio]\n",
      "   -------------------------------- ------- 20/25 [requests-toolbelt]\n",
      "   -------------------------------- ------- 20/25 [requests-toolbelt]\n",
      "   -------------------------------- ------- 20/25 [requests-toolbelt]\n",
      "   -------------------------------- ------- 20/25 [requests-toolbelt]\n",
      "   -------------------------------- ------- 20/25 [requests-toolbelt]\n",
      "   -------------------------------- ------- 20/25 [requests-toolbelt]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   --------------------------------- ------ 21/25 [pydantic]\n",
      "   ----------------------------------- ---- 22/25 [httpx]\n",
      "   ----------------------------------- ---- 22/25 [httpx]\n",
      "   ----------------------------------- ---- 22/25 [httpx]\n",
      "   ----------------------------------- ---- 22/25 [httpx]\n",
      "   ----------------------------------- ---- 22/25 [httpx]\n",
      "   ----------------------------------- ---- 22/25 [httpx]\n",
      "   ----------------------------------- ---- 22/25 [httpx]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   ------------------------------------ --- 23/25 [langsmith]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   -------------------------------------- - 24/25 [langchain_core]\n",
      "   ---------------------------------------- 25/25 [langchain_core]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.1 certifi-2026.1.4 charset_normalizer-3.4.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jsonpatch-1.33 jsonpointer-3.0.0 langchain_core-1.2.9 langsmith-0.7.1 orjson-3.11.7 pydantic-2.12.5 pydantic-core-2.41.5 pyyaml-6.0.3 requests-2.32.5 requests-toolbelt-1.0.0 tenacity-9.1.4 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.3 uuid-utils-0.14.0 xxhash-3.6.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "###Document Structure\n",
    "%pip install langchain_core\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ac09aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'exmaple.txt', 'pages': 1, 'author': 'Krish Naik', 'date_created': '2025-01-01'}, page_content='this is the main text content I am using to create RAG')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=Document(\n",
    "    page_content=\"this is the main text content I am using to create RAG\",\n",
    "    metadata={\n",
    "        \"source\":\"exmaple.txt\",\n",
    "        \"pages\":1,\n",
    "        \"author\":\"Krish Naik\",\n",
    "        \"date_created\":\"2025-01-01\"\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc622eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple txt file\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8364f1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"✅ Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d09c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\india\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain_community in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (1.2.9)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (2.0.46)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (9.1.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (0.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain_community) (2.3.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (26.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\india\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "### TextLoader\n",
    "%pip install langchain_community\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader(\"../data/text_files/python_intro.txt\",encoding=\"utf-8\")\n",
    "document=loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b65c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\", ## Pattern to match files  \n",
    "    loader_cls= TextLoader, ##loader class to use\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39678125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.26.7-cp310-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Using cached pymupdf-1.26.7-cp310-abi3-win_amd64.whl (18.4 MB)\n",
      "Installing collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.26.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\india\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 0}, page_content='Clarence Chio & David Freeman\\nMachine \\nLearning &  \\n Security\\nPROTECTING SYSTEMS WITH DATA AND ALGORITHMS'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 1}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 2}, page_content='Praise for Machine Learning and Security\\nThe future of security and safety online is going to be defined by the ability of defenders\\nto deploy machine learning to find and stop malicious activity at Internet scale and speed.\\nChio and Freeman have written the definitive book on this topic, capturing the latest in\\nacademic thinking as well as hard-learned lessons deploying ML to keep people safe in\\nthe field.\\n—Alex Stamos, Chief Security Oicer, Facebook\\nAn excellent practical guide for anyone looking to learn how machine learning techniques\\nare used to secure computer systems, from detecting anomalies to protecting end users.\\n—Dan Boneh, Professor of Computer Science,\\nStanford University\\nIf you’ve ever wondered what machine learning in security looks like, this book\\ngives you an HD silhouette.\\n—Nwokedi C. Idika, PhD, Sotware Engineer, Google,\\nSecurity & Privacy Organization'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 3}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 4}, page_content='Clarence Chio and David Freeman\\nMachine Learning and Security\\nProtecting Systems with Data and Algorithms\\nBoston\\nFarnham\\nSebastopol\\nTokyo\\nBeijing\\nBoston\\nFarnham\\nSebastopol\\nTokyo\\nBeijing'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 5}, page_content='978-1-491-97990-7\\n[LSI]\\nMachine Learning and Security\\nby Clarence Chio and David Freeman\\nCopyright © 2018 Clarence Chio and David Freeman. All rights reserved.\\nPrinted in the United States of America.\\nPublished by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.\\nO’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are\\nalso available for most titles (http://oreilly.com/safari). For more information, contact our corporate/insti‐\\ntutional sales department: 800-998-9938 or corporate@oreilly.com.\\nEditor: Courtney Allen\\nProduction Editor: Kristen Brown\\nCopyeditor: Octal Publishing, Inc.\\nProofreader: Rachel Head\\nIndexer: WordCo Indexing Services, Inc.\\nInterior Designer: David Futato\\nCover Designer: Karen Montgomery\\nIllustrator: Rebecca Demarest\\nTech Reviewers: Joshua Saxe, Hyrum Anderson,\\nJess Males, and Alex Pinto\\nFebruary 2018:\\n First Edition\\nRevision History for the First Edition\\n2018-01-26: First Release\\nSee http://oreilly.com/catalog/errata.csp?isbn=9781491979907 for release details.\\nThe O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Machine Learning and Security, the\\ncover image, and related trade dress are trademarks of O’Reilly Media, Inc.\\nWhile the publisher and the authors have used good faith efforts to ensure that the information and\\ninstructions contained in this work are accurate, the publisher and the authors disclaim all responsibility\\nfor errors or omissions, including without limitation responsibility for damages resulting from the use of\\nor reliance on this work. Use of the information and instructions contained in this work is at your own\\nrisk. If any code samples or other technology this work contains or describes is subject to open source\\nlicenses or the intellectual property rights of others, it is your responsibility to ensure that your use\\nthereof complies with such licenses and/or rights.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 6}, page_content='Table of Contents\\nPreface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xi\\n1. Why Machine Learning and Security?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1\\nCyber Threat Landscape                                                                                                   3\\nThe Cyber Attacker’s Economy                                                                                        7\\nA Marketplace for Hacking Skills                                                                                7\\nIndirect Monetization                                                                                                    8\\nThe Upshot                                                                                                                      8\\nWhat Is Machine Learning?                                                                                              9\\nWhat Machine Learning Is Not                                                                                  10\\nAdversaries Using Machine Learning                                                                       11\\nReal-World Uses of Machine Learning in Security                                                     12\\nSpam Fighting: An Iterative Approach                                                                         14\\nLimitations of Machine Learning in Security                                                              23\\n2. Classifying and Clustering. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  25\\nMachine Learning: Problems and Approaches                                                           25\\nMachine Learning in Practice: A Worked Example                                                    27\\nTraining Algorithms to Learn                                                                                        32\\nModel Families                                                                                                              33\\nLoss Functions                                                                                                              35\\nOptimization                                                                                                                 36\\nSupervised Classification Algorithms                                                                           40\\nLogistic Regression                                                                                                       40\\nDecision Trees                                                                                                               42\\nDecision Forests                                                                                                           45\\nSupport Vector Machines                                                                                            47\\nNaive Bayes                                                                                                                    49\\nv'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 7}, page_content='k-Nearest Neighbors                                                                                                    52\\nNeural Networks                                                                                                           53\\nPractical Considerations in Classification                                                                    55\\nSelecting a Model Family                                                                                            55\\nTraining Data Construction                                                                                        56\\nFeature Selection                                                                                                          59\\nOverfitting and Underfitting                                                                                      61\\nChoosing Thresholds and Comparing Models                                                        62\\nClustering                                                                                                                          65\\nClustering Algorithms                                                                                                 65\\nEvaluating Clustering Results                                                                                     75\\nConclusion                                                                                                                        77\\n3. Anomaly Detection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  79\\nWhen to Use Anomaly Detection Versus Supervised Learning                               80\\nIntrusion Detection with Heuristics                                                                             81\\nData-Driven Methods                                                                                                     82\\nFeature Engineering for Anomaly Detection                                                               85\\nHost Intrusion Detection                                                                                            85\\nNetwork Intrusion Detection                                                                                     89\\nWeb Application Intrusion Detection                                                                       92\\nIn Summary                                                                                                                  93\\nAnomaly Detection with Data and Algorithms                                                          93\\nForecasting (Supervised Machine Learning)                                                           95\\nStatistical Metrics                                                                                                       106\\nGoodness-of-Fit                                                                                                          107\\nUnsupervised Machine Learning Algorithms                                                        112\\nDensity-Based Methods                                                                                            116\\nIn Summary                                                                                                                118\\nChallenges of Using Machine Learning in Anomaly Detection                             119\\nResponse and Mitigation                                                                                              120\\nPractical System Design Concerns                                                                              121\\nOptimizing for Explainability                                                                                  121\\nMaintainability of Anomaly Detection Systems                                                    123\\nIntegrating Human Feedback                                                                                   123\\nMitigating Adversarial Effects                                                                                  123\\nConclusion                                                                                                                      124\\n4. Malware Analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  125\\nUnderstanding Malware                                                                                               126\\nDefining Malware Classification                                                                              128\\nMalware: Behind the Scenes                                                                                     131\\nvi \\n| \\nTable of Contents'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 8}, page_content='Feature Generation                                                                                                        145\\nData Collection                                                                                                           146\\nGenerating Features                                                                                                   147\\nFeature Selection                                                                                                        171\\nFrom Features to Classification                                                                                   174\\nHow to Get Malware Samples and Labels                                                              178\\nConclusion                                                                                                                      179\\n5. Network Traic Analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  181\\nTheory of Network Defense                                                                                         183\\nAccess Control and Authentication                                                                         183\\nIntrusion Detection                                                                                                    184\\nDetecting In-Network Attackers                                                                              185\\nData-Centric Security                                                                                                185\\nHoneypots                                                                                                                   186\\nSummary                                                                                                                     186\\nMachine Learning and Network Security                                                                  187\\nFrom Captures to Features                                                                                       187\\nThreats in the Network                                                                                              193\\nBotnets and You                                                                                                          197\\nBuilding a Predictive Model to Classify Network Attacks                                       203\\nExploring the Data                                                                                                     205\\nData Preparation                                                                                                        210\\nClassification                                                                                                               214\\nSupervised Learning                                                                                                  216\\nSemi-Supervised Learning                                                                                        222\\nUnsupervised Learning                                                                                             223\\nAdvanced Ensembling                                                                                               228\\nConclusion                                                                                                                      233\\n6. Protecting the Consumer Web. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  235\\nMonetizing the Consumer Web                                                                                   236\\nTypes of Abuse and the Data That Can Stop Them                                                  237\\nAuthentication and Account Takeover                                                                   237\\nAccount Creation                                                                                                       243\\nFinancial Fraud                                                                                                           248\\nBot Activity                                                                                                                 251\\nSupervised Learning for Abuse Problems                                                                  256\\nLabeling Data                                                                                                              256\\nCold Start Versus Warm Start                                                                                  258\\nFalse Positives and False Negatives                                                                          258\\nMultiple Responses                                                                                                    259\\nTable of Contents \\n| \\nvii'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 9}, page_content='Large Attacks                                                                                                               259\\nClustering Abuse                                                                                                            260\\nExample: Clustering Spam Domains                                                                       261\\nGenerating Clusters                                                                                                   262\\nScoring Clusters                                                                                                          266\\nFurther Directions in Clustering                                                                                 271\\nConclusion                                                                                                                      272\\n7. Production Systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  275\\nDefining Machine Learning System Maturity and Scalability                                275\\nWhat’s Important for Security Machine Learning Systems?                                277\\nData Quality                                                                                                                    277\\nProblem: Bias in Datasets                                                                                          277\\nProblem: Label Inaccuracy                                                                                       279\\nSolutions: Data Quality                                                                                             279\\nProblem: Missing Data                                                                                              280\\nSolutions: Missing Data                                                                                             281\\nModel Quality                                                                                                                 284\\nProblem: Hyperparameter Optimization                                                               285\\nSolutions: Hyperparameter Optimization                                                              285\\nFeature: Feedback Loops, A/B Testing of Models                                                  289\\nFeature: Repeatable and Explainable Results                                                         293\\nPerformance                                                                                                                   297\\nGoal: Low Latency, High Scalability                                                                        297\\nPerformance Optimization                                                                                       298\\nHorizontal Scaling with Distributed Computing Frameworks                           300\\nUsing Cloud Services                                                                                                 305\\nMaintainability                                                                                                               307\\nProblem: Checkpointing, Versioning, and Deploying Models                            307\\nGoal: Graceful Degradation                                                                                      308\\nGoal: Easily Tunable and Configurable                                                                   309\\nMonitoring and Alerting                                                                                              310\\nSecurity and Reliability                                                                                                 311\\nFeature: Robustness in Adversarial Contexts                                                         312\\nFeature: Data Privacy Safeguards and Guarantees                                                312\\nFeedback and Usability                                                                                                 313\\nConclusion                                                                                                                      314\\n8. Adversarial Machine Learning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  315\\nTerminology                                                                                                                   316\\nThe Importance of Adversarial ML                                                                             317\\nSecurity Vulnerabilities in Machine Learning Algorithms                                      318\\nviii \\n| \\nTable of Contents'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 10}, page_content='Attack Transferability                                                                                                320\\nAttack Technique: Model Poisoning                                                                           322\\nExample: Binary Classifier Poisoning Attack                                                         325\\nAttacker Knowledge                                                                                                   330\\nDefense Against Poisoning Attacks                                                                         331\\nAttack Technique: Evasion Attack                                                                               333\\nExample: Binary Classifier Evasion Attack                                                             334\\nDefense Against Evasion Attacks                                                                             339\\nConclusion                                                                                                                      340\\nA. Supplemental Material for Chapter 2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  343\\nB. Integrating Open Source Intelligence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  351\\nIndex. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  355\\nTable of Contents \\n| \\nix'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 11}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 12}, page_content='1 Monsanto, “How Machine Learning is Changing Modern Agriculture,” Modern Agriculture, September 13,\\n2017, https://modernag.org/innovation/machine-learning-changing-modern-agriculture/.\\n2 “Meltdown and Spectre,” Graz University of Technology, accessed January 23, 2018, https://spectreattack.com/.\\nPreface\\nMachine learning is eating the world. From communication and finance to transpor‐\\ntation, manufacturing, and even agriculture,1 nearly every technology field has been\\ntransformed by machine learning and artificial intelligence, or will soon be.\\nComputer security is also eating the world. As we become dependent on computers\\nfor an ever-greater proportion of our work, entertainment, and social lives, the value\\nof breaching these systems increases proportionally, drawing in an increasing pool of\\nattackers hoping to make money or simply wreak mischief. Furthermore, as systems\\nbecome increasingly complex and interconnected, it becomes harder and harder to\\nensure that there are no bugs or backdoors that will give attackers a way in. Indeed, as\\nthis book went to press we learned that pretty much every microprocessor currently\\nin use is insecure.2\\nWith machine learning offering (potential) solutions to everything under the sun, it is\\nonly natural that it be applied to computer security, a field which intrinsically pro‐\\nvides the robust data sets on which machine learning thrives. Indeed, for all the secu‐\\nrity threats that appear in the news, we hear just as many claims about how A.I. can\\n“revolutionize” the way we deal with security. Because of the promise that it holds for\\nnullifying some of the most complex advances in attacker competency, machine\\nlearning has been touted as the technique that will finally put an end to the cat-and-\\nmouse game between attackers and defenders. Walking the expo floors of major secu‐\\nrity conferences, the trend is apparent: more and more companies are embracing the\\nuse of machine learning to solve security problems.\\nMirroring the growing interest in the marriage of these two fields, there is a corre‐\\nsponding air of cynicism that dismisses it as hype. So how do we strike a balance?\\nxi'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 13}, page_content='What is the true potential of A.I. applied to security? How can you distinguish the\\nmarketing fluff from promising technologies? What should I actually use to solve my\\nsecurity problems? The best way we can think of to answer these questions is to dive\\ndeep into the science, understand the core concepts, do lots of testing and experimen‐\\ntation, and let the results speak for themselves. However, doing this requires a work‐\\ning knowledge of both data science and computer security. In the course of our work\\nbuilding security systems, leading anti-abuse teams, and speaking at conferences, we\\nhave met a few people who have this knowledge, and many more who understand\\none side and want to learn about the other.\\nThis book is the result.\\nWhat’s In This Book?\\nWe wrote this book to provide a framework for discussing the inevitable marriage of\\ntwo ubiquitous concepts: machine learning and security. While there is some litera‐\\nture on the intersection of these subjects (and multiple conference workshops: CCS’s\\nAISec, AAAI’s AICS, and NIPS’s Machine Deception), most of the existing work is\\nacademic or theoretical. In particular, we did not find a guide that provides concrete,\\nworked examples with code that can educate security practitioners about data science\\nand help machine learning practitioners think about modern security problems\\neffectively.\\nIn examining a broad range of topics in the security space, we provide examples of\\nhow machine learning can be applied to augment or replace rule-based or heuristic\\nsolutions to problems like intrusion detection, malware classification, or network\\nanalysis. In addition to exploring the core machine learning algorithms and techni‐\\nques, we focus on the challenges of building maintainable, reliable, and scalable data\\nmining systems in the security space. Through worked examples and guided discus‐\\nsions, we show you how to think about data in an adversarial environment and how\\nto identify the important signals that can get drowned out by noise.\\nWho Is This Book For?\\nIf you are working in the security field and want to use machine learning to improve\\nyour systems, this book is for you. If you have worked with machine learning and\\nnow want to use it to solve security problems, this book is also for you.\\nWe assume you have some basic knowledge of statistics; most of the more complex\\nmath can be skipped upon your first reading without losing the concepts. We also\\nassume familiarity with a programming language. Our examples are in Python and\\nwe provide references to the Python packages required to implement the concepts we\\ndiscuss, but you can implement the same concepts using open source libraries in Java,\\nScala, C++, Ruby, and many other languages.\\nxii \\n| \\nPreface'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 14}, page_content='Conventions Used in This Book\\nThe following typographical conventions are used in this book:\\nItalic\\nIndicates new terms, URLs, email addresses, filenames, and file extensions.\\nConstant width\\nUsed for program listings, as well as within paragraphs to refer to program ele‐\\nments such as variable or function names, databases, data types, environment\\nvariables, statements, and keywords. Also used for commands and command-\\nline output.\\nConstant width bold\\nShows commands or other text that should be typed literally by the user. Also\\nused for emphasis in command-line output.\\nConstant width italic\\nShows text that should be replaced with user-supplied values or by values deter‐\\nmined by context.\\nThis element signifies a tip, suggestion, or general note.\\nThis element indicates a warning or caution.\\nUsing Code Examples\\nSupplemental material (code examples, exercises, etc.) is available for download at\\nhttps://github.com/oreilly-mlsec/book-resources.\\nThis book is here to help you get your job done. In general, if example code is offered\\nwith this book, you may use it in your programs and documentation. You do not\\nneed to contact us for permission unless you’re reproducing a significant portion of\\nthe code. For example, writing a program that uses several chunks of code from this\\nbook does not require permission. Selling or distributing a CD-ROM of examples\\nfrom O’Reilly books does require permission. Answering a question by citing this\\nbook and quoting example code does not require permission. Incorporating a signifi‐\\nPreface \\n| \\nxiii'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 15}, page_content='cant amount of example code from this book into your product’s documentation does\\nrequire permission.\\nWe appreciate, but do not require, attribution. An attribution usually includes the\\ntitle, author, publisher, and ISBN. For example: “Machine Learning and Security by\\nClarence Chio and David Freeman (O’Reilly). Copyright 2018 Clarence Chio and\\nDavid Freeman, 978-1-491-97990-7.”\\nIf you feel your use of code examples falls outside fair use or the permission given\\nabove, feel free to contact us at permissions@oreilly.com.\\nO’Reilly Safari\\nSafari (formerly Safari Books Online) is a membership-based\\ntraining and reference platform for enterprise, government,\\neducators, and individuals.\\nMembers have access to thousands of books, training videos, Learning Paths, interac‐\\ntive tutorials, and curated playlists from over 250 publishers, including O’Reilly\\nMedia, Harvard Business Review, Prentice Hall Professional, Addison-Wesley Profes‐\\nsional, Microsoft Press, Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press,\\nJohn Wiley & Sons, Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe\\nPress, FT Press, Apress, Manning, New Riders, McGraw-Hill, Jones & Bartlett, and\\nCourse Technology, among others.\\nFor more information, please visit http://oreilly.com/safari.\\nHow to Contact Us\\nPlease address comments and questions concerning this book to the publisher:\\nO’Reilly Media, Inc.\\n1005 Gravenstein Highway North\\nSebastopol, CA 95472\\n800-998-9938 (in the United States or Canada)\\n707-829-0515 (international or local)\\n707-829-0104 (fax)\\nO’Reilly Media has a web page for this book, where they list errata, examples, and any\\nadditional information. You can access this page at http://bit.ly/machineLearningAnd\\nSecurity. The authors have created a website for the book at https://mlsec.net.\\nTo comment or ask technical questions about this book, send email to bookques‐\\ntions@oreilly.com.\\nxiv \\n| \\nPreface'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 16}, page_content='For more information about our books, courses, conferences, and news, see our web‐\\nsite at http://www.oreilly.com.\\nFind us on Facebook: http://facebook.com/oreilly\\nFollow us on Twitter: http://twitter.com/oreillymedia\\nWatch us on YouTube: http://www.youtube.com/oreillymedia\\nAcknowledgments\\nThe authors thank Hyrum Anderson, Jason Craig, Nwokedi Idika, Jess Males, Andy\\nOram, Alex Pinto, and Joshua Saxe for thorough technical reviews and feedback on\\nearly drafts of this work. We also thank Virginia Wilson, Kristen Brown, and all the\\nstaff at O’Reilly who helped us take this project from concept to reality.\\nClarence thanks Christina Zhou for tolerating the countless all-nighters and week‐\\nends spent on this book, Yik Lun Lee for proofreading drafts and finding mistakes in\\nmy code, Jarrod Overson for making me believe I could do this, and Daisy the Chi‐\\nhuahua for being at my side through the toughest of times. Thanks to Anto Joseph for\\nteaching me security, to all the other hackers, researchers, and training attendees who\\nhave influenced this book in one way or another, to my colleagues at Shape Security\\nfor making me a better engineer, and to Data Mining for Cyber Security speakers and\\nattendees for being part of the community that drives this research. Most of all,\\nthanks to my family in Singapore for supporting me from across the globe and ena‐\\nbling me to chase my dreams and pursue my passion.\\nDavid thanks Deepak Agarwal for convincing me to undertake this effort, Dan Boneh\\nfor teaching me how to think about security, and Vicente Silveira and my colleagues\\nat LinkedIn and Facebook for showing me what security is like in the real world.\\nThanks also to Grace Tang for feedback on the machine learning sections as well as\\nthe occasional penguin. And the biggest thanks go to Torrey, Elodie, and Phoebe, who\\nput up with me taking many very late nights and a few odd excursions in order to\\ncomplete this book, and never wavered in their support.\\nPreface \\n| \\nxv'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 17}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 18}, page_content='CHAPTER 1\\nWhy Machine Learning and Security?\\nIn the beginning, there was spam.\\nAs soon as academics and scientists had hooked enough computers together via the\\ninternet to create a communications network that provided value, other people real‐\\nized that this medium of free transmission and broad distribution was a perfect way\\nto advertise sketchy products, steal account credentials, and spread computer viruses.\\nIn the intervening 40 years, the field of computer and network security has come to\\nencompass an enormous range of threats and domains: intrusion detection, web\\napplication security, malware analysis, social network security, advanced persistent\\nthreats, and applied cryptography, just to name a few. But even today spam remains a\\nmajor focus for those in the email or messaging space, and for the general public\\nspam is probably the aspect of computer security that most directly touches their own\\nlives.\\nMachine learning was not invented by spam fighters, but it was quickly adopted by\\nstatistically inclined technologists who saw its potential in dealing with a constantly\\nevolving source of abuse. Email providers and internet service providers (ISPs) have\\naccess to a wealth of email content, metadata, and user behavior. Using email data,\\ncontent-based models can be built to create a generalizable approach to recognize\\nspam. Metadata and entity reputations can be extracted from emails to predict the\\nlikelihood that an email is spam without even looking at its content. By instantiating a\\nuser behavior feedback loop, the system can build a collective intelligence and\\nimprove over time with the help of its users.\\nEmail filters have thus gradually evolved to deal with the growing diversity of circum‐\\nvention methods that spammers have thrown at them. Even though 85% of all emails\\nsent today are spam (according to one research group), the best modern spam filters\\nblock more than 99.9% of all spam, and it is a rarity for users of major email services\\n1'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 19}, page_content='to see unfiltered and undetected spam in their inboxes. These results demonstrate an\\nenormous advance over the simplistic spam filtering techniques developed in the\\nearly days of the internet, which made use of simple word filtering and email meta‐\\ndata reputation to achieve modest results.\\nThe fundamental lesson that both researchers and practitioners have taken away from\\nthis battle is the importance of using data to defeat malicious adversaries and improve\\nthe quality of our interactions with technology. Indeed, the story of spam fighting\\nserves as a representative example for the use of data and machine learning in any\\nfield of computer security. Today, almost all organizations have a critical reliance on\\ntechnology, and almost every piece of technology has security vulnerabilities. Driven\\nby the same core motivations as the spammers from the 1980s (unregulated, cost-free\\naccess to an audience with disposable income and private information to offer), mali‐\\ncious actors can pose security risks to almost all aspects of modern life. Indeed, the\\nfundamental nature of the battle between attacker and defender is the same in all\\nfields of computer security as it is in spam fighting: a motivated adversary is con‐\\nstantly trying to misuse a computer system, and each side races to fix or exploit the\\nflaws in design or technique before the other uncovers it. The problem statement has\\nnot changed one bit.\\nComputer systems and web services have become increasingly centralized, and many\\napplications have evolved to serve millions or even billions of users. Entities that\\nbecome arbiters of information are bigger targets for exploitation, but are also in the\\nperfect position to make use of the data and their user bases to achieve better security.\\nCoupled with the advent of powerful data crunching hardware and the development\\nof more powerful data analysis and machine learning algorithms, there has never\\nbeen a better time for exploiting the potential of machine learning in security.\\nIn this book, we demonstrate applications of machine learning and data analysis tech‐\\nniques to various problem domains in security and abuse. We explore methods for\\nevaluating the suitability of different machine learning techniques in different scenar‐\\nios, and focus on guiding principles that will help you use data to achieve better secu‐\\nrity. Our goal is not to leave you with the answer to every security problem you might\\nface, but rather to give you a framework for thinking about data and security as well\\nas a toolkit from which you can pick the right method for the problem at hand.\\nThe remainder of this chapter sets up context for the rest of the book: we discuss\\nwhat threats modern computer and network systems face, what machine learning is,\\nand how machine learning applies to the aforementioned threats. We conclude with a\\ndetailed examination of approaches to spam fighting, which provides a concrete\\nexample of applying machine learning to security that can be generalized to nearly\\nany domain.\\n2 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 20}, page_content='1 Adapted from the European CSIRT Network project’s Security Incidents Taxonomy.\\nCyber Threat Landscape\\nThe landscape of adversaries and miscreants in computer security has evolved over\\ntime, but the general categories of threats have remained the same. Security research\\nexists to stymie the goals of attackers, and it is always important to have a good\\nunderstanding of the different types of attacks that exist in the wild. As you can see\\nfrom the Cyber Threat Taxonomy tree in Figure 1-1,1 the relationships between threat\\nentities and categories can be complex in some cases.\\nWe begin by defining the principal threats that we will explore in the chapters that\\nfollow:\\nMalware (or virus)\\nShort for “malicious software,” any software designed to cause harm or gain\\nunauthorized access to computer systems.\\nWorm\\nStandalone malware that replicates itself in order to spread to other computer\\nsystems.\\nTrojan\\nMalware disguised as legitimate software to avoid detection.\\nSpyware\\nMalware installed on a computer system without permission and/or knowledge\\nby the operator, for the purposes of espionage and information collection. Key‐\\nloggers fall into this category.\\nAdware\\nMalware that injects unsolicited advertising material (e.g., pop ups, banners, vid‐\\neos) into a user interface, often when a user is browsing the web.\\nRansomware\\nMalware designed to restrict availability of computer systems until a sum of\\nmoney (ransom) is paid.\\nRootkit\\nA collection of (often) low-level software designed to enable access to or gain\\ncontrol of a computer system. (“Root” denotes the most powerful level of access\\nto a system.)\\nCyber Threat Landscape \\n| \\n3'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 21}, page_content='Backdoor\\nAn intentional hole placed in the system perimeter to allow for future accesses\\nthat can bypass perimeter protections.\\nBot\\nA variant of malware that allows attackers to remotely take over and control\\ncomputer systems, making them zombies.\\nBotnet\\nA large network of bots.\\nExploit\\nA piece of code or software that exploits specific vulnerabilities in other software\\napplications or frameworks.\\nScanning\\nAttacks that send a variety of requests to computer systems, often in a brute-force\\nmanner, with the goal of finding weak points and vulnerabilities as well as infor‐\\nmation gathering.\\nSniing\\nSilently observing and recording network and in-server traffic and processes\\nwithout the knowledge of network operators.\\nKeylogger\\nA piece of hardware or software that (often covertly) records the keys pressed on\\na keyboard or similar computer input device.\\nSpam\\nUnsolicited bulk messaging, usually for the purposes of advertising. Typically\\nemail, but could be SMS or through a messaging provider (e.g., WhatsApp).\\nLogin attack\\nMultiple, usually automated, attempts at guessing credentials for authentication\\nsystems, either in a brute-force manner or with stolen/purchased credentials.\\nAccount takeover (ATO)\\nGaining access to an account that is not your own, usually for the purposes of\\ndownstream selling, identity theft, monetary theft, and so on. Typically the goal\\nof a login attack, but also can be small scale and highly targeted (e.g., spyware,\\nsocial engineering).\\nPhishing (aka masquerading)\\nCommunications with a human who pretends to be a reputable entity or person\\nin order to induce the revelation of personal information or to obtain private\\nassets.\\n4 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 22}, page_content='Spear phishing\\nPhishing that is targeted at a particular user, making use of information about\\nthat user gleaned from outside sources.\\nSocial engineering\\nInformation exfiltration (extraction) from a human being using nontechnical\\nmethods such as lying, trickery, bribery, blackmail, and so on.\\nIncendiary speech\\nDiscriminatory, discrediting, or otherwise harmful speech targeted at an individ‐\\nual or group.\\nDenial of service (DoS) and distributed denial of service (DDoS)\\nAttacks on the availability of systems through high-volume bombardment and/or\\nmalformed requests, often also breaking down system integrity and reliability.\\nAdvanced persistent threats (APTs)\\nHighly targeted networks or host attack in which a stealthy intruder remains\\nintentionally undetected for long periods of time in order to steal and exfiltrate\\ndata.\\nZero-day vulnerability\\nA weakness or bug in computer software or systems that is unknown to the ven‐\\ndor, allowing for potential exploitation (called a zero-day attack) before the ven‐\\ndor has a chance to patch/fix the problem.\\nCyber Threat Landscape \\n| \\n5'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 23}, page_content='Figure 1-1. Cyber hreat Taxonomy tree\\n6 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 24}, page_content='2 Charlie Miller, “The Legitimate Vulnerability Market: Inside the Secretive World of 0-day Exploit Sales,” Pro‐\\nceedings of the 6th Workshop on the Economics of Information Security (2007).\\nThe Cyber Attacker’s Economy\\nWhat drives attackers to do what they do? Internet-based criminality has become\\nincreasingly commercialized since the early days of the technology’s conception. The\\ntransformation of cyber attacks from a reputation economy (“street cred,” glory, mis‐\\nchief) to a cash economy (direct monetary gains, advertising, sale of private informa‐\\ntion) has been a fascinating process, especially from the point of view of the\\nadversary. The motivation of cyber attackers today is largely monetary. Attacks on\\nfinancial institutions or conduits (online payment platforms, stored value/gift card\\naccounts, Bitcoin wallets, etc.) can obviously bring attackers direct financial gains.\\nBut because of the higher stakes at play, these institutions often have more advanced\\ndefense mechanisms in place, making the lives of attackers tougher. Because of the\\nallure of a more direct path to financial yield, the marketplace for vulnerabilities tar‐\\ngeting such institutions is also comparatively crowded and noisy. This leads miscre‐\\nants to target entities with more relaxed security measures in place, abusing systems\\nthat are open by design and resorting to more indirect techniques that will eventually\\nstill allow them to monetize.\\nA Marketplace for Hacking Skills\\nThe fact that darknet marketplaces and illegal hacking forums exist is no secret.\\nBefore the existence of organized underground communities for illegal exchanges,\\nonly the most competent of computer hackers could partake in the launching of\\ncyber attacks and the compromising of accounts and computer systems. However,\\nwith the commoditization of hacking and the ubiquitization of computer use, lower-\\nskilled “hackers” can participate in the ecosystem of cyber attacks by purchasing vul‐\\nnerabilities and user-friendly hacking scripts, software, and tools to engage in their\\nown cyber attacks.\\nThe zero-day vulnerability marketplace has variants that exist both legally and ille‐\\ngally. Trading vulnerabilities and exploits can become a viable source of income for\\nboth security researchers and computer hackers.2 Increasingly, the most elite com‐\\nputer hackers are not the ones unleashing zero-days and launching attack campaigns.\\nThe risks are just too high, and the process of monetization is just too long and\\nuncertain. Creating software that empowers the common script-kiddy to carry out the\\nactual hacking, selling vulnerabilities on marketplaces, and in some cases even pro‐\\nviding boutique hacking consulting services promises a more direct and certain path\\nto financial gain. Just as in the California Gold Rush of the late 1840s, merchants\\nThe Cyber Attacker’s Economy \\n| \\n7'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 25}, page_content='3 Juan Caballero et al., “Measuring Pay-per-Install: The Commoditization of Malware Distribution,” Proceedings\\nof the 20th USENIX Conference on Security (2011).\\nproviding amenities to a growing population of wealth-seekers are more frequently\\nthe receivers of windfalls than the seekers themselves.\\nIndirect Monetization\\nThe process of monetization for miscreants involved in different types of computer\\nattacks is highly varied, and worthy of detailed study. We will not dive too deep into\\nthis investigation, but we will look at a couple of examples of how indirect monetiza‐\\ntion can work.\\nMalware distribution has been commoditized in a way similar to the evolution of\\ncloud computing and Infrastructure-as-a-Service (IaaS) providers. The pay-per-install\\n(PPI) marketplace for malware propagation is a complex and mature ecosystem, pro‐\\nviding wide distribution channels available to malware authors and purchasers.3 Bot‐\\nnet rentals operate on the same principle as on-demand cloud infrastructure, with\\nper-hour resource offerings at competitive prices. Deploying malware on remote\\nservers can also be financially rewarding in its own different ways. Targeted attacks\\non entities are sometimes associated with a bounty, and ransomware distributions can\\nbe an efficient way to extort money from a wide audience of victims.\\nSpyware can assist in the stealing of private information, which can then be sold in\\nbulk on the same online marketplaces where the spyware is sold. Adware and spam\\ncan be used as a cheap way to advertise dodgy pharmaceuticals and financial instru‐\\nments. Online accounts are frequently taken over for the purposes of retrieving some\\nform of stored value, such as gift cards, loyalty points, store credit, or cash rewards.\\nStolen credit card numbers, Social Security numbers, email accounts, phone num‐\\nbers, addresses, and other private information can be sold online to criminals intent\\non identity theft, fake account creation, fraud, and so on. But the path to monetiza‐\\ntion, in particular when you have a victim’s credit card number, can be a long and\\ncomplex one. Because of how easily this information is stolen, credit card companies,\\nas well as companies that operate accounts with stored value, often engineer clever\\nways to stop attackers from monetizing. For instance, accounts suspected of having\\nbeen compromised can be invalidated, or cashing out gift cards can require addi‐\\ntional authentication steps.\\nThe Upshot\\nThe motivations of cyber attackers are complex and the paths to monetization are\\nconvoluted. However, the financial gains from internet attacks can be a powerful\\nmotivator for technically skilled people, especially those in less-wealthy nations and\\n8 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 26}, page_content='communities. As long as computer attacks can continue to generate a non-negligible\\nyield for the perpetrators, they will keep coming.\\nWhat Is Machine Learning?\\nSince the dawn of the technological age, researchers have dreamed of teaching com‐\\nputers to reason and make “intelligent” decisions in the way that humans do, by\\ndrawing generalizations and distilling concepts from complex information sets\\nwithout explicit instructions.\\nMachine learning refers to one aspect of this goal—specifically, to algorithms and\\nprocesses that “learn” in the sense of being able to generalize past data and experien‐\\nces in order to predict future outcomes. At its core, machine learning is a set of math‐\\nematical techniques, implemented on computer systems, that enables a process of\\ninformation mining, pattern discovery, and drawing inferences from data.\\nAt the most general level, supervised machine learning methods adopt a Bayesian\\napproach to knowledge discovery, using probabilities of previously observed events\\nto infer the probabilities of new events. Unsupervised methods draw abstractions\\nfrom unlabeled datasets and apply these to new data. Both families of methods can be\\napplied to problems of classiication (assigning observations to categories) or regres‐\\nsion (predicting numerical properties of an observation).\\nSuppose that we want to classify a group of animals into mammals and reptiles. With\\na supervised method, we will have a set of animals for which we are definitively told\\ntheir category (e.g., we are told that the dog and elephant are mammals and the alli‐\\ngator and iguana are reptiles). We then try to extract some features from each of these\\nlabeled data points and find similarities in their properties, allowing us to differenti‐\\nate animals of different classes. For instance, we see that the dog and the elephant\\nboth give birth to live offspring, unlike the alligator and the iguana. The binary prop‐\\nerty “gives birth to live offspring” is what we call a feature, a useful abstraction for\\nobserved properties that allows us to perform comparisons between different obser‐\\nvations. After extracting a set of features that might help differentiate mammals and\\nreptiles in the labeled data, we then can run a learning algorithm on the labeled data\\nand apply what the algorithm learned to new, unseen animals. When the algorithm is\\npresented with a meerkat, it now must classify it as either a mammal or a reptile.\\nExtracting the set of features from this new animal, the algorithm knows that the\\nmeerkat does not lay eggs, has no scales, and is warm-blooded. Driven by prior obser‐\\nvations, it makes a category prediction that the meerkat is a mammal, and it is exactly\\nright.\\nIn the unsupervised case, the premise is similar, but the algorithm is not presented\\nwith the initial set of labeled animals. Instead, the algorithm must group the different\\nsets of data points in a way that will result in a binary classification. Seeing that most\\nWhat Is Machine Learning? \\n| \\n9'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 27}, page_content='animals that don’t have scales do give birth to live offspring and are also warm-\\nblooded, and most animals that have scales lay eggs and are cold-blooded, the algo‐\\nrithm can then derive the two categories from the provided set and make future\\npredictions in the same way as in the supervised case.\\nMachine learning algorithms are driven by mathematics and statistics, and the algo‐\\nrithms that discover patterns, correlations, and anomalies in the data vary widely in\\ncomplexity. In the coming chapters, we go deeper into the mechanics of some of the\\nmost common machine learning algorithms used in this book. This book will not\\ngive you a complete understanding of machine learning, nor will it cover much of the\\nmathematics and theory in the subject. What it will give you is critical intuition in\\nmachine learning and practical skills for designing and implementing intelligent,\\nadaptive systems in the context of security.\\nWhat Machine Learning Is Not\\nArtiicial intelligence (AI) is a popular but loosely defined term that indicates algorith‐\\nmic solutions to complex problems typically solved by humans. As illustrated in\\nFigure 1-2, machine learning is a core building block for AI. For example, self-driving\\ncars must classify observed images as people, cars, trees, and so on; they must predict\\nthe position and speed of other cars; they must determine how far to rotate the\\nwheels in order to make a turn. These classification and prediction problems are\\nsolved using machine learning, and the self-driving system is a form of AI. There are\\nother parts of the self-driving AI decision engine that are hardcoded into rule\\nengines, and that would not be considered machine learning. Machine learning helps\\nus create AI, but is not the only way to achieve it.\\nFigure 1-2. Artiicial intelligence as it relates to machine learning and deep learning\\n10 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 28}, page_content='Deep learning is another popular term that is commonly conflated with machine\\nlearning. Deep learning is a strict subset of machine learning referring to a specific\\nclass of multilayered models that use layers of simpler statistical components to learn\\nrepresentations of data. “Neural network” is a more general term for this type of lay‐\\nered statistical learning architecture that might or might not be “deep” (i.e., have\\nmany layers). For an excellent discussion of this topic, see Deep Learning by Ian\\nGoodfellow, Yoshua Bengio, and Aaron Courville (MIT Press).\\nStatistical analysis is a core part of machine learning: outputs of machine learning\\nalgorithms are often presented in terms of probabilities and confidence intervals. We\\nwill touch on some statistical techniques in our discussion of anomaly detection, but\\nwe will leave aside questions regarding experimentation and statistical hypothesis\\ntesting. For an excellent discussion of this topic, see Probability & Statistics for Engi‐\\nneers & Scientists by Ronald Walpole et al. (Prentice Hall).\\nWhat Is AI?\\nThe definition of AI is a slightly more contentious topic than the definition of\\nmachine learning. Machine learning refers to statistical learning algorithms that are\\nable to create generalizable abstractions (models) by seeing and dissecting a dataset.\\nAI systems have been loosely defined to be machine-driven decision engines that can\\nachieve near-human-level intelligence. How near does this intelligence have to be to\\nhuman intelligence before we consider it to be AI? As you might imagine, differing\\nexpectations and definitions of the term make it quite difficult to draw universally\\nagreeable boundaries around this.\\nAdversaries Using Machine Learning\\nNote that nothing prevents adversaries from taking advantage of machine learning to\\navoid detection and evade defenses. As much as the defenders can learn from the\\nattacks and adjust their countermeasures accordingly, attackers can also learn the\\nnature of defenses to their own benefit. Spammers have been known to apply poly‐\\nmorphism (i.e., changing the appearance of content without changing its meaning) to\\ntheir payloads to circumvent detection, or to probe spam filters by performing A/B\\ntests on email content and learning what causes their click-through rates to rise and\\nfall. Both good guys and bad guys use machine learning in fuzzing campaigns to\\nspeed up the process of finding vulnerabilities in software. Adversaries can even use\\nmachine learning to learn about your personality and interests through social media\\nin order to craft the perfect phishing message for you.\\nFinally, the use of dynamic and adaptive methods in the area of security always con‐\\ntains a certain degree of risk. Especially when explainability of machine learning pre‐\\ndictions is often lacking, attackers have been known to cause various algorithms to\\nWhat Is Machine Learning? \\n| \\n11'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 29}, page_content='4 Ling Huang et al., “Adversarial Machine Learning,” Proceedings of the 4th ACM Workshop on Artiicial Intelli‐\\ngence and Security (2011): 43–58.\\nmake erroneous predictions or learn the wrong thing.4 In this growing field of study\\ncalled adversarial machine learning, attackers with varying degrees of access to a\\nmachine learning system can execute a range of attacks to achieve their ends. Chap‐\\nter 8 is dedicated to this topic, and paints a more complete picture of the problems\\nand solutions in this space.\\nMachine learning algorithms are often not designed with security in mind, and are\\noften vulnerable in the face of attempts made by a motivated adversary. Hence, it is\\nimportant to maintain an awareness of such threat models when designing and build‐\\ning machine learning systems for security purposes.\\nReal-World Uses of Machine Learning in Security\\nIn this book, we explore a range of different computer security applications for which\\nmachine learning has shown promising results. Applying machine learning and data\\nscience to solve problems is not a straightforward task. Although convenient pro‐\\ngramming libraries remove some complexity from the equation, developers still need\\nto make many decisions along the way.\\nBy going through different examples in each chapter, we will explore the most com‐\\nmon issues faced by practitioners when designing machine learning systems, whether\\nin security or otherwise. The applications described in this book are not new, and you\\nalso can find the data science techniques we discuss at the core of many computer\\nsystems that you might interact with on a daily basis.\\nWe can classify machine learning’s use cases in security into two broad categories: \\npattern recognition and anomaly detection. The line differentiating pattern recognition\\nand anomaly detection is sometimes blurry, but each task has a clearly distinguished\\ngoal. In pattern recognition, we try to discover explicit or latent characteristics hid‐\\nden in the data. These characteristics, when distilled into feature sets, can be used to\\nteach an algorithm to recognize other forms of the data that exhibit the same set of\\ncharacteristics. Anomaly detection approaches knowledge discovery from the other\\nside of the same coin. Instead of learning specific patterns that exist within certain\\nsubsets of the data, the goal is to establish a notion of normality that describes most\\n(say, more than 95%) of a given dataset. Thereafter, deviations from this normality of\\nany sort will be detected as anomalies.\\nIt is common to erroneously think of anomaly detection as the process of recognizing\\na set of normal patterns and differentiating it from a set of abnormal patterns. Pat‐\\nterns extracted through pattern recognition must be strictly derived from the\\nobserved data used to train the algorithm. On the other hand, in anomaly detection\\n12 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 30}, page_content='there can be an infinite number of anomalous patterns that fit the bill of an outlier,\\neven those derived from hypothetical data that do not exist in the training or testing\\ndatasets.\\nSpam detection is perhaps the classic example of pattern recognition because spam\\ntypically has a largely predictable set of characteristics, and an algorithm can be\\ntrained to recognize those characteristics as a pattern by which to classify emails. Yet\\nit is also possible to think of spam detection as an anomaly detection problem. If it is\\npossible to derive a set of features that describes normal traffic well enough to treat\\nsignificant deviations from this normality as spam, we have succeeded. In actuality,\\nhowever, spam detection might not be suitable for the anomaly detection paradigm,\\nbecause it is not difficult to convince yourself that it is in most contexts easier to find\\nsimilarities between spam messages than within the broad set of normal traffic.\\nMalware detection and botnet detection are other applications that fall clearly in the\\ncategory of pattern recognition, where machine learning becomes especially useful\\nwhen the attackers employ polymorphism to avoid detection. Fuzzing is the process\\nof throwing arbitrary inputs at a piece of software to force the application into an\\nunintended state, most commonly to force a program to crash or be put into a vul‐\\nnerable mode for further exploitation. Naive fuzzing campaigns often run into the\\nproblem of having to iterate over an intractably large application state space. The\\nmost widely used fuzzing software has optimizations that make fuzzing much more\\nefficient than blind iteration. Machine learning has also been used in such optimiza‐\\ntions, by learning patterns of previously found vulnerabilities in similar programs\\nand guiding the fuzzer to similarly vulnerable code paths or idioms for potentially\\nquicker results.\\nFor user authentication and behavior analysis, the delineation between pattern recog‐\\nnition and anomaly detection becomes less clear. For cases in which the threat model\\nis clearly known, it might be more suitable to approach the problem through the lens\\nof pattern recognition. In other cases, anomaly detection can be the answer. In many\\ncases, a system might make use of both approaches to achieve better coverage. Net‐\\nwork outlier detection is a classic example of anomaly detection because most net‐\\nwork traffic follows strict protocols and normal behavior matches a set of patterns in\\nform or sequence. Any malicious network activity that does not manage to masquer‐\\nade well by mimicking normal traffic will be caught by outlier detection algorithms.\\nOther network-related detection problems, such as malicious URL detection, can also\\nbe approached from the angle of anomaly detection.\\nAccess control refers to any set of policies governing the ability of system users to\\naccess certain pieces of information. Frequently used to protect sensitive information\\nfrom unnecessary exposure, access control policies are often the first line of defense\\nagainst breaches and information theft. Machine learning has gradually found its way\\ninto access control solutions because of the pains experienced by system users at the\\nReal-World Uses of Machine Learning in Security \\n| \\n13'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 31}, page_content='5 Evan Martin and Tao Xie, “Inferring Access-Control Policy Properties via Machine Learning,” Proceedings of\\nthe 7th IEEE International Workshop on Policies for Distributed Systems and Networks (2006): 235–238.\\n6 In real life, you will spend a large proportion of your time cleaning the data in order to make it available to\\nand useful for your algorithms.\\nmercy of rigid and unforgiving access control policies.5 Through a combination of\\nunsupervised learning and anomaly detection, such systems can infer information\\naccess patterns for certain users or roles in an organization and engage in retaliatory\\naction when an unconventional pattern is detected.\\nImagine, for example, a hospital’s patient record storage system, where nurses and\\nmedical technicians frequently need to access individual patient data but don’t neces‐\\nsarily need to do cross-patient correlations. Doctors, on the other hand, frequently\\nquery and aggregate the medical records of multiple patients to look for case similari‐\\nties and diagnostic histories. We don’t necessarily want to prevent nurses and medical\\ntechnicians from querying multiple patient records because there might be rare cases\\nthat warrant such actions. A strict rule-based access control system would not be able\\nto provide the flexibility and adaptability that machine learning systems can provide.\\nIn the rest of this book, we dive deeper into a selection of these real-world applica‐\\ntions. We then will be able to discuss the nuances around applying machine learning\\nfor pattern recognition and anomaly detection in security. In the remainder of this\\nchapter, we focus on the example of spam fighting as one that illustrates the core\\nprinciples used in any application of machine learning to security.\\nSpam Fighting: An Iterative Approach\\nAs discussed earlier, the example of spam fighting is both one of the oldest problems\\nin computer security and one that has been successfully attacked with machine learn‐\\ning. In this section, we dive deep into this topic and show how to gradually build up a\\nsophisticated spam classification system using machine learning. The approach we\\ntake here will generalize to many other types of security problems, including but not\\nlimited to those discussed in later chapters of this book.\\nConsider a scenario in which you are asked to solve the problem of rampant email\\nspam affecting employees in an organization. For whatever reason, you are instructed\\nto develop a custom solution instead of using commercial options. Provided with\\nadministrator access to the private email servers, you are able to extract a body of\\nemails for analysis. All the emails are properly tagged by recipients as either “spam”\\nor “ham” (non-spam), so you don’t need to spend too much time cleaning the data.6\\nHuman beings do a good job at recognizing spam, so you begin by implementing a\\nsimple solution that approximates a person’s thought process while executing this\\ntask. Your theory is that the presence or absence of some prominent keywords in an\\n14 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 32}, page_content=\"7 This validation process, sometimes referred to as conventional validation, is not as rigorous a validation\\nmethod as cross-validation, which refers to a class of methods that repeatedly generate all (or many) different\\npossible splits of the dataset (into training and testing sets), performing validation of the machine learning\\nprediction algorithm separately on each of these. The result of cross-validation is the average prediction accu‐\\nracy across these different splits. Cross-validation estimates model accuracy better than conventional valida‐\\ntion because it avoids the pitfall of information loss from a single train/test split that might not adequately\\ncapture the statistical properties of the data (this is typically not a concern if the training set is sufficiently\\nlarge). Here we chose to use conventional validation for simplicity.\\n8 These helper functions are defined in the file chapter1/email_read_util.py in our code repository.\\n9 To run this code, you need to install the Punkt Tokenizer Models and the stopwords corpus in NLTK using\\nthe nltk.download() utility.\\nemail is a strong binary indicator of whether the email is spam or ham. For instance,\\nyou notice that the word “lottery” appears in the spam data a lot, but seldom appears\\nin regular emails. Perhaps you could come up with a list of similar words and per‐\\nform the classification by checking whether a piece of email contains any words that\\nbelong to this blacklist.\\nThe dataset that we will use to explore this problem is the 2007 TREC Public Spam\\nCorpus. This is a lightly cleaned raw email message corpus containing 75,419 mes‐\\nsages collected from an email server over a three-month period in 2007. One-third of\\nthe dataset is made up of spam examples, and the rest is ham. This dataset was cre‐\\nated by the Text REtrieval Conference (TREC) Spam Track in 2007, as part of an\\neffort to push the boundaries of state-of-the-art spam detection.\\nFor evaluating how well different approaches work, we will go through a simple vali‐\\ndation process.7 We split the dataset into nonoverlapping training and test sets, in\\nwhich the training set consists of 70% of the data (an arbitrarily chosen proportion)\\nand the test set consists of the remaining 30%. This method is standard practice for\\nassessing how well an algorithm or model developed on the basis of the training set\\nwill generalize to an independent dataset.\\nThe first step is to use the Natural Language Toolkit (NLTK) to remove morphologi‐\\ncal affixes from words for more flexible matching (a process called stemming). For\\ninstance, this would reduce the words “congratulations” and “congrats” to the same\\nstem word, “congrat.” We also remove stopwords (e.g., “the,” “is,” and “are,”) before the\\ntoken extraction process, because they typically do not contain much meaning. We\\ndefine a set of functions8 to help with loading and preprocessing the data and labels,\\nas demonstrated in the following code:9\\nimport string\\nimport email\\nimport nltk\\npunctuations = list(string.punctuation)\\nstopwords = set(nltk.corpus.stopwords.words('english'))\\nSpam Fighting: An Iterative Approach \\n| \\n15\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 33}, page_content='stemmer = nltk.PorterStemmer()\\n# Combine the different parts of the email into a flat list of strings\\ndef flatten_to_string(parts):\\n    ret = []\\n    if type(parts) == str:\\n        ret.append(parts)\\n    elif type(parts) == list:\\n        for part in parts:\\n            ret += flatten_to_string(part)\\n    elif parts.get_content_type == \\'text/plain\\':\\n        ret += parts.get_payload()\\n    return ret\\n# Extract subject and body text from a single email file\\ndef extract_email_text(path):\\n    # Load a single email from an input file\\n    with open(path, errors=\\'ignore\\') as f:\\n        msg = email.message_from_file(f)\\n    if not msg:\\n        return \"\"\\n    # Read the email subject\\n    subject = msg[\\'Subject\\']\\n    if not subject:\\n        subject = \"\"\\n    # Read the email body\\n    body = \\' \\'.join(m for m in flatten_to_string(msg.get_payload())\\n                    if type(m) == str)\\n    if not body:\\n        body = \"\"\\n    return subject + \\' \\' + body\\n# Process a single email file into stemmed tokens\\ndef load(path):\\n    email_text = extract_email_text(path)\\n    if not email_text:\\n        return []\\n    # Tokenize the message\\n    tokens = nltk.word_tokenize(email_text)\\n    # Remove punctuation from tokens\\n    tokens = [i.strip(\"\".join(punctuations)) for i in tokens\\n              if i not in punctuations]\\n    # Remove stopwords and stem tokens\\n    if len(tokens) > 2:\\n        return [stemmer.stem(w) for w in tokens if w not in stopwords]\\n    return []\\n16 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 34}, page_content=\"10 This example can be found in the Python Jupyter notebook chapter1/spam-ighting-blacklist.ipynb in our code\\nrepository.\\nNext, we proceed with loading the emails and labels. This dataset provides each email\\nin its own individual file (inmail.1, inmail.2, inmail.3, …), along with a single label file\\n(full/index) in the following format:\\nspam   ../data/inmail.1\\nham    ../data/inmail.2\\nspam   ../data/inmail.3\\n...\\nEach line in the label file contains the “spam” or “ham” label for each email sample in\\nthe dataset. Let’s read the dataset and build a blacklist of spam words now:10\\nimport os\\nDATA_DIR = 'datasets/trec07p/data/'\\nLABELS_FILE = 'datasets/trec07p/full/index'\\nTRAINING_SET_RATIO = 0.7\\nlabels = {}\\nspam_words = set()\\nham_words = set()\\n# Read the labels\\nwith open(LABELS_FILE) as f:\\n    for line in f:\\n        line = line.strip()\\n        label, key = line.split()\\n        labels[key.split('/')[-1]] = 1 if label.lower() == 'ham' else 0\\n# Split corpus into training and test sets\\nfilelist = os.listdir(DATA_DIR)\\nX_train = filelist[:int(len(filelist)*TRAINING_SET_RATIO)]\\nX_test = filelist[int(len(filelist)*TRAINING_SET_RATIO):]\\nfor filename in X_train:\\n    path = os.path.join(DATA_DIR, filename)\\n    if filename in labels:\\n        label = labels[filename]\\n        stems = load(path)\\n        if not stems:\\n            continue\\n        if label == 1:\\n            ham_words.update(stems)\\n        elif label == 0:\\n            spam_words.update(stems)\\n        else:\\n            continue\\nSpam Fighting: An Iterative Approach \\n| \\n17\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 35}, page_content='blacklist = spam_words - ham_words\\nUpon inspection of the tokens in blacklist, you might feel that many of the words\\nare nonsensical (e.g., Unicode, URLs, filenames, symbols, foreign words). You can\\nremedy this problem with a more thorough data-cleaning process, but these simple\\nresults should perform adequately for the purposes of this experiment:\\ngreenback, gonorrhea, lecher, ...\\nEvaluating our methodology on the 22,626 emails in the testing set, we realize that\\nthis simplistic algorithm does not do as well as we had hoped. We report the results in\\na confusion matrix, a 2 × 2 matrix that gives the number of examples with given pre‐\\ndicted and actual labels for each of the four possible pairs:\\nPredicted HAM\\nPredicted SPAM\\nActual HAM\\n6,772\\n714\\nActual SPAM\\n5,835\\n7,543\\nTrue positive: predicted spam + actual ham\\nTrue negative: predicted ham + actual ham\\nFalse positive: predicted spam + actual ham\\nFalse negative: predicted ham + actual spam\\nConverting this to percentages, we get the following:\\nPredicted HAM\\nPredicted SPAM\\nActual HAM\\n32.5%\\n3.4%\\nActual SPAM\\n28.0%\\n36.2%\\nClassiication accuracy: 68.7%\\nIgnoring the fact that 5.8% of emails were not classified because of preprocessing\\nerrors, we see that the performance of this naive algorithm is actually quite fair. Our\\nspam blacklist technique has a 68.7% classification accuracy (i.e., total proportion of\\ncorrect labels). However, the blacklist doesn’t include many words that spam emails\\nuse, because they are also frequently found in legitimate emails. It also seems like an\\nimpossible task to maintain a constantly updated set of words that can cleanly divide\\nspam and ham. Maybe it’s time to go back to the drawing board.\\nNext, you remember reading that one of the popular ways that email providers fought\\nspam in the early days was to perform fuzzy hashing on spam messages and filter\\nemails that produced a similar hash. This is a type of collaborative iltering that relies\\non the wisdom of other users on the platform to build up a collective intelligence that\\n18 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 36}, page_content='11 See Chapter 3 in Mining of Massive Datasets, 2nd ed., by Jure Leskovec, Anand Rajaraman, and Jeffrey David\\nUllman (Cambridge University Press).\\n12 This example can be found in the Python Jupyter notebook chapter1/spam-ighting-lsh.ipynb in our code\\nrepository.\\n13 Note that we specified the MinHashLSH object’s threshold parameter as 0.5. This particular LSH implementa‐\\ntion uses Jaccard similarities between the MinHashes in your collection and the query MinHash, returning\\nthe list of objects that satisfy the threshold condition (i.e., Jaccard similarity score > 0.5). The MinHash algo‐\\nrithm generates short and unique signatures for a string by passing random permutations of the string\\nthrough a hash function. Configuring the num_perm parameter to 128 means that 128 random permutations of\\nthe string were computed and passed through the hash function. In general, the more random permutations\\nused in the algorithm, the higher the accuracy of the hash.\\nwill hopefully generalize well and identify new incoming spam. The hypothesis is that\\nspammers use some automation in crafting spam, and hence produce spam messages\\nthat are only slight variations of one another. A fuzzy hashing algorithm, or more\\nspecifically, a locality-sensitive hash (LSH), can allow you to find approximate matches\\nof emails that have been marked as spam.\\nUpon doing some research, you come across datasketch, a comprehensive Python\\npackage that has efficient implementations of the MinHash + LSH algorithm11 to per‐\\nform string matching with sublinear query costs (with respect to the cardinality of the\\nspam set). MinHash converts string token sets to short signatures while preserving\\nqualities of the original input that enable similarity matching. LSH can then be\\napplied on MinHash signatures instead of raw tokens, greatly improving perfor‐\\nmance. MinHash trades the performance gains for some loss in accuracy, so there will\\nbe some false positives and false negatives in your result. However, performing naive\\nfuzzy string matching on every email message against the full set of n spam messages\\nin your training set incurs either O(n) query complexity (if you scan your corpus\\neach time) or O(n) memory (if you build a hash table of your corpus), and you decide\\nthat you can deal with this trade-off:12,13\\nfrom datasketch import MinHash, MinHashLSH\\n# Extract only spam files for inserting into the LSH matcher\\nspam_files = [x for x in X_train if labels[x] == 0]\\n# Initialize MinHashLSH matcher with a Jaccard\\n# threshold of 0.5 and 128 MinHash permutation functions\\nlsh = MinHashLSH(threshold=0.5, num_perm=128)\\n# Populate the LSH matcher with training spam MinHashes\\nfor idx, f in enumerate(spam_files):\\n    minhash = MinHash(num_perm=128)\\n    stems = load(os.path.join(DATA_DIR, f))\\n    if len(stems) &lt; 2: continue\\n    for s in stems:\\nSpam Fighting: An Iterative Approach \\n| \\n19'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 37}, page_content=\"minhash.update(s.encode('utf-8'))\\n    lsh.insert(f, minhash)\\nNow it’s time to have the LSH matcher predict labels for the test set:\\ndef lsh_predict_label(stems):\\n    '''\\n    Queries the LSH matcher and returns:\\n        0 if predicted spam\\n        1 if predicted ham\\n       −1 if parsing error\\n    '''\\n    minhash = MinHash(num_perm=128)\\n    if len(stems) < 2:\\n        return −1\\n    for s in stems:\\n        minhash.update(s.encode('utf-8'))\\n    matches = lsh.query(minhash)\\n    if matches:\\n        return 0\\n    else:\\n        return 1\\nInspecting the results, you see the following:\\nPredicted HAM\\nPredicted SPAM\\nActual HAM\\n7,350\\n136\\nActual SPAM\\n2,241\\n11,038\\nConverting this to percentages, you get:\\nPredicted HAM\\nPredicted SPAM\\nActual HAM\\n35.4%\\n0.7%\\nActual SPAM\\n10.8%\\n53.2%\\nClassiication accuracy: 88.6%\\nThat’s approximately 20% better than the previous naive blacklisting approach, and\\nsignificantly better with respect to false positives (i.e., predicted spam + actual ham).\\nHowever, these results are still not quite in the same league as modern spam filters.\\nDigging into the data, you realize that it might not be an issue with the algorithm, but\\nwith the nature of the data you have—the spam in your dataset just doesn’t seem all\\nthat repetitive. Email providers are in a much better position to make use of collabo‐\\nrative spam filtering because of the volume and diversity of messages that they see.\\nUnless a spammer were to target a large number of employees in your organization,\\nthere would not be a significant amount of repetition in the spam corpus. You need to\\n20 \\n| \\nChapter 1: Why Machine Learning and Security?\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 38}, page_content=\"14 This example can be found in the Python Jupyter notebook chapter1/spam-ighting-naivebayes.ipynb in our\\ncode repository.\\n15 It is a loose convention in machine learning code to choose lowercase variable names for single columns of\\nvalues and uppercase variable names for multiple columns of values.\\ngo beyond matching stem words and computing Jaccard similarities if you want a\\nbreakthrough.\\nBy this point, you are frustrated with experimentation and decide to do more\\nresearch before proceeding. You see that many others have obtained promising\\nresults using a technique called Naive Bayes classiication. After getting a decent\\nunderstanding of how the algorithm works, you begin to create a prototype solution.\\nScikit-learn provides a surprisingly simple class, sklearn.naive_bayes.Multino\\nmialNB, that you can use to generate quick results for this experiment. You can reuse\\na lot of the earlier code for parsing the email files and preprocessing the labels. How‐\\never, you decide to try passing in the entire email subject and plain text body (separa‐\\nted by a new line) without doing any stopword removal or stemming with NLTK. You\\ndefine a small function to read all the email files into this text form:14,15\\ndef read_email_files():\\n    X = []\\n    y = []\\n    for i in xrange(len(labels)):\\n        filename = 'inmail.' + str(i+1)\\n        email_str = extract_email_text(os.path.join(DATA_DIR, filename))\\n        X.append(email_str)\\n        y.append(labels[filename])\\n    return X, y\\nThen you use the utility function sklearn.model_selection.train_test_split()\\nto randomly split the dataset into training and testing subsets (the argument ran\\ndom_state=123 is passed in for the sake of result reproducibility):\\nfrom sklearn.model_selection import train_test_split\\nX, y = read_email_files()\\nX_train, X_test, y_train, y_test, idx_train, idx_test = \\\\\\n    train_test_split(X, y, range(len(y)),\\n    train_size=TRAINING_SET_RATIO, random_state=2)\\nNow that you have prepared the raw data, you need to do some further processing of\\nthe tokens to convert each email to a vector representation that MultinomialNB\\naccepts as input.\\nOne of the simplest ways to convert a body of text into a feature vector is to use the \\nbag-of-words representation, which goes through the entire corpus of documents and\\ngenerates a vocabulary of tokens used throughout the corpus. Every word in the\\nSpam Fighting: An Iterative Approach \\n| \\n21\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 39}, page_content=\"vocabulary comprises a feature, and each feature value is the count of how many\\ntimes the word appears in the corpus. For example, consider a hypothetical scenario\\nin which you have only three messages in the entire corpus:\\ntokenized_messages: {\\n    'A': ['hello', 'mr', 'bear'],\\n    'B': ['hello', 'hello', 'gunter'],\\n    'C': ['goodbye', 'mr', 'gunter']\\n}\\n# Bag-of-words feature vector column labels:\\n# ['hello', 'mr', 'doggy', 'bear', 'gunter', 'goodbye']\\nvectorized_messages: {\\n    'A': [1,1,0,1,0,0],\\n    'B': [2,0,0,0,1,0],\\n    'C': [0,1,0,0,1,1]\\n}\\nEven though this process discards seemingly important information like the order of\\nwords, content structure, and word similarities, it is very simple to implement using\\nthe sklearn.feature_extraction.CountVectorizer class:\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nvectorizer = CountVectorizer()\\nX_train_vector = vectorizer.fit_transform(X_train)\\nX_test_vector = vectorizer.transform(X_test)\\nYou can also try using the term frequency/inverse document frequency (TF/IDF) vec‐\\ntorizer instead of raw counts. TF/IDF normalizes raw word counts and is in general a\\nbetter indicator of a word’s statistical importance in the text. It is provided as\\nsklearn.feature_extraction.text.TfidfVectorizer.\\nNow you can train and test your multinomial Naive Bayes classifier:\\nfrom sklearn.naive_bayes import MultinomialNB\\nfrom sklearn.metrics import accuracy_score\\n# Initialize the classifier and make label predictions\\nmnb = MultinomialNB()\\nmnb.fit(X_train_vector, y_train)\\ny_pred = mnb.predict(X_test_vector)\\n# Print results\\nprint('Accuracy {:.3f}'.format(accuracy_score(y_test, y_pred)))\\n> Accuracy: 0.956\\n22 \\n| \\nChapter 1: Why Machine Learning and Security?\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 40}, page_content='16 In general, using only accuracy to measure model prediction performance is crude and incomprehensive.\\nModel evaluation is an important topic that we discuss further in Chapter 2. Here we opt for simplicity and\\nuse accuracy as an approximate measure of performance. The sklearn.metrics.classification_report()\\nmethod provides the precision, recall, f1-score, and support for each class, which can be used in combination to\\nget a more accurate picture of how the model performs.\\nAn accuracy of 95.6%—a whole 7% better than the LSH approach!16 That’s not a bad\\nresult for a few lines of code, and it’s in the ballpark of what modern spam filters can\\ndo. Some state-of-the-art spam filters are in fact actually driven by some variant of\\nNaive Bayes classification. In machine learning, combining multiple independent\\nclassifiers and algorithms into an ensemble (also known as stacked generalization or\\nstacking) is a common way of taking advantage of each method’s strengths. So, you\\ncan imagine how a combination of word blacklists, fuzzy hash matching, and a Naive\\nBayes model can help to improve this result.\\nAlas, spam detection in the real world is not as simple as we have made it out to be in\\nthis example. There are many different types of spam, each with a different attack vec‐\\ntor and method of avoiding detection. For instance, some spam messages rely heavily\\non tempting the reader to click links. The email’s content body thus might not con‐\\ntain as much incriminating text as other kinds of spam. This kind of spam then might\\ntry to circumvent link-spam detection classifiers using complex methods like cloak‐\\ning and redirection chains. Other kinds of spam might just rely on images and not\\nrely on text at all.\\nFor now, you are happy with your progress and decide to deploy this solution. As is\\nalways the case when dealing with human adversaries, the spammers will eventually\\nrealize that their emails are no longer getting through and might act to avoid detec‐\\ntion. This response is nothing out of the ordinary for problems in security. You must\\nconstantly improve your detection algorithms and classifiers and stay one step ahead\\nof your adversaries.\\nIn the following chapters, we explore how machine learning methods can help you\\navoid having to be constantly engaged in this whack-a-mole game with attackers, and\\nhow you can create a more adaptive solution to minimize constant manual tweaking.\\nLimitations of Machine Learning in Security\\nThe notion that machine learning methods will always give good results across differ‐\\nent use cases is categorically false. In real-world scenarios there are usually factors to\\noptimize for other than precision, recall, or accuracy.\\nAs an example, explainability of classification results can be more important in some\\napplications than others. It can be considerably more difficult to extract the reasons\\nfor a decision made by a machine learning system compared to a simple rule. Some\\nLimitations of Machine Learning in Security \\n| \\n23'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 41}, page_content='machine learning systems might also be significantly more resource intensive than\\nother alternatives, which can be a dealbreaker for execution in constrained environ‐\\nments such as embedded systems.\\nThere is no silver bullet machine learning algorithm that works well across all prob‐\\nlem spaces. Different algorithms vary vastly in their suitability for different applica‐\\ntions and different datasets. Although machine learning methods contribute to the\\nnotion of artificial intelligence, their capabilities can still only be compared to human\\nintelligence along certain dimensions.\\nThe human decision-making process is informed by a vast body of context drawn\\nfrom cultural and experiential knowledge. This process is very difficult for machine\\nlearning systems to emulate. Take the initial blacklisted-words approach that we used\\nfor spam filtering as an example. When a person evaluates the content of an email to\\ndetermine if it’s ham or spam, the decision-making process is never as simple as look‐\\ning for the existence of certain words. The context in which a blacklisted word is\\nbeing used can result in it being a reasonable inclusion in non-spam email. Also,\\nspammers might use synonyms of blacklisted words in future emails to convey the\\nsame meaning, but a simplistic blacklist would not adapt appropriately. The system\\nsimply doesn’t have the context that a human has—it does not know what relevance a\\nparticular word bears to the reader. Continually updating the blacklist with new sus‐\\npicious words is a laborious process, and in no way guarantees perfect coverage.\\nEven though your machine-learned model may work perfectly on a training set, you\\nmight find that it performs badly on a testing set. A common reason for this problem\\nis that the model has overit its classification boundaries to the training data, learning\\ncharacteristics of the dataset that do not generalize well across other unseen datasets.\\nFor instance, your spam filter might learn from a training set that all emails contain‐\\ning the words “inheritance” and “Nigeria” can immediately be given a high suspicion\\nscore, but it does not know about the legitimate email chain discussion between\\nemployees about estate inheritances in Nigerian agricultural insurance schemes.\\nWith all these limitations in mind, we should approach machine learning with equal\\nparts of enthusiasm and caution, remembering that not everything can instantly be\\nmade better with AI.\\n24 \\n| \\nChapter 1: Why Machine Learning and Security?'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 42}, page_content='CHAPTER 2\\nClassifying and Clustering\\nIn this chapter, we discuss the most useful machine learning techniques for security\\napplications. After covering some of the basic principles of machine learning, we\\noffer up a toolbox of machine learning algorithms that you can choose from when\\napproaching any given security problem. We have tried to include enough detail\\nabout each technique so that you can know when and how to use it, but we do not\\nattempt to cover all the nuances and complexities of the algorithms.\\nThis chapter has more mathematical detail than the rest of the book; if you want to\\nskip the details and begin trying out the techniques, we recommend you read the sec‐\\ntions “Machine Learning in Practice: A Worked Example” on page 27 and “Practical\\nConsiderations in Classification” on page 55 and then look at a few of the most popu‐\\nlar supervised and unsupervised algorithms: logistic regression, decision trees and\\nforests, and k-means clustering.\\nMachine Learning: Problems and Approaches\\nSuppose that you are in charge of computer security for your company. You install\\nfirewalls, hold phishing training, ensure secure coding practices, and much more. But\\nat the end of the day, all your CEO cares about is that you don’t have a breach. So, you\\ntake it upon yourself to build systems that can detect and block malicious traffic to\\nany attack surface. Ultimately, these systems must decide the following:\\n• For every file sent through the network, does it contain malware?\\n• For every login attempt, has someone’s password been compromised?\\n• For every email received, is it a phishing attempt?\\n• For every request to your servers, is it a denial-of-service (DoS) attack?\\n25'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 43}, page_content='1 Simple algorithms like this one are usually called “rules.”\\n• For every outbound request from your network, is it a bot calling its command-\\nand-control server?\\nThese tasks are all classiication tasks—binary decisions about the nature of the\\nobserved event.\\nYour job can thus be rephrased as follows:\\nClassify all events in your network as malicious or legitimate.\\nWhen phrased in this manner, the task seems almost hopeless; how are you supposed\\nto classify all traffic? But not to fear! You have a secret weapon: data.\\nSpecifically, you have historical logs of binary files, login attempts, emails received,\\nand inbound and outbound requests. In some cases, you might even know of attacks\\nin the past and be able to associate these attacks with the corresponding events in\\nyour logs. Now, to begin solving your problem, you look for patterns in the past data\\nthat seem to indicate malicious attacks. For example, you observe that when a single\\nIP address is making more than 20 requests per second to your servers over a period\\nof 5 minutes, it’s probably a DoS attack. (Maybe your servers went down under such a\\nload in the past.)\\nAfter you have found patterns in the data, the next step is to encode these patterns as\\nan algorithm—that is, a function that takes as input data about whatever you’re trying\\nto classify and outputs a binary response: “malicious” or “legitimate.” In our example,\\nthis algorithm would be very simple:1 it takes as input the number of requests from an\\nIP address over the 5 minutes prior to the request, and outputs “legitimate” if the\\nnumber is less than 6,000 and “malicious” if it is greater than 6,000.\\nAt this point, you have learned from the data and created an algorithm to block bad\\ntraffic. Congratulations! But there should be something nagging at you: what’s special\\nabout the number 20? Why isn’t the limit 19 or 21? Or 19.77? Ideally you should have\\nsome principled way of determining which one of these options, or in fact which real\\nnumber, is best. And if you use an algorithm to scan historical data and find the best\\nclassification rule according to some mathematical definition of “best,” this process is\\ncalled machine learning.\\nMore generally, machine learning is the process of using historical data to create a\\nprediction algorithm for future data. The task we just considered was one of classii‐\\ncation: determine which class a new data point (the request) falls into. Classification\\ncan be binary, as we just saw, in which there are only two classes, or multiclass; for\\nexample, if you want to determine whether a piece of malware is ransomware, a key‐\\nlogger, or a remote access trojan.\\n26 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 44}, page_content='2 You can find the dataset in chapter2/datasets/payment_fraud.csv in our code repository.\\nMachine learning can also be used to solve regression problems, in which we try to\\npredict the value of a real-number variable. For example, you might want to predict\\nthe number of phishing emails an employee receives in a given month, given data\\nabout their position, access privileges, tenure in the company, security hygiene score,\\nand so on. Regression problems for which the inputs have a time dimension are\\nsometimes called time series analysis; for example, predicting the value of a stock\\ntomorrow given its past performance, or the number of account sign-ins from the\\nSeattle office given a known history. Anomaly detection is a layer on top of regression:\\nit refers to the problem of determining when an observed value is sufficiently differ‐\\nent from a predicted value to indicate that something unusual is going on.\\nMachine learning is also used to solve clustering problems: given a bunch of data\\npoints, which ones are similar to one another? For example, if you are trying to ana‐\\nlyze a large dataset of internet traffic to your site, you might want to know which\\nrequests group together. Some clusters might be botnets, some might be mobile pro‐\\nviders, and some might be legitimate users.\\nMachine learning can be supervised, in which case you have labels on historical data\\nand you are trying to predict labels on future data. For example, given a large corpus\\nof emails labeled as spam or ham, you can train a spam classifier that tries to predict\\nwhether a new incoming message is spam. Alternatively, machine learning can be\\nunsupervised, in which case you have no labels on the historical data; you might not\\neven know what the labels are that you’re trying to predict, for example if you have an\\nunknown number of botnets attacking your network that you want to disambiguate\\nfrom one another. Classification and regression tasks are examples of supervised\\nlearning, and clustering is a typical form of unsupervised learning.\\nMachine Learning in Practice: A Worked Example\\nAs we said earlier, machine learning is the process of using historical data to come up\\nwith a prediction algorithm for previously unseen data. Let’s examine how this pro‐\\ncess works, using a simple dataset as an example. The dataset that we are using is\\ntransaction data for online purchases collected from an ecommerce retailer.2 The\\ndataset contains 39,221 transactions, each comprising 5 properties that can be used to\\ndescribe the transaction, as well as a binary “label” indicating whether this transac‐\\ntion is an instance of fraud—“1” if fraudulent, and “0” if not. The comma-separated\\nvalues (CSV) format that this data is in is a standard way of representing data for ana‐\\nlytics. Observing that the first row in the file indicates the names for each positional\\nvalue in each subsequent line, let’s consider what each value means by examining a\\nrandomly selected row of data:\\nMachine Learning in Practice: A Worked Example \\n| \\n27'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 45}, page_content='accountAgeDays,numItems,localTime,paymentMethod,paymentMethodAgeDays,label\\n...\\n196, 1, 4.962055, creditcard, 5.10625, 0\\nPutting this in a more human-readable form:\\naccountAgeDays:       196\\nnumItems:             1\\nlocalTime:            4.962055\\npaymentMethod:        creditcard\\npaymentMethodAgeDays: 5.10625\\nlabel:                0\\nWe see that this transaction was made through a user account that was created 196\\ndays ago (accountAgeDays), and that the user purchased 1 item (numItems) at around\\n4:58 AM in the consumer’s local time (localTime). Payment was made through credit\\ncard (paymentMethod), and this method of payment was added about 5 days before\\nthe transaction (paymentMethodAgeDays). The label is 0, which indicates that this\\ntransaction is not fraudulent.\\nNow, you might ask how we came to learn that a certain transaction was fraudulent.\\nIf someone made an unauthorized transaction using your credit card, assuming that\\nyou were vigilant, you would file a chargeback for this transaction, indicating that the\\ntransaction was not made by you and you want to get your money back. Similar pro‐\\ncesses exist for payments made through other payment methods, such as PayPal or\\nstore credit. The chargeback is a strong and clear indication that the transaction is\\nfraudulent, allowing us to collect data about fraudulent transactions.\\nHowever, the reason we can’t use chargeback data in real time is that merchants\\nreceive chargeback details many months after the transaction has gone through—\\nafter they have shipped the items out to the attackers, never to be seen again. Typi‐\\ncally, the retailer absorbs all losses in situations like this, which could translate to\\npotentially enormous losses in revenue. This financial loss could be mitigated if we\\nhad a way to predict how likely a transaction is to be fraudulent before we ship the\\nitems out. Now, we could examine the data and come up with some rules, such as “If\\nthe payment method was added in the last day and the number of items is at least 10,\\nthe transaction is fraudulent.” But such a rule might have too many false positives.\\nHow can we use data to find the best prediction algorithm? This is what machine\\nlearning does.\\nEach property of a transaction is called a feature in machine learning parlance. What\\nwe want to achieve is to have a machine learning algorithm learn how to identify a\\nfraudulent transaction from the five features in our dataset. Because the dataset con‐\\ntains a label for what we are aiming to predict, we call this a “labeled dataset” and can\\nperform supervised learning on it. (If there had been no label, we could only have\\nperformed semi-supervised learning or unsupervised learning.) The ideal fraud\\ndetection system will take in features of a transaction and return a probability score\\n28 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 46}, page_content=\"3 For more information on Pandas DataFrames, see the documentation.\\n4 This is not true for all machine learning algorithms. For example, decision trees do not require any or all fea‐\\ntures to be numeric. The advantage of expressing features in numeric terms is that each data point can be\\nexpressed as a vector in a real vector space, and we can apply all the techniques of linear algebra and multi‐\\nvariable calculus to the problem.\\n5 Typically, we’ll set the pd.get_dummies() argument drop_first to True to avoid the so-called “dummy vari‐\\nable trap,” in which independent variables being closely correlated violates assumptions of independence in\\nregression. We chose to keep things simple to avoid confusion, but elaborate on this problem in Chapter 5.\\nfor how likely this transaction is to be fraudulent. Let’s see how we can create a proto‐\\ntype system by using machine learning.\\nSimilar to how we approached the spam classification problem in Chapter 1, we’ll\\ntake advantage of the functionality in the Python machine learning library scikit-\\nlearn. In addition, we’ll use Pandas, a popular data analysis library for Python, to per‐\\nform some lightweight data wrangling. First, we’ll use the pandas.read_csv() utility\\nto read the dataset in the CSV file:\\nimport pandas as pd\\ndf = pd.read_csv('ch1/payment_fraud.csv')\\nNotice that the result of read_csv() is stored into the variable df, short for Data‐\\nFrame. A DataFrame is a Pandas data structure that represents datasets in a two-\\ndimensional table-like form, allowing for operations to be applied on rows or\\ncolumns. DataFrame objects allow you to perform a plethora of manipulations on the\\ndata, but we will not dive into the specifics here.3 Let’s use the DataFrame.sample()\\nfunction to retrieve a snippet of three rows from df:\\ndf.sample(3)\\naccountAgeDays\\nnumItems localTime\\npaymentMethod paymentMethodAgeDays\\nlabel\\n31442\\n2000\\n1\\n4.748314\\nstorecredit\\n0.000000\\n0\\n27232\\n1\\n1\\n4.886641\\nstorecredit\\n0.000000\\n1\\n8687\\n878\\n1\\n4.921349\\npaypal\\n0.000000\\n0\\nThis command returns a tabular view of three random rows. The left column indi‐\\ncates the numerical index of each selected row, and the top row indicates the name of\\neach column. Note that one column stands out because it is of non-numerical type:\\npaymentMethod. There are three possible values that this feature takes on in our data‐\\nset: creditcard, paypal, and storecredit. This feature is called a categorical variable\\nbecause it takes on a value indicating the category it belongs to. Many machine learn‐\\ning algorithms require all features to be numeric.4 We can use pandas.get_dummies()\\nto convert variables from categorical to numeric:5\\nMachine Learning in Practice: A Worked Example \\n| \\n29\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 47}, page_content=\"df = pd.get_dummies(df, columns=['paymentMethod'])\\nUpon inspection of the new DataFrame object, we notice that three new columns\\nhave been added to the table—paymentMethod_creditcard, paymentMethod_paypal,\\nand paymentMethod_storecredit:\\ndf.sample(3)\\naccountAgeDays\\n… paymentMethod_creditcard paymentMethod_paypal\\npaymentMethod_storecredit\\n23393\\n57\\n… 1\\n0\\n0\\n3355\\n1,366\\n… 0\\n1\\n0\\n34248\\n19\\n… 1\\n0\\n0\\nEach of these features is a binary feature (i.e., they take on a value of either 0 or 1),\\nand each row has exactly one of these features set to 1, hence the name of this method\\nof categorical variable encoding: one-hot encoding. These variables are called dummy\\nvariables in statistics terminology.\\nNow, we can divide the dataset into training and test sets (as we did in Chapter 1):\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(\\n    df.drop('label', axis=1), df['label'],\\n    test_size=0.33, random_state=17)\\nThe sklearn.model_selection.train_test_split() function helps us split our\\ndataset into training and test sets. Notice that in the first argument to the function, we\\npassed in df.drop('label', axis=1). This will be split into X_train and X_test to\\nthe ratio of 0.67:0.33 because we passed in test_size=0.33, which means that we\\nwant two-thirds of the dataset to be used for training the machine learning algorithm,\\nand the remaining third, the test set, to be used to see how well the algorithm per‐\\nforms. We are dropping the label column from X before splitting it into X_train and\\nX_test, and passing in the label column as y—df['label']. The labels will then be\\nsplit in the same ratio into y_train and y_test.\\nNow let’s apply a standard supervised learning algorithm, logistic regression, to this\\ndata:\\nfrom sklearn.linear_model import LogisticRegression\\nclf = LogisticRegression()\\nclf.fit(X_train, y_train)\\nIn the first line, we import the sklearn.linear_model.LogisticRegression class.\\nThen, in the second line, we initialize the LogisticRegression object by invoking the\\nconstructor. In the third line, we feed X_train and y_train (i.e., the training set) into\\nthe fit() function, resulting in a trained classifier model, which is stored in the clf\\n30 \\n| \\nChapter 2: Classifying and Clustering\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 48}, page_content='6 You can find this example as a Python Jupyter notebook in our repo at chapter2/logistic-regression-fraud-\\ndetection.ipynb.\\nobject. This classifier has taken the training data and used logistic regression (which\\nwe elaborate on further in the next section) to distill some generalizations about frau‐\\ndulent and nonfraudulent transactions into a model.\\nTo make predictions using this model, all we need to do now is to pass some unla‐\\nbeled features into this classifier object’s predict() function:\\ny_pred = clf.predict(X_test)\\nInspecting y_pred, we can see the label predictions made for each row in X_test.\\nNote that at training time the classifier did not have any access to y_test at all; the\\npredictions made, contained in y_pred, are thus purely a result of the generalizations\\nlearned from the training set. We use the sklearn.metrics.accuracy_score() func‐\\ntion (that we also used in Chapter 1) to get a feel of how good these predictions are:\\nfrom sklearn.metrics import accuracy_score\\nprint(accuracy_score(y_pred, y_test))\\n> 0.99992273816\\nA 99.992% accuracy is pretty good! However, we discussed in Chapter 1 that the\\naccuracy score can often be a misleading oversimplification and is quite a bad metric\\nfor evaluating results like this. Let’s generate a confusion matrix, instead:\\nfrom sklearn.metrics import confusion_matrix\\nprint(confusion_matrix(y_test, y_pred))\\n0\\nPredicted NOT FRAUD Predicted FRAUD\\nActual NOT FRAUD 12,753\\n0\\nActual FRAUD\\n1\\n189\\nThere appears to only be a single misclassification in the entire test set. 189 transac‐\\ntions are correctly flagged as fraud, and there is 1 false negative in which the fraudu‐\\nlent transaction was not detected. There are zero false positives.\\nAs a recap, here is the entire piece of code that we used to train and test our logistic\\nregression payment fraud detection model:6\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score, confusion_matrix\\nMachine Learning in Practice: A Worked Example \\n| \\n31'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 49}, page_content=\"# Read in the data from the CSV file\\ndf = pd.read_csv('ch1/payment_fraud.csv')\\n# Convert categorical feature into dummy variables with one-hot encoding\\ndf = pd.get_dummies(df, columns=['paymentMethod'])\\n# Split dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    df.drop('label', axis=1), df['label'],\\n    test_size=0.33, random_state=17)\\n# Initialize and train classifier model\\nclf = LogisticRegression().fit(X_train, y_train)\\n# Make predictions on test set\\ny_pred = clf.predict(X_test)\\n# Compare test set predictions with ground truth labels\\nprint(accuracy_score(y_pred, y_test))\\nprint(confusion_matrix(y_test, y_pred))\\nWe can apply this model to any given incoming transaction and get a probability\\nscore for how likely this transaction is to be fraudulent:\\nclf.predict_proba(df_real)\\n  # Array that represents the probability of the transaction\\n  # having a label of 0 (in position 0) or 1 (in position 1)\\n> [[  9.99999994e-01   5.87025707e-09]]\\nTaking df_real to be a DataFrame that contains a single row representing an incom‐\\ning transaction received by the online retailer, the classifier predicts that this transac‐\\ntion is 99.9999994% likely to not be fraudulent (remember that y = 0 means not\\nfraudulent).\\nYou might have noticed that all the work of machine learning—i.e., the part where we\\nlearn the prediction algorithm—has been abstracted out into the single scikit-learn\\nAPI call, LogisticRegression.fit(). So, what actually goes on in this black box that\\nallows this model to learn how to predict fraudulent transactions? We will now open\\nup the box and find out.\\nTraining Algorithms to Learn\\nAt its core, a machine learning algorithm takes in a training dataset and outputs a\\nmodel. The model is an algorithm that takes in new data points in the same form as\\nthe training data and outputs a prediction. All machine learning algorithms are\\ndefined by three interdependent components:\\n32 \\n| \\nChapter 2: Classifying and Clustering\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 50}, page_content='7 Technically, a differentiable, oriented surface.\\n• A model family, which describes the universe of models from which we can\\nchoose\\n• A loss function, which allows us to quantitatively compare different models\\n• An optimization procedure, which allows us to choose the best model in the\\nfamily\\nLet’s now consider each of these components.\\nModel Families\\nRecall that we expressed our fraud dataset in terms of seven numerical features: four\\nfeatures from the raw data and three from the one-hot encoding of the payment\\nmethod. We can thus think of each transaction as a point in a seven-dimensional real\\nvector space, and our goal is to divide up the space into areas of fraud and nonfraud\\ntransactions. The “model” output by our machine learning algorithm is a description\\nof this division of the vector space.\\nIn theory, the division of our vector space into fraud and nonfraud areas can be infin‐\\nitely complex; in practice, most algorithms produce a decision boundary, which is a\\nsurface in the vector space.7 One side of the decision boundary consists of the points\\nlabeled as fraud, and the other side consists of the points labeled as nonfraud. The\\nboundary can be as simple as a line (or hyperplane in higher dimensions) or as com‐\\nplex as a union of nonlinear disconnected regions. Figure 2-1 presents some\\nexamples.\\nFigure 2-1. Examples of two-dimensional spaces divided by a decision boundary\\nTraining Algorithms to Learn \\n| \\n33'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 51}, page_content='8 The full background for why this particular function is selected as the hypothesis function for binary logistic\\nregression is slightly more involved, and we will not go into much more detail here. For further details, see\\nsection 4.4 of he Elements of Statistical Learning, 2nd ed., by Trevor Hastie, Robert Tibshirani, and Jerome H.\\nFriedman (Springer).\\nIf we want to be more granular, instead of mapping each point in the vector space to\\neither “fraud” or “nonfraud,” we can map each point to a probability of fraud. In this\\ncase our machine learning algorithm outputs a function that assigns each point in the\\nvector space a value between 0 and 1, to be interpreted in our example as the proba‐\\nbility of fraud.\\nAny given machine learning algorithm restricts itself to finding a certain type of deci‐\\nsion boundary or probability function that can be described by a finite number of\\nmodel parameters. The simplest decision boundary is a linear decision boundary—\\nthat is, a hyperplane in the vector space. An oriented hyperplane H in an n-\\ndimensional vector space can be described by an n-dimensional vector θ orthogonal\\nto the hyperplane, plus another vector β indicating how far the hyperplane is from\\nthe origin:\\nH: θ · x −β = 0\\nThis description allows us to divide the vector space in two; to assign probabilities we\\nwant to look at the distance of the point x from the hyperplane H. We can thus com‐\\npute a real-valued “score”:\\ns x = θ · x −β = θ · x + b\\nwhere we have let b = −θ · β. Our model to compute the score can thus be described\\nby n + 1 model parameters: n parameters to describe the vector θ, and one “offset”\\nparameter b. To turn the score into a classification, we simply choose a threshold t\\nabove which all scores indicate fraud, and below which all scores indicate nonfraud.\\nIf we want to map the real-valued score s x  to a probability, we must apply a function\\nthat maps the real numbers to the interval [0,1]. The standard function to apply is\\nknown as the logistic function or sigmoid function,8 as illustrated in Figure 2-2. It is\\nformulated as:\\nhθ x =\\n1\\n1 + e−θTx\\n34 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 52}, page_content='Figure 2-2. he sigmoid function\\nThe output of the logistic function can be interpreted as a probability, allowing us to\\ndefine the likelihood of the dependent variable taking on a particular value given\\nsome input feature vector x.\\nLoss Functions\\nNow that we have restricted our choice of prediction algorithms to a certain parame‐\\ntrized family, we must choose the best one for the given training data. How do we\\nknow when we have found the best algorithm? We define the best algorithm to be one\\nthat optimizes some quantity computed from the data. This quantity is called an\\nobjective function. In the case of machine learning, the objective function is also\\nknown as a cost function or loss function, because it measures the “cost” of wrong pre‐\\ndictions or the “loss” associated with them.\\nMathematically, a loss function is a function that maps a set of pairs of (predicted\\nlabel, truth label) to a real number. The goal of a machine learning algorithm is to find\\nthe model parameters that produce predicted labels for the training set that minimize\\nthe loss function.\\nIn regression problems, for which the prediction algorithm outputs a real number\\ninstead of a label, the standard loss function is the sum of squared errors. If yi is the\\ntrue value and yi is the predicted value, the loss function is as follows:\\nC Y = ∑\\ni yi −yi\\n2\\nTraining Algorithms to Learn \\n| \\n35'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 53}, page_content='9 A seminal book that defined the field of convex optimization (note that not all optimization problems we\\nspeak of may be convex in nature) is Convex Optimization by Stephen P. Boyd and Lieven Vandenberghe\\n(Cambridge University Press).\\nWe can use this loss function for classification problems as well, where yi is either 0\\nor 1, and yi is the probability estimate output by the algorithm.\\nFor logistic regression, we use negative log likelihood as the loss function. The likeli‐\\nhood of a set of probability predictions pi  for a given set of ground truth labels yi\\nis defined to be the probability that these truth labels would have arisen if sampled\\nfrom a set of binomial distributions according to the probabilities pi . Concretely, if\\nthe truth label yi is 0, the likelihood of 0 is 1 −pi—the probability that 0 would have\\nbeen sampled from a binomial distribution with mean pi. If the truth label yi is 1, the\\nlikelihood is pi.\\nThe likelihood of the entire set of predictions is the product of the individual likeli‐\\nhoods:\\nℒ\\npi , yi\\n= ∏\\nyi = 0 1 −pi · ∏\\nyi = 1 pi\\nThe goal of logistic regression is to find parameters that produce probabilities pi\\nthat maximize the likelihood.\\nTo make computations easier, and, in particular, because most optimization methods\\nrequire computing derivatives of the loss function, we take the negative log of the\\nlikelihood. As maximizing the likelihood is equivalent to minimizing the negative log\\nlikelihood, we call negative log likelihood the loss function:\\nℓpi , yi\\n= −∑\\ni\\n1 −yi log 1 −pi + yi log pi\\nHere we have used the fact that yi is always 0 or 1 to combine the two products into a\\nsingle term.\\nOptimization\\nThe last step in the machine learning procedure is to search for the optimal set of\\nparameters that minimizes the loss function. To carry out this search we use an opti‐\\nmization algorithm. There may be many different optimization algorithms available to\\nyou when fitting your machine learning model.9 Most scikit-learn estimators (e.g.,\\n36 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 54}, page_content='10 Rong-En Fan et al., “LIBLINEAR: A Library for Large Linear Classification,” Journal of Machine Learning\\nResearch 9 (2008): 1871–1874.\\n11 Francis Bach, “Stochastic Optimization: Beyond Stochastic Gradients and Convexity.” INRIA - Ecole Normale\\nSupérieure, Paris, France. Joint tutorial with Suvrit Sra, MIT - NIPS - 2016.\\nLogisticRegression) allow you to specify the numerical solver to use, but what are\\nthe differences between the different options, and how do you go about selecting one?\\nThe job of an optimization algorithm is to minimize (or maximize) an objective func‐\\ntion. In the case of machine learning, the objective function is expressed in terms of\\nthe model’s learnable parameters (θ and b in the previous example), and the goal is to\\nfind the values of θ and b that optimize the objective function.\\nOptimization algorithms mainly come in two different flavors:\\nFirst-order algorithms\\nThese algorithms optimize the objective function using the first derivatives of the\\nfunction with respect to the learnable parameters. Gradient descent methods are\\nthe most popular types of first-order optimization algorithms; we can use them\\nto find the inputs to a function that give the minimum (or maximum) value.\\nComputing the gradient of a function (i.e., the partial derivatives with respect to\\neach variable) allows us to determine the instantaneous direction that the param‐\\neters need to move in order to achieve a more optimal outcome.\\nSecond-order algorithms\\nAs the name suggests, these algorithms use the second derivatives to optimize the\\nobjective function. Second-order algorithms will not fall victim to paths of slow\\nconvergence. For example, second-order algorithms are good at detecting saddle\\npoints, whereas first-order algorithms are likely to become stuck at these points.\\nHowever, second-order methods are often slower and more expensive to\\ncompute.\\nFirst-order methods tend to be much more frequently used because of their relative\\nefficiency. Picking a suitable optimization algorithm depends on the size of the data‐\\nset, the nature of the cost function, the type of learning problem, and speed/resource\\nrequirements for the operation. In addition, some regularization techniques can also\\nhave compatibility issues with certain types of optimizers. First-order algorithms\\ninclude the following:\\n• LIBLINEAR10 is the default solver for the linear estimators in scikit-learn. This\\nalgorithm tends to not do well on larger datasets; as suggested by the scikit-learn\\ndocumentation, the Stochastic Average Gradient (SAG) or SAGA (improvement\\nto SAG) methods work better for large datasets.11\\nTraining Algorithms to Learn \\n| \\n37'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 55}, page_content='12 Stephen Boyd et al., “Distributed Optimization and Statistical Learning via the Alternating Direction Method\\nof Multipliers,” Foundations and Trends in Machine Learning 3 (2011): 1–122.\\nDifferent optimization algorithms deal with multiclass classification differently.\\nLIBLINEAR works only on binary classification. For it to work in a multiclass\\nscenario, it has to use the one-versus-rest scheme; we discuss this scheme more\\nfully in Chapter 5.\\n• Stochastic Gradient Descent (SGD) is a very simple and efficient algorithm for\\noptimization that performs a parameter update for each separate training exam‐\\nple. The stochastic nature of the gradient descent means that the algorithm is\\nmore likely to discover new and possibly better local minima as compared to\\nstandard gradient descent. However, it typically results in high-variance oscilla‐\\ntions, which can result in a delay in convergence. This can be solved with a\\ndecreasing learning rate (i.e., exponentially decrease the learning rate) that results\\nin smaller fluctuations as the algorithm approaches convergence.\\nThe technique called momentum also helps accelerate SGD convergence by navi‐\\ngating the optimization movement only in the relevant directions and softening\\nany movement in irrelevant directions, which stabilizes SGD.\\n• Optimization algorithms such as AdaGrad, AdaDelta, and Adam (Adaptive\\nMoment Estimation) allow for separate and adaptive learning rates for each\\nparameter that solve some problems in the other simpler gradient descent algo‐\\nrithms.\\n• When your training dataset is large, you will need to use a distributed optimiza‐\\ntion algorithm. One popular algorithm is the Alternating Direction Method of\\nMultipliers (ADMM).12\\nExample: Gradient descent\\nTo conclude this section, we go briefly into the details of gradient descent, a powerful\\noptimization algorithm that has been applied to many different machine learning\\nproblems.\\nThe standard algorithm for gradient descent is as follows:\\n1. Select random starting parameters for the machine learning model. In the case of\\na linear model, this means selecting a random normal vector θ and offset β,\\nwhich results in a random hyperplane in n-dimensional space.\\n2. Compute the value of the gradient of the loss function for this model at the point\\ndescribed by these parameters.\\n38 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 56}, page_content='3. Change the model parameters in the direction of greatest gradient decrease by a\\ncertain small magnitude, typically referred to as the α or learning rate.\\n4. Iterate: repeat steps 2 and 3 until convergence or a satisfactory optimization result\\nis attained.\\nFigure 2-3 illustrates the intermediate results of a gradient descent optimization pro‐\\ncess of a linear regression. At zero iterations, observe that the regression line, formed\\nwith the randomly chosen parameters, does not fit the dataset at all. As you can imag‐\\nine, the value of the sum-of-squares cost function is quite large at this point. At three\\niterations, notice that the regression line has very quickly moved to a more sensible\\nposition. Between 5 and 20 iterations the regression line slowly adjusts itself to more\\noptimal positions where the cost function is minimized. If performing any more iter‐\\nations doesn’t decrease the cost function significantly, we can say that the optimiza‐\\ntion has converged, and we have the final learned parameters for the trained model.\\nFigure 2-3. Regression line ater a progressive number of iterations of gradient descent\\noptimization (0, 3, 5, and 20 iterations of gradient descent, shown at the upper let,\\nupper right, lower let, and lower right, respectively)\\nWhich optimization algorithm?\\nAs with many things in data science, no optimization algorithm is one-size-fits-all,\\nand there are no clear rules for which algorithm definitely performs better for certain\\nTraining Algorithms to Learn \\n| \\n39'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 57}, page_content='13 For an event X that occurs with probability p, the odds of X are p/ 1 −p , and the log odds are log p/ 1 −p .\\ntypes of problems. A certain amount of trial-and-error experimentation is often\\nneeded to find an algorithm that suits your requirements and meets your needs.\\nThere are many considerations other than convergence or speed that you should take\\ninto account when selecting an optimizer. Starting with the default or the most sensi‐\\nble option and iterating when you see clues for improvements is generally a good\\nstrategy.\\nSupervised Classiication Algorithms\\nNow that we know how machine learning algorithms work in principle, we will\\nbriefly describe some of the most popular supervised learning algorithms for classifi‐\\ncation.\\nLogistic Regression\\nAlthough we discussed logistic regression in some detail earlier, we go over its key\\nproperties here. Logistic regression takes as input numerical feature vectors and\\nattempts to predict the log odds13 of each data point occurring; we can convert the log\\nodds to probabilities by using the sigmoid function discussed earlier. In the log odds\\nspace, the decision boundary is linear, so increasing the value of a feature monotoni‐\\ncally increases or decreases (depending on the sign of the coefficient) the score out‐\\nput by the model.\\nWhy Not Linear Regression?\\nLinear regression, taught in every introductory statistics course, is a powerful tool for\\npredicting future outcomes based on past data. The algorithm takes data consisting of\\ninput variables (expressed as vectors in a vector space) and a response variable (a real\\nnumber) and produces a “best fit” linear model that maps each point in the vector\\nspace to its predicted response. Why can’t we use it to solve classification problems?\\nThe issue is that linear regression predicts a real-valued variable, and in classification\\nwe want to predict a categorical variable. If we try to map the two categories to 0 and 1\\nand perform linear regression, we end up with a line that maps input variables to\\nsome output, as demonstrated in Figure 2-4. But what does this output mean? We\\ncan’t interpret it as a probability, because it can take values below 0 or above 1, as in\\nthe figure. We could interpret it as a score and choose a threshold for the class bound‐\\nary, but while this approach works technically it does not produce a good classifier.\\nThe reason is that the squared-error loss function used in linear regression does not\\naccurately reflect how far points are from the classification boundary: in the example\\n40 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 58}, page_content='14 This assumption is not exclusive to logistic regression. Most other machine learning algorithms also require\\nthat features be uncorrelated.\\nof Figure 2-4, the point at X = 1 has larger error than the points around X = 10, even\\nthough this point will be farther from the classification boundary (e.g., X = 50).\\nFigure 2-4. Linear regression for classiication\\nLogistic regression is one of the most popular algorithms in practice due to a number\\nof properties: it can be trained very efficiently and in a distributed manner, it scales\\nwell to millions of features, it admits a concise description and fast scoring algorithm\\n(a simple dot product), and it is explainable—each feature’s contribution to the final\\nscore can be computed.\\nHowever, there are a few important things to be aware of when considering logistic\\nregression as a supervised learning technique:\\n• Logistic regression assumes linearity of features (independent variables) and log\\nodds, requiring that features are linearly related to the log odds. If this assumption\\nis broken the model will perform poorly.\\n• Features should have little to no multicollinearity;14 that is, independent variables\\nshould be truly independent from one another.\\n• Logistic regression typically requires a larger sample size compared to other\\nmachine learning algorithms like linear regression. Maximum likelihood esti‐\\nSupervised Classiication Algorithms \\n| \\n41'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 59}, page_content='15 For performing logistic regression on smaller datasets, consider using exact logistic regression.\\n16 Note that as of late 2017, scikit-learn’s implementation of decision trees (sklearn.tree.DecisionTreeClassi\\nfier and other tree-based learners) does not properly handle categorical data. Categorical variables encoded\\nwith integer labels (i.e., with sklearn.preprocessing.LabelEncoder and not sklearn.preprocessing.OneHo\\ntEncoder or the pandas.get_dummies() function) will be incorrectly treated as numerical variables. Even\\nthough a scikit-learn maintainer claimed that models like sklearn.tree.RandomForestClassifier tend to be\\n“very robust to categorical features abusively encoded as integer features in practice,”, it is still highly recom‐\\nmended that you convert categorical variables to dummy/one-hot variables before feeding them into sklearn\\ndecision trees. There should be a new feature for tree-based learners to have support for categorical splits (up\\nto 64 categories per feature) in 2018.\\nmates (used in logistic regression) are less powerful than ordinary least squares\\n(used in linear regression), which results in requiring more training samples to\\nachieve the same statistical learning power.15\\nDecision Trees\\nDecision trees are very versatile supervised learning models that have the important\\nproperty of being easy to interpret. A decision tree is, as its name suggests, a binary\\ntree data structure that is used to make a decision. Trees are a very intuitive way of\\ndisplaying and analyzing data and are popularly used even outside of the machine\\nlearning field. With the ability to predict both categorical values (classification trees)\\nand real values (regression trees) as well as being able to take in numerical and cate‐\\ngorical data without any normalization or dummy variable creation,16 it’s not difficult\\nto see why they are a popular choice for machine learning.\\nLet’s see how a typical (top-down) learning decision tree is constructed:\\n1. Starting at the root of the tree, the full dataset is split based on a binary condition\\ninto two child subsets. For example, if the condition is “age ≥ 18,” all data points\\nfor which this condition is true go to the left child and all data points for which\\nthis condition is false go to the right child.\\n2. The child subsets are further recursively partitioned into smaller subsets based\\non other conditions. Splitting conditions are automatically selected at each step\\nbased on what condition best splits the set of items. There are a few common\\nmetrics by which the quality of a split is measured:\\nGini impurity\\nIf samples in a subset were randomly labeled according to the distribution of\\nlabels in the set, the proportion of samples incorrectly labeled would be the\\nGini impurity. For example, if a subset were made up of 25% samples with\\nlabel 0 (and 75% with label 1), assigning label 0 to a random 25% of all sam‐\\nples (and label 1 to the rest) would give 37.5% incorrect labels: 75% of the\\n42 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 60}, page_content='label-0 samples and 25% of the label-1 samples would be incorrect. A higher-\\nquality decision tree split would split the set into subsets cleanly separated by\\ntheir label, hence resulting in a lower Gini impurity; that is, the rate of mis‐\\nclassification would be low if most points in a set belong to the same class.\\nVariance reduction\\nOften used in regression trees, where the dependent variable is continuous.\\nVariance reduction is defined as the total reduction in a set’s variance as a\\nresult of the split into two subsets. The best split at a node in a decision tree\\nwould be the split that results in the greatest variance reduction.\\nInformation gain\\nInformation gain is a measure of the purity of the subsets resulting from a\\nsplit. It is calculated by subtracting the weighted sum of each decision tree\\nchild node’s entropy from the parent node’s entropy. The smaller the entropy\\nof the children, the greater the information gain, hence the better the split.\\n3. There are a few different methods for determining when to stop splitting nodes:\\n• When all leaves of the tree are pure—that is, all leaf nodes each only contain\\nsamples belonging to the same class—stop splitting.\\n• When a branch of the tree has reached a certain predefined maximum depth,\\nthe branch stops being split.\\n• When either of the child nodes will contain fewer than the minimum number\\nof samples, the node will not be partitioned.\\n4. Ultimately the algorithm outputs a tree structure where each node represents a\\nbinary decision, the children of each node represent the two possible outcomes\\nof that decision, and each leaf represents the classification of data points follow‐\\ning the path from the root to that leaf. (For impure leaves, the decision is deter‐\\nmined by majority vote of the training data samples at that leaf.)\\nAn important quality of decision trees is the relative ease of explaining classification\\nor regression results, since every prediction can be expressed in a series of Boolean\\nconditions that trace a path from the root of the tree to a leaf node. For example, if a\\ndecision tree model predicted that a malware sample belongs to malware family A, we\\nknow it is because the binary was signed before 2015, does not hook into the window\\nmanager framework, does make multiple network calls out to Russian IP addresses,\\netc. Because each sample traverses at most the height of the binary tree (time com‐\\nplexity O log n ), decision trees are also efficient to train and make predictions on. As\\na result, they perform favorably for large datasets.\\nSupervised Classiication Algorithms \\n| \\n43'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 61}, page_content='Nevertheless, decision trees have some limitations:\\n• Decision trees often suffer from the problem of overitting, wherein trees are\\noverly complex and don’t generalize well beyond the training set. Pruning is\\nintroduced as a regularization method to reduce the complexity of trees.\\n• Decision trees are more ineicient at expressing some kinds of relationships than\\nothers. For example, Figures 2-5 and 2-6 present the minimal decision tree\\nrequired to represent the AND, OR, and XOR relationships. Notice how XOR\\nrequires one more intermediate node and split to be appropriately represented,\\neven in this simple example. For realistic datasets, this can quickly result in\\nexploding model complexity.\\nFigure 2-5. Decision tree for A-AND-B → y=1 (let), A-OR-B → y=1 (right)\\nFigure 2-6. Decision tree for A-XOR-B → y=1 (bottom)\\n44 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 62}, page_content='17 Laurent Hyafil and R.L. Rivest, “Constructing Optimal Binary Decision Trees is NP-Complete,” Information\\nProcessing Letters 5:1 (1976): 15–17.\\n• Decision trees tend to be less accurate and robust than other supervised learning\\ntechniques. Small changes to the training dataset can result in large changes to\\nthe tree, which in turn result in changes to model predictions. This means that\\ndecision trees (and most other related models) are unsuitable for use in online\\nlearning or incremental learning.\\n• Split-quality metrics for categorical variables in decision trees are biased toward\\nvariables with more possible values; that is, splits on continuous variables or cate‐\\ngorical variables with three or more categories will be chosen with a greater prob‐\\nability than binary variables.\\n• Greedy training of decision trees (as it is almost always done) does not guarantee\\nan optimal decision tree because locally optimal and not globally optimal deci‐\\nsions are made at each split point. In fact, the training of a globally optimal deci‐\\nsion tree is an NP-complete problem.17\\nDecision Forests\\nAn ensemble refers to a combination of multiple classifiers that creates a more com‐\\nplex, and often better performing, classifier. Combining decision trees into ensembles\\nis a proved technique for creating high-quality classifiers. These ensembles are aptly\\nnamed decision forests. The two most common types of forests used in practice are\\ndecision forests and gradient-boosted decision trees:\\n• Random forests are formed by simple ensembling of multiple decision trees, typi‐\\ncally ranging from tens to thousands of trees. After training each individual deci‐\\nsion tree, overall random forest predictions are made by taking the statistical\\nmode of individual tree predictions for classification trees (i.e., each tree “votes”),\\nand the statistical mean of individual tree predictions for regression trees.\\nYou might notice that simply having many decision trees in the forest will result\\nin highly similar trees and a lot of repeated splits across different trees, especially\\nfor features that are strong predictors of the dependent variable. The random for‐\\nest algorithm addresses this issue using the following training algorithm:\\n1. For the training of each individual tree, randomly draw a subset of N samples\\nfrom the training dataset.\\nSupervised Classiication Algorithms \\n| \\n45'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 63}, page_content='18 For classification problems with p total features, m =\\np is recommended. For regression tasks, m = p/3 is\\nrecommended. Refer to section 15.2 of he Elements of Statistical Learning, 2nd ed., by Trevor Hastie, Robert\\nTibshirani, and Jerome Friedman.\\n19 There also exist variants of random forests that limit the set of features available to an individual decision tree;\\nfor example, if the total feature set is {A,B,C,D,E,F,G}, all split points made in decision tree 1 might randomly\\nselect only three features out of the subset of features {A,B,D,F,G}.\\n2. At each split point, we randomly select m features from the p available features,\\nwhere m ≤p,18 and pick the optimal split point from these m features.19\\n3. Repeat step 2 until the individual tree is trained.\\n4. Repeat steps 1, 2, and 3 until all trees in the forest are trained.\\nSingle decision trees tend to overfit to their training sets, and random forests\\nmitigate this effect by taking the average of multiple decision trees, which usually\\nimproves model performance. In addition, because each tree in the random for‐\\nest can be trained independently of all other trees, it is straightforward to paral‐\\nlelize the training algorithm and therefore random forests are very efficient to\\ntrain. However, the increased complexity of random forests can make them much\\nmore storage intensive, and it is much harder to explain predictions than with sin‐\\ngle decision trees.\\n• Gradient-boosted decision trees (GBDTs) make use of smarter combinations of\\nindividual decision tree predictions to result in better overall predictions. In gra‐\\ndient boosting, multiple weak learners are selectively combined by performing\\ngradient descent optimization on the loss function to result in a much stronger\\nlearning model.\\nThe basic technique of gradient boosting is to add individual trees to the forest\\none at a time, using a gradient descent procedure to minimize the loss when\\nadding trees. Addition of more trees to the forest stops either when a fixed limit\\nis hit, when validation set loss reaches an acceptable level, or when adding more\\ntrees no longer improves this loss.\\nSeveral improvements to basic GBDTs have been made to result in better per‐\\nforming, better generalizing, and more efficient models. Let’s look at a handful of\\nthem:\\n1. Gradient boosting requires weak learners. Placing artiicial constraints on trees,\\nsuch as limits on tree depth, number of nodes per tree, or minimum number of\\nsamples per node, can help constrain these trees without overly diminishing\\ntheir learning ability.\\n2. It can happen that the decision trees added early on in the additive training of\\ngradient-boosted ensembles contribute much more to the overall prediction\\nthan the trees added later in the process. This situation results in an imbal‐\\n46 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 64}, page_content='20 Tianqi Chen and Carlos Guestrin, “XGBoost: A Scalable Tree Boosting System,” Proceedings of the 22nd ACM\\nSIGKDD International Conference on Knowledge Discovery and Data Mining (2016): 785–794.\\nanced model that limits the benefits of ensembling. To solve this problem, the\\ncontribution of each tree is weighted to slow down the learning process, using a\\ntechnique called shrinkage, to reduce the influence of individual trees and\\nallow future trees to further improve the model.\\n3. We can combine the stochasticity of random forests with gradient boosting by\\nsubsampling the dataset before creating a tree and subsampling the features\\nbefore creating a split.\\n4. We can use standard and popular regularization techniques such as L1 and L2\\nregularization to smooth final learned weights to further avoid overfitting.\\nXGBoost20 is a popular GBDT flavor that achieves state-of-the-art results while\\nscaling well to large datasets. As the algorithm that was responsible for many\\nwinning submissions to machine learning competitions, it garnered the attention\\nof the machine learning community and has become the decision forest algo‐\\nrithm of choice for many practitioners. Nevertheless, GBDTs are more prone to\\noveritting than random forests, and also more diicult to parallelize because they\\nuse additive training, which relies on the results of a given tree to update gradi‐\\nents for the subsequent tree. We can mitigate overfitting of GBDTs by using\\nshrinkage, and we can parallelize training within a single tree instead of across\\nmultiple trees.\\nSupport Vector Machines\\nLike logistic regression, a support vector machine (SVM) is (in its simplest form) a lin‐\\near classifier, which means that it produces a hyperplane in a vector space that\\nattempts to separate the two classes in the dataset. The difference between logistic\\nregression and SVMs is the loss function. Logistic regression uses a log-likelihood\\nfunction that penalizes all points proportionally to the error in the probability esti‐\\nmate, even those on the correct side of the hyperplane. An SVM, on the other hand,\\nuses a hinge loss, which penalizes only those points on the wrong side of the hyper‐\\nplane or very near it on the correct side.\\nMore specifically, the SVM classifier attempts to find the maximum-margin hyper‐\\nplane separating the two classes, where “margin” indicates the distance from the sepa‐\\nrating plane to the closest data points on each side. For the case in which the data is\\nnot linearly separable, points within the margin are penalized proportionately to their\\ndistance from the margin. Figure 2-7 shows a concrete example: the two classes are\\nrepresented by white and black points, respectively. The solid line is the separating\\nSupervised Classiication Algorithms \\n| \\n47'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 65}, page_content='plane and the dashed lines are the margins. The square points are the support vectors;\\nthat is, those that provide nonzero contribution to the loss function. This loss func‐\\ntion is expressed mathematically as:\\nβ + C ∑\\ni = 1\\nN\\nξi\\nwhere β is the margin, ξi is the distance from the ith support vector to the margin,\\nand C is a model hyperparameter that determines the relative contribution of the two\\nterms.\\nFigure 2-7. Classiication boundary (dark line) and margins (dashed lines) for linear\\nSVM separating two classes (black and white points); squares represent support vectors\\nTo classify a new data point x, we simply determine which side of the plane x falls on.\\nIf we want to get a real-valued score we can compute the distance from x to the sepa‐\\nrating plane and then apply a sigmoid to map to [0,1].\\nThe real power of SVMs comes from the kernel trick, which is a mathematical trans‐\\nformation that takes a linear decision boundary and produces a nonlinear boundary.\\nAt a high level, a kernel transforms one vector space, V1, to another space, V2. Math‐\\nematically, the kernel is a function on V1 × V1 defined by K x, y , and each x ∈V1 is\\nmapped to the function K x, · ; V2 is the space spanned by all such functions. For\\nexample, we can recover the linear SVM by defining K to be the usual dot product\\nK x, y = x · y.\\n48 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 66}, page_content='21 See section 5.8 and Chapter 12 of he Elements of Statistical Learning by Trevor Hastie, Robert Tibshirani, and\\nJerome Friedman.\\nIf the kernel is nonlinear, a linear classifier in V1 will produce a nonlinear classifier in\\nV2. The most popular choice is the radial basis function K x, y = e−γ x −y . Even\\nthough we omit the mathematical details here,21 you can think of an SVM with the\\nRBF kernel as producing a sort of smoothed linear combination of spheres around\\neach point x, where the inside of each sphere is classified the same as x, and the out‐\\nside is assigned the opposite class. The parameter γ determines the radius of these\\nspheres; i.e., how close to each point you need to be in order to be classified like that\\npoint. The parameter C determines the “smoothing”; a large value of C will lead to the\\nclassifier consisting of a union of spheres, while a small value will yield a wigglier\\nboundary influenced somewhat by each sphere. We can therefore see that too large a\\nvalue of C will produce a model that overfits the training data, whereas too small a\\nvalue will give a poor classifier in terms of accuracy. (Note that γ is unique to the RBF\\nkernel, whereas C exhibits the same properties for any kernel, including the linear\\nSVM. Optimal values of these parameters are usually found using grid search.)\\nSVMs have shown very good performance in practice, especially in high-dimensional\\nspaces, and the fact that they can be described in terms of support vectors leads to\\nefficient implementations for scoring new data points. However, the complexity of\\ntraining a kernelized SVM grows quadratically with the number of training samples,\\nso that for training set sizes beyond a few million, kernels are rarely used and the\\ndecision boundary is linear. Another disadvantage is that the scores output by SVMs\\nare not interpretable as probabilities; converting scores to probabilities requires addi‐\\ntional computation and cross-validation, for example using Platt scaling or isotonic\\nregression. The scikit-learn documentation has further details.\\nNaive Bayes\\nThe Naive Bayes classifier is one of the oldest statistical classifiers. The classifier is\\ncalled “naive” because it makes a very strong statistical assumption, namely that fea‐\\ntures are chosen independently from some (unknown) distribution. This assumption\\nnever actually holds in real life. For example, consider a spam classifier for which the\\nfeatures are the words in the message. The Naive Bayes assumption posits that a spam\\nmessage is composed by sampling words independently, where each word w has a\\nprobability pw, spam of being sampled, and similarly for good messages. This assump‐\\ntion is clearly ludicrous; for one thing, it completely ignores word ordering. Yet\\ndespite the fact that the assumption doesn’t hold, Naive Bayes classifiers have been\\nshown to be quite effective for problems such as spam classification.\\nSupervised Classiication Algorithms \\n| \\n49'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 67}, page_content='The main idea behind Naive Bayes is as follows: given a data point with feature set\\nX = x1, ..., xn, we want to determine the probability that the label Y for this point is\\nthe class C. In Equation 2-1, this concept is expressed as a conditional probability.\\nEquation 2-1.  \\nPr Y = C ∣X = x1, ..., xn\\nNow using Bayes’ heorem, this probability can be reexpressed as in Equation 2-2.\\nEquation 2-2.  \\nPr X = x1, …, xn\\nY = C · Pr Y = C\\nPr X = x1, …, xn\\nIf we make the very strong assumption that for samples in each class the features are\\nchosen independently of one another, we get Equation 2-3.\\nEquation 2-3.  \\nPr X = x1, ..., xn ∣Y = C = ∏\\ni = 1\\nn\\nPr Xi = xi ∣Y = C\\nwe \\ncan \\nestimate \\nthe \\nnumerator \\nof \\nEquation \\n2-2 \\nfrom \\nlabeled \\ndata:\\nPr Xi = xi ∣Y = C  is simply the fraction of samples with the ith feature equal to xi\\nout of all the samples in class C, whereas Pr Y = C  is the fraction of samples in class\\nC out of all the labeled samples.\\nWhat about the denominator of Equation 2-2? It turns out that we don’t need to com‐\\npute this, because in two-class classification it is sufficient to compute the ratio of the\\nprobability estimates for the two classes C1 and C2. This ratio (Equation 2-4) gives a\\npositive real number score.\\nEquation 2-4.  \\nθ =\\nPr Y = C1 ∣X = x1, ..., xn\\nPr Y = C2 ∣X = x1, ..., xn\\n≈\\nPr Y = C1 ∏i = 1\\nn\\nPr Xi = xi ∣Y = C1\\nPr Y = C2 ∏i = 1\\nn\\nPr Xi = xi ∣Y = C2\\n50 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 68}, page_content='22 David Freeman, “Using Naive Bayes to Detect Spammy Names in Social Networks,” Proceedings of the 2013\\nACM Workshop on Artiicial Intelligence in Security (2013): 3–12.\\nA score of θ > 1 indicates that C1 is the more likely class, whereas θ < 1 indicates that\\nC2 is more likely. (If optimizing for one of precision or recall you might want to\\nchoose a different threshold for the classification boundary.)\\nThe astute observer will notice that we obtained our score θ without reference to a\\nloss function or an optimization algorithm. The optimization algorithm is actually\\nhidden in the estimate of Pr Xi = xi ∣Y = C ; using the fraction of samples observed\\nin the training data gives the maximum likelihood estimate, the same loss function\\nused for logistic regression. The similarity to logistic regression doesn’t stop there: if\\nwe take logarithms of Equation 2-4 the righthand side becomes a linear function of\\nthe features, so we can view Naive Bayes as a linear classifier, as well.\\nA few subtleties arise when trying to use Naive Bayes in practice:\\n• What happens when all of the examples of some feature are in the same class (e.g.\\nbrand names of common sex enhancement drugs appear only in spam mes‐\\nsages)? Then, one of the terms of Equation 2-4 will be zero, leading to a zero or\\ninfinity estimate for θ, which doesn’t make sense. To get around this problem we\\nuse smoothing, which means adding “phantom” samples to the labeled data for\\neach feature. For example, if we are smoothing by a factor of α, we would calcu‐\\nlate the value for a feature as follows:\\nPr Xi = xi ∣Y = C =\\n# samples in class C with feature xi + α\\n# samples in class C\\n+ α · # of features\\nThe choice α = 1 is called Laplace smoothing, whereas α < 1 is called Lidstone\\nsmoothing.\\n• What happens if a feature xi appears in our validation set (or worse, in real-life\\nscoring) that did not appear in the training set? In this case we have no estimate\\nfor Pr Xi = xi ∣Y = C  at all. A naive estimate would be to set the probability to\\nPr Y = C ; for more sophisticated approaches see the work of Freeman.22\\nAs a final note, we can map the score θ ∈0, ∞ to a probability in (0,1) using the\\nmapping θ\\nθ\\n1 + θ; however, this probability estimate will not be properly calibrated.\\nAs with SVMs, to obtain better probability estimates we recommend techniques such\\nas Platt scaling or isotonic regression.\\nSupervised Classiication Algorithms \\n| \\n51'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 69}, page_content='23 k-NN can also be used for regression—typically, the average of a test sample’s k nearest neighboring sample\\nlabels is taken to be the prediction result.\\n24 Jon Louis Bentley, “Multidimensional Binary Search Trees Used for Associative Searching,” Communications\\nof the ACM 18 (1975): 509–517.\\nk-Nearest Neighbors\\nThe k-nearest neighbors (k-NN) algorithm is the most well-known example of a lazy\\nlearning algorithm. This type of machine learning technique puts off most computa‐\\ntions to classification time instead of doing the work at training time. Lazy learning\\nmodels don’t learn generalizations of the data during the training phase. Instead, they\\nrecord all of the training data points they are passed and use this information to make\\nthe local generalizations around the test sample during classification. k-NN is one of\\nthe simplest machine learning algorithms:\\n• The training phase simply consists of storing all the feature vectors and corre‐\\nsponding sample labels in the model.\\n• The classification prediction23 is simply the most common label out of the test\\nsample’s k nearest neighbors (hence the name).\\nThe distance metrics for determining how “near” points are to each other in an n-\\ndimensional feature space (where n is the size of the feature vectors) are typically the\\nEuclidean distance for continuous variables and the Hamming distance for discrete\\nvariables.\\nAs you might imagine, with such a simple algorithm the training phase of k-NN is\\ntypically very fast compared to other learning algorithms, at the cost of classification\\nprocessing time. Also, the fact that all feature vectors and labels need to be stored\\nwithin the model results in a very space-ineicient model. (A k-NN model that takes\\nin 1 GB of training feature vectors will at least be 1 GB in size.)\\nThe simplicity of k-NN makes it a popular example for teaching the concept of\\nmachine learning to novices, but it is rarely seen in practical scenarios because of the\\nserious drawbacks it has. These include:\\n• Large model sizes, because models must store (at least) all training data feature\\nvectors and labels.\\n• Slow classiication speeds, because all generalization work is pushed off until clas‐\\nsification time. Searching for the nearest neighbors can be time consuming, espe‐\\ncially if the model stores training data points in a manner that is not optimized\\nfor spatial search. k-d trees (explained in “k-d trees” on page 72) are often used as\\nan optimized data structure to speed up neighbor searches.24\\n52 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 70}, page_content='25 We explain the concept of class imbalance in greater detail in Chapter 5.\\n26 W.S. McCulloch and W.H. Pitts, “A Logical Calculus of Ideas Immanent in Nervous Activity,” Bulletin of Math‐\\nematical Biophysics 5 (1942): 115–133.\\n• High sensitivity to class imbalance25 in the dataset. Classifications will be skewed\\ntowards the classes with more samples in the training data since there is a greater\\nlikelihood that samples of these classes will make it into the k-NN set of any\\ngiven test sample.\\n• Diminished classiication accuracy due to noisy, redundant, or unscaled features.\\n(Choosing a larger k reduces the effect of noise in the training data, but also can\\nresult in a weaker learner.)\\n• Diiculty in choosing the parameter k. Classification results are highly dependent\\non this parameter, and it can be difficult to choose a k that works well across all\\nparts of the feature space because of differing densities within the dataset.\\n• Breaks down in high dimensions due to the “curse of dimensionality.” In addition,\\nwith more dimensions in the feature space, the “neighborhood” of any arbitrary\\npoint becomes larger, which results in noisier neighbor selection.\\nNeural Networks\\nArtificial neural networks (ANNs) are a class of machine learning techniques that\\nhave seen a resurgence in popularity recently. One can trace the origins of neural net‐\\nworks all the way back to 1942, when McCulloch and Pitts published a groundbreak‐\\ning paper postulating how neurons in the human nervous system might work.26\\nBetween then and the 1970s, neural network research advanced at a slow pace, in\\nlarge part due to von Neumann computing architectures (which are quite in opposi‐\\ntion to the idea of ANNs) being in vogue. Even after interest in the field was renewed\\nin the 1980s, research was still slow because the computational requirements of train‐\\ning these networks meant that researchers often had to wait days or weeks for the\\nresults of their experiments. What triggered the recent popularity of neural networks\\nwas a combination of hardware advancements—namely graphics processing units\\n(GPUs) for “almost magically” parallelizing and speeding up ANN training—and the\\navailability of the huge amounts of data that ANNs need to get good at complex tasks\\nlike image and speech recognition.\\nThe human brain is composed of a humongous number of neurons (on the order of\\n10 billion), each with connections to tens of thousands of other neurons. Each neu‐\\nron receives electrochemical inputs from other neurons, and if the sum of these elec‐\\ntrical inputs exceeds a certain level, the neuron then triggers an output transmission\\nof another electrochemical signal to its attached neurons. If the input does not exceed\\nthis level, the neuron does not trigger any output. Each neuron is a very simple\\nSupervised Classiication Algorithms \\n| \\n53'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 71}, page_content='27 This oversimplification of how ANNs work barely does justice to the field. For a more complete discussion of\\nthis topic, read Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (MIT Press).\\nprocessing unit capable of only very limited functionality, but in combination with a\\nlarge number of other neurons connected in various patterns and layers, the brain is\\ncapable of performing extremely complex tasks ranging from telling apart a cat from\\na dog to grasping profound philosophical concepts.\\nANNs were originally attempts at modeling neurons in the brain to achieve human-\\nlike learning. Individual neurons were modeled with simple mathematical step func‐\\ntions (called activation functions), taking in weighted input from some neurons and\\nemitting output to some other neurons if triggered. This mathematical model of a\\nbiological neuron is also called a perceptron. Armed with perceptrons, we then can\\nform a plethora of different neural networks by varying the topology, activation func‐\\ntions, learning objectives, or training methods of the model.\\nTypically, ANNs are made up of neurons arranged in layers. Each neuron in a layer\\nreceives input from the previous layer and, if activated, emits output to one or more\\nneurons in the next layer. Each connection of two neurons is associated with a weight,\\nand each neuron or layer might also have an associated bias. These are the parameters\\nto be trained by the process of backpropagation, which we describe simply and briefly.\\nBefore starting, all of the weights and biases are randomly initialized. For each sample\\nin the training set, we perform two steps:27\\n1. Forward pass. Feed the input through the ANN and get the current prediction.\\n2. Backward pass. If the prediction is correct, reward the connections that produced\\nthis result by increasing their weights in proportion to the confidence of the pre‐\\ndiction. If the prediction is wrong, penalize the connections that contributed to\\nthis wrong result.\\nNeural networks have been extensively used in industry for many years and are\\nbacked by large bodies of academic research. There are hundreds of variations of\\nneural network infrastructures, and we can use them for both supervised and unsu‐\\npervised learning. An important quality of some ANNs is that they can perform \\nunsupervised feature learning (which is different from unsupervised learning), which\\nmeans that minimal or no feature engineering is required. For example, building a\\nmalware classifier with an SVM requires domain experts to generate features (as we\\ndiscuss in Chapter 4). If we use ANNs, it is possible to feed the raw processor instruc‐\\ntions or call graphs into the network and have the network itself figure out which fea‐\\ntures are relevant for the classification task.\\nEven though there are a lot of hardware and software optimizations available for the\\ntraining of neural networks, they are still significantly more computationally expen‐\\n54 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 72}, page_content='sive than training a decision tree, for instance. (Predictions, on the other hand, can be\\nmade rather efficiently because of the layered structure.) The number of model\\nhyperparameters to tune in the training of ANNs can be enormous. For instance, you\\nmust choose the configuration of network architecture, the type of activation func‐\\ntion, whether to fully connect neurons or leave layers sparsely connected, and so on.\\nLastly, although ANNs—or deep learning networks, as the deep (many-layered) var‐\\niants of neural networks are popularly called—are frequently thought to be a silver\\nbullet in machine learning, they can be very complex and difficult to reason about.\\nThere are often alternatives (such as the other algorithms that we discussed in this\\nsection) that are faster, simpler, and easier to train, understand, and explain.\\nPractical Considerations in Classiication\\nIn theory, applying a machine learning algorithm is straightforward: you put your\\ntraining data into a large matrix (called the design matrix), run your training proce‐\\ndure, and use the resulting model to classify unseen data. However, after you actually\\nbegin coding, you will realize that the task is not so simple. There are dozens of\\nchoices to be made in the model construction process, and each choice can lead to\\nvery different outcomes in your final model. We now consider some of the most\\nimportant choices to be made during the modeling process.\\nSelecting a Model Family\\nIn the previous section, we discussed a number of different supervised classification\\nalgorithms. How are you supposed to decide which one to pick for a given task? The\\nbest answer is to let the data decide: try a number of different approaches and see\\nwhat works best. If you don’t have the time or infrastructure to do this, here are some\\nfactors to consider:\\nComputational complexity\\nYou want to be able to train your model in a reasonable amount of time, using all\\nof the data you have. Logistic regression models and linear SVMs can be trained\\nvery quickly. In addition, logistic regression and decision forests have very effi‐\\ncient parallel implementations that can handle very large amounts of data. Kernel\\nSVMs and neural networks can take a long time to train.\\nMathematical complexity\\nYour data might be such that a linear decision boundary will provide good classi‐\\nfication; on the other hand, many datasets have nonlinear boundaries. Logistic\\nregression, linear SVM, and Naive Bayes are all linear algorithms; for nonlinear\\nboundaries you can use decision forests, kernel SVMs, or neural networks.\\nPractical Considerations in Classiication \\n| \\n55'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 73}, page_content='Explainability\\nA human might need to read the output of your model and determine why it\\nmade the decision it did; for example, if you block a legitimate user, you should\\neducate them as to what they did that was suspicious. The best model family for\\nexplainability is a decision tree, because it says exactly why the classification was\\nmade. We can use relative feature weights to explain logistic regression and Naive\\nBayes. Decision forests, SVMs, and neural networks are very difficult to explain.\\nThere are many opinions on what model to use in which situation; an internet search\\nfor “machine learning cheat sheet” will produce dozens. Our basic recommendation\\nis to use decision forests for high accuracy on a moderate number of features (up to\\nthousands), and logistic regression for fast training on a very large number of features\\n(tens of thousands or more). But ultimately, you should experiment to find the best\\nchoice for your data.\\nTraining Data Construction\\nIn a supervised learning problem, you will (somehow) have assembled labeled exam‐\\nples of the thing that you want to classify—account registrations, user logins, email\\nmessages, or whatever. Because your goal is to come up with a model that can predict\\nthe future based on past data, you will need to reserve some of your labeled data to\\nact as this “future” data so that you can evaluate your model. There are a number of\\ndifferent ways you can do this:\\nCross-validation\\nThis technique is a standard method for evaluating models when there is not a\\nlot of training data, so every labeled example makes a significant contribution to\\nthe learned model. In this method, you divide the labeled data into k equal parts\\n(usually 5 or 10) and train k different models: each model “holds out” a different\\none of the k parts and trains on the remaining k–1 parts. The held-out part is\\nthen used for validation. Finally, the k different models are combined by averag‐\\ning both the performance statistics and the model parameters.\\nTrain/validate/test\\nThis approach is most common when you have enough training data so that\\nremoving up to half of it doesn’t affect your model very much. In this approach\\nyou randomly divide your labeled data into three parts. (See the left side of\\nFigure 2-8.) The majority (say, 60%) is the training set and is input to the learning\\nalgorithm. The second part (say, 20%) is the validation set and is used to evaluate\\nand iterate on the model output by the learning algorithm. For example, you can\\ntune model parameters based on performance on the validation set. Finally, after\\nyou have settled on an optimal model, you use the remaining part (say, 20%) as\\nthe test set to estimate real-world performance on unseen data.\\n56 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 74}, page_content='Out-of-time validation\\nThis approach addresses the problem of validating models when the data distri‐\\nbution changes over time. In this case, sampling training and validation sets at\\nrandom from the same labeled set is “cheating” in some sense—the distributions\\nof the training and validation sets will match closely and not reflect the time\\naspect. A better approach is to split the training and validation sets based on a\\ntime cutoff: samples before time t are in the training set and samples after time t\\nare in the validation set. (See the right side of Figure 2-8.) You might want to have\\nthe test set come from the same time period as the validation set, or a subsequent\\nperiod entirely.\\nFigure 2-8. In-time validation (let) and out-of-time validation (right)\\nThe composition of the training set might also require some attention. Let’s take a\\nlook at a few common issues.\\nUnbalanced data\\nIf you are trying to classify a rare event—for example, account hijacking—your\\n“good” samples can be 99% or even 99.9% of the labeled data. In this case the “bad”\\nsamples might not have enough weight to influence the classifier, and your model\\nmight perform poorly when trained on this highly unbalanced data. You have a few\\noptions here. You can:\\n• Oversample the minority class; in other words, repeat observations in your train‐\\ning data to make a more balanced set.\\n• Undersample the majority class; that is, select a random subset of the majority\\nclass to produce a more balanced set.\\n• Change your loss function to weight performance on the minority class more\\nheavily so that each minority sample has more influence on the model.\\nThere is some debate as to the proper class balance when training to classify rare\\nevents. The fundamental issue is the trade-off between learning from the rare events\\nand learning the prior; that is, that a rare event is rare. For example, if you train on a\\nset that’s 50% rare events, your model might learn that this event should happen half\\nthe time. Some experimentation will be necessary to determine the optimal balance.\\nPractical Considerations in Classiication \\n| \\n57'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 75}, page_content='In any case, if you are artificially sampling your training data, be sure to either leave\\nthe validation and test sets unsampled or use a performance metric that is invariant\\nunder sampling (such as ROC AUC, described in “Choosing Thresholds and Com‐\\nparing Models” on page 62). Otherwise, sampling the validation set will skew your\\nperformance metrics.\\nMissing features\\nIn an ideal world every event is logged perfectly with exactly the data you need to\\nclassify. In real life, things go wrong: bugs appear in the logging; you only realize\\npartway through data collection that you need to log a certain feature; some features\\nare delayed or purged. As a result, some of your samples might have missing features.\\nHow do you incorporate these samples into your training set?\\nOne approach is to simply remove any event with missing features. If the features are\\nmissing due to sporadic random failures this might be a good choice; however, if the\\ndata with missing features is clustered around a certain event or type of data, throw‐\\ning out this data will change your distribution.\\nTo use a sample with a missing feature you will need to impute the value of the miss‐\\ning feature. There is a large literature on imputation that we won’t attempt to delve\\ninto here; it suffices to say that the simplest approach is to assign the missing feature\\nthe average or median value for that feature. More complex approaches involve using\\nexisting features to predict the value of the missing feature.\\nLarge events\\nIn an adversarial setting, you might have large-scale attacks from relatively unsophis‐\\nticated actors that you are able to stop easily. If you naïvely include these events in\\nyour training data your model might learn how to stop these attacks but not how to\\naddress smaller, more sophisticated attacks. Thus, for better performance you might\\nneed to downsample large-scale events.\\nAttacker evolution\\nIn an adversarial environment the attackers will rarely give up after you deploy a new\\ndefense—instead, they will modify their methods to try to circumvent your defenses,\\nyou will need to respond, and so on, and so forth, and so on. Thus, not only does the\\ndistribution of attacks change over time, but it changes directly in response to your\\nactions. To produce a model that is robust against current attacks, your training set\\nshould thus weight recent data more heavily, either by relying only on the past n days\\nor weeks, or by using some kind of decay function to downsample historical data.\\nOn the other hand, it may be dangerous for your model to “forget” attacks from the\\npast. As a concrete example, suppose that each day you train a new model on the past\\nseven days’ worth of data. An attack happens on Monday that you are not able to stop\\n58 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 76}, page_content='(though you do find and label it quickly). On Tuesday your model picks up the new\\nlabeled data and is able to stop the attack. On Wednesday the attacker realizes they\\nare blocked and gives up. Now consider what happens the next Wednesday: there\\nhave been no examples of this attack in the past seven days, so the model you produce\\nmight not be tuned to stop it—and if the attacker finds the hole, the entire cycle will\\nrepeat.\\nAll of the preceding considerations illustrate what could go wrong with certain\\nchoices of training data. It is up to you to weigh the trade-offs between data freshness,\\nhistorical robustness, and system capacity to produce the best solution for your\\nneeds.\\nFeature Selection\\nIf you have a reasonably efficient machine learning infrastructure, most of your time\\nand energy will be spent on feature engineering—figuring out signals that you can\\nuse to identify attacks, and then building them into your training and scoring pipe‐\\nline. To make best use of your effort, you want to use only features that provide high\\ndiscriminatory power; the addition of each feature should noticeably improve your\\nmodel.\\nIn addition to requiring extra effort to build and maintain, redundant features can\\nhurt the quality of your model. If the number of features is greater than the number\\nof data points, your model will be overfit: there are enough model parameters to draw\\na curve through all the training data. In addition, highly correlated features can lead\\nto instability in model decisions. For example, if you have a feature that is “number of\\nlogins yesterday” and one that is “number of logins in the last two days,” the informa‐\\ntion you are trying to collect will be split between the two features essentially arbitrar‐\\nily, and the model might not learn that either of these features is important.\\nYou can solve the feature correlation problem by computing covariance matrices\\nbetween your features and combining highly correlated features (or projecting them\\ninto orthogonal spaces; in the previous example, “number of logins in the day before\\nyesterday” would be a better choice than “number of logins in the last two days”).\\nThere are number of techniques to address the feature selection problem:\\n• Logistic regression, SVMs, and decision trees/forests have methods of determin‐\\ning relative feature importance; you can run these and keep only the features with\\nhighest importance.\\n• You can use L1 regularization (see the next section) for feature selection in logis‐\\ntic regression and SVM classifiers.\\n• If the number n of features is reasonably small (say, n < 100) you can use a “build\\nit up” approach: build n one-feature models and determine which is best on your\\nPractical Considerations in Classiication \\n| \\n59'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 77}, page_content='28 Most tree-based estimators like DecisionTreeClassifier and RandomForestClassifier, as well as some\\nensemble estimators like GradientBoostingClassifier, have the feature_importances_ attribute. General‐\\nized linear models such as LinearRegression and LogisticRegression and support vector machines such as\\nSVC have the coef_ attribute, allowing SelectFromModel to compare magnitudes of the coefficients or impor‐\\ntances corresponding to each feature.\\n29 Using the mean as a feature importance threshold is the default strategy of SelectFromModel unless you spec‐\\nify the threshold parameter as something else; for example, median or a static value.\\n30 You can find an example of applying sklearn.feature_selection.SelectFromModel to a real problem in a\\nPython Jupyter notebook in chapter2/select-from-model-nslkdd.ipynb from our code repository.\\nvalidation set; then build n–1 two-feature models, and so on, until the gain of\\nadding an additional feature is below a certain threshold.\\n• Similarly, you can use a “leave one out” approach: build a model on n features,\\nthen n models on n–1 features and keep the best, and so on until the loss of\\nremoving an additional feature is too great.\\nscikit-learn implements the sklearn.feature_selection.SelectFromModel helper\\nutility that assists operators in selecting features based on importance weights. As\\nlong as a trained estimator has the feature_importances_ or coef_ attribute after fit‐\\nting,28 it can be passed into SelectFromModel for feature selection importance rank‐\\ning. Assuming that we have a pretrained DecisionTreeClassifier model (variable\\nname clf) and an original training dataset (variable name train_x) with 119 fea‐\\ntures, here is a short code snippet showing how to use SelectFromModel to keep only\\nfeatures with a feature_importance that lies above the mean:29,30\\nfrom sklearn.feature_selection import SelectFromModel\\nsfm = SelectFromModel(clf, prefit=True)\\n# Generate new training set, keeping only the selected features\\ntrain_x_new = sfm.transform(train_x)\\nprint(\"Original num features: {}, selected num features: {}\"\\n      .format(train_x.shape[1], train_x_new.shape[1]))\\n> Original num features: 119, selected num features: 7\\n60 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 78}, page_content='Overitting and Underitting\\nOne problem that can occur with any machine learning algorithm is overitting: the\\nmodel you construct matches the training data so thoroughly that it does not general‐\\nize well to unseen data. For example, consider the decision boundary shown for a\\ntwo-dimensional dataset in the left of Figure 2-9. All points are classified correctly,\\nbut the shape of the boundary is very complex, and it is unlikely that this boundary\\ncan be used to effectively separate new points.\\nFigure 2-9. Let: overit decision boundary; right: underit decision boundary\\nOn the other hand, too simple of a model might also result in poor generalization to\\nunseen data; this problem is called underitting. Consider, for example, the decision\\nboundary shown on the right side of Figure 2-9; this simple line is correct on the\\ntraining data a majority of the time, but makes a lot of errors and will likely also have\\npoor performance on unseen data.\\nThe most common approach to minimizing overfitting and underfitting is to incor‐\\nporate model complexity into the training procedure. The mathematical term for this\\nis regularization, which means adding a term to the loss function that represents\\nmodel complexity quantitatively. If ϕ represents the model, yi the training labels, and\\nyi the predictions (either labels or probabilities), the regularized loss function is:\\nℒϕ = ∑\\ni ℓyi, yi + λ · Ω ϕ\\nPractical Considerations in Classiication \\n| \\n61'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 79}, page_content='31 The default method that most machine learning libraries use to deal with this is to pick the class that has the\\nhighest score and use that as the prediction result. For instance, for a binary classification problem this simply\\ntranslates to a threshold of 50%, but for a three-class (or more) classification problem the class with the high‐\\nest probability/confidence is selected as the classifier’s prediction result.\\nwhere ℓ is the aforementioned ordinary loss function, and Ω is a penalty term. For\\nexample, in a decision tree Ω could be the number of leaves; then trees with too many\\nleaves would be penalized. You can adjust the parameter λ to balance the trade-off\\nbetween the ordinary loss function and the regularization term. If λ is too small, you\\nmight get an overfit model; if it is too large, you might get an underfit model.\\nIn logistic regression the standard regularization term is the norm of the coefficient\\nvector β = β0, ..., βn . There are two different ways to compute the norm: L2 regulari‐\\nzation uses the standard Euclidean norm β = Σi βi\\n2, whereas L1 regularization uses\\nthe so-called “Manhattan distance” norm β = Σi βi . The L1 norm has the property\\nthat local minima occur when feature coefficients are zero; L1 regularization thus\\nselects the features that contribute most to the model.\\nWhen using regularized logistic regression, you must take care to normalize the fea‐\\ntures before training the model, for example by applying a linear transformation that\\nresults in each feature having mean 0 and standard deviation 1. If no such transfor‐\\nmation is applied, the coefficients of different features are not comparable. For exam‐\\nple, the feature that is account age in seconds will in general be much larger than the\\nfeature that is number of friends in the social graph. Thus, the coefficient for age will\\nbe much smaller than the coefficient for friends in order to have the same effect, and\\nregularization will penalize the friends coefficient much more strongly.\\nRegardless of the model you are using, you should choose your regularization param‐\\neters based on experimental data from the validation set. But be careful not to overfit\\nto your validation set! That’s what the test set is for: if performance on the test set is\\nmuch worse than on the validation set, you have overfit your parameters.\\nChoosing Thresholds and Comparing Models\\nThe supervised classification algorithm you choose will typically output a real-valued\\nscore, and you will need to choose a threshold or thresholds31 above which to block\\nthe activity or show additional friction (e.g., require a phone number). How do you\\nchoose this threshold? This choice is ultimately a business decision, based on the\\ntrade-off between security and user friction. Ideally you can come up with some cost\\nfunction—for example, 1 false positive is equal to 10 false negatives—and minimize\\nthe total cost on a representative sample of the data. Another option is to fix a\\nprecision or recall target—for example, 98%—and choose a threshold that achieves\\nthat target.\\n62 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 80}, page_content='32 If the AUC is less than 0.5, by reversing the classifier labels you can produce a classifier with AUC > 0.5.\\nNow suppose that you have two versions of your model with different parameters\\n(e.g., different regularization) or even different model families (e.g., logistic regres‐\\nsion versus random forest). Which one is better? If you have a cost function this is\\neasy: compute the cost of the two versions on the same dataset and choose the lower-\\ncost option. If fixing a precision target, choose the version that optimizes recall, and\\nvice versa.\\nAnother common method for model comparison is to plot the receiver operating\\ncharacteristic (ROC) curve and compute the area under the curve (AUC). The ROC\\ncurve plots false positive rate (FP / (FP + TN)) on the x-axis and true positive rate\\n(TP / (TP + FN), also known as recall) on the y-axis. Each point on the curve corre‐\\nsponds to a score threshold and represents the (FPR, TPR) pair at that threshold. The\\nAUC can be interpreted as the probability that a randomly chosen positive example\\nhas a higher score than a randomly chosen negative example; under this interpreta‐\\ntion it’s easy to see that the worst case is AUC 0.5, which is equivalent to a random\\nordering of samples.32\\nFigure 2-10 shows an example ROC curve, with the line y = x plotted for comparison.\\nBecause the AUC is very high, we have used a log scale to zoom in on the lefthand\\nside, which is where differences between high-performance models will appear; if you\\nare operating only in the high-precision region of the curve, you may want to calcu‐\\nlate up to a threshold false positive rate, such as 1%.\\nOne nice property of AUC is that it is unaffected by sampling bias. Thus, if you sam‐\\nple two classes with different weights, the AUC you get on the resulting dataset will be\\nrepresentative of the AUC on the unsampled dataset.\\nPractical Considerations in Classiication \\n| \\n63'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 81}, page_content='Figure 2-10. ROC curves\\nOne common metric that is limited in real-world usefulness is the F-score, which is\\ndefined as follows:\\nFα =\\n1 + α\\n1\\nprecision +\\nα\\nrecall\\nThe F-score combines precision and recall and harshly penalizes extremes; however,\\nit requires choosing a threshold and a relative weighting of precision and recall (para‐\\nmetrized by α).\\n64 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 82}, page_content='Clustering\\nBad things often happen in bunches. For example, if someone is trying to breach your\\nnetwork, there is a good chance that they will try many times before actually getting\\nthrough. Or, if someone is sending pharmaceutical spam, they will need to send a lot\\nof emails in order to get enough people to fall for the scam. Thus, your job as a\\ndefender will be made easier if you can segment your traffic into groups belonging to\\nthe same actor, and then block traffic from malicious actors. This process of segmen‐\\ntation is called clustering.\\nIn this section, we survey some common techniques for clustering data. Of course,\\ngrouping your data is not an end in and of itself—your ultimate goal is to determine\\nwhich clusters consist of malicious activity. Thus, we will also discuss various techni‐\\nques for labeling the clusters generated by the different algorithms.\\nClustering Algorithms\\nThe geometric intuition behind clustering is straightforward: you want to group\\ntogether data points that are “close together” in some sense. Thus, for any algorithm\\nto work you need to have some concrete way to measure “closeness”; such a measure‐\\nment is called a metric. The metric and clustering algorithm you use will depend on\\nthe form your data is in; for example, your data might consist of real-valued vectors,\\nlists of items, or sequences of bits. We now consider the most popular algorithms.\\nGrouping\\nThe most basic clustering method is so simple that it is not even usually thought of as\\na clustering method: namely, pick one or more dimensions and define each cluster to\\nbe the set of items that share values in that dimension. In SQL syntax, this is the\\nGROUP BY statement, so we call this technique “grouping.” For example, if you group\\non IP address, you will define one cluster per IP address, and the elements of the clus‐\\nter will be entities that share the same IP address.\\nWe already saw the grouping technique at the beginning of this chapter, when we\\nconsidered high-volume requests coming in on the same IP address; this approach is\\nequivalent to clustering on IP address and labeling as malicious any cluster with more\\nthan 20 queries per second. This example illustrated the power of clustering via sim‐\\nple grouping, and you will find that you can go pretty far without resorting to more\\ncomplex algorithms.\\nk-means\\nk-means is usually the first algorithm that comes to mind when you think of cluster‐\\ning. k-means applies to real-valued vectors, when you know how many clusters you\\nexpect; the number of clusters is denoted by k. The goal of the algorithm is to assign\\nClustering \\n| \\n65'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 83}, page_content='each data point to a cluster such that the sum of the distances from each point to its\\ncluster centroid is minimized. Here the notion of distance is the usual Euclidean dis‐\\ntance in a vector space:\\nd x, y = ∑i xi −yi\\n2\\nIn mathematical terms, the k-means algorithm computes a cluster assignment f: X →\\n{1,…k} that minimizes the loss function:\\nL(X) = ∑\\ni\\nd(xi, cf (xi))\\nwhere X = x1, ..., xn  is your dataset, cj is the jth centroid, and d is the distance\\nbetween two points. The value L X  is called “inertia.”\\nThe standard algorithm for computing k-means clusters is as follows:\\n1. Choose k centroids c1, ..., ck at random.\\n2. Assign each data point xi to its nearest centroid.\\n3. Recompute the centroids cj by taking the average of all the data points assigned\\nto the jth cluster.\\n4. Repeat (2) and (3) until the algorithm converges; that is, the difference between\\nL X  on successive iterations is below a predetermined threshold.\\nk-means is a simple and effective clustering algorithm that scales well to very large\\ndatasets. However, there are some things for which you need to be on the lookout:\\n• Since k is a fixed parameter of the algorithm, you must choose it appropriately. If\\nyou know how many clusters you are looking for (e.g., if you are trying to cluster\\ndifferent families of malware), you can simply choose k to be that number. Other‐\\nwise, you will need to experiment with different values of k. It is also common to\\nchoose values of k that are between one to three times the number of classes\\n(labels) in your data, in case some categories are discontinuous. Warning: loss\\nfunctions computed using different values of k are not comparable to each other!\\n• You must normalize your data before using k-means. A typical normalization is\\nto map the jth coordinate xij to (xij-µj)/σj, where µj is the mean of the jth coordi‐\\nnates, and σj is the standard deviation.\\n66 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 84}, page_content='To see why normalization is necessary, consider a two-dimensional dataset whose\\nfirst coordinate ranges between 0 and 1, and whose second coordinate ranges\\nbetween 0 and 100. Clearly the second coordinate will have a much greater\\nimpact on the loss function, so you will lose information about how close\\ntogether points are in the first coordinate.\\n• Do not use k-means with categorical features, even if you can represent them as a\\nnumber. For example, you could encode “red,” “green,” and “blue” as 0, 1, and 2,\\nrespectively, but these numbers don’t make sense in a vector space—there is no\\nreason that blue should be twice as far from red as green is. This problem can be\\naddressed by one-hot encoding the categorical features as multiple binary fea‐\\ntures (as discussed in the worked example earlier in this chapter), but…\\n• Beware when using k-means with binary features. k-means can sometimes be used\\nwith binary features, encoding the two responses as 0 and 1, or −1 and 1, but\\nresults here can be unpredictable; the binary feature might become the dominant\\nfeature determining the cluster, or its information might be lost entirely.\\n• k-means loses efectiveness in high dimensions, due to the “curse of dimensional‐\\nity”—all points are roughly equally distant from each other. For best results use\\nk-means in low dimensions or after applying a dimensionality reduction algo‐\\nrithm such as principal component analysis (PCA). Another option is to use the\\nL-ininity distance, where the distance between two points is taken to be the max‐\\nimum of the difference of any coordinate:\\nd x, y = maxi xi −yi\\n• k-means works best when the initial centroids are chosen at random; however,\\nthis choice can make reproducing results difficult. Try diferent choices of initial\\ncentroids to see how the results depend on the initialization.\\n• k-means assumes that the clusters are spherical (globular) in nature. As you can\\nimagine, it does not work well on non-spherical distributions, such as the one illus‐\\ntrated in Figure 2-11.\\nClustering \\n| \\n67'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 85}, page_content='Figure 2-11. Nonspherical data distribution\\nHierarchical clustering\\nUnlike the k-means algorithm, hierarchical clustering methods are not parametrized\\nby an operator-selected value k (the number of clusters you want to create). Choosing\\nan appropriate k is a nontrivial task, and can significantly affect clustering results. \\nAgglomerative (bottom-up) hierarchical clustering builds clusters as follows (illustrated\\nin Figure 2-12):\\n1. Assign each data point to its own cluster (Figure 2-12, bottom layer).\\n2. Merge the two clusters that are the most similar, where “most similar” is deter‐\\nmined by a distance metric such as the Euclidean distance or Mahalanobis dis‐\\ntance.\\n3. Repeat step 2 until there is only one cluster remaining (Figure 2-12, top layer).\\n4. Navigate the layers of this tree (dendrogram) and select the layer that gives you\\nthe most appropriate clustering result.\\nDivisive (top-down) hierarchical clustering is another form of hierarchical clustering\\nthat works in the opposite direction. Instead of starting with as many clusters as there\\nare data points, we begin with a single cluster consisting of all data points and start\\ndividing clusters based on the distance metric, stopping when each data point is in its\\nown separate cluster.\\n68 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 86}, page_content='Figure 2-12. Agglomerative hierarchical clustering dendrogram\\nThere are some important points to take note of when considering whether to use\\nhierarchical clustering:\\n• Hierarchical clustering produces a dendrogram tree model, as illustrated in\\nFigure 2-12. This model can be more complex to analyze and takes up more stor‐\\nage space than the centroids produced by k-means, but also conveys more infor‐\\nmation about the underlying structure of the data. If model compactness or ease\\nof analysis is a priority, hierarchical clustering might not be your best option.\\n• k-means works with only a small selection of distance metrics (mostly Euclidean\\ndistance) and requires numerical data to work. In contrast, hierarchical cluster‐\\ning works with almost any kind of distance metric or similarity function, as long\\nas it produces a result that can be numerically compared (e.g., C is more similar\\nto A than to B). You can use it with categorical data, mixed type data, strings,\\nimages, and so on as long as an appropriate distance function is provided.\\n• Hierarchical clustering has high time complexity, which makes it unsuitable for\\nlarge datasets. Taking n to be the number of data points, agglomerative hierarchi‐\\ncal clustering has a time complexity of O(n2 log (n)), and naive divisive cluster‐\\ning has a time complexity of O(2n).\\nLocality-sensitive hashing\\nk-means is good for determining which items are close together when each item can\\nbe represented as a sequence of numbers (i.e., a vector in a vector space). However,\\nmany items that you would want to cluster do not easily admit such a representation.\\nThe classic example is text documents, which are of variable length and admit essen‐\\ntially an infinite choice of words and word orders. Another example is lists, such as\\nClustering \\n| \\n69'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 87}, page_content='the set of IP addresses accessed by a given user, or the set of all of a user’s friends in a\\nsocial graph.\\nOne very common similarity metric for unordered sets is Jaccard similarity. Jaccard\\nsimilarity is defined to be the proportion of common items between two sets, out of\\nall the items in the two sets. More precisely, for two sets X and Y, the Jaccard similar‐\\nity is defined as follows:\\nJ X, Y = X ∩Y\\nX ∪Y\\nTo generate clusters when your items are sets, all you need to do is find the groups of\\nitems whose Jaccard similarities are very high. The problem here is that this compu‐\\ntation is quadratic in the number of items—so as your dataset grows, finding the clus‐\\nters will quickly become impossible. Locality-sensitive hashing (LSH) attempts to solve\\nthis problem. LSH is not normally considered a clustering algorithm, but you can use\\nit as a method for grouping similar items together according to some notion of “dis‐\\ntance,” effectively achieving a similar effect to other more typical clustering algo‐\\nrithms.\\nIf the items you want to cluster are not unordered sets (e.g., a text document), the\\nfirst step is to convert them into sets. For text documents, the most straightforward\\nconversion is into a bag of words—simply, a list of all the words that are included in\\nthe document. Depending on your implementation, repeated words might or might\\nnot be included multiple times in your list, and/or “stopwords” such as “a,” “the,” and\\n“of” might be excluded.\\nHowever, the bag-of-words conversion loses an important aspect of a text document,\\nnamely the ordering of the words. To retain information about the ordering, we gen‐\\neralize the conversion into shingling: taking our list to be (overlapping) sequences of\\nconsecutive words in the document. For example, if the document was “the quick\\nbrown fox jumps over the lazy dog,” the three-word shingles would be:\\n{(the, quick, brown), (quick, brown, fox), (brown, fox, jumps), (fox, jumps, over),\\n(jumps, over, the), (over, the lazy), (the, lazy, dog)}\\nYou also can perform shingling at the character level, which can be useful for short\\ndocuments or text strings that can’t be parsed into words.\\nNow, given a dataset consisting of unordered sets, the question is how to efficiently\\ndetermine which ones are similar to one another according to the Jaccard metric. The\\nfirst step is to convert each set into a short “signature,” in such a way that documents\\nthat are similar have similar signatures. The standard algorithm for this task is Min‐\\nHash, which works as follows:\\n70 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 88}, page_content='33 Let’s try to understand why this property holds. To begin, we can simplify by assuming that there are no colli‐\\nsions between hash functions, so the hi(xj) are all distinct, and therefore mi x = mi y  implies that there are\\nsome j, j′ such that xj = yj′; or in other words, the minimal hash is of an element common to the two sets.\\nNow consider all the elements of x ∪y as a set {z1, …, zt}. If the hash function hi looks random, the probabil‐\\nity that the smallest hi(zj) is in the intersection x ∩y is exactly x ∩y / x ∪y , which is J x, y .\\n1. Choose k independent hash functions hi that take arbitrary data and output 32-\\nbit integers.\\n2. Given an item x = {x1, …, xn}, for each i, let mi(x) = min({hi(x1), … hi(xn)}).\\n3. Output the signature H(x) = (m1(x), …, mk(x)).\\nThe key property of this algorithm is that if the hash functions you choose behave\\nsufficiently randomly, then for two items x and y, the probability that mi x = mi y  is\\nequal to the Jaccard similarity of x and y.33 Because we use k independent hash func‐\\ntions, we can estimate J x, y  simply by counting the number of collisions\\nmi x = mi y  and dividing by k; the estimate becomes more accurate as k increases.\\nNow that we have computed the MinHash signatures, the key property that we just\\nlooked at implies that two elements with highly overlapping signatures have high Jac‐\\ncard similarities. Thus, to produce clusters of similar items, we must find groups of\\nsignatures that overlap in many places. There are two established ways to do this:\\n• For each i, compute the reverse mapping from mi x  to all the elements x that\\nhave that particular hash value. Now for a given element x0, we can look up all\\nthe x that match mi x0 , and keep the ones that match in at least t places.\\n• Reorganize the k hashes into b buckets, each consisting of r “rows.” Let L be a\\nsecond hash function that maps the hashes in a row to a fixed-size string. We can\\ngroup together elements whose hashes L match on all rows in at least one bucket.\\nTuning the values of b and r allows us to trade off false positives (i.e., dissimilar\\nitems where L matches) and false negatives (i.e., similar items where L doesn’t\\nmatch): a higher b reduces false negatives, whereas a higher r reduces false posi‐\\ntives. For further details, see Chapter 3 of Mining of Massive Datasets, 2nd ed., by\\nJure Leskovek, Anand Rajaraman, and Jeffrey D. Ullman (Cambridge University\\nPress).\\nMinHash is just one example of a locality-sensitive function; that is, one that maps ele‐\\nments that are close together in the input space to values that are close together in the\\noutput space. If you measure “closeness” by some metric other than Jaccard similarity\\n—for example, Euclidean distance or Hamming distance—there are specific functions\\nClustering \\n| \\n71'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 89}, page_content='that you can use instead of MinHash in the above procedure; Lescovec et al. provide\\nfurther details.\\nk-d trees\\nA k-dimensional (k-d) tree is a binary tree that stores data in a format optimized for\\nmultidimensional spatial analysis. k-d tree construction can be viewed as the pre-\\nprocessing step of k-NN classification algorithms, but it can also be thought of as its\\nown clustering algorithm. As in hierarchical clustering, the algorithm creates a tree\\nstructure, but here the clusters are stored in the leaves rather than in interior nodes.\\nThe typical algorithm used to construct k-d trees proceeds as follows. For each non-\\nleaf node, do the following:\\n1. Choose a dimension to split on.\\n2. Choose a split point (e.g., the median of this dimension in the node’s feature sub‐\\nspace).\\n3. Split the subspace according to the chosen dimension and split point.\\n4. Stop splitting subspaces when the subspace contains fewer than the number of\\nsamples per subspace, leaf_size (e.g., if leaf_size == 1, every leaf node in the tree\\nshould represent a feature subspace that contains only one sample).\\nThis procedure results in a binary search tree of feature subspaces, where the combi‐\\nnation of all leaf node subspaces makes up the entire feature space. When building k-\\nd tree models for nearest neighbor searches, the space-partitioning binary tree needs\\nto be stored in addition to the training data points. Furthermore, additional data\\nabout which samples belong to which leaf nodes needs to be stored in the model,\\nwhich makes the model even more space inefficient than vanilla k-NN models.\\nYou can use k-d trees to speed up nearest neighbor searches (e.g., during k-NN classi‐\\nfication). When searching for the k nearest neighbors of a sample x:\\n1. Starting from the root of the tree, traverse the tree looking for the node repre‐\\nsenting the feature subspace that contains x.\\n2. Analyze the feature subspace containing x:\\na. If leaf_size == k, return all points in this subspace as the result.\\nb. If leaf_size > k, do an exhaustive (brute-force) search within this feature sub‐\\nspace for the k points closest to x, and return those k points as the result.\\nc. If leaf_size < k, save all points in the subspace as part of the result and con‐\\ntinue to the next step.\\n72 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 90}, page_content='34 For high-dimensional feature spaces, k-d trees will perform similarly to a brute-force linear search.\\n35 Ram Anant, et al., “A Density Based Algorithm for Discovering Density Varied Clusters in Large Spatial Data‐\\nbases,” International Journal of Computer Applications 3:6 (2010).\\n3. Traverse one step up the tree and analyze the feature subspace represented by\\nthat node, continuing to add neighbor points to the result until all k neighbors\\nhave been found. Repeat this step as necessary to obtain k points.\\nSimilar to the k-NN algorithm, k-d trees are usually not suitable for high-dimensional\\ndata,34 and they are even bulkier than k-NN models. Nevertheless, they are very useful\\nfor quickly finding nearest neighbors, with an average-case time complexity of\\nO log n . Variations of k-d trees have been developed to address various issues with\\nthis algorithm; one example is quadtrees, which are optimized for searching in two-\\ndimensional spaces.\\nDBSCAN\\nDensity-Based Spatial Clustering of Applications with Noise35 (DBSCAN) is one of the\\nmost popular and widely used clustering algorithms because of its generally good\\nperformance in different scenarios. Unlike with k-means, the number of clusters is\\nnot operator-defined but instead inferred from the data. Unlike hierarchical cluster‐\\ning, which is distance-based, DBSCAN is a density-based algorithm that divides data‐\\nsets up into subgroups of high-density regions. Let’s consider some of the\\nterminology introduced by this algorithm:\\n• The operator passes two parameters into the algorithm:\\n— ε defines the radius around a certain point within which to search for\\nneighbors.\\n— minPoints is the minimum number of points required to form a cluster.\\n• Each data point is classified as a core point, a border point, or a noise point:\\n— Core points are points that have at least minPoints number of points within\\ntheir ε-radius.\\n— Border points are themselves not core points, but are covered within the ε-\\nradius of some core point.\\n— Noise points are neither core points nor border points.\\nIn naive implementations, this classification step is done by iterating through each\\npoint in the dataset, calculating its distance to all other points in the dataset, and then\\nassociating each point with its neighbors (points that are closer than ε distance away\\nfrom it). With this information, you can tag all points as either core, border, or noise\\nClustering \\n| \\n73'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 91}, page_content='36 Mihael Ankerst, et al., “OPTICS: Ordering Points to Identify the Clustering Structure,” SIGMOD Record 28:2\\n(1999): 49–60.\\npoints. After classifying all the data points in the dataset as one of these three types of\\npoints, the DBSCAN algorithm proceeds as follows:\\n1. Select a point P at random out of all unvisited points.\\n2. If P is not a core point, mark it as visited and continue.\\n3. If P is a core point, form a cluster around it, and recursively find and usurp all\\nother points within the ε-radius of P as well as any other point that is in the ε-\\nradius of all core points usurped by this cluster.\\nLet’s say there exists a core point Q within the ε-radius of P. Q (along with all its\\nborder points) will be added to the cluster formed around P. If there is another\\ncore point R within the ε-radius of Q, core point R (along with all its border\\npoints) will also be added to the cluster formed around P.\\nThis recursive step is repeated until there are no more core points to usurp.\\n4. Repeat until all points in the dataset have been visited.\\nEven though DBSCAN has been shown to work very well in a variety of situations,\\nthere are some caveats:\\n• DBSCAN does not work well when clusters in the dataset have diferent densities.\\nThis makes it difficult to select values of ε and minPoints that are suitable for all\\nclusters in the data. Ordering Points to Identify the Clustering Structure\\n(OPTICS)36 is an algorithm very similar to DBSCAN that addresses this weak‐\\nness by introducing spatial ordering into the point selection process, albeit at the\\ncost of speed.\\n• Careful selection of parameters ε and minPoints is important for good perfor‐\\nmance of the algorithm. It can be challenging to select good values for these\\nunless you have a good understanding of the data’s distribution and densities.\\n• The algorithm is nondeterministic and can produce different results depending\\non which points are first visited in the random selection in step 1.\\n• DBSCAN performs poorly on high-dimensional data because it most commonly\\nuses the Euclidean distance as a distance metric, which suffers from the “curse of\\ndimensionality.”\\n• If your dataset is produced by sampling a raw source, the sampling method that\\nyou use can significantly alter the density characteristics of the data. Density-\\n74 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 92}, page_content='37 W.M. Rand, “Objective Criteria for the Evaluation of Clustering Methods,” Journal of the American Statistical\\nAssociation 66 (1971): 846–850.\\n38 Nguyen Xuan Vinh, Julien Epps, and James Bailey, “Information Theoretic Measures for Clustering Compari‐\\nson: Is a Correction for Chance Necessary?”, Proceedings of the 26th Annual International Conference on\\nMachine Learning (2009): 1073–1080.\\n39 Andrew Rosenberg and Julia Hirschberg, “V-Measure: A Conditional Entropy-Based External Cluster Evalua‐\\ntion Measure,” Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing\\nand Computational Natural Language Learning (2007): 410–420.\\nbased algorithms will then be unsuitable because the results they produce rely on\\nan accurate representation of the data’s true density characteristics.\\nEvaluating Clustering Results\\nIt can sometimes be difficult to make sense of the results of clustering operations.\\nEvaluating supervised learning algorithms is a much more straightforward task\\nbecause we have access to the ground truth labels: we can simply count the number of\\nsamples to which the algorithm correctly and wrongly assigns labels. In the case of\\nunsupervised learning, it is unlikely we have access to labels, though if we do evalua‐\\ntion becomes much easier.37,38 For example, commonly used metrics for evaluating\\nclustering results if the ground truth labels are known are:\\nHomogeneity\\nThe degree to which each cluster contains only members of a single class.\\nCompleteness\\nThe degree to which all members of a certain class are assigned to the same\\ncluster.\\nThe harmonic mean of these two metrics is known as the V-measure,39 an entropy-\\nbased score representing the clustering operation’s accuracy, which has the formula:\\nv = 2hc\\nh + c\\nwhere h is homogeneity and c is completeness.\\nWe will use the scikit-learn implementations of these clustering evaluation metrics in\\nChapter 5.\\nOn the other hand, the fact that we are considering clustering at all means it is likely\\nthat we do not have any ground truth labels for our dataset. Instead, we can no longer\\nuse the V-measure because both homogeneity and completeness can be measured\\nonly by comparing prediction labels to ground truth labels. In this case, we have to\\nClustering \\n| \\n75'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 93}, page_content='40 Peter Rousseeuw, “Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis,” Jour‐\\nnal of Computational and Applied Mathematics 20 (1987): 53–65.\\n41 Wei Wang, Jiong Yang, and Richard Muntz, “STING: A Statistical Information Grid Approach to Spatial Data\\nMining,” Proceedings of the 23rd International Conference on Very Large Data Bases (1997): 186–195.\\nrely on signals derived directly from the trained model itself. Essentially, we consider\\nthe clustering operation to be successful if samples assigned to the same cluster are all\\nsimilar to one another, and samples assigned to different clusters are all completely\\ndissimilar from one another. There are two popular ways to measure this:\\nSilhouette coeicient\\nThis score is calculated separately for each sample in the dataset. Using some dis‐\\ntance metric (e.g., Euclidean distance), we find the following two mean distances\\nfor some sample x:\\n• a: the mean distance between sample x and all other samples in the same\\ncluster\\n• b: the mean distance between sample x and all other samples in the next\\nnearest cluster\\nThe Silhouette coefficient s is then defined as follows:40\\ns =\\nb −a\\nmax a, b\\nFor a clustering result that is hugely incorrect, the a will be much larger than b,\\nresulting in the numerator being negative. Because the denominator will never be\\nnegative (distance metrics do not take on negative values), s will itself be nega‐\\ntive. In fact, s is bounded between −1 and +1. The closer s is to +1, the better the\\nclustering result. When s is very close to 0, we have highly overlapping clusters.\\nNevertheless, it is found that the Silhouette coefficient is biased toward distance-\\nbased (e.g., k-means), grid-based (e.g., STING41), and hierarchical clustering algo‐\\nrithms that produce convex clusters. It does not work well for clusters produced\\nby density-based algorithms such as DBSCAN and OPTICS, because neither a\\nnor b take cluster density into consideration. Also, because the Silhouette coeffi‐\\ncient must be independently calculated for each sample in the dataset, it can be\\nquite slow.\\n76 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 94}, page_content='42 Tadeusz Caliński and J.A. Harabasz, “A Dendrite Method for Cluster Analysis: Communications in Statistics,”\\nheory and Methods 3 (1974): 1–27.\\n43 The trace of a matrix is defined to be the sum of the elements on the diagonal (upper left to lower right).\\nCalinski-Harabaz index\\nThe Calinski-Harabaz (C-H) index42 is higher (better) when clusters are dense\\nand well separated. By most measures, this measure of clustering effectiveness is\\ncloser to how humans evaluate clustering results. We consider a clustering result\\nto be good if there are visibly separated and densely gathered groups of samples.\\nThe C-H index uses two measures:\\n• Wk: the within-cluster dispersion, a matrix of distances between samples in a\\ncluster and the geometric center of the cluster\\n• Bk: the between-group dispersion, a matrix of distances between the center of\\na cluster and the centers of all other clusters\\n(Here, k is the number of clusters in the model.)\\nThe C-H score (s) takes the ratio of Wk and Bk (where N is the number of sam‐\\nples in the dataset and tr is the trace of the matrix43):\\ns =\\ntr Bk\\ntr Wk\\n× N −k\\nk −1\\nThe C-H score can be computed much more efficiently than the Silhouette index.\\nEven though it is still biased against density-based clusters, it is comparatively\\nmore reliable than the Silhouette index.\\nNo matter which method you choose, there will be some inherent limitations in eval‐\\nuating clustering results without any human labeling. If you suspect that clustering\\nmodels are not performing well in practice in spite of good evaluation metrics, it may\\nbe necessary to invest resources in manually labeling a subset of samples and use\\nsemi-supervised approaches to evaluate the model.\\nConclusion\\nMachine learning, at its most basic, is the process of using historical data to derive a\\nprediction algorithm for previously unseen data. In this chapter, we focused on classi‐\\nfication (i.e., determining which category each data point belongs to) and clustering\\n(i.e., determining which data points are similar to each other). Classification can be\\nsupervised, in which case the historical data comes with class labels; the unsupervised\\nConclusion \\n| \\n77'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 95}, page_content='case, in which there are no (or very few) historical labels, is more amenable to\\nclustering.\\nWe described, at a high level, a number of commonly used classification and cluster‐\\ning algorithms, and we made some sense of which tasks each algorithm is good at.\\nThe details behind all of these algorithms could fill an entire textbook; indeed, Hastie,\\nTibshirani, and Friedman cover much of the applicable theory in their book he Ele‐\\nments of Statistical Learning (Springer), and we recommend it if you are interested.\\nThe algorithms we discussed require a significant amount of data to be effective—the\\nmore data, the better. But what happens if the event you are trying to detect is very\\nrare? Solving this problem will be the subject of the next chapter.\\n78 \\n| \\nChapter 2: Classifying and Clustering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 96}, page_content='CHAPTER 3\\nAnomaly Detection\\nThis chapter is about detecting unexpected events, or anomalies, in systems. In the\\ncontext of network and host security, anomaly detection refers to identifying unexpec‐\\nted intruders or breaches. On average it takes tens of days for a system breach to be\\ndetected. After an attacker gains entry, however, the damage is usually done in a few\\ndays or less. Whether the nature of the attack is data exfiltration, extortion through\\nransomware, adware, or advanced persistent threats (APTs), it is clear that time is not\\non the defender’s side.\\nThe importance of anomaly detection is not confined to the context of security. In a\\nmore general context, anomaly detection is any method for finding events that don’t\\nconform to an expectation. For instances in which system reliability is of critical\\nimportance, you can use anomaly detection to identify early signs of system failure,\\ntriggering early or preventive investigations by operators. For example, if the power\\ncompany can find anomalies in the electrical power grid and remedy them, it can\\npotentially avoid expensive damage that occurs when a power surge causes outages in\\nother system components. Another important application of anomaly detection is in\\nthe field of fraud detection. Fraud in the financial industry can often be fished out of\\na vast pool of legitimate transactions by studying patterns of normal events and\\ndetecting when deviations occur.\\nTerminology\\nThroughout the course of this chapter, we use the terms “outlier” and “anomaly”\\ninterchangeably. On the other hand, there is an important distinction between outlier\\ndetection and novelty detection. The task of novelty detection involves learning a rep‐\\nresentation of “regular” data using data that does not contain any outliers, whereas\\nthe task of outlier detection involves learning from data that contains both regular\\n79'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 97}, page_content='data and outliers. The importance of this distinction is discussed later in the chapter.\\nBoth novelty detection and outlier detection are forms of anomaly detection.\\nWe refer to nonanomalous data points as regular data. Do not confuse this with any\\nreferences made to normal or standard data. The term “normal” used in this chapter\\nrefers to its meaning in statistics; that is, a normal (Gaussian) distribution. The term\\n“standard” is also used in the statistical context, referring to a normal distribution\\nwith mean zero and unit variance.\\nA time series is a sequence of data points of an event or process observed at successive\\npoints in time. These data points, often collected at regular intervals, constitute a\\nsequence of discrete metrics that characterize changes in the series as time progresses.\\nFor example, a stock chart depicts the time series corresponding to the value of the\\ngiven stock over time. In the same vein, Bash commands entered into a command-\\nline shell can also form a time series. In this case, the data points are not likely to be\\nequally spaced in time. Instead, the series is event-driven, where each event is an exe‐\\ncuted command in the shell. Still, we will consider such a data stream as a time series\\nbecause each data point is associated with the time of a corresponding event occur‐\\nrence.\\nThe study of anomaly detection is closely coupled with the concept of time series\\nanalysis because an anomaly is often defined as a deviation from what is normal or\\nexpected, given what had been observed in the past. Studying anomalies in the con‐\\ntext of time thus makes a lot of sense. In the following pages we look at what anomaly\\ndetection is, examine the process of generating a time series, and discuss the techni‐\\nques used to identify anomalies in a stream of data.\\nWhen to Use Anomaly Detection Versus Supervised\\nLearning\\nAs we discussed in Chapter 1, anomaly detection is often conflated with pattern rec‐\\nognition—for example, using supervised learning—and it is sometimes unclear\\nwhich approach to take when looking to develop a solution for a problem. For exam‐\\nple, if you are looking for fraudulent credit card transactions, it might make sense to\\nuse a supervised learning model if you have a large number of both legitimate and\\nfraudulent transactions with which to train your model. Supervised learning would\\nbe especially suited for the problem if you expect future instances of fraud to look\\nsimilar to the examples of fraud you have in your training set. Credit card companies\\nsometimes look for specific patterns that are more likely to appear in fraudulent\\ntransactions than in legitimate ones: for example, large purchases made after small\\npurchases, purchases from an unusual location, or purchases of a product that doesn’t\\nfit the customer’s spending profile. These patterns can be extracted from a body of\\npositive and negative training examples via supervised learning.\\n80 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 98}, page_content='1 Dorothy Denning, “An Intrusion-Detection Model,” IEEE Transactions on Sotware Engineering SE-13:2\\n(1987): 222–232.\\n2 See chapter3/ids_heuristics_a.py in our code repository.\\nIn many other scenarios, it can be difficult to find a representative pool of positive\\nexamples that is sufficient for the algorithm to get a sense of what positive events are\\nlike. Server breaches are sometimes caused by zero-day attacks or newly released vul‐\\nnerabilities in software. By definition, the method of intrusion cannot be predicted in\\nadvance, and it is difficult to build a profile of every possible method of intrusion in a\\nsystem. Because these events are relatively rare, this also contributes to the class\\nimbalance problem that makes for difficult application of supervised learning.\\nAnomaly detection is perfect for such problems.\\nIntrusion Detection with Heuristics\\nIntrusion detection systems (IDSs)1 have been around since 1986 and are common‐\\nplace in security-constrained environments. Even today, using thresholds, heuristics,\\nand simple statistical profiles remains a reliable way of detecting intrusions and\\nanomalies. For example, suppose that we define 10 queries per hour to be the upper\\nlimit of normal use for a certain database. Each time the database is queried, we\\ninvoke a function is_anomaly(user) with the user’s ID as an argument. If the user\\nqueries the database for an 11th time within an hour, the function will indicate that\\naccess as an anomaly.2\\nAlthough threshold-based anomaly detection logic is easy to implement, some ques‐\\ntions quickly arise. How do we set the threshold? Could some users require a higher\\nthreshold than others? Could there be times when users legitimately need to access\\nthe database more often? How frequently do we need to update the threshold? Could\\nan attacker exfiltrate data by taking over many user accounts, thus requiring a smaller\\nnumber of accesses per account? We shall soon see that using machine learning can\\nhelp us to avoid having to come up with answers to all of these questions, instead let‐\\nting the data define the solution to the problem.\\nThe first thing we might want to try to make our detection more robust is to replace\\nthe hardcoded threshold of 10 queries per hour with a threshold dynamically gener‐\\nated from the data. For example, we could compute a moving average of the number\\nof queries per user per day, and every time the average is updated set the hourly thres‐\\nhold to be a fixed multiple of the daily average. (A reasonable multiple might be 5/24;\\nthat is, having the hourly threshold be five times the hourly average.)\\nWe can make further improvements:\\nIntrusion Detection with Heuristics \\n| \\n81'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 99}, page_content='3 See chapter3/ids_heuristics_b.py in our code repository.\\n• Because data analysts will likely need to query customer data with a greater fre‐\\nquency than receptionists, we could classify users by roles and set different query\\nthresholds for each role.\\n• Instead of updating the threshold with averages that can be easily manipulated,\\nwe can use other statistical properties of the dataset. For example, if we use the\\nmedian or interquartile ranges, thresholds will be more resistant to outliers and\\ndeliberate attempts to tamper with the integrity of the system.\\nThe preceding method uses simple statistical accumulation to avoid having to man‐\\nually define a threshold, but still retains characteristics of the heuristic method,\\nincluding having to decide on arbitrary parameters such as avg_multiplier. How‐\\never, in an adaptive-threshold solution, we begin to see the roots of machine learning\\nanomaly detectors. The query_threshold3 is reminiscent of a model parameter\\nextracted from a dataset of regular events, and the hourly threshold update cycle is\\nthe continuous training process necessary for the system to adapt to changing user\\nrequirements.\\nStill, it is easy to see the flaws in a system like this. In an artificially simple environ‐\\nment such as that described here, maintaining a single threshold parameter that\\nlearns from a single feature in the system (query counts per user, per hour) is an\\nacceptable solution. However, in even slightly more complex systems, the number of\\nthresholds to compute can quickly get out of hand. There might even be common\\nscenarios in which anomalies are not triggered by a single threshold, but by a combi‐\\nnation of different thresholds selected differently in different scenarios. In some sit‐\\nuations, it might even be inappropriate to use a deterministic set of conditions. If user\\nA makes 11 queries in the hour, and user B makes 99 queries in the hour, shouldn’t\\nwe assign a higher risk score to B than to A? A probabilistic approach might make\\nmore sense and allow us to estimate the likelihood that an event is anomalous instead\\nof making binary decisions.\\nData-Driven Methods\\nBefore beginning to explore alternative solutions for anomaly detection, it is impor‐\\ntant that we define a set of objectives for an optimal anomaly detection system:\\nLow false positives and false negatives\\nThe term anomaly suggests an event that stands out from the rest. Given this\\nconnotation, it might seem counterintuitive to suggest that finding anomalies is\\noften akin to locating a white rabbit in a snowstorm. Because of the difficulty of\\nreliably defining normality with a descriptive feature set, anomalies raised by\\n82 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 100}, page_content='systems can sometimes be fraught with false alarms (false positives) or missed\\nalerts (false negatives).\\nFalse negatives occur when the system does not find something that the users\\nintend it to find. Imagine that you install a new deadbolt lock on your front door,\\nand it only manages to thwart 9 out of 10 lockpick attempts. How would you feel\\nabout the effectiveness of the lock? Conversely, false positives occur when the\\nsystem erroneously recognizes normal events as anomalous ones. If you try\\nunlocking the bolt with the key and it refuses to let you in, thinking that you are\\nan intruder, that is a case of a false positive.\\nFalse positives can seem benign, and having an aggressive detection system that\\n“plays it safe” and raises alerts on even the slightest suspicion of anomalies might\\nnot seem like a bad option. However, every alert has a cost associated with it, and\\nevery false alarm wastes precious time of human analysts who must investigate it.\\nHigh false alarm rates can rapidly degrade the integrity of the system, and ana‐\\nlysts will no longer treat anomaly alerts as events requiring speedy response and\\ncareful investigation. An optimal anomaly detector would accurately find all\\nanomalies with no false positives.\\nEasy to conigure, tune, and maintain\\nAs we’ve seen, configuring anomaly detection systems can be a nontrivial task.\\nInadequate configuration of threshold-based systems directly causes false posi‐\\ntives or false negatives. After there are more than a handful of parameters to\\ntune, you lose the attention of users, who will often fall back to default values (if\\navailable) or random values. System usability is greatly affected by the ease of ini‐\\ntial configuration and long-term maintenance. A machine learning anomaly\\ndetector that has been sitting in your network for a long period of time might\\nstart producing a high rate of false alarms, causing an operator to have to dive in\\nto investigate. An optimal anomaly detector should provide a clear picture of\\nhow changing system parameters will directly cause a change in the quality,\\nquantity, and nature of alert outputs.\\nAdapts to changing trends in the data\\nSeasonality is the tendency of data to show regular patterns due to natural cycles\\nof user activity (e.g., low activity on weekends). Seasonality needs to be addressed\\nin all time series pattern-recognition systems, and anomaly detectors are no\\nexception. Different datasets have different characteristics, but many exhibit\\nsome type of seasonality across varying periodicities. For example, web traffic\\nthat originates from a dominant time zone will have a diurnal pattern that peaks\\nin the day and troughs in the night. Most websites see higher traffic on weekdays\\ncompared to weekends, whereas other sites see the opposite trend. Some season‐\\nality trends play out over longer periods. Online shopping websites expect a spike\\nin traffic every year during the peak shopping seasons, whereas traffic to the\\nData-Driven Methods \\n| \\n83'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 101}, page_content='4 A kernel is a function that is provided to a machine learning algorithm that indicates how similar two inputs\\nare. Kernels offer an alternate approach to feature engineering—instead of extracting individual features from\\nthe raw data, kernel functions can be efficiently computed, sometimes in high-dimensional space, to generate\\nimplicit features from the data that would otherwise be expensive to generate. The approach of efficiently\\ntransforming data into a high-dimensional, implicit feature space is known as the kernel trick. Chapter 2 pro‐\\nvides more details.\\nUnited States Internal Revenue Service (IRS) website builds up between January\\nand April, and then drops off drastically afterward.\\nAnomaly detection algorithms that do not have a mechanism for capturing sea‐\\nsonality will suffer high false positive rates when these trends are observed to be\\ndifferent from previous data. Organic drit in the data caused by viral promotions\\nor more a gentle uptick in popularity of certain entities can also cause anomaly\\ndetectors to raise alerts for events that do not require human intervention. An\\nideal anomaly detection system would be able to identify and learn all trends in\\nthe data and adjust for them when performing outlier detection.\\nWorks well across datasets of diferent nature\\nEven though the Gaussian distribution dominates many areas of statistics, not all\\ndatasets have a Gaussian distribution. In fact, few anomaly detection problems in\\nsecurity are suitably modeled using a Gaussian distribution. Density estimation is\\na central concept in modeling normality for anomaly detection, but there are\\nother kernels4 that can be more suitable for modeling the distribution of your\\ndataset. For example, some datasets might be better fitted with the exponential,\\ntophat, cosine, or Epanechnikov kernels. An ideal anomaly detection system\\nshould not make assumptions about the data, and should work well across data\\nwith different properties.\\nResource-eicient and suitable for real-time application\\nEspecially in the context of security, anomaly detection is often a time-sensitive\\ntask. Operators want to be alerted of potential breaches or system failures within\\nminutes of suspicious signals. Every second counts when dealing with an attacker\\nthat is actively exploiting a system. Hence, these anomaly detection systems need\\nto run in a streaming fashion, consuming data and generating insights with mini‐\\nmal latency. This requirement rules out some slow and/or resource-intensive\\ntechniques.\\nExplainable alerts\\nAuditing alerts raised by an anomaly detector is important for evaluating the sys‐\\ntem as well as investigating false positives and negatives. We can easily audit\\nalerts that come from a static threshold-based anomaly detector. Simply running\\nthe event through the rule engine again will indicate exactly which conditions\\ntriggered the alert. For adaptive systems and machine learning anomaly detec‐\\n84 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 102}, page_content='tors, however, the problem is more complex. When there is no explicit decision\\nboundary for the parameters within the system, it can sometimes be difficult to\\npoint to a specific property of the event that triggered an alert. Lack of explaina‐\\nbility makes it difficult to debug and tune systems and leads to lower confidence\\nin the decisions made by the detection engine. The explainability problem is an\\nactive research topic in the field of machine learning and is not exclusive to the\\nanomaly detection paradigm. However, when alerts must be audited in a time-\\npressured environment, having clear explanations can make for a much easier\\ndecision-making process by the human or machine components that react to\\nanomaly alerts.\\nFeature Engineering for Anomaly Detection\\nAs with any other task in machine learning, selecting good features for anomaly\\ndetection is of paramount importance. Many online (streaming) anomaly detection\\nalgorithms require input in the form of a time series data stream. If your data source\\nalready outputs metrics in this form, you might not need to do any further feature\\nengineering. For example, to detect when a system process has an abnormally high\\nCPU utilization, all you will need is the CPU utilization metric, which you can extract\\nfrom most basic system monitoring modules. However, many use cases will require\\nyou to generate your own data streams on which to apply anomaly detection\\nalgorithms.\\nIn this section, we focus our feature engineering discussions on three domains: host\\nintrusion detection, network intrusion detection, and web application intrusion detec‐\\ntion. There are notable differences between the three, and each requires a set of\\nunique considerations that are specific to its particular space. We take a look at exam‐\\nples of tools that you can use to extract these features, and evaluate the pros and cons\\nof the different methods of feature extraction.\\nOf course, anomaly detection is not restricted to hosts and networks only. Other use\\ncases such as fraud detection and detecting anomalies in public API calls also rely on\\ngood feature extraction to achieve a reliable data source on which to apply algo‐\\nrithms. After we have discussed the principles of extracting useful features and time\\nseries data from the host and network domains, it will be your job to apply these\\nprinciples to your specific application domain.\\nHost Intrusion Detection\\nWhen developing an intrusion detection agent for hosts (e.g., servers, desktops, lap‐\\ntops, embedded systems), you will likely need to generate your own metrics and\\nmight even want to perform correlations of signals collected from different sources.\\nThe relevance of different metrics varies widely depending on the threat model, but\\nbasic system- and network-level statistics make for a good starting point. You can\\nFeature Engineering for Anomaly Detection \\n| \\n85'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 103}, page_content='carry out the collection of these system metrics in a variety of ways, and there is a\\ndiversity of tools and frameworks to help you with the task. We’ll take a look at\\nosquery, a popular operating system (OS) instrumentation framework that collects\\nand exposes low-level OS metrics, making them available for querying through a\\nSQL-based interface. Making scheduled queries through osquery can allow you to\\nestablish a baseline of host and application behavior, thereby allowing the intrusion\\ndetector to identify suspicious events that occur unexpectedly.\\nMalware is the most dominant threat vector for hosts in many environments. Of\\ncourse, malware detection and analysis warrants its own full discussion, which we\\nprovide in Chapter 4. For now, we base our analysis on the assumption that most\\nmalware affects system-level actions, and therefore we can detect the malware by col‐\\nlecting system-level activity signals and looking for indicators of compromise (IoCs)\\nin the data. Here are examples of some common signals that you can collect:\\n• Running processes\\n• Active/new user accounts\\n• Kernel modules loaded\\n• DNS lookups\\n• Network connections\\n• System scheduler changes\\n• Daemon/background/persistent processes\\n• Startup operations, launchd entries\\n• OS registry databases, .plist files\\n• Temporary file directories\\n• Browser extensions\\nThis list is far from exhaustive; different types of malware naturally generate different\\nsets of behavior, but collecting a wide range of signals will ensure that you have visi‐\\nbility into the parts of the system for which the risk of compromise by malware is the\\nhighest.\\nosquery\\nIn osquery, you can schedule queries to be run periodically by the osqueryd daemon,\\npopulating tables that you can then query for later inspection. For investigative pur‐\\nposes, you can also run queries in an ad hoc fashion by using the command-line\\ninterface, osqueryi. An example query that gives you a list of all users on the system is\\nas follows:\\nSELECT * FROM users;\\n86 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 104}, page_content='5 You can find an example configuration file on GitHub.\\nIf you wanted to locate the top five memory-hogging processes:\\nSELECT pid, name, resident_size FROM processes\\nORDER BY resident_size DESC LIMIT 5\\nAlthough you can use osquery to monitor system reliability or compliance, one of its\\nprincipal applications is to detect behavior on the system that could potentially be\\ncaused by intruders. A malicious binary will usually try to reduce its footprint on a\\nsystem by getting rid of any traces it leaves in the filesystem; for example, by deleting\\nitself after it starts execution. A common query for finding anomalous running binar‐\\nies is to check for currently running processes that have a deleted executable:\\nSELECT * FROM processes WHERE on_disk = 0;\\nSuppose that this query generates some data that looks like this:\\n2017-06-04T18:24:17+00:00        []\\n2017-06-04T18:54:17+00:00        []\\n2017-06-04T19:24:17+00:00        [\"/tmp/YBBHNCA8J0\"]\\n2017-06-04T19:54:17+00:00        []\\nA very simple way to convert this data into a numerical time series is to use the length\\nof the list as the value. It should then be clear that the third entry in this example will\\nregister as an anomaly.\\nBesides tapping into system state, the osquery daemon can also listen in on OS-level\\nevents such as filesystem modifications and accesses, drive mounts, process state\\nchanges, network setting changes, and more. This allows for event-based OS intro‐\\nspection to monitor filesystem integrity and audit processes and sockets.\\nosquery includes convenient query packs—sets of queries and met‐\\nrics grouped by problem domain and use case that users can down‐\\nload and apply to the osquery daemon. For example, the incident-\\nresponse pack exposes metrics related to the application firewall,\\ncrontab, IP forwarding, iptables, launchd, listening ports, drive\\nmounts, open files and sockets, shell history, startup items, and\\nmore. The osx-attacks pack looks for specific signals exhibited by a\\nset of common macOS malware, checking for specific plists, pro‐\\ncess names, or applications that a well-known piece of malware\\ninstalls.\\nYou can set up osquery by creating a configuration file that defines what queries and\\npacks the system should use.5 For instance, you can schedule a query to run every half\\nhour (i.e., every 1,800 seconds) that detects deleted running binaries by putting the\\nfollowing query statement in the configuration:\\nFeature Engineering for Anomaly Detection \\n| \\n87'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 105}, page_content='{\\n ...\\n  // Define a schedule of queries to run periodically:\\n  \"deleted_running_binary\": {\\n    \"query\": \"SELECT * FROM processes WHERE on_disk = 0;\",\\n    \"interval\": 1800\\n  }\\n  ...\\n}\\nNote that osquery can log query results as either snapshots or differentials. Differen‐\\ntial logging can be useful in reducing the verbosity of received information, but it can\\nalso be more complex to parse. After the daemon logs this data, extracting time series\\nmetrics is simply a matter of analyzing log files or performing more SQL queries on\\nthe generated tables.\\nLimitations of osquery for Security\\nIt is important to consider that osquery wasn’t designed to operate\\nin an untrusted environment. There’s no built-in feature to obfus‐\\ncate osquery operations and logs, so it’s possible for malware to\\nmeddle with the metric collection process or osquery logs/database\\nto hide its tracks. Although it’s simple to deploy osquery on a single\\nhost, most operationally mature organizations are likely to have\\nmultiple servers in a variety of flavors deployed in a variety of envi‐\\nronments. There’s no built-in capability for orchestration or central\\ndeployment and control in osquery, so you need to exert some\\ndevelopment effort to integrate it into your organization’s automa‐\\ntion and orchestration frameworks (e.g., Chef, Puppet, Ansible,\\nSaltStack). Third-party tools intended to make the operationaliza‐\\ntion of osquery easier, such as Kolide for distributed osquery com‐\\nmand and control and doorman, an osquery distributed fleet\\nmanager, are also growing in number.\\nAlternatives to osquery\\nThere are many open source and commercial alternatives to\\nosquery that can help you to achieve the same end result: continu‐\\nous and detailed introspection of your hosts. Mining the wealth of\\ninformation that many Unix-based systems provide natively (e.g.,\\nin /proc) is a lightweight solution that might be sufficient for your\\nuse case. The Linux Auditing System (auditd, etc.) is much more\\nmature than osquery and is a tool that forensics experts and opera‐\\ntional gurus have sworn by for decades.\\n88 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 106}, page_content='Network Intrusion Detection\\nAlmost all forms of host intrusion instigate communication with the outside world.\\nMost breaches are carried out with the objective of stealing some valuable data from\\nthe target, so it makes sense to detect intrusions by focusing on the network. For bot‐\\nnets, remote command-and-control servers communicate with the compromised\\n“zombie” machines to give instructions on operations to execute. For APTs, hackers\\ncan remotely access the machines through a vulnerable or misconfigured service,\\nallowing them shell and/or root access. For adware, communication with external\\nservers is required for downloading unsolicited ad content. For spyware, results of\\nthe covert monitoring are often transmitted over the network to an external receiving\\nserver.\\nFrom simple protocol-tapping utilities like tcpdump to some more complex sniffing\\ntools like Bro, the network intrusion detection software ecosystem has many utilities\\nand application suites that can help you collect signals from network traffic of all\\nsorts. Network intrusion detection tools operate on the basic concept of inspecting\\ntraffic that passes between hosts. Just like with host intrusion detection, attacks can be\\nidentified either by matching traffic to a known signature of malicious traffic or by\\nanomaly detection, comparing traffic to previously established baselines. In this sec‐\\ntion, we focus on anomaly detection rather than signature matching; however, we do\\nexamine the latter in Chapter 4, which discusses malware analysis in depth.\\nSnort is a popular open source IDS that sniffs packets and network traffic for real-\\ntime anomaly detection. It is the de facto choice for intrusion-detection monitoring,\\nproviding a good balance of usability and functionality. Furthermore, it is backed by a\\nvibrant open source community of users and contributors who have created add-ons\\nand GUIs for it. Snort has a relatively simple architecture, allowing users to perform\\nreal-time traffic analysis on IP networks, write rules that can be triggered by detected\\nconditions, and compare traffic to an established baseline of the normal network\\ncommunication profile.\\nIn extracting features for network intrusion detection, there is a noteworthy differ‐\\nence between extracting network traffic metadata and inspecting network traffic con‐\\ntent. The former is used in stateful packet inspection (SPI), working at the network\\nand transport layers—OSI layers 3 and 4—and examining each network packet’s\\nheader and footer without touching the packet context. This approach maintains state\\non previous packets received, and hence is able to associate newly received packets\\nwith previously seen packets. SPI systems are able to know whether a packet is part of\\na handshake to establish a new connection, a section of an existing network connec‐\\ntion, or an unexpected rogue packet. These systems are useful in enforcing access\\ncontrol—the traditional function of network irewalls—because they have a clear pic‐\\nture of the IP addresses and ports involved in correspondence. They can also be\\nFeature Engineering for Anomaly Detection \\n| \\n89'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 107}, page_content=\"6 Frédéric Cuppens et al., “Handling Stateful Firewall Anomalies,” Proceedings of the IFIP International Informa‐\\ntion Security Conference (2012): 174-186.\\n7 Ganesh Kumar Varadarajan, “Web Application Attack Analysis Using Bro IDS,” SANS Institute (2012).\\nuseful in detecting slightly more complex layer 3/4 attacks6 such as IP spoofing,\\nTCP/IP attacks (such as ARP cache poisoning or SYN flooding), and denial-of-\\nservice (DOS) attacks. However, there are obvious limitations to restricting analysis\\nto just packet headers and footers. For example, SPI cannot detect signs of breaches\\nor intrusions on the application level, because doing so would require a deeper level\\nof inspection.\\nDeep packet inspection\\nDeep packet inspection (DPI) is the process of examining the data encapsulated in net‐\\nwork packets, in addition to the headers and footers. This allows for the collection of\\nsignals and statistics about the network correspondence originating from the applica‐\\ntion layer. Because of this, DPI is capable of collecting signals that can help detect\\nspam, malware, intrusions, and subtle anomalies. Real-time streaming DPI is a chal‐\\nlenging computer science problem because of the computational requirements neces‐\\nsary to decrypt, disassemble, and analyze packets going through a network\\nintersection.\\nBro is one of the earliest systems that implemented a passive network monitoring\\nframework for network intrusion detection. Bro consists of two components: an effi‐\\ncient event engine that extracts signals from live network traffic, and a policy engine\\nthat consumes events and policy scripts and takes the relevant action in response to\\ndifferent observed signals.\\nOne thing you can use Bro for is to detect suspicious activity in web applications by\\ninspecting the strings present in the POST body of HTTP requests. For example, you\\ncan detect SQL injections and cross-site scripting (XSS) reflection attacks by creating\\na profile of the POST body content for a particular web application entry point. A\\nsuspicion score can be generated by comparing the presence of certain anomalous\\ncharacters (the ' character in the case of SQL injections, and the < or > script tag sym‐\\nbols in the case of XSS reflections) with the baseline, which can be valuable signals for\\ndetecting when a malicious actor is attacking your web application.7\\nThe set of features to generate through DPI for anomaly detection is strongly depen‐\\ndent on the nature of the applications that operate within your network as well as the\\nthreat vectors relevant to your infrastructure. If your network does not include any\\noutward-facing web servers, using DPI to detect XSS attacks is irrelevant. If your net‐\\nwork contains only point-of-sale systems connected to PostgreSQL databases storing\\ncustomer data, perhaps you should focus on unexpected network connections that\\ncould be indicative of an attacker pivoting in your network.\\n90 \\n| \\nChapter 3: Anomaly Detection\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 108}, page_content='8 Ralf Staudemeyer and Christian Omlin, “Extracting Salient Features for Network Intrusion Detection Using\\nMachine Learning Methods,” South African Computer Journal 52 (2014): 82–96.\\nPivoting, or island hopping, is a multilayered attack strategy used by\\nhackers to circumvent firewall restrictions in a network. A properly\\nconfigured network will not allow external accesses to a sensitive\\ndatabase. However, if there is a publicly accessible and vulnerable\\ncomponent in a network with internal access to the database,\\nattackers can exploit that component and hop over to the database\\nservers, indirectly accessing the machines. Depending on the open\\nports and allowed protocols between the compromised host and\\nthe target host, attackers can use different methods for pivoting.\\nFor example, the attacker might set up a proxy server on the com‐\\npromised host, creating a covert tunnel between the target and the\\noutside world.\\nIf DPI is used in an environment with Transport Layer Security/Secure Sockets Layer\\n(TLS/SSL) in place, where the packets to be inspected are encrypted, the application\\nperforming DPI must terminate SSL. DPI essentially requires the anomaly detection\\nsystem to operate as a man-in-the-middle, meaning that communication passing\\nthrough the inspection point is no longer end-to-end secure. This architecture can\\npose a serious security and/or performance risk to your environment, especially for\\ncases in which SSL termination and reencryption of packets is improperly imple‐\\nmented. You need to review and audit feature generation techniques that intercept\\nTLS/SSL traffic very carefully before deploying them in production.\\nFeatures for network intrusion detection\\nThe Knowledge Discovery and Data Mining Special Interest Group (SIGKDD) from\\nthe Association of Computing Machinery (ACM) holds the KDD Cup every year,\\nposing a different challenge to participants. In 1999, the topic was “computer network\\nintrusion detection”, in which the task was to “learn a predictive model capable of\\ndistinguishing between legitimate and illegitimate connections in a computer net‐\\nwork.” This artificial dataset is very old and has been shown to have significant flaws,\\nbut the list of derived features provided by the dataset is a good source of example\\nfeatures to extract for network intrusion detection in your own environment. Staude‐\\nmeyer and Omlin have used this dataset to find out which of these features are most\\nimportant;8 their work might be useful to refer to when considering what types of fea‐\\ntures to generate for network anomaly and intrusion detection. Aggregating transac‐\\ntions by IP addresses, geolocation, netblocks (e.g., /16, /14), BFP prefixes,\\nautonomous system number (ASN) information, and so on can often be good ways to\\nFeature Engineering for Anomaly Detection \\n| \\n91'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 109}, page_content='9 Alex Pinto, “Applying Machine Learning to Network Security Monitoring,” Black Hat webcast presented May\\n2014, http://ubm.io/2D9EUru.\\ndistill complex network captures and generate simple count metrics for anomaly\\ndetection.9\\nWeb Application Intrusion Detection\\nWe saw earlier that we can detect web application attacks like XSS and SQL injections\\nby using deep network packet inspection tools such as Bro. Inspecting HTTP server\\nlogs can provide you with a similar level of information and is a more direct way of\\nobtaining features derived from web application user interactions. Standard web\\nservers like Apache, IIS, and Nginx generate logs in the NCSA Common Log Format,\\nalso called access logs. NCSA combined logs and error logs also record information\\nabout the client’s user agent, referral URL, and any server errors generated by\\nrequests. In these logs, each line represents a separate HTTP request made to the\\nserver, and each line is made up of tokens in a well-defined format. Here is an exam‐\\nple of a record in the combined log format that includes the requestor’s user agent\\nand referral URL:\\n123.123.123.123 - jsmith [17/Dec/2016:18:55:05 +0800] \"GET /index.html HTTP/1.0\"\\n200 2046 \"http://referer.com/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.17.3)\\nAppleWebKit/536.27.14 (KHTML, like Gecko) Chrome/55.0.2734.24 Safari/536.27.14\"\\nUnlike DPI, the standard web access logs do not log POST body data out of the box.\\nThis means that attack vectors embedded in the user input cannot be detected by\\ninspecting standard access logs.\\nMost popular web servers provide modules and plug-ins that\\nenable you to log HTTP data payloads. Apache’s mod_dumpio mod‐\\nule logs all input received and output sent by the server. You can\\nadd the proxy_pass or fastcgi_pass directives to the Nginx con‐\\nfiguration file to force Nginx servers to populate the\\n$request_body variable with the actual POST request body con‐\\ntent. Microsoft provides IIS servers with the Advanced Logging\\nextension, which you can configure to log POST data.\\nEven with the comparatively limited scope of visibility provided in standard HTTP\\nserver log files, there are still some interesting features that you can extract:\\nIP-level access statistics\\nHigh frequency, periodicity, or volume by a single IP address or subnet is\\nsuspicious.\\n92 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 110}, page_content='10 Roger Meyer, “Detecting Attacks on Web Applications from Log Files,” SANS Institute (2008).\\nURL string aberrations\\nSelf-referencing paths (/./) or backreferences (/../) are frequently used in path-\\ntraversal attacks.\\nDecoded URL and HTML entities, escaped characters, null-byte string termination\\nThese are frequently used by simple signature/rule engines to avoid detection.\\nUnusual referrer patterns\\nPage accesses with an abnormal referrer URL are often a signal of an unwelcome\\naccess to an HTTP endpoint.\\nSequence of accesses to endpoints\\nOut-of-order access to HTTP endpoints that do not correspond to the website’s\\nlogical flow is indicative of fuzzing or malicious explorations.\\nFor instance, if a user’s typical access to a website is a POST to /login followed by\\nthree successive GETs to /a, /b, and /c, but a particular IP address is repeatedly\\nmaking GET requests to /b and /c without a corresponding /login or /a request,\\nthat could be a sign of bot automation or manual reconnaissance activity.\\nUser agent patterns\\nYou can perform frequency analysis on user agent strings to alert on never-\\nbefore-seen user agent strings or extremely old clients (e.g., a “Mosaic/0.9” user\\nagent from 1993) which are likely spoofed.\\nWeb logs provide enough information to detect different kinds of attacks on web\\napplications,10 including, but not limited to, the OWASP Top Ten—XSS, Injection,\\nCSRF, Insecure Direct Object References, etc.\\nIn Summary\\nGenerating a reliable and comprehensive set of features is critical for the anomaly\\ndetection process. The goal of feature engineering is to distill complex information\\ninto a compact form that removes unnecessary information, but does not sacrifice\\nany important characteristics of the data. These generated features will then be fed\\ninto algorithms, which will consume the data and use it to train machine learning\\nmodels. In the next section, we will see how you can convert feature sets into valuable\\ninsights that drive anomaly detection systems.\\nAnomaly Detection with Data and Algorithms\\nAfter you have engineered a set of features from a raw event stream to generate a time\\nseries, it is time to use algorithms to generate insights from this data. Anomaly\\nAnomaly Detection with Data and Algorithms \\n| \\n93'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 111}, page_content='11 We use the terms “algorithm,” “method,” and “technique” interchangeably in this section, all referring to a sin‐\\ngle specific way of implementing anomaly detection; for example, a one-class SVM or elliptical envelope.\\ndetection has had a long history of academic study, but like all other application areas\\nin data analysis, there is no one-size-fits-all algorithm that works for all types of time\\nseries. Thus, you should expect that the process of finding the best algorithm for your\\nparticular application will be a journey of exploration and experimentation.\\nBefore selecting an algorithm, it is important to think about the nature and quality of\\nthe data source. Whether the data is significantly polluted by anomalies will affect the\\ndetection methodology. As defined earlier in the chapter, if the data does not contain\\nanomalies (or has anomalies labeled so we can remove them), we refer to the task as\\nnovelty detection. Otherwise, we refer to the task as outlier detection. In outlier detec‐\\ntion, the chosen algorithm needs to be insensitive to small deviations that will hurt\\nthe quality of the trained model. Often, determining which approach to take is a non‐\\ntrivial decision. Cleaning a dataset to remove anomalies is laborious and sometimes\\ndownright impossible. If you have no idea as to whether your data contains any\\nanomalies, it might be best to start off by assuming that it does, and iteratively move\\ntoward a better solution.\\nIn this discussion, we attempt to synthesize a large variety of anomaly detection\\nmethods11 from literature and industry into a categorization scheme based on the\\nfundamental principles of each algorithm. In our scheme each category contains one\\nor more specific algorithms, and each algorithm belongs to a maximum of one cate‐\\ngory. Our categories are as follows:\\n• Forecasting (supervised machine learning)\\n• Statistical metrics\\n• Unsupervised machine learning\\n• Goodness-of-fit tests\\n• Density-based methods\\nEach category considers a different approach to the problem of finding anomalies.\\nWe present the strengths and pitfalls of each approach and discuss how different\\ndatasets might be better suited for some than for others. For instance, forecasting is\\nsuitable only for one-dimensional time series data, whereas density-based methods\\nare more suitable for high-dimensional datasets.\\nOur survey is not meant to be comprehensive, nor is it meant to be a detailed descrip‐\\ntion of each algorithm’s theory and implementation. Rather, it is meant to give a\\nbroad overview of some of the different options you have for implementing your own\\n94 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 112}, page_content='anomaly detection systems, which we hope you can then use to arrive at the optimal\\nsolution for your use case.\\nForecasting (Supervised Machine Learning)\\nForecasting is a highly intuitive way of performing anomaly detection: we learn from\\nprior data and make a prediction about the future. We can consider any substantial\\ndeviations between the forecasts and observations as anomalous. Taking the weather\\nas an example, if it had not been raining for weeks, and there was no visible sign of\\nupcoming rain, the forecast would predict a low chance of rain in the coming days. If\\nit did rain in the coming days, it would be a deviation from the forecast.\\nThis class of anomaly detection algorithms uses past data to predict current data, and\\nmeasures how different the currently observed data is from the prediction. By this\\ndefinition, forecasting lies in the realm of supervised machine learning because it\\ntrains a regression model of data values versus time. Because these algorithms also\\noperate strictly within the notion of past and present, they are suitable only for single-\\ndimension time series datasets. Predictions made by a forecasting model will corre‐\\nspond to the expected value that this time series will have in the next time step, so\\napplying forecasting to datasets other than time series data does not make sense.\\nTime series data is naturally suited for representation in a line chart. Humans are\\nadept at studying line charts, recognizing trends, and identifying anomalies, but\\nmachines have a more difficult time of it. A major reason for this difficulty is the\\nnoise embedded within time series data, caused either by measurement inaccuracies,\\nsampling frequency, or other external factors associated with the nature of the data.\\nNoise results in a choppy and volatile series, which can camouflage outbreaks or\\nspikes that we are interested in identifying. In combination with seasonality and\\ncyclic patterns that can sometimes be complex, attempting to use naive linear-fit\\nmethods to detect anomalies would likely not give you great results.\\nIn forecasting, it is important to define the following descriptors of time series:\\nTrends\\nLong-term direction of changes in the data, undisturbed by relatively small-scale\\nvolatility and perturbations. Trends are sometimes nonlinear, but can typically be\\nfit to a low-order polynomial curve.\\nSeasons\\nPeriodic repetitions of patterns in the data, typically coinciding with factors\\nclosely related to the nature of the data; for example, day-night patterns,\\nsummer-winter differences, moon phases.\\nCycles\\nGeneral changes in the data that have pattern similarities but vary in periodicity,\\ne.g., long-term stock market cycles.\\nAnomaly Detection with Data and Algorithms \\n| \\n95'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 113}, page_content='12 To be pedantic, autocorrelation is the correlation of the time series vector with the same vector shifted by\\nsome negative time delta.\\n13 Robert Nau of Duke University provides a great, detailed resource for forecasting, ARIMA, and more.\\nFigure 3-1 depicts a diurnal-patterned seasonality, with a gentle upward trend illus‐\\ntrated by a regression line fitted to the data.\\nFigure 3-1. A diurnal season and upward trend\\nARIMA\\nUsing the ARIMA (autoregressive integrated moving average) family of functions is a\\npowerful and flexible way to perform forecasting on time series. Autoregressive mod‐\\nels are a class of statistical models that have outputs that are linearly dependent on\\ntheir own previous values in combination with a stochastic factor.12 You might have\\nheard of exponential smoothing, which can often be equated/approximated to special\\ncases of ARIMA (e.g., Holt-Winters exponential smoothing). These operations\\nsmooth jagged line charts, using different variants of weighted moving averages to\\nnormalize the data. Seasonal variants of these operations can take periodic patterns\\ninto account, helping make more accurate forecasts. For instance, seasonal ARIMA\\n(SARIMA) defines both a seasonal and a nonseasonal component of the ARIMA\\nmodel, allowing periodic characteristics to be captured.13\\nIn choosing an appropriate forecasting model, always visualize your data to identify\\ntrends, seasonalities, and cycles. If seasonality is a strong characteristic of the series,\\nconsider models with seasonal adjustments such as SARIMA and seasonal Holt-\\nWinters methods. Forecasting methods learn characteristics of the time series by\\nlooking at previous points and making predictions about the future. In exploring the\\ndata, a useful metric to learn is the autocorrelation, which is the correlation between\\nthe series and itself at a previous point in time. A good forecast of the series can be\\nthought of as the future points having high autocorrelation with the previous points.\\n96 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 114}, page_content='14 See chapter3/datasets/cpu-utilization in our code repository.\\n15 You can find documentation for PyFlux at http://www.pylux.com/docs/arima.html?highlight=mle.\\nARIMA uses a distributed lag model in which regressions are used to predict future\\nvalues based on lagged values (an autoregressive process). Autoregressive and moving\\naverage parameters are used to tune the model, along with polynomial factor difer‐\\nencing—a process used to make the series stationary (i.e., having constant statistical\\nproperties over time, such as mean and variance), a condition that ARIMA requires\\nthe input series to have.\\nIn this example, we attempt to perform anomaly detection on per-minute metrics of a\\nhost’s CPU utilization.14 The y-axis of Figure 3-2 shows the percentage CPU utiliza‐\\ntion, and the x-axis shows time.\\nFigure 3-2. CPU utilization over time\\nWe can observe a clear periodic pattern in this series, with peaks in CPU utilization\\nroughly every 2.5 hours. Using a convenient time series library for Python, PyFlux,\\nwe apply the ARIMA forecasting algorithm with autoregressive (AR) order 11, mov‐\\ning average (MA) order 11, and a differencing order of 0 (because the series looks sta‐\\ntionary).15 There are some tricks to determining the AR and MA orders and the\\ndifferencing order, which we will not elaborate on here. To oversimplify matters, AR\\nand MA orders are needed to correct any residual autocorrelations that remain in the\\ndifferenced series (i.e., between the time-shifted series and itself). The differencing\\norder is a term used to make the series stationary—an already stationary series\\nshould have a differencing order of 0, a series with a constant average trend (steadily\\ntrending upward or downward) should have a differencing order of 1, and a series\\nwith a time-varying trend (a trend that changes in velocity and direction over the\\nAnomaly Detection with Data and Algorithms \\n| \\n97'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 115}, page_content='16 Full example code is given as a Python Jupyter notebook at chapter3/arima-forecasting.ipynb in our code\\nrepository.\\nseries) should have a differencing order of 2. Let’s plot the in-sample fit to get an idea\\nof how the algorithm does:16\\nimport pandas as pd\\nimport pyflux as pf\\nfrom datetime import datetime\\n# Read in the training and testing dataset files\\ndata_train_a = pd.read_csv(\\'cpu-train-a.csv\\',\\n    parse_dates=[0], infer_datetime_format=True)\\ndata_test_a = pd.read_csv(\\'cpu-test-a.csv\\',\\n    parse_dates=[0], infer_datetime_format=True)\\n# Define the model\\nmodel_a = pf.ARIMA(data=data_train_a,\\n                   ar=11, ma=11, integ=0, target=\\'cpu\\')\\n# Estimate latent variables for the model using the\\n# Metropolis-Hastings algorithm as the inference method\\nx = model_a.fit(\"M-H\")\\n# Plot the fit of the ARIMA model against the data\\nmodel_a.plot_fit()\\nFigure 3-3 presents the result of the plot.\\nFigure 3-3. CPU utilization over time itted with ARIMA model prediction\\nAs we can observe in Figure 3-3, the results fit the observed data quite well. Next, we\\ncan do an in-sample test on the last 60 data points of the training data. The in-sample\\ntest is a validation step that treats the last subsection of the series as unknown and\\n98 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 116}, page_content='performs forecasting for those time steps. This process allows us to evaluate perfor‐\\nmance of the model without running tests on future/test data:\\n> model_a.plot_predict_is(h=60)\\nThe in-sample prediction test (depicted in Figure 3-4) looks pretty good because it\\ndoes not deviate from the original series significantly in phase and amplitude.\\nFigure 3-4. In-sample (training set) ARIMA prediction\\nNow, let’s run the actual forecasting, plotting the most recent 100 observed data\\npoints followed by the model’s 60 predicted values along with their confidence\\nintervals:\\n> model_a.plot_predict(h=60, past_values=100)\\nBands with a darker shade imply a higher confidence; see Figure 3-5.\\nFigure 3-5. Out-of-sample (test-set) ARIMA prediction\\nAnomaly Detection with Data and Algorithms \\n| \\n99'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 117}, page_content=\"17 ARIMAX is a slight modification of ARIMA that adds components originating from standard econometrics,\\nknown as explanatory variables, to the prediction models.\\nComparing the prediction illustrated in Figure 3-5 to the actual observed points illus‐\\ntrated in Figure 3-6, we see that the prediction is spot-on.\\nFigure 3-6. Actual observed data points\\nTo perform anomaly detection using forecasting, we compare the observed data\\npoints with a rolling prediction made periodically. For example, an arbitrary but sen‐\\nsible system might make a new 60-minute forecast every 30 minutes, training a new\\nARIMA model using the previous 24 hours of data. Comparisons between the fore‐\\ncast and observations can be made much more frequently (e.g., every three minutes).\\nWe can apply this method of incremental learning to almost all the algorithms that we\\nwill discuss, which allows us to approximate streaming behavior from algorithms\\noriginally designed for batch processing.\\nLet’s perform the same forecasting operations on another segment of the CPU utiliza‐\\ntion dataset captured at a different time:\\ndata_train_b = pd.read_csv('cpu-train-b.csv',\\n    parse_dates=[0], infer_datetime_format=True)\\ndata_test_b = pd.read_csv('cpu-test-b.csv',\\n    parse_dates=[0], infer_datetime_format=True)\\nForecasting using the same ARIMAX model17 trained on data_train_b, the predic‐\\ntion is illustrated in Figure 3-7.\\n100 \\n| \\nChapter 3: Anomaly Detection\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 118}, page_content='Figure 3-7. Out-of-sample (test-set, data_train_b) ARIMAX prediction\\nThe observed values are, however, very different from the predictions illustrated in\\nFigure 3-8.\\nFigure 3-8. Actual observed data points (data_train_b)\\nWe see a visible anomaly that occurs a short time after our training period. Because\\nthe observed values fall within the low-confidence bands, we will raise an anomaly\\nalert. The specific threshold conditions for how different the forecasted and observed\\nseries must be to raise an anomaly alert is something that is highly application spe‐\\ncific but should be simple enough to implement on your own.\\nAnomaly Detection with Data and Algorithms \\n| \\n101'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 119}, page_content='18 Sepp Hochreiter and Jürgen Schmidhuber, “Long Short-Term Memory,” Neural Computation 9 (1997): 1735–\\n1780.\\n19 Alex Graves, “Generating Sequences with Recurrent Neural Networks”, University of Toronto (2014).\\nArtiicial neural networks\\nAnother way to perform forecasting on time series data is to use artificial neural net‐\\nworks. In particular, long short-term memory (LSTM) networks18,19 are suitable for\\nthis application. LSTMs are a variant of recurrent neural networks (RNNs) that are\\nuniquely architected to learn trends and patterns in time series input for the purposes\\nof classification or prediction. We will not go into the theory or implementation\\ndetails of neural networks here; instead, we will approach them as black boxes that\\ncan learn information from time series containing patterns that occur at unknown or\\nirregular periodicities. We will use the Keras LSTM API, backed by TensorFlow, to\\nperform forecasting on the same CPU utilization dataset that we used earlier.\\nThe training methodology for our LSTM network is fairly straightforward. We first\\nextract all continuous length-n subsequences of data from the training input, treating\\nthe last point in each subsequence as the label for the sample. In other words, we are\\ngenerating n-grams from the input. For example, taking n = 3, for this raw data:\\nraw: [0.51, 0.29, 0.14, 1.00, 0.00, 0.13, 0.56]\\nwe get the following n-grams:\\nn-grams: [[0.51, 0.29, 0.14],\\n          [0.29, 0.14, 1.00],\\n          [0.14, 1.00, 0.00],\\n          [1.00, 0.00, 0.13],\\n          [0.00, 0.13, 0.56]]\\nand the resulting training set is:\\nsample\\nlabel\\n(0.51, 0.29)\\n(0.29, 0.14)\\n(0.14, 1.00)\\n(1.00, 0.00)\\n(0.00, 0.13)\\n0.14\\n1.00\\n0.00\\n0.13\\n0.56\\n102 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 120}, page_content=\"20 Neural networks are made up of layers of individual units. Data is fed into the input layer and predictions are\\nproduced from the output layer. In between, there can be an arbitrary number of hidden layers. In counting\\nthe number of layers in a neural network, a widely accepted convention is to not count the input layer. For\\nexample, in a six-layer neural network, we have one input layer, five hidden layers, and one output layer.\\n21 Full example code is given as a Python Jupyter notebook at chapter3/lstm-anomaly-detection.ipynb in our code\\nrepository.\\nThe model is learning to predict the third value in the sequence following the two\\nalready seen values. LSTM networks have a little more complexity built in that deals\\nwith remembering patterns and information from previous sequences, but as men‐\\ntioned before, we will leave the details out. Let’s define a four-layer20 LSTM network:21\\nfrom keras.models import Sequential\\nfrom keras.layers.recurrent import LSTM\\nfrom keras.layers.core import Dense, Activation, Dropout\\n# Each training data point will be length 100-1,\\n# since the last value in each sequence is the label\\nsequence_length = 100\\nmodel = Sequential()\\n# First LSTM layer defining the input sequence length\\nmodel.add(LSTM(input_shape=(sequence_length-1, 1),\\n               units=32,\\n               return_sequences=True))\\nmodel.add(Dropout(0.2))\\n# Second LSTM layer with 128 units\\nmodel.add(LSTM(units=128,\\n               return_sequences=True))\\nmodel.add(Dropout(0.2))\\n# Third LSTM layer with 100 units\\nmodel.add(LSTM(units=100,\\n               return_sequences=False))\\nmodel.add(Dropout(0.2))\\n# Densely connected output layer with the linear activation function\\nmodel.add(Dense(units=1))\\nmodel.add(Activation('linear'))\\nmodel.compile(loss='mean_squared_error', optimizer='rmsprop')\\nThe precise architecture of the network (number of layers, size of each layer, type of\\nlayer, etc.) is arbitrarily chosen, roughly based on other LSTM networks that work\\nwell for similar problems. Notice that we are adding a Dropout(0.2) term after each\\nAnomaly Detection with Data and Algorithms \\n| \\n103\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 121}, page_content='22 Nitish Srivastava et al., “Dropout: A Simple Way to Prevent Neural Networks from Overfitting,” Journal of\\nMachine Learning Research 15 (2014): 1929−1958.\\nhidden layer—dropout22 is a regularization technique that is commonly used to pre‐\\nvent neural networks from overfitting. At the end of the model definition, we make a\\ncall to the model.compile() method, which configures the learning process. We\\nchoose the rmsprop optimizer because the documentation states that it is usually a\\ngood choice for RNNs. The model fitting process will use the rmsprop optimization\\nalgorithm to minimize the loss function, which we have defined to be the\\nmean_squared_error. There are many other tunable knobs and different architec‐\\ntures that will contribute to model performance, but, as usual, we opt for simplicity\\nover accuracy.\\nLet’s prepare our input:\\n...\\n# Generate n-grams from the raw training data series\\nn_grams = []\\nfor ix in range(len(training_data)-sequence_length):\\nn_grams.append(training_data[ix:ix+sequence_length])\\n# Normalize and shuffle the values\\nn_grams_arr = normalize(np.array(n_grams))\\nnp.random.shuffle(n_grams_arr)\\n# Separate each sample from its label\\nx = n_grams_arr[:, :-1]\\nlabels = n_grams_arr[:, −1]\\n...\\nThen, we can proceed to run the data through the model and make predictions:\\n...\\nmodel.fit(x,\\n   labels,\\n   batch_size=50,\\n   nb_epochs=3,\\n   validation_split=0.05)\\ny_pred = model.predict(x_test)\\n...\\nFigure 3-9 shows the results alongside the root-mean-squared (RMS) deviation.\\nWe see that the prediction follows the nonanomalous observed series closely (both\\nnormalized), which hints to us that the LSTM network is indeed working well. When\\nthe anomalous observations occur, we see a large deviation between the predicted and\\nobserved series, evident in the RMS plot. Similar to the ARIMA case, such measures\\nof deviations between predictions and observations can be used to signal when\\n104 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 122}, page_content='23 Eamonn Keogh and Jessica Lin, “Clustering of Time-Series Subsequences Is Meaningless: Implications for\\nPrevious and Future Research,” Knowledge and Information Systems 8 (2005): 154–177.\\nanomalies are detected. Thresholding on the observed versus predicted series diver‐\\ngence is a good way to abstract out the quirks of the data into a simple measure of\\nunexpected deviations.\\nFigure 3-9. Observed, predicted, and RMS deviation plots of LSTM anomaly detection\\napplied on the CPU time series\\nSummary\\nForecasting is an intuitive method of performing anomaly detection. Especially when\\nthe time series has predictable seasonality patterns and an observable trend, models\\nsuch as ARIMA can capture the data and reliably make forecasts. For more complex\\ntime series data, LSTM networks can work well. There are other methods of forecast‐\\ning that utilize the same principles and achieve the same goal. Reconstructing time\\nseries data from a trained machine learning model (such as a clustering model) can\\nbe used to generate a forecast, but the validity of such an approach has been disputed\\nin academia.23\\nNote that forecasting does not typically work well for outlier detection; that is, if the\\ntraining data for your model contains anomalies that you cannot easily filter out,\\nyour model will fit to both the inliers and outliers, which will make it difficult to\\ndetect future outliers. It is well suited for novelty detection, which means that the\\nanomalies are only contained in the test data and not the training data. If the time\\nseries is highly erratic and does not follow any observable trend, or if the amplitude\\nof fluctuations varies widely, forecasting is not likely to perform well. Forecasting\\nworks best on one-dimensional series of real-valued metrics, so if your dataset con‐\\ntains multidimensional feature vectors or categorical variables, you will be better off\\nusing another method of anomaly detection.\\nAnomaly Detection with Data and Algorithms \\n| \\n105'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 123}, page_content='24 This example can be found at chapter3/mad.py in our code repository.\\nStatistical Metrics\\nWe can use statistical tests to determine whether a single new data point is similar to\\nthe previously seen data. Our example at the beginning of the chapter, in which we\\nmade a threshold-based anomaly detector adapt to changing data by maintaining an\\naggregate moving average of the series, falls into this category. We can use moving\\naverages of time series data as an adaptive metric that indicates how well data points\\nconform to a long-term trend. Specifically, the moving average (also known as a low-\\npass ilter in signal processing terminology) is the reference point for statistical com‐\\nparisons, and significant deviations from the average will be considered anomalies.\\nHere we briefly discuss a few noteworthy metrics, but we do not dwell too long on\\neach, because they are fairly straightforward to use.\\nMedian absolute deviation\\nThe standard deviation of a data series is frequently used in adaptive thresholding to\\ndetect anomalies. For instance, a sensible definition of anomaly can be any point that\\nlies more than two standard deviations from the mean. So, for a standard normal\\ndataset with a mean of 0 and standard deviation of 1, any data points that lie between\\n−2 and 2 will be considered regular, while a data point with the value 2.5 would be\\nconsidered anomalous. This algorithm works if your data is perfectly clean, but if the\\ndata contains outliers the calculated mean and standard deviations will be skewed.\\nThe median absolute deviation (MAD) is a commonly used alternative to the standard\\ndeviation for finding outliers in one-dimensional data. MAD is defined as the median\\nof the absolute deviations from the series median:24\\nimport numpy as np\\n# Input data series\\nx = [1, 2, 3, 4, 5, 6]\\n# Calculate median absolute deviation\\nmad = np.median(np.abs(x - np.median(x)))\\n# MAD of x is 1.5\\nBecause median is much less susceptible than mean to being influenced by outliers,\\nMAD is a robust measure suitable for use in scenarios where the training data con‐\\ntains outliers.\\n106 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 124}, page_content='25 The law of large numbers is a theorem that postulates that repeating an experiment a large number of times\\nwill produce a mean result that is close to the expected value.\\nGrubbs’ outlier test\\nGrubbs’ test is an algorithm that finds a single outlier in a normally distributed data‐\\nset by considering the current minimum or maximum value in the series. The algo‐\\nrithm is applied iteratively, removing the previously detected outlier between each\\niteration. Although we do not go into the details here, a common way to use Grubbs’\\noutlier test to detect anomalies is to calculate the Grubbs’ test statistic and Grubbs’ crit‐\\nical value, and mark the point as an outlier if the test statistic is greater than the criti‐\\ncal value. This approach is only suitable for normal distributions, and can be\\ninefficient because it only detects one anomaly in each iteration.\\nSummary\\nStatistical metric comparison is a very simple way to perform anomaly detection, and\\nmight not be considered by many to be a machine learning technique. However, it\\ndoes check many of the boxes for features of an optimal anomaly detector that we\\ndiscussed earlier: anomaly alerts are reproducible and easy to explain, algorithms\\nadapt to changing trends in the data, it can be very performant because of its simplic‐\\nity, and it is relatively easy to tune and maintain. Because of these properties, statisti‐\\ncal metric comparison might be an optimal choice for some scenarios in which\\nstatistical measures can perform accurately, or for which a lower level of accuracy can\\nbe accepted. Because of their simplicity, statistical metrics have limited learning capa‐\\nbilities, and often perform worse than more powerful machine learning algorithms.\\nGoodness-of-Fit\\nIn building an anomaly detection system, it is important to consider whether the data\\nused to train the initial model is contaminated with anomalies. As discussed earlier,\\nthis question can be difficult to answer, but you can often make an informed guess\\ngiven a proper understanding of the nature of the data source and threat model. In a\\nperfect world, the expected distributions of a dataset can be accurately modeled with\\nknown distributions. For instance, the distribution of API calls to an application\\nserver per day (over time) might closely fit a normal distribution, and the number of\\nhits to a website in the hours after a promotion is launched might be accurately\\ndescribed by an exponential decay. However, because we do not live in a perfect\\nworld, it is rare to find real datasets that conform perfectly to simple distributions.\\nEven if a dataset can be fitted to some hypothetical analytical distribution, accurately\\ndetermining what this distribution is can be a challenge. Nevertheless, this approach\\ncan be feasible in some cases, especially when dealing with a large dataset for which\\nthe expected distribution is well known.25 In such cases, comparing the divergence\\nAnomaly Detection with Data and Algorithms \\n| \\n107'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 125}, page_content='between the expected and observed distributions can be a method of anomaly\\ndetection.\\nGoodness-of-it tests such as the chi-squared test, the Kolmogorov–Smirnov test, and\\nthe Cramér–von Mises criterion can be used to quantify how similar two continuous\\ndistributions are. These tests are mostly only valid for one-dimensional datasets,\\nhowever, which can largely limit their usefulness. We will not dive too deeply into tra‐\\nditional goodness-of-fit tests because of their limited usefulness in real-world anom‐\\naly detection. Instead, we will take a closer look at more versatile methods such as the\\nelliptic envelope fitting method provided in scikit-learn.\\nElliptic envelope itting (covariance estimate itting)\\nFor normally distributed datasets, elliptic envelope itting can be a simple and elegant\\nway to perform anomaly detection. Because anomalies are, by definition, points that\\ndo not conform to the expected distribution, it is easy for these algorithms to exclude\\nsuch outliers in the training data. Thus, this method is only minimally affected by the\\npresence of anomalies in the dataset.\\nThe use of this method requires that you make a rather strong assumption about your\\ndata—that the inliers come from a known analytical distribution. Let’s take an exam‐\\nple of a hypothetical dataset containing two appropriately scaled and normalized fea‐\\ntures (e.g., peak CPU utilization and start time of user-invoked processes on a host in\\n24 hours). Note that it is rare to find time series datasets that correspond to simple\\nand known analytical distributions. More likely than not, this method will be suitable\\nin anomaly detection problems with the time dimension excluded. We will synthesize\\nthis dataset by sampling a Gaussian distribution and then including a 0.01 ratio of\\noutliers in the mixture:\\nimport numpy as np\\nnum_dimensions = 2\\nnum_samples = 1000\\noutlier_ratio = 0.01\\nnum_inliers = int(num_samples * (1-outlier_ratio))\\nnum_outliers = num_samples - num_inliers\\n# Generate the normally distributed inliers\\nx = np.random.randn(num_inliers, num_dimensions)\\n# Add outliers sampled from a random uniform distribution\\nx_rand = np.random.uniform(low=-10, high=10, size=(num_outliers, num_dimensions))\\nx = np.r_[x, x_rand]\\n# Generate labels, 1 for inliers and −1 for outliers\\nlabels = np.ones(num_samples, dtype=int)\\nlabels[-num_outliers:] = −1\\n108 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 126}, page_content=\"26 The full code can be found as a Python Jupyter notebook at chapter3/elliptic-envelope-itting.ipynb in our code\\nrepository.\\nPlotting this dataset in a scatter plot (see Figure 3-10), we see that the outliers are visi‐\\nbly separated from the central mode cluster:\\nimport matplotlib.pyplot as plt\\nplt.plot(x[:num_inliers,0], x[:num_inliers,1], 'wo', label='inliers')\\nplt.plot(x[-num_outliers:,0], x[-num_outliers:,1], 'ko', label='outliers')\\nplt.xlim(-11,11)\\nplt.ylim(-11,11)\\nplt.legend(numpoints=1)\\nplt.show()\\nFigure 3-10. Scatter plot of synthetic dataset with inlier/outlier ground truth labels\\nElliptical envelope fitting does seem like a suitable option for anomaly detection\\ngiven that the data looks normally distributed (as illustrated in Figure 3-10). We use\\nthe convenient sklearn.covariance.EllipticEnvelope class in the following\\nanalysis:26\\nfrom sklearn.covariance import EllipticEnvelope\\nclassifier = EllipticEnvelope(contamination=outlier_ratio)\\nclassifier.fit(x)\\ny_pred = classifier.predict(x)\\nnum_errors = sum(y_pred != labels)\\nprint('Number of errors: {}'.format(num_errors))\\n> Number of errors: 0\\nAnomaly Detection with Data and Algorithms \\n| \\n109\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 127}, page_content='This method performs very well on this dataset, but that is not surprising at all given\\nthe regularity of the distribution. In this example, we know the accurate value for\\noutlier_ratio to be 0.01 because we created the dataset synthetically. This is an\\nimportant parameter because it informs the classifier of the proportion of outliers it\\nshould look for. For realistic scenarios in which the outlier ratio is not known, you\\nshould make your best guess for the initial value based on your knowledge of the\\nproblem. Thereafter, you can iteratively tune the outlier_ratio upward if you are\\nnot detecting some outliers that the algorithm should have found, or tune it down‐\\nward if there is a problem with false positives.\\nLet’s take a closer look at the decision boundary formed by this classifier, which is\\nillustrated in Figure 3-11.\\nFigure 3-11. Decision boundary for elliptic envelope itting on Gaussian synthetic data\\nThe center mode is shaded in gray, demarcated by an elliptical decision boundary.\\nAny points lying beyond the decision boundary of the ellipse are considered to be\\noutliers.\\nWe need to keep in mind that this method’s effectiveness varies across different data\\ndistributions. Let’s consider at a dataset that does not fit a regular Gaussian distribu‐\\ntion (see Figure 3-12).\\n110 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 128}, page_content='27 In statistics, robust is a property that is used to describe a resilience to outliers. More generally, the term robust\\nstatistics refers to statistics that are not strongly affected by certain degrees of departures from model\\nassumptions.\\nFigure 3-12. Decision boundary for elliptic envelope itting on non-Gaussian synthetic\\ndata\\nThere are now eight misclassifications: four outliers are now classified as inliers, and\\nfour inliers that fall just outside the decision boundary are flagged as outliers.\\nApplying this method in a streaming anomaly detection system is straightforward. By\\nperiodically fitting the elliptical envelope to new data, you will have a constantly\\nupdating decision boundary with which to classify incoming data points. To remove\\neffects of drit and a continually expanding decision boundary over time, it is a good\\nidea to retire data points after a certain amount of time. However, to ensure that sea‐\\nsonal and cyclical effects are covered, this sliding window of fresh data points needs to\\nbe wide enough to encapsulate information about daily or weekly patterns.\\nThe EllipticEnvelope() function in sklearn is located in the sklearn.covariance\\nmodule. The covariance of features in a dataset refers to the joint variability of the fea‐\\ntures. In other words, it is a measure of the magnitude and direction of the effect that\\na change in one feature has on another. The covariance is a characteristic of a dataset\\nthat we can use to describe distributions, and in turn to detect outliers that do not fit\\nwithin the described distributions. Covariance estimators can be used to empirically\\nestimate the covariance of a dataset given some training data, which is exactly how\\ncovariance-based fitting for anomaly detection works.\\nRobust covariance estimates27 such as the Minimum Covariance Determinant (MCD)\\nestimator will minimize the influence of training data outliers on the fitted model. We\\nAnomaly Detection with Data and Algorithms \\n| \\n111'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 129}, page_content='can measure the quality of a fitted model by the distance between outliers and the\\nmodel’s distribution, using a distance function such as Mahalanobis distance. Com‐\\npared with nonrobust estimates such as the Maximum Likelihood Estimator (MLE),\\nMCD is able to discriminate between outliers and inliers, generating a better fit that\\nresults in inliers having small distances and outliers having large distances to the cen‐\\ntral mode of the fitted model.\\nThe elliptic envelope fitting method makes use of robust covariance estimators to\\nattain covariance estimates that model the distribution of the regular training data,\\nand then classifies points that do not meet these estimates as anomalies. We’ve seen\\nthat elliptic envelope fitting works reasonably well for a two-dimensional contamina‐\\nted dataset with a known Gaussian distribution, but not so well on a non-Gaussian\\ndataset. You can apply this technique to higher-dimensional datasets as well, but your\\nmileage may vary—elliptic envelopes work better on datasets with low dimensional‐\\nity. When using it on time series data, you might find it useful in some scenarios to\\nremove time from the feature set and just fit the model to a subset of other features.\\nIn this case, however, note that you will not be able to capture an anomaly that is stat‐\\nistically regular relative to the aggregate distribution, but in fact is anomalous relative\\nto the time it appeared. For example, if some anomalous data points from the middle\\nof the night have features that exhibit values that are not out of the ordinary for a\\nmidday data point, but are highly anomalous for nighttime measurements, the outli‐\\ners might not be detected if you omit the time dimension.\\nUnsupervised Machine Learning Algorithms\\nWe now turn to a class of solutions to the anomaly detection problem that arise from\\nmodifications of typical supervised machine learning models. Supervised machine\\nlearning classifiers are typically used to solve problems that involve two or more\\nclasses. However, when used for anomaly detection, the modifications of these algo‐\\nrithms give them characteristics of unsupervised learning. In this section we look at a\\ncouple such algorithms.\\nOne-class support vector machines\\nWe can use a one-class SVM to detect anomalies by fitting the SVM with data belong‐\\ning to only a single class. This data (which is assumed to contain no anomalies) is\\nused to train the model, creating a decision boundary that can be used to classify\\nfuture incoming data points. There is no robustness mechanism built into standard\\none-class SVM implementations, which means that the model training is less resilient\\nto outliers in the dataset. As such, this method is more suitable for novelty detection\\nthan outlier detection; that is, the training data should ideally be thoroughly cleaned\\nand contain no anomalies.\\n112 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 130}, page_content='28 The full code can be found as a Python Jupyter notebook at chapter3/one-class-svm.ipynb in our code\\nrepository.\\nWhere the one-class SVM method pulls apart from the pack is in dealing with non-\\nGaussian or multimodal distributions (i.e., when there is more than one “center” of\\nregular inliers), as well as high-dimensional datasets. We will apply the one-class\\nSVM classifier to the second dataset we used in the preceding section. Note that this\\ndataset is not ideal for this method, because outliers comprise one percent of the data,\\nbut let’s see how much the resulting model is affected by the presence of contami‐\\nnants:28\\nfrom sklearn import svm\\nclassifier = svm.OneClassSVM(nu=0.99 * outlier_ratio + 0.01,\\n                             kernel=\"rbf\",\\n                             gamma=0.1)\\nclassifier.fit(x)\\ny_pred = classifier.predict(x)\\nnum_errors = sum(y_pred != labels)\\nprint(\\'Number of errors: {}\\'.format(num_errors))\\nLet’s examine the custom parameters that we specified in the creation of the svm.One\\nClassSVM object. Note that these parameters are dependent on datasets and usage sce‐\\nnarios; in general, you should always have a good understanding of all tunable\\nparameters offered by a classifier before you use it. To deal with a small proportion of\\noutliers in the data, we set the nu parameter to be roughly equivalent to the outlier\\nratio. According to the sklearn documentation, this parameter controls the “upper\\nbound on the fraction of training errors and the lower bound of the fraction of sup‐\\nport vectors.” In other words, it represents the acceptable range of errors generated by\\nthe model that can be caused by stray outliers, allowing the model some flexibility to\\nprevent overfitting the model to outliers in the training set.\\nThe kernel is selected by visually inspecting the dataset’s distribution. Each cluster in\\nthe bimodal distribution has Gaussian characteristics, which suggests that the radial\\nbasis function (RBF) kernel would be a good fit given that the values of both the\\nGaussian function and the RBF decrease exponentially as points move radially further\\naway from the center.\\nThe gamma parameter is used to tune the RBF kernel. This parameter defines how\\nmuch influence any one training sample has on the resulting model. Its default value\\nis 0.5. Smaller values of gamma would result in a “smoother” decision boundary, which\\nmight not be able to adequately capture the shape of the dataset. Larger values might\\nresult in overfitting. We chose a smaller value of gamma in this case to prevent overfit‐\\nting to outliers that are close to the decision boundary.\\nAnomaly Detection with Data and Algorithms \\n| \\n113'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 131}, page_content='Inspecting the resulting model, we see that the one-class SVM is able to fit this\\nstrongly bimodal dataset quite well, generating two mode clusters of inliers, as\\ndemonstrated in Figure 3-13. There are 16 misclassifications, so the presence of outli‐\\ners in the training data did have some effect on the resulting model.\\nFigure 3-13. Decision boundary for one-class SVM on bimodal synthetic data—trained\\nusing both outliers and inliers\\nLet’s retrain the model on purely the inliers and see if it does any better. Figure 3-14\\npresents the result.\\nFigure 3-14. Decision boundary for one-class SVM on bimodal synthetic data—trained\\nusing only inliers\\n114 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 132}, page_content='29 The full code can be found as a Python Jupyter notebook at chapter3/isolation-forest.ipynb in our code\\nrepository.\\nIndeed, as can be observed from Figure 3-14, there now are only three classification\\nerrors.\\nOne-class SVMs offer a more flexible method for fitting a learned distribution to\\nyour dataset than robust covariance estimation. If you are thinking of using one as\\nthe engine for your anomaly detection system, however, you need to pay special\\nattention to potential outliers that might slip past detection and cause the gradual\\ndegradation of the model’s accuracy.\\nIsolation forests\\nRandom forest classifiers have a reputation for working well as anomaly detection\\nengines in high-dimensional datasets. Random forests are algorithmic trees, and\\nstream classification on tree data structures is much more efficient compared to mod‐\\nels that involve many cluster or distance function computations. The number of fea‐\\nture value comparisons required to classify an incoming data point is the height of\\nthe tree (vertical distance between the root node and the terminating leaf node). This\\nmakes it very suitable for real-time anomaly detection on time series data.\\nThe sklearn.ensemble.IsolationForest class helps determine the anomaly score\\nof a sample using the Isolation Forest algorithm. This algorithm trains a model by\\niterating through data points in the training set, randomly selecting a feature and ran‐\\ndomly selecting a split value between the maximum and minimum values of that fea‐\\nture (across the entire dataset). The algorithm operates in the context of anomaly\\ndetection by computing the number of splits required to isolate a single sample; that\\nis, how many times we need to perform splits on features in the dataset before we end\\nup with a region that contains only the single target sample. The intuition behind this\\nmethod is that inliers have more feature value similarities, which requires them to go\\nthrough more splits to be isolated. Outliers, on the other hand, should be easier to\\nisolate with a small number of splits because they will likely have some feature value\\ndifferences that distinguish them from inliers. By measuring the “path length” of\\nrecursive splits from the root of the tree, we have a metric with which we can\\nattribute an anomaly score to data points. Anomalous data points should have shorter\\npath lengths than regular data points. In the sklearn implementation, the threshold\\nfor points to be considered anomalous is defined by the contamination ratio. With a\\ncontamination ratio of 0.01, the shortest 1% of paths will be considered anomalies.\\nLet’s see this method in action by applying the Isolation Forest algorithm on the non-\\nGaussian contaminated dataset we saw in earlier sections (see Figure 3-15):29\\nAnomaly Detection with Data and Algorithms \\n| \\n115'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 133}, page_content=\"from sklearn.ensemble import IsolationForest\\nrng = np.random.RandomState(99)\\nclassifier = IsolationForest(max_samples=num_samples,\\n                             contamination=outlier_ratio,\\n                             random_state=rng)\\nclassifier.fit(x)\\ny_pred = classifier.predict(x)\\nnum_errors = sum(y_pred != labels)\\nprint('Number of errors: {}'.format(num_errors))\\n> Number of errors: 8\\nFigure 3-15. Decision boundary for isolation forest on synthetic non-Gaussian data\\nUsing isolation forests in streaming time series anomaly detection is very similar to\\nusing one-class SVMs or robust covariance estimations. The anomaly detector simply\\nmaintains a tree of isolation forest splits and updates the model with new incoming\\npoints (as long as they are not deemed anomalies) in newly isolated segments of the\\nfeature space.\\nIt is important to note that even though testing/classification is efficient, initially\\ntraining the model is often more resource and time intensive than other methods of\\nanomaly detection discussed earlier. On very low-dimensional data, using isolation\\nforests for anomaly detection might not be suitable, because the small number of fea‐\\ntures on which we can perform splits can limit the effectiveness of the algorithm.\\nDensity-Based Methods\\nClustering methods such as the k-means algorithm are known for their use in unsu‐\\npervised classification and regression. We can use similar density-based methods in\\n116 \\n| \\nChapter 3: Anomaly Detection\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 134}, page_content='30 Alexandr Andoni and Piotr Indyk, “Nearest Neighbors in High-Dimensional Spaces,” in Handbook of Discrete\\nand Computational Geometry, 3rd ed., ed. Jacob E. Goodman, Joseph O’Rourke, and Piotr Indyk (CRC Press).\\n31 The full code can be found as a Python Jupyter notebook at chapter3/local-outlier-factor.ipynb in our code\\nrepository.\\nthe context of anomaly detection to identify outliers. Density-based methods are well\\nsuited for high-dimensional datasets, which can be difficult to deal with using the\\nother classes of anomaly detection methods. Several different density-based methods\\nhave been adapted for use in anomaly detection. The main idea behind all of them is\\nto form a cluster representation of the training data, under the hypothesis that outli‐\\ners or anomalies will be located in low-density regions of this cluster representation.\\nThis approach has the convenient property of being resilient to outliers in the train‐\\ning data because such instances will likely also be found in low-density regions.\\nEven though the k-nearest neighbors (k-NN) algorithm is not a clustering algorithm,\\nit is commonly considered a density-based method and is actually quite a popular\\nway to measure the probability that a data point is an outlier. In essence, the algo‐\\nrithm can estimate the local sample density of a point by measuring its distance to the\\nkth nearest neighbor. You can also use k-means clustering for anomaly detection in a\\nsimilar way, using distances between the point and centroids as a measure of sample\\ndensity. k-NN has the potential to scale well to large datasets by using k-d trees (k-\\ndimensional trees), which can greatly improve computation times for smaller-\\ndimensional datasets.30 In this section, we will focus on a method called the local\\noutlier factor (LOF), which is a classic density-based machine learning method for\\nanomaly detection.\\nLocal outlier factor\\nThe LOF is an anomaly score that you can generate using the scikit-learn class\\nsklearn.neighbors.LocalOutlierFactor. Similar to the aforementioned k-NN and\\nk-means anomaly detection methods, LOF classifies anomalies using local density\\naround a sample. The local density of a data point refers to the concentration of other\\npoints in the immediate surrounding region, where the size of this region can be\\ndefined either by a fixed distance threshold or by the closest n neighboring points.\\nLOF measures the isolation of a single data point with respect to its closest n neigh‐\\nbors. Data points with a significantly lower local density than that of their closest n\\nneighbors are considered to be anomalies. Let’s run an example on a similar non-\\nGaussian, contaminated dataset once again:31\\nfrom sklearn.neighbors import LocalOutlierFactor\\nclassifier = LocalOutlierFactor(n_neighbors=100)\\ny_pred = classifier.fit_predict(x)\\nAnomaly Detection with Data and Algorithms \\n| \\n117'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 135}, page_content=\"Z = classifier._decision_function(np.c_[xx.ravel(), yy.ravel()])\\nZ = Z.reshape(xx.shape)\\nnum_errors = sum(y_pred != labels)\\nprint('Number of errors: {}'.format(num_errors))\\n> Number of errors: 9\\nFigure 3-16 presents the result.\\nFigure 3-16. Decision boundary for local outlier factor on bimodal synthetic distribution\\nAs we can observe from Figure 3-16, LOF works very well even when there is con‐\\ntamination in the training set, and it is not very strongly affected by dimensionality of\\nthe data. As long as the dataset maintains the property that outliers have a weaker\\nlocal density than their neighbors in a majority of the training features, LOF can find\\nclusters of inliers well. Because of the algorithm’s approach, it is able to distinguish\\nbetween outliers in datasets with varying cluster densities. For instance, a point in a\\nsparse cluster might have a higher distance to its nearest neighbors than another\\npoint in a denser cluster (in another area of the same dataset), but because density\\ncomparisons are made only with local neighbors, each cluster will have different dis‐\\ntance conditions for what constitutes an outlier. Lastly, LOF’s nonparametric nature\\nmeans that it can easily be generalized across multiple different dimensions as long as\\nthe data is numerical and continuous.\\nIn Summary\\nHaving analyzed the five categories of anomaly detection algorithms, it should be\\nclear that there is no lack of machine learning methods applicable to this classic data\\nmining problem. Selecting which algorithm to use can sometimes be daunting and\\ncan take a few iterations of trial and error. However, using our guidelines and hints\\n118 \\n| \\nChapter 3: Anomaly Detection\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 136}, page_content='for which classes of algorithms work better for the nature of the data you have and for\\nthe problem you are solving, you will be in a much better position to take advantage\\nof the power of machine learning to detect anomalies.\\nChallenges of Using Machine Learning in Anomaly\\nDetection\\nOne of the most successful applications of machine learning is in recommendation\\nsystems. Using techniques such as collaborative filtering, such systems are able to\\nextract latent preferences of users and act as an engine for active demand generation.\\nWhat if a wrong recommendation is made? If an irrelevant product is recommended\\nto a user browsing through an online shopping site, the repercussions are insignifi‐\\ncant. Beyond the lost opportunity cost of a potential successful recommendation, the\\nuser simply ignores the uninteresting recommendation. If an error is made in the\\npersonalized search ranking algorithm, the user might not find what they are looking\\nfor, but there is no large, tangible loss incurred.\\nAnomaly detection is rooted in a fundamentally different paradigm. The cost of\\nerrors in intrusion or anomaly detection is huge. Misclassification of one anomaly\\ncan cause a crippling breach in the system. Raising false positive alerts has a less dras‐\\ntic impact, but spurious false positives can quickly degrade confidence in the system,\\neven resulting in alerts being entirely ignored. Because of the high cost of classifica‐\\ntion errors, fully automated, end-to-end anomaly detection systems that are powered\\npurely by machine learning are very rare—there is almost always a human in the loop\\nto verify that alerts are relevant before any action is taken on them.\\nThe semantic gap is a real problem with machine learning in many environments.\\nCompared with static rulesets or heuristics, it can sometimes be difficult to explain\\nwhy an event was flagged as an anomaly, leading to longer incident investigation\\ncycles. In practical cases, interpretability or explainability of results is often as impor‐\\ntant as accuracy of the results. Especially for anomaly detection systems that con‐\\nstantly evolve their decision models over time, it is worthwhile to invest engineering\\nresources into system components that can generate human-readable explanations\\nfor alerts generated by a machine learning system. For instance, if an alert is raised by\\nan outlier detection system powered by a one-class SVM using a latent combination\\nof features selected through dimensionality reduction techniques, it can be difficult\\nfor humans to figure out what combinations of explicit signals the system is looking\\nfor. As much as is possible given the opacity of many machine learning processes, it\\nwill be helpful to generate explanations of why the model made the decision it made.\\nDevising a sound evaluation scheme for anomaly detection systems can be even more\\ndifficult than building the system itself. Because performing anomaly detection on\\ntime series data implies that there is the possibility of data input never seen in the\\nChallenges of Using Machine Learning in Anomaly Detection \\n| \\n119'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 137}, page_content='past, there is no comprehensive way of evaluating the system given the vast possibili‐\\nties of different anomalies that the system may encounter in the wild.\\nAdvanced actors can (and will) spend time and effort to bypass anomaly detection\\nsystems if there is a worthwhile payoff on the other side. The effect of adversarial\\nadaptation on machine learning systems and algorithms is real and is a necessary\\nconsideration when deploying systems in a potentially hostile environment. Chap‐\\nter 8 explores adversarial machine learning in greater detail, but any security machine\\nlearning system should have some built-in safeguards against tampering. We also dis‐\\ncuss these safeguards in Chapter 8.\\nResponse and Mitigation\\nAfter receiving an anomaly alert, what comes next? Incident response and threat mit‐\\nigation are fields of practice that deserve their own publications, and we cannot possi‐\\nbly paint a complete picture of all the nuances and complexities involved. We can,\\nhowever, consider how machine learning can be infused into traditional security\\noperations workflows to improve the efficacy and yield of human effort.\\nSimple anomaly alerts can come in the form of an email or a mobile notification. In\\nmany cases, organizations that maintain a variety of different anomaly detection and\\nsecurity monitoring systems find value in aggregating alerts from multiple sources\\ninto a single platform known as a Security Information and Event Management\\n(SIEM) system. SIEMs can help with the management of the output of fragmented\\nsecurity systems, which can quickly grow out of hand in volume. SIEMs can also cor‐\\nrelate alerts raised by different systems to help analysts gather insights from a wide\\nvariety of security detection systems.\\nHaving a unified location for reporting and alerting can also make a noticeable differ‐\\nence in the value of security alerts raised. Security alerts can often trigger action items\\nfor parts of the organization beyond the security team or even the engineering team.\\nMany improvements to an organization’s security require coordinated efforts by\\ncross-team management who do not necessarily have low-level knowledge of security\\noperations. Having a platform that can assist with the generation of reports and\\ndigestible, human-readable insights into security incidents can be highly valuable\\nwhen communicating the security needs of an organization to external stakeholders.\\nIncident response typically involves a human at the receiving end of security alerts,\\nperforming manual actions to investigate, verify, and escalate. Incident response is\\nfrequently associated with digital forensics (hence the field of digital forensics and\\nincident response, or DFIR), which covers a large scope of actions that a security oper‐\\nations analyst must perform to triage alerts, collect evidence for investigations, verify\\nthe authenticity of collected data, and present the information in a format friendly to\\ndownstream consumers. Even as other areas of security adapt to more and more\\n120 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 138}, page_content='automation, incident response has remained a stubbornly manual process. For\\ninstance, there are tools that help with inspecting binaries and reading memory\\ndumps, but there is no real substitute for a human hypothesizing about an attacker’s\\nprobable actions and intentions on a compromised host.\\nThat said, machine-assisted incident response has shown significant promise.\\nMachine learning can efficiently mine massive datasets for patterns and anomalies,\\nwhereas human analysts can make informed conjectures and perform complex tasks\\nrequiring deep contextual and experiential knowledge. Combining these sets of com‐\\nplementary strengths can potentially help improve the efficiency of incident response\\noperations.\\nhreat mitigation is the process of reacting to intruders and attackers and preventing\\nthem from succeeding in their actions. A first reaction to an intrusion alert might be\\nto nip the threat in the bud and prevent the risk from spreading any further. How‐\\never, this action prevents you from collecting any further information about the\\nattacker’s capabilities, intent, and origin. In an environment in which attackers can\\niterate quickly and pivot their strategies to circumvent detection, banning or blocking\\nthem can be counterproductive. The immediate feedback to the attackers can give\\nthem information about how they are being detected, allowing them to iterate to the\\npoint where they will be difficult to detect. Silently observing attackers while limiting\\ntheir scope of damage is a better tactic, giving defenders more time to conceive a\\nlonger-term strategy that can stop attackers for good.\\nStealth banning (or shadow banning, hell banning, ghost banning, etc.) is a practice\\nadopted by social networks and online community platforms to block abusive or\\nspam content precisely for the purpose of not giving these actors an immediate feed‐\\nback loop. A stealth banning platform creates a synthetic environment visible to\\nattackers after they are detected. This environment looks to the attacker like the nor‐\\nmal platform, so they initially still thinks their actions are valid, when in fact anyone\\nwho has been stealth banned can cause no side effects nor be visible to other users or\\nsystem components.\\nPractical System Design Concerns\\nIn designing and implementing machine learning systems for security, there are a\\nnumber of practical system design decisions to make that go beyond improving clas‐\\nsification accuracy.\\nOptimizing for Explainability\\nAs mentioned earlier, the semantic gap of alert explainability is one of the biggest\\nstumbling blocks of anomaly detectors using machine learning. Many practical\\nmachine learning applications value explanations of results. However, true explaina‐\\nPractical System Design Concerns \\n| \\n121'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 139}, page_content='32 In Chapter 7, we examine the details of dealing with explainability in machine learning in more depth.\\n33 Ryan Turner, “A Model Explanation System”, Black Box Learning and Inference NIPS Workshop (2015).\\nbility of machine learning is an area of research that hasn’t yet seen many definitive\\nanswers.\\nSimple machine learning classifiers, and even non–machine learning classification\\nengines, are quite transparent in their predictions. For example, a linear regression\\nmodel on a two-dimensional dataset generates very explainable results, but lacks the\\nability to learn more complex and nuanced features. More complex machine learning\\nmodels, such as neural networks, random forest classifiers, and ensemble techniques,\\ncan fit real-world data better, but they are very black-box—the decision-making pro‐\\ncesses are completely opaque to an external observer. However, there are ways to\\napproach the problem that can alleviate the concern that machine learning predic‐\\ntions are difficult to explain, proving that explainability is not in fact at odds with\\naccuracy.32 Having an external system generate simple, human-readable explanations\\nfor the decisions made by a black-box classifier satisfies the conditions of result\\nexplainability,33 even if the explanations do not describe the actual decision-making\\nconditions of the machine learning system. This external system analyzes any output\\nfrom the machine learning system and performs context-aware data analysis to gen‐\\nerate the most probable reasons for why the alert was raised.\\nPerformance and scalability in real-time streaming applications\\nMany applications of anomaly detection in the context of security require a system\\nthat can handle real-time streaming classification requests and deal with shifting\\ntrends in the data over time. But unlike with ad hoc machine learning processes, clas‐\\nsification accuracy is not the only metric to optimize. Even though they might yield\\ninferior classification results, some algorithms are less time and resource intensive\\nthan others and can be the optimal choice for designing systems in resource-critical\\nenvironments (e.g., for performing machine learning on mobile devices or embedded\\nsystems).\\nParallelization is the classic computer science answer to performance problems. Par‐\\nallelizing machine learning algorithms and/or running them in a distributed fashion\\non MapReduce frameworks such as Apache Spark (Streaming) are good ways to\\nimprove performance by orders of magnitude. In designing systems for the real\\nworld, keep in mind that some machine learning algorithms cannot easily be parallel‐\\nized, because internode communication is required (e.g., simple clustering algo‐\\nrithms). Using distributed machine learning libraries such as Apache Spark MLlib\\ncan help you to avoid the pain of having to implement and optimize distributed\\nmachine learning systems. We further investigate the use of these frameworks in\\nChapter 7.\\n122 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 140}, page_content='Maintainability of Anomaly Detection Systems\\nThe longevity and usefulness of machine learning systems is dictated not by accuracy\\nor efficacy, but by the understandability, maintainability, and ease of configuration of\\nthe software. Designing a modular system that allows for swapping out, removing,\\nand reimplementing subcomponents is crucial in environments that are in constant\\nflux. The nature of data constantly changes, and a well-performing machine learning\\nmodel today might no longer be suitable half a year down the road. If the anomaly\\ndetection system is designed and implemented on the assumption that elliptic enve‐\\nlope fitting is to be used, it will be difficult to swap the algorithm out for, say, isolation\\nforests in the future. Flexible configuration of both system and algorithm parameters\\nis important for the same reason. If tuning model parameters requires recompiling\\nbinaries, the system is not configurable enough.\\nIntegrating Human Feedback\\nHaving a feedback loop in your anomaly detection system can make for a formidable\\nadaptive system. If security analysts are able to report false positives and false nega‐\\ntives directly to a system that adjusts model parameters based on this feedback, the\\nmaintainability and flexibility of the system can be vastly elevated. In untrusted envi‐\\nronments, however, directly integrating human feedback into the model training can\\nhave negative effects.\\nMitigating Adversarial Efects\\nAs mentioned earlier, in a hostile environment your machine learning security sys‐\\ntems almost certainly will be attacked. Attackers of machine learning systems gener‐\\nally use one of two classes of methods to achieve their goals. If the system continually\\nlearns from input data and instantaneous feedback labels provided by users (online\\nlearning model), attackers can poison the model by injecting intentionally misleading\\nchaf traffic to skew the decision boundaries of classifiers. Attackers can also evade\\nclassifiers with adversarial examples that are specially crafted to trick specific models\\nand implementations. It is important to put specific processes in place to explicitly\\nprevent these threat vectors from penetrating your system. In particular, designing a\\nsystem that blindly takes user input to update the model is risky. In an online learning\\nmodel, inspecting any input that will be converted to model training data is impor‐\\ntant for detecting attempts at poisoning the system. Using robust statistics that are\\nresilient to poisoning and probing attempts is another way of slowing down the\\nattacker. Maintaining test sets and heuristics that periodically test for abnormalities in\\nthe input data, model decision boundary, or classification results can also be useful.\\nWe further explore adversarial problems and their solutions in Chapter 8.\\nPractical System Design Concerns \\n| \\n123'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 141}, page_content='Conclusion\\nAnomaly detection is an area in which machine learning techniques have shown a lot\\nof efficacy. Before diving into complex algorithms and statistical models, take a\\nmoment to think carefully about the problem you are trying to solve and the data\\navailable to you. The answer to a better anomaly detection system might not be to use\\na more advanced algorithm, but might rather be to generate a more complete and\\ndescriptive set of input. Because of the large scope of threats they are required to miti‐\\ngate, security systems have a tendency to grow uncontrollably in complexity. In build‐\\ning or improving anomaly detection systems, always keep simplicity as a top priority.\\n124 \\n| \\nChapter 3: Anomaly Detection'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 142}, page_content='1 We go into detailed discussions on statistical learning methods like classification, clustering, and anomaly\\ndetection in Chapters 2, 3, and 5.\\nCHAPTER 4\\nMalware Analysis\\nWhen the air-gapped nuclear centrifuges in Iran’s Natanz uranium enrichment\\nfacility inexplicably ceased to function in 2010, no one knew for sure who was\\nresponsible. The Stuxnet worm was one of the most sensational successes of interna‐\\ntional cyber warfare, and a game-changing demonstration of the far-reaching\\ndestructive capabilities of malicious computer software. This piece of malware propa‐\\ngated itself indiscriminately around the world, only unleashing its payload when it\\ndetected a specific make of industrial computer system that the target used. Stuxnet\\nreportedly ended up on tens of thousands of Windows machines in its dormant state,\\nwhile resulting in the destruction of one-fifth of Iran’s nuclear centrifuges, thereby\\nachieving its alleged goal of obstructing the state’s weapons program.\\nMalware analysis is the study of the functionality, purpose, origin, and potential\\nimpact of malicious software. This task is traditionally highly manual and laborious,\\nrequiring analysts with expert knowledge in software internals and reverse engineer‐\\ning. Data science and machine learning have shown promise in automating certain\\nparts of malware analysis, but these methods still rely heavily on extracting meaning‐\\nful features from the data, which is a nontrivial task that continues to require practi‐\\ntioners with specialized skillsets.\\nIn this chapter, we do not focus on statistical learning methods.1 Instead, we discuss\\none of the most important but often underemphasized steps of machine learning: fea‐\\nture engineering. This chapter seeks to explain the behavior and inner workings of\\nmalicious executable binaries. Specifically, we approach the task of malware analysis\\nand classification from the lens of data science, examining how to meaningfully\\nextract useful information from computer binaries.\\n125'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 143}, page_content='2 Our use of the term binary data in this chapter refers to a data representation format that is solely made up of\\nzeros and ones. Each individual 0/1 unit is called a bit, and each consecutive set of eight bits is called a byte. In\\nmodern computer systems, binary files are commonplace, and software functions convert this bit/byte-level\\nrepresentation into higher-level information abstractions for further interpretation by other software (assem‐\\nbly instructions, uncompressed files, etc.) or for display on a user interface (text, images, audio, etc.).\\nBecause of the amount of background knowledge necessary for a useful discussion of\\nperforming feature engineering on malware, this chapter is split into two parts. The\\nfirst part, “Understanding Malware”, provides context on the ways to classify mal‐\\nware, the malware economy, software execution mechanisms, and typical malware\\nbehavior. This discussion sets us up for the second part, “Feature Generation”, in\\nwhich we discuss specific techniques for extracting and engineering features from\\nbinary data formats2 for use in data science and machine learning.\\nUnderstanding Malware\\nSource code goes through a series of steps before being run as a software program on\\na computer. Understanding these steps is critical for any malware analyst. There are\\nabout as many different types of malware as there are different types of software, each\\ntype potentially written in a different programming language, targeting different run‐\\ntime environments, and having different execution requirements. With access to the\\nhigh-level code (such as C/C++, Java, or Python), it is relatively easy to figure out\\nwhat the program is doing and how to profile its behavior. However, you likely will\\nnot be able to get easy access to the high-level code used to produce malware. Most\\nmalware is captured and collected in the wild, trapped in honeypots, traded on\\nunderground forums, or found on the machines of its unwitting victims. In its pack‐\\naged and deployed state, most malware exists as binaries, which are often not human\\nreadable and are intended for direct machine execution. Profiling the characteristics\\nand behavior of malware then becomes a process of reverse engineering to figure out\\nwhat it is doing as if we had access to its high-level code.\\nBinaries are by their nature obfuscated, presenting great difficulties to those who try\\nto extract information from them. Without knowing the context of interpretation,\\nencoding standards, and decoding algorithm, binary data itself is meaningless. As\\ndiscussed in earlier chapters, a machine learning system is only as good as the quality\\nof its input data. In particular, even more than other forms of input, raw data requires\\na plan for data collection, cleaning, and validation before applying a machine learning\\nalgorithm. Preprocessing this raw data is important for selecting the optimal format\\nand representation to feed into the learning algorithm.\\nIn this book, we refer broadly to the entire process of collecting and sculpting the\\ndata into a format suitable for input into algorithms as feature engineering. Feature\\nextraction is the term we use to describe the process of extracting features from the\\n126 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 144}, page_content='3 WAV (or WAVE) is an audio file format standard for storing an audio bitstream on computers.\\n4 For example, Practical Malware Analysis by Michael Sikorski and Andrew Honig (No Starch Press) and\\nMichael Hale Ligh et al.’s Malware Analyst’s Cookbook (Wiley).\\nraw data. For instance, if we wanted to classify WAV music files3 into different musi‐\\ncal genres (e.g., classical, rock, pop, jazz), our raw data would be WAV files. The most\\ndirect translation of each WAV file to an input to a machine learning algorithm is to\\nuse the bit-level binary representation of the file. However, this is neither the most\\neffective nor the most efficient representation of music files. Instead, we can perform\\nfeature engineering on the raw input to generate other representations of this data.\\nFor instance, we might run it through a music analysis program to extract features\\nsuch as the minimum, maximum, and mean amplitude and frequency. More sophisti‐\\ncated analysis programs might be able to extract features like the number of beats per\\nminute, the musical key the piece is in, and subtler polyphonic characteristics of the\\nmusic. As you can imagine, these features can help to paint a much more complete\\npicture of each piece of music, allowing a machine learning classifier to learn the dif‐\\nferences in tempo, rhythm, and tonal characteristics between samples of different\\ngenres.\\nTo identify and extract good features for performing security analysis on computer\\nbinaries, a deep understanding of software internals is required. This field of study is \\ncalled sotware reverse engineering—the process of extracting information and knowl‐\\nedge of the inner workings of software to fully understand its properties, how it\\nworks, and its flaws. By reverse engineering a binary, we can understand its function‐\\nality, its purpose, and sometimes even its origin. Reverse engineering is a specialized\\nskill that requires a lot of training and practice, and this chapter will not serve as a\\ncomprehensive guide to reverse engineering—there are many such guides available.4\\nInstead, we aim to provide a foundation for approaching feature generation with\\nreverse engineering principles. By understanding how a piece of software works and\\nidentifying properties unique to its function, we can design better features that will\\nhelp machine learning algorithms generate better predictions.\\nMalicious software can be embedded in a variety of different binary formats that\\nwork quite differently from one another. For instance, Windows PE files (Portable\\nExecutables, with file extensions .exe, .dll, .ei, etc.), Unix ELF files (Executable and\\nLinkable Format), and Android APK files (Android Package Kit format, with file\\nextensions .apk, etc.) have very different file structures and execution contexts. Natu‐\\nrally, the background required to analyze each class of executables is different, as well.\\nWe need also to consider malware that exist in forms other than standalone binary\\nexecutables. Document-based malware with file extensions such as .doc, .pdf, and .rtf\\nUnderstanding Malware \\n| \\n127'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 145}, page_content='5 A macro is a set of commands for automating certain specific repetitive tasks within the context of applica‐\\ntions like Microsoft Word or Excel. Macro malware was widespread in the 1990s, exploiting the automation\\ncapabilities of these popular programs to run malicious code on the victim’s machine. Macro malware has\\nseen a comeback in recent years, often driven by social engineering campaigns to achieve widespread\\ndistribution.\\n is commonly found to make use of macros5 and dynamic executable elements in the\\ndocument structure to carry out malicious acts. Malware can also come in the form\\nof extensions and plug-ins for popular software platforms such as web browsers and\\nweb frameworks. We do not go into too much detail on each of these formats, and\\ninstead just touch on important differences between them, focusing on Android\\nAPKs as an example to guide your own research and development in malware data\\nanalysis.\\nDeining Malware Classiication\\nBefore we begin tearing apart binaries, let’s ground the discussion with some defini‐\\ntions. Malware classification groups distinct malware samples together based on\\ncommon properties. We can classify malware in many different ways, depending on\\nthe purpose of the task. For instance, a security operations team might group mal‐\\nware by severity and function in order to effectively triage the risk that it poses to an\\norganization. Security response teams might group malware by potential scope of\\ndamage and entry vector in order to devise remediation and mitigation strategies.\\nMalware researchers might categorize malware by origin and authorship in order to\\nunderstand its genealogy and purpose.\\nFor general-purpose malware analysis, industry practice is to group samples by family\\n—a term used by malware analysts that allows for tracking authorship, correlating\\ninformation, and identifying new variants of newly found malware. Malware samples\\nof the same family can have similar code, capabilities, authorship, functions, pur‐\\nposes, and/or origins. A famous example of a malware family is Conicker, a worm\\ntargeting the Microsoft Windows operating system. Even though there are many var‐\\niations of the Conficker worm, each with different code, authors, and behavior, cer‐\\ntain characteristics of the worms cause them to be attributed to the same malware\\nfamily, indicating that they have likely evolved from a previously known ancestor. For\\nexample, all of the Conficker worms exploit Windows OS vulnerabilities and engage\\nin dictionary attacks to crack the password of the administrator account, thereafter\\ninstalling covert software on the exploited host to engage in botnet activity.\\nDifferences between malware samples within the same family can originate from dif‐\\nferent compilers used to compile the source code, or from sections of code added\\nand/or removed to modify the functionality of the malware itself. Malware samples\\nthat evolve over time in response to changing detection or mitigation strategies often\\nalso exhibit similarities between the older and newer versions, allowing analysts to\\n128 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 146}, page_content='6 There is a subtle difference between metamorphism and polymorphism in malware. Polymorphic malware typ‐\\nically contains two sections: the core logic that performs the infection, and another enveloping section that\\nuses various forms of encryption and decryption to hide the infection code. Metamorphic malware injects,\\nrearranges, reimplements, adds, and removes code in the malware. Because the infection logic is not altered\\nbetween each malware evolution stage, it is comparatively easier to detect polymorphic malware than meta‐\\nmorphic malware.\\ntrace the evolution of a family of malware. Nevertheless, malware family attribution is\\na notoriously difficult task that can have different results depending on the classifica‐\\ntion definitions and methods used by the analyst.\\nMalware classification can also be generalized to include the classification of nonma‐\\nlicious binaries. This type of classification is used to determine whether a piece of\\nsoftware is malicious. Given an arbitrary binary, we want to know the likelihood that\\nwe are able to trust it and execute it in a trusted environment. This is a core objective\\nof antivirus software and is an especially critical task for computer security practi‐\\ntioners, because this knowledge can help to prevent the spread of malware within an\\norganization. Traditionally, this task is driven by signature matching: given a trove of\\nproperties and behavior of previously seen malware, new incoming binaries can be\\ncompared against this dataset to determine whether it matches something seen\\nbefore.\\nThe signature-matching method performs well so long as malware authors fail to sig‐\\nnificantly change properties and behavior of the malware to avoid detection, and the\\nselected properties and behavior have a good balance of signal stability (so all mal‐\\nware samples belonging to this family exhibit this signal) and distinctiveness (so\\nbenign binaries will not exhibit properties or behaviors that cause them to be wrongly\\nclassified as malware). However, malware authors have a strong incentive to continu‐\\nously alter the properties and behavior of their software to avoid detection.\\nMetamorphic or polymorphic6 viruses and worms employ static and dynamic obfus‐\\ncation techniques to change characteristics of their code, behavior, and properties\\nused in the signature generation algorithms of malware identification engines. This\\nlevel of sophistication in malware used to be rare but has become more common due\\nto its continued success in thwarting syntactic signature malware engines. Syntactic\\nsignature engines continue to chase the ever-narrowing set of static signals that mal‐\\nware authors neglect to obfuscate or fundamentally cannot change.\\nMachine learning in malware classiication\\nData science and machine learning can help with some of the problems caused by\\nmodern malware, largely due to three characteristics that give them a leg up com‐\\npared to static signature matching:\\nUnderstanding Malware \\n| \\n129'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 147}, page_content='Fuzzy matching\\nMachine learning algorithms can express the similarity between two or more\\nentities using a distance metric. Similarity matching engines that previously\\nemitted a binary output—match or no match—can now output a real number\\nbetween 0 and 1 that indicates a conidence score associated with how likely the\\nalgorithm thinks it is that the two entities are the same or belong to the same\\nclass. Referring to the intuitive example of clustering methods, data samples that\\nare mapped into a vector space of features can be grouped together based on the\\nrelative distances between each of them. Points that are close to one another can\\nbe considered to be highly similar, whereas points that are far apart from one\\nanother can be considered to be highly dissimilar.\\nThis ability to express approximate matches between entities is very helpful in\\nclassifying malware whose differences confuse static signature matching.\\nAutomated property selection\\nAutomatic feature weighting and selection is a key aspect of machine learning\\nthat helps with malware classification. Based on statistical properties of the train‐\\ning set, features can be ranked by their relative importance in distinguishing a\\nsample belonging to class A from another sample belonging to class B as well as\\nin being able to group two samples belonging to class A together. Malware classi‐\\nfication has traditionally been a highly manual task, involving a large amount of\\nexpert background knowledge about how malware operates and what properties\\nto use in a malware classification engine. Some dimensionality reduction and fea‐\\nture selection algorithms can even uncover latent properties of samples that\\nwould otherwise have been difficult for even an expert malware analyst to find.\\nMachine learning relieves malware analysts of some of the burden of determin‐\\ning the value of each feature. By letting the data automatically detect and dictate\\nthe set of features to use in a classification scheme, analysts can instead focus\\ntheir efforts on feature engineering, enriching the algorithm’s abilities by provid‐\\ning a larger and more descriptive dataset.\\nAdaptiveness\\nThe constant battle between malware perpetrators and system defenders implies\\na constant state of flux in the attack samples generated. Just as in typical software\\ndevelopment, malware evolves over time as its authors add functionality and fix\\nbugs. In addition, as we discussed earlier, malware authors have an incentive to\\nconstantly be on the move, changing the behavior of the malware to avoid detec‐\\ntion. With fuzzy matching and a data-driven feature selection process, malware\\nclassification systems implemented with machine learning can adapt to changing\\ninput and track the evolution of malware over time.\\nFor instance, samples of the Conficker malware family from 2008 and 2010 can\\nexhibit vastly different behavior and appearances. An adaptive classification\\n130 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 148}, page_content='system that has consistently tracked and detected gradual changes in samples\\nfrom this family over time has learned to look for properties that match not only\\nthe early data samples, but also the evolved samples from the same family.\\nMalware attribution might not be crucial for the classification task at hand, but\\nobtaining a comprehensive understanding of the attacker’s objectives and origin can\\nhelp defenders to devise more farsighted mitigation strategies that will stymie long-\\nterm attempts by perpetrators to penetrate a system.\\nMachine learning can help to greatly reduce the amount of manual work and expert\\nknowledge required in malware classification. Allowing data and algorithms to drive\\ndecisions that require drawing correlations between large numbers of samples turns\\nout to yield much better results than humans doing the job. Finding patterns and\\nsimilarities in data is the forte of machine learning algorithms, but some aspects of\\nthe task still require human effort. Generating descriptive datasets in a format that\\naids algorithms in the learning and classification tasks is a job that requires a data sci‐\\nentist with an innate understanding of both how malware works and how algorithms\\nwork.\\nMalware: Behind the Scenes\\nTo generate a descriptive dataset for classifying malware, we need to understand how\\nmalware works. This in turn requires some discussion of the malware economy, com‐\\nmon types of malware, and general software execution processes in modern comput‐\\ning environments.\\nThe malware economy\\nAs we discussed in “The Cyber Attacker’s Economy” on page 7, the malware economy\\nis vibrant and bustling because of the fundamental imbalance between the cost and\\nbenefits of distributing malware. Approaching this topic from the perspective of eco‐\\nnomics, it is easy to understand why malware is so prevalent. Malware distributors\\nneed only expend minimal effort or a small amount of money to acquire malware\\nbinaries. Pay-per-install (PPI) marketplaces then provide cheap and guaranteed mal‐\\nware distribution channels. Even without organized distribution platforms, malware\\ncan still easily be spread widely through the web, email, and social engineering tech‐\\nniques. After malware is distributed to an unwitting group of victims, miscreants can\\nreap potentially huge returns because of the high underground market value of the\\nstolen credentials or credit card numbers, and illegitimate advertising revenue.\\nMalware authors are typically experienced and talented developers who work either\\nfor themselves or with an organized group. However, most malware distributors are\\nnot authors. Malware distributors most commonly purchase their payloads from\\nunderground online marketplaces and forums. The slightly more technically compe‐\\ntent actors steal and adapt malware from other authors for their own purposes. A\\nUnderstanding Malware \\n| \\n131'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 149}, page_content='family of malware samples can all exhibit similar functionality and seem to stem from\\na common strain that evolves over time, but not all changes to the malware might be\\nmade by the same author (or group). New iterations of a malware strain can be devel‐\\noped independently without the knowledge of the original authors. With access to the\\ncode, or with the ability to reverse engineer and reassemble programs, simple edits\\ncan be made by any dedicated actor and redistributed as new malware.\\nCompared to its potential benefits, the cost of obtaining and distributing malware is\\nminiscule. Let’s take ransomware as an example. Ransomware offers a uniquely\\nstraightforward cash-out process for perpetrators. Customizable ransomware (allow‐\\ning buyers to insert their own ransom messages and Bitcoin wallet addresses before\\nsending it out) can be purchased from underground marketplaces for tens of dollars.\\nIt costs about $180 per thousand successful installations of the ransomware on a com‐\\nputer in an affluent region. If a demand for ransom equivalent to $50 is posted to\\nevery infected computer, and 10% of people choose to pay up—a conservative esti‐\\nmate—the perpetrator’s expected earnings would be more than 25 times the initial\\ninvestment. This highly lucrative business model explains the surge in ransomware\\ninfections over the past few years.\\nAn important thing to note is that most illegitimate businesses would have had simi‐\\nlarly skewed economies had they not been strictly controlled by enforceable laws and\\nregulations. Drug dealers, cashing in on human addiction tendencies, can exploit a\\nhighly inelastic supply curve to astronomically boost their profit margins. Gangs that\\nextort money from victims under the threat of violence can undoubtedly make a\\ngood profit from their operations. The difference between these examples and the\\nmalware economy is the difficulty in subjecting the latter to crime attribution and law\\nenforcement. It is nearly impossible to confidently attribute responsibility for a cyber\\nattack or malware authorship to a specific actor, and hence almost impossible to exact\\nlegal consequences. This property makes malware distribution one of the most lucra‐\\ntive and least risky illegal businesses ever to exist.\\nModern code execution processes\\nWe now examine how general classes of modern programs are written and executed,\\nand consider how one might inspect binaries and executing programs to understand\\ntheir inner workings without any access to the written code.\\n132 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 150}, page_content='7 Languages that are commonly (but not exclusively) compiled include C/C++, Go, and Haskell.\\n8 Languages that have bytecode interpreters include Python, Ruby, Smalltalk, and Lua.\\n9 Java is an interesting example of a popular language that can be considered to be both a compiled and an\\ninterpreted language, depending on the implementation. Java uses a two-step compilation process: human-\\nwritten Java source code is first compiled into bytecode by the Java compiler, which is then executed by the\\nJava virtual machine (JVM). Most modern JVMs make use of JIT compilation to translate this bytecode into\\nnative machine instructions that will be directly executed on hardware. In some other JVM implementations,\\nthe bytecode can be directly interpreted by a virtual machine, similar to how pure interpreted languages are\\nrun.\\nThe following discussion describes the code execution process for a\\nlarge class of common computer programs, which applies to many\\nmodern programming languages and execution platforms. It is by\\nno means a comprehensive or representative depiction of how all\\nkinds of programs are executed. The vast and diverse ecosystem of\\nprogramming environments and system runtimes results in a range\\nof subtle to obtuse differences in how code executes in different\\nenvironments. Nevertheless, many of the concepts we discuss are\\ngeneralizable and parallels can often be drawn with other types of\\ncode execution processes.\\nIn general, there are two types of code execution: compiled execution and interpreted\\nexecution. In compiled execution, the written code is translated into native machine\\ninstructions by a series of conversion steps7 (often referred to as the sotware build\\nprocess). These machine instructions are packaged into binaries, which can then be\\nexecuted directly by hardware. In interpreted execution implementations, the written\\ncode (sometimes referred to as a script) is translated into an intermediate format\\nwhich is then fed into an interpreter for program execution. The interpreter is in\\ncharge of enacting the program’s instructions on the hardware it is running on. The\\nintermediate format varies between different implementations, but is most commonly\\na form of bytecode (binary machine instructions) that will be executed on a virtual\\nmachine.8 Some implementations are a hybrid of compiled and interpreted execu‐\\ntions, often using a process called just-in-time (JIT) compilation, in which interpreter\\nbytecode is compiled into native machine instructions in real time.9\\nFigure 4-1 depicts common code execution processes for some modern software\\nimplementations.\\nUnderstanding Malware \\n| \\n133'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 151}, page_content='Figure 4-1. Code execution and program analysis lowchart\\nLet’s take a closer look at the elements in Figure 4-1:\\n• The rectangular boxes represent the program in its various states of existence.\\n• The ellipses represent software conversion steps that translate the program from\\none state to another.\\n• The solid arrows between nodes represent the progression of the code from its\\nhuman-written state to its eventual execution on the hardware.\\n• The gray box contains some tools that reverse engineers can use to inspect the\\nstatic or dynamic state of a binary or running program (as indicated by the\\ndashed arrows), providing valuable points of visibility into the code execution\\nprocess.\\nCompiled code execution.    As an example, we’ll take a piece of C code that performs\\nsome simple arithmetic and go step-by-step through the build process for a compiled\\nimplementation. Referring to Figure 4-1, we follow the path of a program from the\\n134 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 152}, page_content='10 Code for this example can be found in chapter4/code-exec-eg/c in our code repository.\\ninitial “Source Code (Compiled Execution)” state. Here is the code we want to build,\\nsaved in a file named add.c:10\\n#include <stdio.h>\\nint main() {\\n    // Adds 1 to variable x\\n    int x = 3;\\n    printf(\"x + 1 = %d\", x + 1);\\n    return 0;\\n}\\n1. The first step of the build process is a small but important one: preprocessing\\n(omitted in Figure 4-1). In C, lines starting with the # character are interpreted\\nby the preprocessor as preprocessor directives. The preprocessor simply iterates\\nthrough the code and treats these directives as macros, preparing the code for\\ncompilation by inserting contents of included libraries and removing code com‐\\nments, amongst other similar actions it performs. To inspect the results of the\\npreprocessing stage, you can run the following command:\\n> cc -E add.c\\n[above lines omitted for brevity]\\nextern void funlockfile (FILE *__stream)\\n                          __attribute__ ((__nothrow__ , __leaf__));\\n# 942 \"/usr/include/stdio.h\" 3 4\\n# 2 \"add.c\" 2\\n# 3 \"add.c\"\\nint main() {\\n    int x = 3;\\n    printf(\"x + 1 = %d\", x + 1);\\n    return 0;\\n}\\nNote that the output of the preprocessing stage contains many lines of code that\\nweren’t in the original add.c file. The preprocessor has replaced the #include\\n<stdio.h> line with some contents from the standard C library stdio.h. Also\\nnote that the inline comment in the original code no longer shows up in this\\noutput.\\n2. The next step of the build process is compilation. Here, the compiler translates\\nthe preprocessed code into assembly code. The assembly code generated is spe‐\\ncific to the target processor architecture, since it contains instructions that the\\nUnderstanding Malware \\n| \\n135'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 153}, page_content='11 In particular, GCC version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4) was used in this example.\\nCPU has to understand and execute. The assembly instructions generated by the\\ncompiler must be part of the instruction set understood by the underlying pro‐\\ncessor. To inspect the output of the C compiler by saving the assembly code to a\\nfile, you can run the following:\\n> cc -S add.c\\nThis is the assembly code generated on a specific version of the GCC11 (GNU\\nCompiler Collection) C compiler, targeted at a 64-bit Linux system (x86_64-\\nlinux-gnu):\\n> cat add.s\\n    .file   \"add.c\"\\n    .section    .rodata\\n.LC0:\\n    .string \"x + 1 = %d\"\\n    .text\\n    .globl  main\\n    .type   main, @function\\nmain:\\n.LFB0:\\n    .cfi_startproc\\n    pushq   %rbp\\n    .cfi_def_cfa_offset 16\\n    .cfi_offset 6, −16\\n    movq    %rsp, %rbp\\n    .cfi_def_cfa_register 6\\n    subq    $16, %rsp\\n    movl    $3, −4(%rbp)\\n    movl    −4(%rbp), %eax\\n    addl    $1, %eax\\n    movl    %eax, %esi\\n    movl    $.LC0, %edi\\n    movl    $0, %eax\\n    call    printf\\n    movl    $0, %eax\\n    leave\\n    .cfi_def_cfa 7, 8\\n    ret\\n    .cfi_endproc\\n.LFE0:\\n    .size   main, .-main\\n    .ident  \"GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\"\\n    .section    .note.GNU-stack,\"\",@progbits\\n136 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 154}, page_content='12 There are many good books for learning assembly, including Assembly Language Step-by-Step: Programming\\nwith Linux, 3rd ed., by Jeff Duntemann (Wiley), and he Art of Assembly Language, 2nd ed., by Randall Hyde\\n(No Starch Press).\\nThis output will seem unintelligible unless you are familiar with assembly code\\n(in this case, x64 assembly code). However, with some knowledge of assembly it\\nis possible to gather quite a complete picture of what the program is doing solely\\nbased on this code. Looking at the two lines in bold in example output, addl ...\\nand call printf, it is pretty easy to guess that the program is doing an addition\\nand then invoking the print function. Most of the other lines just make up the\\nplumbing—moving values in and out of CPU registers and memory locations\\nwhere other functions can access them. Nevertheless, analyzing assembly code is\\nan involved topic, and we will not go into further detail here.12\\n3. After the assembly code is generated, it is then up to the assembler to translate\\nthis into object code (machine code). The output of the assembler is a set of\\nmachine instructions that the target processor will directly execute:\\n> cc -c add.c\\nThis command creates the object file add.o. The contents of this file are in binary\\nformat and are difficult to decipher, but let’s inspect it anyway. We can do this\\nusing tools such as hexdump and od. The hexdump utility, by default, displays the\\ncontents of the target file in hexadecimal format. The first column of the output\\nindicates the offset of the file (in hexadecimal) where you can find the corre‐\\nsponding content:\\n> hexdump add.o\\n0000000 457f 464c 0102 0001 0000 0000 0000 0000\\n0000010 0001 003e 0001 0000 0000 0000 0000 0000\\n0000020 0000 0000 0000 0000 02b8 0000 0000 0000\\n0000030 0000 0000 0040 0000 0000 0040 000d 000a\\n0000040 4855 e589 8348 10ec 45c7 03fc 0000 8b00\\n0000050 fc45 c083 8901 bfc6 0000 0000 00b8 0000\\n0000060 e800 0000 0000 00b8 0000 c900 78c3 2b20\\n             [omitted for brevity]\\n00005c0 0000 0000 0000 0000 0000 0000 0000 0000\\n00005d0 01f0 0000 0000 0000 0013 0000 0000 0000\\n00005e0 0000 0000 0000 0000 0001 0000 0000 0000\\n*\\n00005f8\\nThe od (which stands for octal dump) utility dumps contents of files in octal and\\nother formats. Its output might be slightly more readable, unless you are a hex-\\nreading wizard:\\nUnderstanding Malware \\n| \\n137'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 155}, page_content=\"13 To run a binary on Unix systems, we need to grant execution permission to the file. chmod is the command\\nand system call that can change the access permissions to Unix files, and the +x argument indicates that we\\nwant to grant the “execute” permission to this file.\\n> od -c add.o\\n...0000 177   E   L   F 002 001 001  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0\\n...0020 001  \\\\0   >  \\\\0 001  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0\\n...0040  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0 270 002  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0\\n...0060  \\\\0  \\\\0  \\\\0  \\\\0   @  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0   @  \\\\0  \\\\r  \\\\0  \\\\n  \\\\0\\n...0100   U   H 211 345   H 203 354 020 307   E 374 003  \\\\0  \\\\0  \\\\0 213\\n                         [omitted for brevity]\\n...2700  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0\\n...2720 360 001  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0 023  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0\\n...2740  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0 001  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0\\n...2760  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0  \\\\0\\n...2770\\nThis allows us to directly make out some of the structure of the binary file. For\\ninstance, notice that around the beginning of the file lie the characters E, L, and\\nF. The assembler produced an ELF file (Executable and Linkable Format, specifi‐\\ncally ELF64), and every ELF file begins with a header indicating some properties\\nof the file, including what type of file it is. A utility such as readelf can help us to\\nparse out all of the information embedded within this header:\\n> readelf -h add.o\\nELF Header:\\n  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00\\n  Class:                             ELF64\\n  Data:                              2's complement, little endian\\n  Version:                           1 (current)\\n  OS/ABI:                            UNIX - System V\\n  ABI Version:                       0\\n  Type:                              REL (Relocatable file)\\n  Machine:                           Advanced Micro Devices X86-64\\n  Version:                           0x1\\n  Entry point address:               0x0\\n  Start of program headers:          0 (bytes into file)\\n  Start of section headers:          696 (bytes into file)\\n  Flags:                             0x0\\n  Size of this header:               64 (bytes)\\n  Size of program headers:           0 (bytes)\\n  Number of program headers:         0\\n  Size of section headers:           64 (bytes)\\n  Number of section headers:         13\\n  Section header string table index: 10\\n4. At this stage, let’s try to execute the object file generated by the assembler:13\\n138 \\n| \\nChapter 4: Malware Analysis\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 156}, page_content='14 Most often, Unix and its derivatives (such as Linux and the modern macOS) use the term “shared libraries”\\n(or shared objects) for dynamic libraries, whereas Windows uses the term “dynamically linked libraries”\\n(DLLs). In some language environments (e.g., Lua), there is a subtle difference between shared libraries and\\ndynamic libraries: a shared library or shared object is a special type of dynamic library for which only one\\ncopy is shared between running processes.\\n15 Not to be confused with Cython, which is an extension of the Python language written in C, with functionality\\nthat allows you to hook into external C libraries.\\n> chmod u+x add.o\\n> ./add.o\\nbash: ./add.o: cannot execute binary file: Exec format error\\nWhy does the Exec format error show up? The object code generated by the\\nassembler is missing some crucial pieces of the program that are required for\\nexecution. Furthermore, sections of the program are not arranged properly, so\\nlibrary and program functions cannot be successfully invoked. Linking, the final\\nstage of the build process, will fix these issues. In this case, the linker will insert\\nthe object code for the printf library function into the binary. Let’s invoke cc to\\ngenerate the final executable binary (specifying the name of the output as add;\\notherwise, cc will use the default name of a.out), and then run the program:\\n> cc -o add add.c\\n> chmod u+x add\\n> ./add\\nx + 1 = 4\\nThis concludes the build process for a simple program in C, from code to\\nexecution.\\nIn the preceding example, the stdio.h external library was statically linked into the\\nbinary, which means that it was compiled together with the rest of the code in a single\\npackage. Some languages and implementations allow for the dynamic inclusion of\\nexternal libraries, which means that library components referenced in the code are\\nnot included in the compiled binary. Upon execution, the loader is invoked, scanning\\nthe program for references to dynamically linked libraries (or shared libraries,14 with\\nextensions .so, .dll, etc.) and then resolving these references by locating the libraries\\non the system. We do not go into further detail on dynamic library loading mecha‐\\nnisms here.\\nInterpreted code execution.    As an example of interpreted language implementations,\\nwe will dissect the typical Python script execution process. Note that there are several\\ndifferent implementations of Python with different code execution processes. In this\\nexample, we look at CPython,15 the standard and original implementation of Python\\nwritten in C. In particular, we are using Python 3.5.2 on Ubuntu 16.04. Again\\nUnderstanding Malware \\n| \\n139'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 157}, page_content=\"16 Code for this example can be found in chapter4/code-exec-eg/python in our code repository.\\n17 When Python code is compiled with optimizations turned on, a .pyo file is created. This .pyo file is essentially\\nthe same as a .pyc file.\\n18 Compiled files are created as an optimization to speed up program startup time. In Python versions lower\\nthan 3.2, the autogenerated .pyc files are created in the same directory as the main .py file. In later versions,\\nthese files are created in a pycache subdirectory and are assigned other names depending on the Python inter‐\\npreter that created them.\\nreferring to Figure 4-1, we follow the path of a program from the initial “Source Code\\n(Interpreted Execution)” state:16\\nclass AddOne():\\n    def __init__(self, start):\\n        self.val = start\\n    def res(self):\\n        return self.val + 1\\ndef main():\\n    x = AddOne(3)\\n    print('3 + 1 = {} '.format(x.res()))\\nif __name__ == '__main__':\\n    main()\\n1. We begin with this Python source code saved in a file, add.py. Running the script\\nby passing it as an argument to the Python interpreter yields the expected result:\\n> python add.py\\n3 + 1 = 4\\nAdmittedly, this is quite a convoluted way to add two numbers, but this example\\ngives us a chance to explore the Python build mechanism. Internally, this human-\\nwritten Python code is compiled into an intermediate format known as bytecode,\\na platform-independent representation of the program. We can see compiled\\nPython modules (.pyc files17) created if the script imports external modules and is\\nable to write to the target directory.18 In this case, no external modules were\\nimported, so no .pyc files were created. For the sake of inspecting the build pro‐\\ncess, we can force the creation of this file by using the py_compile module:\\n> python -m py_compile add.py\\nThis creates the .pyc file, which contains the compiled bytecode for our program.\\nIn Python 3.5.2, the compiled Python file is created as pycache/\\nadd.cpython-35.pyc. We then can inspect the contents of this binary file by\\nremoving the header and unmarshaling the file into a types.CodeType structure:\\nimport marshal\\nimport types\\n140 \\n| \\nChapter 4: Malware Analysis\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 158}, page_content=\"# Convert a big-endian 32-bit byte array to a long\\ndef to_long(s):\\n    return s[0] + (s[1] << 8) + (s[2] << 16) + (s[3] << 24)\\n# Print out hierarchy of code names and line numbers\\ndef inspect_code(code, indent='    '):\\n    print('{}{}(line:{})'.format(indent,\\n        code.co_name, code.co_firstlineno))\\n    for c in code.co_consts:\\n        if isinstance(c, types.CodeType):\\n            inspect_code(c, indent + '    ')\\nf = open('__pycache__/add.cpython-35.pyc', 'rb')\\n# Read .pyc file header\\nmagic = f.read(4)\\nprint('magic: {}'.format(magic.hex()))\\nmod_time = to_long(f.read(4))\\nprint('mod_time: {}'.format(mod_time))\\n# Only Python >=3.3 .pyc files contain the source_size header \\nsource_size = to_long(f.read(4))\\nprint('source_size: {}'.format(source_size))\\nprint('\\\\ncode:')\\ncode = marshal.load(f)\\ninspect_code(code)\\nf.close()\\nPython .pyc files from version 3.2 and below have a header containing two\\n32-bit big-endian numbers followed by the marshaled code object. In ver‐\\nsions 3.3 and above, a new 32-bit field that encodes the size of the source file\\nis included in the header, as well (increasing the size of the header from 8\\nbytes to 12 bytes in Python 3.3 compared to earlier version).\\nExecuting this script yields the following results:\\nmagic: 160d0d0a\\nmod_time: 1493965574\\nsource_size: 231\\ncode:\\n    <module>(line:1)\\n        AddOne(line:1)\\n            __init__(line:2)\\n            res(line:4)\\n        main(line:7)\\nUnderstanding Malware \\n| \\n141\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 159}, page_content='There is more information encoded in the CodeType object that we are not dis‐\\nplaying, but this shows the general structure of the bytecode binary.\\n2. This bytecode is executed by the Python virtual machine runtime. Note that this\\nbytecode is not binary machine code, but rather Python-specific opcodes that are\\ninterpreted by this virtual machine, which then translates the code into machine\\ninstructions. Using the dis.disassemble() function to disassemble the code\\nobject we created previously, we get the following:\\n> import dis\\n> dis.disassemble(code)\\n  1           0 LOAD_BUILD_CLASS\\n              1 LOAD_CONST               0 (< code object AddOne at\\n                                            0x7f78741f7930, file\\n                                            \"add.py\", line 1> )\\n              4 LOAD_CONST               1 (\\'AddOne\\')\\n              7 MAKE_FUNCTION            0\\n             10 LOAD_CONST               1 (\\'AddOne\\')\\n             13 CALL_FUNCTION            2 (2 positional,\\n                                            0 keyword pair)\\n             16 STORE_NAME               0 (AddOne)\\n  7          19 LOAD_CONST               2 (< code object main at\\n                                            0x7f78741f79c0, file\\n                                            \"add.py\", line 7> )\\n             22 LOAD_CONST               3 (\\'main\\')\\n             25 MAKE_FUNCTION            0\\n             28 STORE_NAME               1 (main)\\n 11          31 LOAD_NAME                2 (__name__)\\n             34 LOAD_CONST               4 (\\'__main__\\')\\n             37 COMPARE_OP               2 (==)\\n             40 POP_JUMP_IF_FALSE       50\\n 12          43 LOAD_NAME                1 (main)\\n             46 CALL_FUNCTION            0 (0 positional,\\n                                            0 keyword pair)\\n             49 POP_TOP\\n        > >    50 LOAD_CONST               5 (None)\\n             53 RETURN_VALUE\\nYou can also obtain the output shown in the previous two steps by invoking the\\nPython trace module on the command line via python -m trace add.py.\\nYou can immediately see the similarities between this output and the x86 assem‐\\nbly code we discussed earlier. The Python virtual machine reads in this bytecode\\n142 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 160}, page_content='19 The CPython interpreter’s conversion of Python opcodes to machine instruction code is fairly simple. A bit\\nswitch statement maps each line of Python opcode to C code, which can then be executed on the target\\nmachine after the assembler translates it into machine code.\\nand converts it to machine code,19 which executes on the target architecture,\\nthereby completing the code execution process.\\nThe code execution process for interpreted languages is shorter because there is no\\nrequired build or compilation step: you can run code immediately after you write it.\\nYou cannot run Python bytecode directly on target hardware, as it relies on interpre‐\\ntation by the Python virtual machine and further translation to machine code. This\\nprocess results in some inefficiencies and performance losses compared to “lower-\\nlevel” languages like C. Nevertheless, note that the Python file code execution\\ndescribed earlier involves some degree of compilation, so the Python virtual machine\\ndoesn’t need to reanalyze and reparse each source statement repeatedly through the\\ncourse of the program. Running Python in interactive shell mode is closer to the\\nmodel of a pure interpreted language implementation, because each line is analyzed\\nand parsed at execution time.\\nWith access to human-written source code, we can easily parse specific properties\\nand intentions of a piece of software that allow us to accurately classify it by family\\nand function. However, because we don’t often have access to the code, we must\\nresort to more indirect means to extract information about the program. With an\\nunderstanding of modern code execution processes, we can now begin to look at\\nsome different ways to approach static and runtime analysis of malware. Code traver‐\\nses a well-defined path in its journey from authorship to execution. Intercepting it at\\nany point along the path can reveal a great deal of information about the program.\\nTypical malware attack low\\nTo study and classify malware, it is important to understand what malware does and\\nhow a breach happens. As discussed in Chapter 1, different types of malware have\\ndifferent methods of propagation, serve different purposes, and pose different levels\\nof risk to individuals and organizations. However, it is possible to characterize a typi‐\\ncal malware attack flow; Figure 4-2 depicts this flow.\\nUnderstanding Malware \\n| \\n143'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 161}, page_content='Figure 4-2. Typical malware attack low\\nIn Phase 1, initial reconnaissance efforts are typically passive, using indirect methods\\nto scope out the target. After that, active reconnaissance efforts such as port scanning\\nare carried out to collect more specific and up-to-date information about the target,\\nfinding a weakness for infiltration. This weakness might be an open port running\\nunpatched vulnerable software, or an employee prone to spear phishing attacks.\\nExploiting the weakness can result in the malware successfully infiltrating the perim‐\\neter. Upon successful infiltration, the target is converted to a victim.\\nIn Phase 2, the malware is already in the victim’s environment. Through a process of\\ninternal reconnaissance efforts and host pivoting (aka horizontal movement), the mal‐\\nware can maneuver through the network to find high-value hosts. Then, it entrenches\\nitself within the environment using means such as installing backdoors for future\\naccess, or installing itself as a persistent background daemon process.\\nIn Phase 3, the malware is ready to remove itself from the environment and leave no\\ntrace. For malware that does any kind of private information stealing, the exfiltration\\nstep sends this stolen data (e.g., user credentials, credit card numbers, and critical\\nbusiness logic) to a remote server. Finally, when the task is completed, the malware\\nmight choose to purge itself and remove all traces of its actions from the victim\\nmachine.\\nDepending on the type of malware in question, some or all of the steps in the three\\nphases might be relevant. Malware also often exhibits certain types of behaviors that\\nwe would do well to understand:\\nHiding its presence\\nMalware frequently employs packers and encryption techniques to compress and\\nobfuscate its code. The purpose for doing this is to avoid detection and hinder\\nthe progress of researcher analysis.\\n144 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 162}, page_content='Performing its function\\nTo effectively perform its function, malware needs to ensure some degree of per‐\\nsistence so that it will not be wiped by system changes or detected by human\\nadministrators. Defense evasion techniques such as DLL side-loading and termi‐\\nnating antivirus processes are commonly employed. Certain types of malware\\nneed to maneuver across the network through lateral movement, and most types\\nof malware attempt some form of privilege escalation (either by exploiting a soft‐\\nware/OS vulnerability such as buffer overflows or social engineering the end\\nuser) to gain administrator access to a platform.\\nCollecting data and phoning home\\nAfter the malware collects all the data it needs (server/application credentials,\\nweb access logs, database entries, and so on) it sends the data to an external rally\\npoint. It might also “phone home” to a remote command-and-control (C&C)\\nserver and receive further instructions.\\nFeature Generation\\nAs a data scientist, far more of your time will be spent on getting data into a place and\\nformat where it can be used effectively than on building classifiers or performing stat‐\\nistical analysis. In the remainder of this chapter, we approach the subject of feature\\nextraction and feature engineering using malware and executable binaries as an\\nexample. We begin with an overview of the difficulties in getting the data in a form\\nsuitable for feature extraction. We then dive into the task of generating features for\\nmalware classification through a rich set of techniques for analyzing executables,\\nsome conducive to automation.\\nFeature engineering is relevant across all applications of machine learning, so why do\\nwe choose to focus on binaries? Binary data is the lowest common denominator of\\ndata representation. All other forms of information can be represented in binary for‐\\nmat, and extracting data from binaries is a matter of interpreting the bits that make\\nup the binary. Feature extraction and engineering is the process of interpreting raw\\ndata to generate facets of the data that best represent the nature of a distribution, and\\nthere is no data format more complex to analyze nor more pertinent to the security\\nprofession than executable binaries.\\nThe importance of data collection and feature engineering in machine learning can‐\\nnot be stressed enough. Data scientists and machine learning engineers sometimes\\nfind themselves in a position where they have little to no influence over the data col‐\\nlection methodology and process. This is a terrible setup because the biggest break‐\\nthroughs and improvements in machine learning and data science often come from\\nimproving the quality of the raw data, not from using fancier algorithms or designing\\nbetter systems. Whatever the task, there is great value in getting down and dirty with\\nraw data sources to find the best way of extracting the information that you need to\\nFeature Generation \\n| \\n145'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 163}, page_content='obtain good results. If a machine learning algorithm does not perform well, always\\nremember to consider whether it might be due to poor data quality rather than short‐\\ncomings in the algorithm.\\nNevertheless, data collection can often be the most laborious, expensive, and time-\\nconsuming part of data science. It is important to design flexible and efficient archi‐\\ntectures for data collection because of how much it can speed up the process of\\nbuilding a machine learning system. It can pay substantial dividends to do ample\\nupfront research on the best way to collect data and to determine what is worth col‐\\nlecting and what is not. Let’s look at some important things to consider when collect‐\\ning data for machine learning.\\nData Collection\\nSimply opening a valve and letting scads of data flood in from the internet to your\\napplication rarely produces data of sufficient quality for machine learning. You will\\nend up collecting data you don’t need along with the data that you do, and it might be\\nbiased or opaque. Here are some considerations that data scientists use to improve\\ndata collection:\\nImportance of domain knowledge\\nCollecting data for machine learning–driven malware analysis obviously requires\\na very different set of domain knowledge from that needed for other applications,\\nsuch as computer vision. Even though a fresh perspective (i.e., lack of domain\\nknowledge) is sometimes useful in thinking differently about a problem, deep\\ndomain expertise in the application area can help to very quickly identify impor‐\\ntant features to collect to help learning algorithms hone in on important parts of\\nthe data.\\nIn the security domain, it is useful to have an intuitive understanding of com‐\\nputer networking, OS fundamentals, code execution processes, and so on before\\nyou begin to apply machine learning to these areas. It can sometimes be difficult\\nto attain a satisfactory degree of expertise in various different domains, and real\\nexperience in dealing with specific problems is difficult to acquire overnight. In\\nsuch cases, it can be very valuable to consult with domain experts before design‐\\ning data collection and feature engineering schemes.\\nScalable data collection processes\\nTo get good results, we often need to feed large amounts of data into our machine\\nlearning algorithms. It can be simple to manually extract features from a dozen\\ndata samples, but when there are a million or more samples, things can become\\npretty complicated. Similarly, reverse engineering of binaries is a notoriously\\ntime-consuming and resource-intensive task. It is prohibitively expensive to\\nmanually reverse engineer a dataset of a hundred thousand different malware\\nsamples.\\n146 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 164}, page_content='Therefore, it is crucial to think about the automation of data collection processes\\nbefore you have to scale up your operation. However, with a combination of\\ndomain knowledge and data exploration, you can always devise ways to focus\\nyour efforts on automating the collection of only the most important features\\nrequired for the task.\\nValidation and bias\\nHow do you know that the collected data is correct and complete? Data valida‐\\ntion is of paramount importance, because systematic and consistent errors in\\ndata collection can render any downstream analysis invalid and can have cata‐\\nstrophic results on a machine learning system. But there is no easy way to vali‐\\ndate input data algorithmically. The best way to identify such problems early is to\\nperform frequent and random manual validation on collected data. If something\\ndoesn’t align with your expectations, it is important to find the root cause and\\ndetermine whether the discrepancy is caused by a data collection error.\\nDealing with intrinsic bias in the collected data requires a little bit more nuance,\\nbecause it is more difficult to detect even upon manual inspection. The only way\\nto reliably detect such an issue is to explicitly consider it as a potential cause for\\npoor machine learning results. For example, if an animal image classification sys‐\\ntem has a good overall accuracy but achieves consistently bad results for the bird\\ncategories, it might be because the selected features from the raw data are biased\\ntoward the better identification of other animals, or because the collected data\\nonly consists of images of birds at rest and not birds in flight.\\nMalware datasets frequently face the issue of staleness because of how quickly the\\nnature of the samples can change over time. For instance, samples from a mal‐\\nware family collected in January can be very unrepresentative of samples collec‐\\nted in March, because of how agile malware developers need to be to avoid\\nsignature-based detection. Security datasets also frequently face class imbalance\\nissues because it can be difficult to find an equal number of benign and malicious\\nsamples.\\nIterative experimentation\\nMachine learning is a process of iterative experimentation, and the data collec‐\\ntion phase is no exception. If you get stuck with bad results at a certain point in\\nthe process, remember to approach the situation with a scientific mindset and\\ntreat it as a failed instance of a controlled experiment. Just as a scientist would\\nchange an experiment variable and restart the experiment, you need to make an\\neducated guess about the most probable cause of the failure and try again.\\nGenerating Features\\nThis chapter’s mission is to devise a general strategy for extracting information from\\ncomplex binary files of different formats. We motivate our strategy with a detailed\\nFeature Generation \\n| \\n147'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 165}, page_content='20 Android phones accounted for 81.7% of worldwide sales of smartphones to end users in 2016.\\n21 This observation does not necessarily imply that Android devices are fundamentally less secure than iOS\\ndevices. Each operating system has its own set of documented security issues. Android and iOS embody clear\\nphilosophical differences in software openness and application vetting, and it is not obvious which is better.\\nThere are a comparable number of security vulnerabilities in both operating systems, and each ecosystem’s\\nsecurity strategy has pros and cons.\\ndiscussion of how to derive a complete and descriptive set of features from one spe‐\\ncific type of binary. We choose to use Android binaries as our example because of\\ntheir growing relevance in the increasingly mobile-centric world of today and because\\nthe methods that we will use to analyze Android applications can quite easily be gen‐\\neralized to analyze other executable binary data formats, such as desktop or mobile\\napplications, executable document macros, or browser plug-ins. Even though some of\\nthe tools and analysis methods that we will discuss are specific to the Android ecosys‐\\ntem, they will often have close equivalents in other operating ecosystems.\\nWhen extracting features for any machine learning task, we should always keep the\\npurpose of the task in mind. Some tasks rely on certain features much more heavily\\nthan others, but we will not look at feature importance or relevance here, as these\\nmeasurements are invariably bound to how we use generated data to achieve a spe‐\\ncific goal. We will not be extracting features through the lens of any single machine\\nlearning task (malware family classification, behavior classification, maliciousness\\ndetection, etc.); instead, we approach feature generation more generally, with the\\noverall goal being to generate as many descriptive features as possible from a complex\\nbinary file.\\nAndroid malware analysis\\nAndroid is everywhere. By smartphone (OS) market share, it is by far the most domi‐\\nnant player.20 Because of this popularity, Android presents itself as an attractive attack\\nplatform for miscreants looking to maximize their impact on victims. This, in combi‐\\nnation with its liberal and open application marketplaces (compared to Apple’s\\nlocked-down iOS application ecosystem), has meant that Android has quickly\\nbecome the mobile platform of choice for malware authors.21\\nExploring the internal structure and workings of Android applications, we can apply\\nreverse engineering techniques to find features that can help identify and classify\\nmalware. Manual steps like these can help us to generate rich features for a few\\nAndroid applications, but this method does not scale well when we need to apply the\\nsame feature extractions to larger datasets. So, during this exercise, please keep in\\nmind that the ease of automating feature extraction is as important as the richness of\\nthe features selected. In addition to considering which features to extract, it is thus\\nalso crucial to consider how to extract them in an efficient and scalable way.\\n148 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 166}, page_content='22 The Android binary APK file, along with the decompiled files, can be found in the chapter4/datasets folder in\\nour code repository.\\nA general methodology for feature engineering is to be as thorough as possible in\\nconsidering useful representations of the data. When each sample is made up of just a\\nfew Boolean features, no complex feature extraction is necessary—it will suffice to\\njust use the raw data as input to the classification algorithms. However, when each\\nsample is as rich and complex as software applications and executable binaries, our\\nwork is cut out for us. A modest 1 MB binary file contains 223 bits of information,\\nwhich works out to the geometric explosion of a whopping 8,388,608 different possi‐\\nble values. Attempting to perform classification tasks using bit-level information can\\nquickly become intractable, and this is not an efficient representation because the\\ndata contains a lot of redundant information that is not useful for the machine learn‐\\ning process. We need to apply some domain knowledge of the structure of the binary\\n(as we laid out earlier in this chapter) and how it will be executed in a system envi‐\\nronment in order to extract higher-level descriptive features. In the following pages,\\nwe dive into different methods of dissecting Android applications, keeping in mind\\nthat many of these methods can be generalized to the task of generating features for\\nother types of executable binaries as well. As a general framework for analyzing exe‐\\ncutable binaries, we consider the following methods:\\n• Static methods\\n— Structural analysis\\n— Static analysis\\n• Dynamic analysis\\n— Behavioral analysis\\n— Debugging\\n— Dynamic instrumentation\\nLet’s now use these methods (not in the listed order) to analyze real, malicious\\nAndroid applications in the same way that an experienced malware analyst would.\\nThis manual exercise is typically the first, and most important, step of the feature\\ngeneration process. In the following sections, we will use the common filename infec‐\\nted.apk to refer to each of the Android malware packages we will be analyzing.22\\nFeature Generation \\n| \\n149'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 167}, page_content='23 The .odex file extension is also used for valid Dalvik executable files that are distinguished by containing opti‐\\nmized Dalvik bytecode. After the succession of Dalvik by the Android Runtime, .odex files were rendered\\nobsolete and are no longer used. ART uses ahead-of-time (AOT) compilation—at installation, .dex code is\\ncompiled to native code in .oat files, which replace Dalvik’s .odex files.\\nJava and the Android Runtime\\nAlthough Android applications are written in a Java-like language, there are clear dif‐\\nferences between the Java API and the Android API. In a typical Java execution set‐\\nting, Java source code is compiled into Java bytecode, which is executed by the Java\\nvirtual machine (JVM). In earlier versions of Android (before Android 4.4 KitKat),\\nthe compiled bytecode is stored in .dex (Dalvik Executable) files23 and executed by a\\nDalvik virtual machine. Dalvik has a register-based architecture, whereas the JVM has\\na stack-based architecture. Because Dalvik is designed to run in resource-constrained\\nenvironments like mobile devices and embedded systems, it is also designed to use\\nless space and includes many simplifications for efficiency. In newer versions of\\nAndroid, the Android Runtime (ART) succeeded Dalvik as the new standard for\\nAndroid program execution. ART takes in the same .dex bytecode but has even more\\nperformance optimizations (such as ahead-of-time compilation at install time) to\\nimprove applications’ speed and resource consumption.\\nStructural analysis.    Android applications come packaged as Android Package Kit\\n(APK) files, which are just ZIP archives containing all the resources and metadata\\nthat the application needs to run. We can unzip the package using any standard\\nextraction utility, such as unzip. Upon unzipping the file, we see something along\\nthese lines:\\n> unzip infected.apk\\nAndroidManifest.xml\\nclasses.dex\\nresources.arsc\\nMETA-INF/\\nassets/\\nres/\\nThe first thing we try to do is inspect these files. In particular, the AndroidMani‐\\nfest.xml file looks like it could provide an overview of this application. This manifest\\nfile is required in every Android app; it contains essential information about the\\napplication, such as its required permissions, external library dependencies, compo‐\\nnents, and so on. Note that we do not need to declare all of the permissions that the\\napplication uses here. Applications can also request permissions at runtime, just\\nbefore a function that requires a special permission is invoked. (For instance, just\\nbefore the photo-taking functionality is engaged, a dialog box opens asking the user\\n150 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 168}, page_content='to grant the application camera access permissions.) The manifest file also declares\\nthe following:\\nActivities\\nScreens with which the user interacts\\nServices\\nClasses running in the background\\nReceivers\\nClasses that interact with system-level events such as SMS or network connection\\nchanges\\nThus, the manifest is a great starting point for our analysis.\\nHowever, it quickly becomes clear that almost all the files we unzipped are encoded in\\nsome binary format. Attempting to view or edit these files as they are is impossible.\\nThis is where third-party tools come into play. Apktool is an Android package reverse\\nengineering Swiss Army knife of sorts, most widely used for disassembling and\\ndecoding the resources found in APK files. After we install it, we can use it to unarch‐\\nive the APK into something a lot more human readable:\\n> apktool decode infected.apk\\nI: Using Apktool 2.2.2 on infected.apk\\nI: Loading resource table...\\nI: Decoding AndroidManifest.xml with resources...\\nI: Loading resource table from file: <redacted>\\nI: Regular manifest package...\\nI: Decoding file-resources...\\nI: Decoding values */* XMLs...\\nI: Baksmaling classes.dex...\\nI: Copying assets and libs...\\nI: Copying unknown files...\\nI: Copying original files...\\n>  cd infected\\n>  ls\\nAndroidManifest.xml\\napktool.yml\\nassets/\\noriginal/\\nres/\\nsmali/\\nNow AndroidManifest.xml is readable. The permission list in the manifest is a very\\nbasic feature that we can use to detect and classify potentially malicious applications.\\nIt can be obviously suspicious when an application asks for a more liberal set of\\nFeature Generation \\n| \\n151'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 169}, page_content='permissions than we think it needs. A particular malicious app with the package\\nname cn.dump.pencil asks for the following list of permissions in the manifest:\\n<uses-permission android:name=\\n    \"android.permission.INTERNET\"/>\\n<uses-permission android:name=\\n    \"android.permission.ACCESS_NETWORK_STATE\"/>\\n<uses-permission android:name=\\n    \"android.permission.RECEIVE_BOOT_COMPLETED\"/>\\n<uses-permission android:name=\\n    \"android.permission.READ_PHONE_STATE\"/>\\n<uses-permission android:name=\\n    \"android.permission.ACCESS_COARSE_LOCATION\"/>\\n<uses-permission android:name=\\n    \"android.permission.ACCESS_FINE_LOCATION\"/>\\n<uses-permission android:name=\\n    \"android.permission.ACCESS_WIFI_STATE\"/>\\n<uses-permission android:name=\\n    \"android.permission.WRITE_EXTERNAL_STORAGE\"/>\\n<uses-permission android:name=\\n    \"android.permission.READ_EXTERNAL_STORAGE\"/>\\n<uses-permission android:name=\\n    \"android.permission.MOUNT_UNMOUNT_FILESYSTEMS\"/>\\n<uses-permission android:name=\\n    \"android.permission.GET_TASKS\"/>\\n<uses-permission android:name=\\n    \"android.permission.CHANGE_WIFI_STATE\"/>\\n<uses-permission android:name=\\n    \"android.permission.VIBRATE\"/>\\n<uses-permission android:name=\\n    \"android.permission.SYSTEM_ALERT_WINDOW\"/>\\n<uses-permission android:name=\\n    \"com.android.launcher.permission.INSTALL_SHORTCUT\"/>\\n<uses-permission android:name=\\n    \"com.android.launcher.permission.UNINSTALL_SHORTCUT\"/>\\n<uses-permission android:name=\\n    \"android.permission.GET_PACKAGE_SIZE\"/>\\n<uses-permission android:name=\\n    \"android.permission.RESTART_PACKAGES\"/>\\n<uses-permission android:name=\\n    \"android.permission.READ_LOGS\"/>\\n<uses-permission android:name=\\n    \"android.permission.WRITE_SETTINGS\"/>\\n<uses-permission android:name=\\n    \"android.permission.CHANGE_NETWORK_STATE\"/>\\n<uses-permission android:name=\\n    \"android.permission.ACCESS_MTK_MMHW\"/>\\n<uses-permission android:name=\\n    \"android.permission.WRITE_SECURE_SETTINGS\"/>\\nGiven that this app is supposed to apply pencil-sketch image styles to camera photos,\\nit seems quite unreasonable to ask for full access to the internet (android.permis\\n152 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 170}, page_content='24 The WRITE_SECURE_SETTINGS and READ_LOGS permissions will not typically be granted to third-party applica‐\\ntions running on nonrooted Android devices. ACCESS_MTK_MMHW is a permission meant to grant access to a\\nspecific FM radio chip in some devices. Applications that request suspicious or obscure permissions like these\\nwill likely be guilty of malicious activity. That said, requesting obscure permissions do not necessarily imply\\nthat the application is malicious.\\n25 The inform argument is short for “input format,” and allows you to specify the input format of the certificate.\\nsion.INTERNET) and the ability to display system alert windows (android.permis\\nsion.SYSTEM_ALERT_WINDOW). Indeed, the official documentation for the latter states\\n“Very few apps should use this permission; these windows are intended for system-\\nlevel interaction with the user.” Some of the other requested permissions\\n(WRITE_SECURE_SETTINGS, ACCESS_MTK_MMHW, READ_LOGS,24 etc.) are downright dan‐\\ngerous. The requested permissions in the manifest are obvious features that we can\\ninclude in our feature set. There is a fixed set of possible permissions that an app can\\nrequest, so encoding each requested permission as a binary variable seems like a sen‐\\nsible thing to do.\\nSomething interesting buried in the package is the certificate used to sign the app.\\nEvery Android application needs to be signed with a certificate in order to be run on\\na device. The META-INF folder in an APK contains resources that the Android plat‐\\nform uses to verify the integrity and ownership of the code, including the certificate\\nused to sign the app. Apktool places the META-INF folder under the root folder of\\nthe package. We can use the openssl utility to print out information about the DER-\\nencoded certificate, which is the *.RSA file in that folder:25\\n> openssl pkcs7 -in original/META-INF/CERT.RSA -inform DER -print\\nThis command prints out detailed information about the certificate. Some interesting\\ndata points that are especially useful for authorship attribution are the issuer and val‐\\nidity sections. In this case, we see that the certificate issuer section is not too useful:\\nissuer: CN=sui yun\\nHowever, the validity period of the certificate can at least tell us when the application\\nwas signed:\\nnotBefore: Nov 16 03:11:34 2015 GMT\\nnotAfter: Mar 19 03:11:34 3015 GMT\\nIn some cases, the certificate issuer/signer information can be quite revealing of\\nauthorship, as in this example:\\nSubject\\n    DN: C=US, ST=California, L=Mountain View, O=Android,\\n        OU=Android, CN=Android, E=android@android.com\\n    C: US\\n    E: android@android.com\\n    CN: Android\\nFeature Generation \\n| \\n153'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 171}, page_content='L: Mountain View\\n    O: Android\\n    S: California\\n    OU: Android\\nvalidto: 11:40 PM 09/01/2035\\nserialnumber: 00B3998086D056CFFA\\nthumbprint: DF3DAB75FAD679618EF9C9FAFE6F8424AB1DBBFA\\nvalidfrom: 11:40 PM 04/15/2008\\nIssuer\\n    DN: C=US, ST=California, L=Mountain View, O=Android,\\n        OU=Android, CN=Android, E=android@android.com\\n    C: US\\n    E: android@android.com\\n    CN: Android\\n    L: Mountain View\\n    O: Android\\n    S: California\\n    OU: Android\\nFurthermore, if two apps have the same certificate or share an obscure signing\\nauthority, there is a high chance that they were created by the same authors. We do\\nthat next.\\nTo gather more information about the application, we must go beyond simply look‐\\ning at its internal structure and attempt to analyze its contents.\\nStatic analysis.    Static analysis is the study of an application’s code without executing\\nit. In some cases where the human-readable code is accessible, such as in malicious\\nPython scripts or JavaScript snippets, this is a straightforward matter of simply read‐\\ning the code and extracting features like the number of “high-risk” system APIs\\ninvoked, number of network calls to external servers, and so on. In most cases, as in\\nthe case of Android application packages, we need to put in some legwork to reverse\\nengineer the app. Referring back to the modern code execution process shown in\\nFigure 4-1, we will look into two of the three program analysis tools mentioned: the\\ndisassembler and the decompiler.\\nWe used Apktool in the previous section to analyze the structure and metadata of the\\nAPK file. If you noticed the line Baksmaling classes.dex... in the console output\\nwhen calling apktool decode on infected.apk, you might be able to guess what it is.\\nThe Android application’s compiled bytecode is stored in .dex files and executed by a\\nDalvik virtual machine. In most APKs, the compiled bytecode is consolidated in a file\\ncalled classes.dex. Baksmali is a disassembler for the .dex format (smali is the name of\\nthe corresponding assembler) that converts the consolidated .dex file into smali\\nsource code. Let’s inspect the smali folder generated by apktool decode earlier:\\nsmali\\n├── android\\n│   └── annotation\\n154 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 172}, page_content='26 An n-gram is a contiguous sequence of n items taken from a longer sequence of items. For instance, 3-grams\\nof the sequence {1,2,3,4,5} are {1,2,3}, {2,3,4}, and {3,4,5}.\\n├── cmn\\n│   ├── a.smali\\n│   ├── b.smali\\n│   ├── ...\\n├── com\\n│   ├── android\\n│   ├── appbrain\\n│   ├── dumplingsandwich\\n│   ├── google\\n│   ├── ...\\n│   ├── third\\n│   └── umeng\\n└── ...\\nNow let’s look into a snippet of the main entry point’s smali class, smali/com/dump‐\\nlingsandwich/pencilsketch/MainActivity.smali:\\n.method public onCreate(Landroid/os/Bundle;)V\\n    .locals 2\\n    .param p1, \"savedInstanceState\"    # Landroid/os/Bundle;\\n...\\n    .line 50\\n    const/4 v0, 0x1\\n...\\n    move-result-object v0\\nSmali is the human-readable representation of Dalvik bytecode. Like the x64 assem‐\\nbly code we saw earlier in the chapter, smali can be difficult to understand without\\nstudy. Nevertheless, it can sometimes still be useful to generate features for a learning\\nalgorithm based off n-grams26 of smali instructions. We can see certain activities by\\nexamining smali code, such as the following:\\nconst-string v0, \"http://178.57.217.238:3000\"\\niget-object v1, p0, Lcom/fanta/services/SocketService;->b:La/a/b/c;\\ninvoke-static {v0, v1}, La/a/b/b;->\\n    a(Ljava/lang/String;La/a/b/c;)La/a/b/ac;\\nmove-result-object v0\\niput-object v0, p0, Lcom/fanta/services/SocketService;->a:La/a/b/ac;\\nThe first line defines a hardcoded IP address for a C&C server. The second line reads\\nan object reference from an instance field, placing SocketService into register v1.\\nThe third line invokes a static method with the IP address and object reference as\\nparameters. After that, the result of the static method is moved into register v0 and\\nwritten out to the SocketService instance field. This is a form of outbound informa‐\\ntion transfer that we can attempt to capture as part of a feature generated by n-grams\\nFeature Generation \\n| \\n155'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 173}, page_content='27 B. Kang, S.Y. Yerima, K. Mclaughlin, and S. Sezer, “N-opcode Analysis for Android Malware Classification\\nand Categorization,” Proceedings of the 2016 International Conference on Cyber Security and Protection of Digi‐\\ntal Services (2016): 1–7.\\n28 A book with documentation and tutorials for radare2 is available online.\\n29 An entry point is the point in code where control is transferred from the operating system to the program.\\nof smali-format Dalvik opcodes. For instance, the 5-gram representation for the smali\\nidiom just shown will be:\\n{const-string, iget-object, invoke-static,\\n    move-result-object, iput-object}\\nUsing syscall or opcode n-grams as features has shown significant promise in mal‐\\nware classification.27\\nThe baksmali disassembler can produce all the smali code corresponding to a .dex\\nfile, but that can sometimes be overwhelming. Here are some other reverse engineer‐\\ning frameworks that can help expedite the process of static analysis:\\n• Radare228 is a popular reverse engineering framework. It’s one of the easiest tools\\nto install and use, and has a diverse suite of forensic and analysis tools you can\\napply to a wide range of binary file formats (not just Android) and run on multi‐\\nple operating systems. For example:\\n— You can use the rafind2 command to find byte patterns in files. This is a\\nmore powerful version of the Unix strings command commonly used to find\\nprintable sequences of characters from binary files.\\n— You can use the rabin2 command to show properties of a binary. For\\ninstance, to get information about a .dex file:\\n> rabin2 -I classes.dex\\n...\\nbintype  class\\nclass    035\\nlang     dalvik\\narch     dalvik\\nbits     32\\nmachine  Dalvik VM\\nos       linux\\nminopsz  1\\nmaxopsz  16\\npcalign  0\\nsubsys   any\\nendian   little\\n...\\nTo find program or function entry points29 and their corresponding addresses:\\n156 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 174}, page_content='30 The PLT is a table of offsets/mappings used by executable programs to call external functions and procedures\\nwhose addresses are not yet assigned at the time of linking. The final address resolution of these external\\nfunctions is done by the dynamic linker at runtime.\\n> rabin2 -e classes.dex\\n[Entrypoints]\\nvaddr=0x00060fd4 paddr=0x00060fd4 baddr=0x00000000\\n    laddr=0x00000000 haddr=-1 type=program\\nTo find what libraries the executable imports and their corresponding offsets\\nin the Procedure Linkage Table (PLT):30\\n> rabin2 -i classes.dex\\n[Imports]\\nordinal=000 plt=0x00001943 bind=NONE type=FUNC name=Landroid/app/\\n    Activity.method.<init>()V\\nordinal=001 plt=0x0000194b bind=NONE type=FUNC name=Landroid/app/\\n    Activity.method.finish()V\\nordinal=002 plt=0x00001953 bind=NONE type=FUNC name=Landroid/app/\\n    Activity.method.getApplicationContext()Landroid/content/Context;\\n...\\nThere is a lot more that you can do with radare2, including through an inter‐\\nactive console session:\\n> r2 classes.dex\\n# List all program imports\\n[0x00097f44]> iiq\\n# List classes and methods\\n[0x00097f44]> izq\\n...\\n• Capstone is another very lightweight but powerful multiplatform and multiarchi‐\\ntecture disassembly framework. It heavily leverages LLVM, a compiler infrastruc‐\\nture toolchain that can generate, optimize, and convert intermediate\\nrepresentation (IR) code emitted from compilers such as GCC. Even though\\nCapstone has a steeper learning curve than radare2, it is more feature rich and is\\ngenerally more suitable for automating bulk disassembly tasks.\\n• Hex-Rays IDA is a state-of-the-art disassembler and debugger that is most widely\\nused by professional reverse engineers. It has the most mature toolkits for per‐\\nforming a large set of functions, but requires an expensive license if you want the\\nlatest full version of the software.\\nFeature Generation \\n| \\n157'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 175}, page_content='Even with all these tools available to analyze it, smali code might still be too low-level\\na format to be useful in capturing large-scope actions that the application might\\nundertake. We need to somehow decompile the Android application into a higher-\\nlevel representation. Fortunately, there are many decompilation tools in the Android\\necosystem. Dex2jar is an open source tool for converting APKs to JAR files, after\\nwhich you can use JD-GUI (Java Decompiler GUI) to display the corresponding Java\\nsource code of the Java class files within the JAR files. In this example, however, we\\nwill be using an alternative .dex-to-Java tool suite called JADX. We can use the JADX-\\nGUI for interactive exploration of the application’s Java source code, as seen in\\nFigure 4-3.\\nFigure 4-3. Decompiled MainActivity Java class displayed in JADX-GUI\\n158 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 176}, page_content='31 The radare2 project maintains a cheat sheet of commonly used commands.\\nThe GUI is not that convenient for automating the generation of Java code for an\\nAPK dataset, but JADX also provides a command-line interface that you can invoke\\nwith the jadx infected.apk command.\\nGenerating useful machine learning features from source code requires some domain\\nknowledge of typical malware behavior. In general, we want the extracted features to\\nbe able to capture suspicious code patterns, hardcoded strings, API calls, and\\nidiomatic statements that might suggest malicious behavior. As with all the previously\\ndiscussed feature generation techniques, we can go with a simplistic n-gram approach\\nor try to capture features that mimic the level of detail that a human malware analyst\\nwould go into.\\nEven a simple Android application can present a large amount of Java code that needs\\nto be analyzed to fully understand what the entire application is doing. When trying\\nto determine the maliciousness of an application, or find out the functionality of a\\npiece of malware, analysts do not typically read every line of Java code resulting from\\ndecompilation. Analysts will combine some degree of expertise and knowledge of\\ntypical malware behavior to look for specific aspects of the program that might\\ninform their decisions. For instance, Android malware typically does one or more of\\nthe following:\\n• Employs obfuscation techniques to hide malicious code\\n• Hardcodes strings referencing system binaries\\n• Hardcodes C&C server IP addresses or hostnames\\n• Checks whether it is executing in an emulated environment (to prevent sand‐\\nboxed execution)\\n• Includes links to external, covertly downloaded and sideloaded APK payloads\\n• Asks for excessive permissions during installation or at runtime, including some‐\\ntimes asking for administrative privileges\\n• Includes ARM-only libraries to prevent the application from being run on an x86\\nemulator\\n• Leaves traces of files in unexpected locations on the device\\n• Modifies legitimate apps on the device and creates or removes shortcut icons\\nWe can use radare2/rafind2 to search for interesting string patterns in our binary that\\nmight indicate some of this malicious behavior, such as strings referencing /bin/su,\\nhttp://, hardcoded IP addresses, other external .apk files, and so on. In the interac‐\\ntive radare2 console:31\\nFeature Generation \\n| \\n159'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 177}, page_content='32 For example, Practical Malware Analysis by Michael Sikorski and Andrew Honig (No Starch Press) and\\nReverse Engineering for Beginners by Dennis Yurichev (https://beginners.re/).\\n> r2 classes.dex\\n# List all printable strings in the program, grepping for \"bin/su\"\\n[0x00097f44]> izq ~bin/su\\n0x47d4c 7 7 /bin/su\\n0x47da8 8 8 /sbin/su\\n0x47ed5 8 8 /xbin/su\\n# Do the same, now grepping for \".apk\"\\n[0x00097f44]> izq ~.apk\\n...\\n0x72f07 43 43 http://appapk.kemoge.com/appmobi/300010.apk\\n0x76e17 17 17 magic_encrypt.apk\\n...\\nWe indeed find some references to the Unix su (super user) privilege escalation com‐\\nmand and external APK files, including one from an external URL—very suspicious.\\nYou can carry out further investigation using the console to find the specific code ref‐\\nerences to methods and strings that we find, but we do not discuss this further and\\ninstead defer to dedicated texts on this subject matter.32\\nPacking for Obfuscation\\nMany Android packages (whether malicious or not) use software called packers or\\nprotectors to protect themselves from reverse engineering through obfuscation,\\nencryption, and redirection. There are many legitimate reasons to obfuscate, such as\\nto prevent business competitors from stealing code, to compress distributable arti‐\\nfacts, and so on. Android malware authors were, of course, quick to pick up on this\\npowerful technique to slow down security researchers’ efforts to detect and circum‐\\nvent their software. Application packing is not a technique specific to Android binar‐\\nies—packers are also used on PE and ELF files.\\nIt is possible to unpack Android applications using unpackers such as Kisskiss, which\\nworks on binaries packed with certain specific packers like Bangcle, APKProtect,\\nLIAPP, and Qihoo Android Packers.\\nBehavioral (dynamic) analysis.    Structural analysis, such as looking at the metadata of\\nan Android application, gives a very restricted view into what the software actually\\ndoes. Static analysis can theoretically turn up malicious behavior through complete\\ncode coverage, but it sometimes incurs unrealistically high resource costs, especially\\nwhen dealing with large and complex applications. Furthermore, static analysis can\\n160 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 178}, page_content='be very inefficient, because the features that are the strongest signals that differentiate\\ndifferent categories of binaries (e.g., malware family, benign/malicious) are often con‐\\ntained in only a small part of the binary’s logic. Analyzing 100 code blocks of a binary\\nto find a single code block that contains the most telling features is quite wasteful.\\nActually running the program can be a much more efficient way to generate rich data.\\nEven though it will probably not exercise all code paths in the application, different\\ncategories of binaries are likely to have different side effects that can be observed and\\nextracted as features for classification.\\nTo obtain an accurate picture of an executable’s side effects, the established practice is\\nto run the malware in an application sandbox. Sandboxing is a technique for isolating\\nthe execution of untrusted, suspicious, or malicious code in order to prevent the host\\nfrom being exposed to harm.\\nThe most obvious execution side effect to look for when analyzing malware is net‐\\nwork behavior. Many malicious applications require some form of external commu‐\\nnication to receive instructions from a C&C server, exfiltrate stolen data, or serve\\nunwanted content. By observing an application’s runtime network behavior, we can\\nget a glimpse into some of these illegitimate communications and generate a rough\\nsignature of the application.\\nFirst of all, we will need a sandboxed Android environment in which to run the appli‐\\ncation. Never execute malicious apps (whether suspected or confirmed) on private\\ndevices on which you also store valuable data. You can choose to run the app on a\\nspare physical Android device, but we are going to run our example on an Android\\nemulator. The emulator that we are using is created through the Android Virtual\\nDevice (AVD) manager in Android Studio, running the Android 4.4 x86 OS on a\\nNexus 5 (4.95 1080x1920 xxhdpi). For the purposes of this exercise, we shall affec‐\\ntionately refer to this virtual device by its AVD name, “pwned.” It is a good idea to run\\nthe Android virtual device within a throwaway VM, because the AVD platform does\\nnot guarantee isolation of the emulated environment from the host OS.\\nOur line of communication between the host and the emulator is the Android Debug\\nBridge (adb). adb is a command-line tool you can use to communicate with a virtual\\nor physical Android device. There are a few different ways to sniff network traffic\\ngoing into and out of the emulator (such as plain old tcpdump or the feature-rich\\nCharles proxy), but we will use a tool called mitmproxy for our example. mitmproxy\\nis a command-line tool that presents an interactive user interface for the examination\\nand modification of HTTP traffic. For apps that use SSL/TLS, mitmproxy provides its\\nown root certificate that you can install on the Android device to let encrypted traffic\\nbe intercepted. For apps that properly implement certificate pinning (not many apps\\nFeature Generation \\n| \\n161'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 179}, page_content='33 The SSLUnpinning module in the Xposed Framework allows the bypassing of SSL certificate pinning in\\nAndroid apps. Other similar modules exist, such as JustTrustMe.\\ndo this), the process is a little more complicated, but it can still be circumvented33 as\\nlong as you have control of the client device/emulator.\\nFirst, let’s start mitmproxy in a separate terminal window:\\n> mitmproxy\\nThen, let’s start the emulator. The -wipe-data flag ensures that we start with a fresh\\nemulator disk image, and the -http-proxy flag routes traffic through the mitmproxy\\nserver running on localhost:8080:\\n> cd <ANDROID-SDK-LOCATION>/tools\\n> emulator -avd pwned -wipe-data -http-proxy http://localhost:8080\\nAfter the emulator starts, the virtual device should be visible to adb. We run adb in a\\nseparate terminal window:\\n> adb devices\\nList of devices attached\\nemulator-5554    device\\nNow, we are ready to install the APK file:\\n> adb install infected.apk\\ninfected.apk: 1 file pushed. 23.3 MB/s (1431126 bytes in 0.059s)\\n    pkg: /data/local/tmp/infected.apk\\nSuccess\\nWhen we return to the emulator’s graphical interface, the newly installed app should\\nbe quite easy to find through the Android app drawer. You can click the “Pencil\\nSketch” app (Figure 4-4) to start it, or run it via the package/MainActivity names\\n(obtained from AndroidManifest.xml) via adb:\\n> adb shell am start \\\\\\n      -n cn.dump.pencil/com.dumplingsandwich.pencilsketch.MainActivity\\nStarting: Intent { cmp=cn.dump.pencil/\\n    com.dumplingsandwich.pencilsketch.MainActivity }\\nYou should now be able to see in the emulator’s graphical interface that the app is\\nrunning (Figure 4-5).\\n162 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 180}, page_content='Figure 4-4. Android malware “Pencil Sketch” app icon\\nFigure 4-5. Android malware “Pencil Sketch” app main screen\\nFeature Generation \\n| \\n163'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 181}, page_content='34 You can use mitmdump to write the captures to a file so that you can programmatically capture traffic in a\\nformat that is convenient for automated postprocessing.\\nNow, returning to the mitmproxy terminal window, we will be able to observe the\\ncaptured traffic in real time, as demonstrated in Figure 4-6.34\\nFigure 4-6. Mitmproxy interactive terminal displaying “Pencil Sketch” Android malware\\nnetwork traic\\nInspecting the HTTP requests made, we can immediately observe some suspicious\\ntraffic:\\n127.0.0.1 GET http://p.appbrain.com/promoted.data?v=11\\n127.0.0.1 POST http://alog.umeng.com/app_logs\\n127.0.0.1 POST http://123.158.32.182:24100/\\n...\\n127.0.0.1 GET http://218.85.139.168:89/ads_manage/sendAdNewStatus?\\nuser_id=000000000000000&id=-1&\\nrecord_type=4&position_type=2&apk_id=993\\n127.0.0.1 GET http://218.85.139.168:89/ads_manage/getDownloadInfo?\\nid=0&user_id=000000000000000&ad_class=1\\n127.0.0.1 POST http://47.88.137.232:7070/\\nThe requests made to p.appbrain.com and alog.umeng.com look like innocuous ad-\\nserving traffic (both Umeng and AppBrain are mobile app advertising networks), but\\nthe POST requests made to http://123.158.32.182:24100 and http://\\n164 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 182}, page_content='35 Xi Xiao et al., “Identifying Android Malware with System Call Co-occurrence Matrices,” Transactions on\\nEmerging Telecommunications Technologies 27 (2016) 675–684.\\n36 Marko Dimjasevic et al., “Android Malware Detection Based on System Calls,” Proceedings of the 2016 ACM\\nInternational Workshop on Security and Privacy Analytics (2016): 1–8.\\n37 Lifan Xu et al., “Dynamic Android Malware Classification Using Graph-Based Representations,” Proceedings\\nof IEEE 3rd International Conference on Cyber Security and Cloud Computing (2016): 220–231.\\n47.88.137.232:7070/ look quite suspicious. mitmproxy allows us to view request\\nand response details like the host, POST body, and so on, as illustrated in Figure 4-7.\\nFigure 4-7. he mitmproxy interactive terminal, inspecting a suspected POST request to\\na C&C server\\nLooking at the hostnames and request body, it seems likely that the hosts jxyxin\\ntel.slhjk.com:7070 and hzdns.zjnetcom.com:24100 are C&C servers. Depending\\non how new and current the malware sample is, the C&C servers might or might not\\nstill be active. In our case, the outbound requests receive no responses, so it appears\\nthe servers are no longer active. This should not affect the quality of our features too\\nmuch.\\nBesides network profiling, several other behavioral side effects of Android applica‐\\ntions are useful to capture and use as classification features:\\n• The system call (syscall) sequence that an application makes during execution is\\nan important feature that has seen great success in malware classification.35,36,37\\nFeature Generation \\n| \\n165'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 183}, page_content='38 strace does not exist or does not work on some Android distributions on certain platforms. jtrace is a free\\ntool that purports to be an “augmented, Android-aware strace,” with Android-specific information provided\\nthat goes beyond the generic and sometimes difficult-to-parse output of strace.\\n39 If you are running a newer version of the Android OS and SELinux is enabled, you might find that the strace\\noperation will fail with a permission error. The only ways to get around this is to set the androidboot.seli\\nnux=permissive flag for Android SELinux -userdebug and -eng builds, or use a more strace-friendly\\ndevice.\\nThere are a few different ways to trace syscalls, but the most popular and direct is\\nto use the strace module included in most modern Android distributions.38 Let’s\\ntake a quick look at how to extract an application’s syscalls using adb and our\\nemulator. Android applications are started by forking the Zygote daemon app\\nlauncher process. Because we want to trace an app’s syscalls from the very start of\\nits main process, we will run strace on Zygote and then grep for the process ID\\nof the app process in the collected strace logs.\\nAssuming that the target app is already loaded and installed on the Android vir‐\\ntual device, we start an adb shell and start strace on Zygote’s process ID (the fol‐\\nlowing commands are run from within the adb shell):39\\n> ps zygote\\nUSER     PID   PPID  VSIZE  RSS     WCHAN    PC         NAME\\nroot      1134  1     707388 46504 ffffffff b766a610 S zygote\\n> strace -f -p 1134\\nProcess 1134 attached with 4 threads - interrupt to quit\\n...\\nThen, we start the application through adb in another terminal:\\n> adb shell am start -n \\\\\\n      cn.dump.pencil/com.dumplingsandwich.pencilsketch.MainActivity\\nReturning to the strace window, we should now see some activity:\\nfork(Process 2890 attached\\n...\\n[pid  2890] ioctl(35, 0xc0046209, 0xbf90e5c8) = 0\\n[pid  2890] ioctl(35, 0x40046205, 0xbf90e5cc) = 0\\n[pid  2890] mmap2(NULL, 1040384, PROT_READ,\\nMAP_PRIVATE|MAP_NORESERVE, 35, 0) = 0x8c0c4000\\n...\\n[pid  2890] clone(Process 2958 attached\\n...\\n[pid  2958] access(\\n\"/data/data/cn.dump.pencil/files/3b0b23e7fd0/\\nf9662419-bd87-43de-ad36-9514578fcd67.zip\", F_OK)\\n= −1 ENOENT (No such file or directory)\\n...\\n166 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 184}, page_content='[pid  2958] write(101, \"\\\\4\", 1)         = 1\\n[pid  2958] write(101, \"\\\\n\", 1)         = 1\\nIt should be fairly obvious what the parent process ID of the main application is;\\nin this case, it is 2890. Note that you should also take into account clones or forks\\nof the parent application process. In the preceding output, PID 2890 cloned into\\nanother process 2958, which exhibited some interesting syscall behavior that we\\nwould like to associate with the application.\\n• adb provides a convenient command-line tool called logcat that collects and\\ndumps verbose system-wide and application-specific messages, errors, and traces\\nfor everything that happens in the system. Logcat is intended for debugging but\\nis sometimes a useful feature-generation alternative to strace.\\n• File access and creation pattern information can be distilled from syscall and log‐\\ncat traces. These can be important features to collect for malware classification\\nbecause many malicious apps write and access files in obscure or covert locations\\non the device filesystem. (Look for the write and access syscalls.)\\nA common way of generating representative features from network, syscall, logcat, or\\nfile-access captures is to generate n-gram sequences of entities. You should generate\\nthese sequences after doing some preprocessing such as removing filenames, memory\\naddresses, overly specific arguments, and so on. The important thing is to retain the\\nrelative sequence of events in each set of captured events while balancing the entropy\\nand stability in the generated n-gram tokens. A small value of n creates a smaller pos‐\\nsible number of unique tokens, resulting in smaller entropy (and hence less feature\\nexpressiveness) but greater stability, because apps exhibiting the same behavior are\\nmore likely to have more token overlap. In contrast, a large value of n leads to a low\\ndegree of stability because there will be a much larger set of unique token sequences,\\nbut each token will constitute a much more expressive feature. To choose a good\\nvalue of n requires some degree of experimentation and a good understanding of how\\nnetwork traffic, syscalls, or file-access patterns relate to actual malicious behavior. For\\ninstance, if it takes a sequence of six syscalls to write some data received over a socket\\nto a file, perhaps n should be set to 6.\\nDynamic analysis is the classic way of characterizing malware behavior. A single\\nPOST request made to a suspicious IP address might not be sufficient to indict the\\nentire application, but when that information is combined with suspicious file-access\\npatterns, system call sequences, and requested permissions, the application can be\\nclassified as malicious with high confidence. Machine learning is perfect for problems\\nlike these, because fuzzy matching and subtle similarities can help to classify the\\nintent and behavior of executables.\\nThe weakness of behavioral analysis lies in the difficulty of ensuring the complete\\nanalysis and characterization of all possible execution paths in a program. Sotware\\nfuzzing is a black-box technique that can find bugs in programs by providing invalid\\nFeature Generation \\n| \\n167'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 185}, page_content='40 This example can be found in chapter4/secret.py in our code repository.\\nor unexpected inputs, but it is highly inefficient to attempt to profile applications\\nusing fuzzing principles. Conditional and loop statements within application code are\\ncommon, and some unique program characteristics might be exhibited only when\\nsome rare conditions are met. Take this example Python program, secret.py, for\\nexample:40\\nimport sys\\nif len(sys.argv) != 2 or sys.argv[1] != \\'s3cretp4ssw0rd\\':\\n    print(\\'i am benign!\\')\\nelse:\\n    print(\\'i am malicious!\\')\\nThe program exhibits its “maliciousness” only when executed with a specific\\ninput argument: python secret.py s3cretp4ssw0rd. Fuzzing techniques would be\\nunlikely to come up with this specific program input. This example is quite extreme,\\nbut the same argument holds for apps that require some specific human interactions\\nbefore the malicious behavior is exhibited: for instance, a malicious online banking\\ntrojan that behaves normally upon starting up but steals your credentials and sends\\nthem to a remote server only when a successful login request is made, or mobile ran‐\\nsomware that checks whether there are more than 20 contacts in the phonebook and\\nmore than a week’s worth of web bookmarks and history entries before it begins to\\nencrypt the SD card—features designed specifically to thwart malware researchers’\\nuse of fresh virtual device sandboxes to profile malware.\\nTo generate features that can describe the entire program space, including all mali‐\\ncious and obscure code paths, we need to dive in and analyze some code, which we\\ncover next.\\nDebugging.    Debuggers (such as GDB, the free software tool provided by the GNU\\nproject) are typically used to aid the development and validation of computer pro‐\\ngrams by stepping into application logic and inspecting intermediate internal states.\\nHowever, they can also be very useful tools for the manual research phase of deter‐\\nmining the behavior of malware. Essentially, a debugger allows you to control the\\nexecution state and time of a program, set breakpoints and watchpoints, dump mem‐\\nory values, and walk through the application code line by line. This process helps\\nmalware analysts more quickly assemble a clearer picture of what the malware is\\ndoing by observing what the program does at every step of execution.\\nIn most Android applications distributed to end users, debugging will typically be\\ndisabled. However, enabling debugging is quite straightforward: you just need to\\nmodify the decoded AndroidManifest.xml file by adding the android:debugga\\nble=\"true\" attribute to the XML file’s application node, repackage the app using\\n168 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 186}, page_content='41 A handful of third-party tools exist that make the step of signing APK files for debug execution a breeze. An\\nexample is the Uber APK Signer.\\n42 The TrendLabs Security Intelligence Blog provides a good tutorial on how to use KGDB.\\napktool build, and then sign the newly produced APK file with debug certificates.41\\nDebugging the application can then be done with the official Android Studio IDE, or\\nwith the more specialized IDA if you own a license that supports Dalvik debugging.\\nFor debugging on a physical device, which can sometimes give you a more realistic\\npicture of application execution behavior, you can use a low-level debugger like\\nKGDB.42\\nDo note that application debugging is inherently an interactive process that is not\\npractical to automate on unknown binaries. The value of debugging in the context of\\nour discussion—to extract diverse and informative features for binary executables—is\\ncomplementary to manual reconnaissance efforts to find salient facets of the program\\nto which we can then apply automated dynamic or static analysis techniques. For\\ninstance, it might be the case that a large and complex Android gaming application\\nexhibits largely benign behavior, but at some unpredictable point in execution\\nreceives malicious code from a C&C server. Static analysis might not be able to effec‐\\ntively detect this covert behavior buried in complex application logic, and running\\nthe application dynamically in a sandbox will not be guaranteed to uncover the\\nbehavior. If we use a debugger to watch for external network behavior and closely\\ninspect payloads received over time, we will more likely be able to determine when\\nthe unusual activity happens and trace this behavior back to the code responsible for\\nit. This information will give us a clearer indication of what to look for when statically\\nanalyzing similar applications.\\nDynamic instrumentation.    Because we are in full control of the application’s runtime\\nenvironment, we can perform some very powerful actions to influence its behavior\\nand make things more convenient for us when extracting features. Dynamic instru‐\\nmentation is a powerful technique for modifying an application or the environment’s\\nruntime behavior by hooking into running processes and injecting custom logic into\\nthe application. Frida is an easy-to-use and fully scriptable dynamic binary instru‐\\nmentation tool with which we can inject JavaScript code into the user space of native\\napplications on multiple platforms, including Android, iOS, Windows, macOS, and\\nLinux. We can use Frida to automate some dynamic analysis or debugging tasks\\nwithout tracing or logging all syscalls or network accesses. For instance, we can use\\nFrida to log a message whenever the Android app makes an open() call:\\n> frida-trace -U -i open com.android.chrome\\nUploading data...\\nopen: Auto-generated handler .../linker/open.js\\nFeature Generation \\n| \\n169'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 187}, page_content='43 Haehyun Cho et al., “Anti-Debugging Scheme for Protecting Mobile Apps on Android Platform,” he Journal\\nof Supercomputing 72 (2016): 232–246.\\n44 Debugging and dynamic instrumentation might be unrealistic in cases in which the tooling is immature—for\\ninstance, PDF malware debuggers might not exist.\\nopen: Auto-generated handler .../libc.so/open.js\\nStarted tracing 2 functions. Press Ctrl+C to stop.\\nThe Xposed Framework approaches dynamic instrumentation from an entirely differ‐\\nent perspective. It instruments the entire Dalvik VM by hooking into the Zygote app\\nlauncher daemon process, which is the very heart of the Android runtime. Because of\\nthis, Xposed modules can operate in the context of Zygote and perform convenient\\ntasks such as bypassing certificate pinning in applications by hooking into common\\nSSL classes (e.g., javax.net.ssl.*, org.apache.http.conn.ssl.*, and okhttp3.*)\\nto bypass certificate verifications altogether. The SSLUnpinning module we men‐\\ntioned earlier is an example of the many user-contributed modules in the Xposed\\nModule Repository.\\nJust as there are techniques to prevent decompilation and disassembly of Android\\napps, there are also some anti-debug43 and anti-hook techniques that are designed to\\nmake application debugging and dynamic instrumentation difficult for researchers.\\nSome advanced malware samples have been found to contain code to detect popular\\nprocess hooking frameworks like Xposed and terminate those processes. Neverthe‐\\nless, by spending more time and manual effort on the task, it will almost always be\\npossible to find ways to defeat obfuscation techniques.\\nSummary.    The examples in this section have shown the power of tools that probe and\\nanalyze binary executables. Even if you don’t work with the particular types of execut‐\\nables shown in this chapter, you now know the typical categories of tools that are\\navailable, often as free and open source software. Although we focused on Android\\nmalware, similar tools are available for other types of malware. Similarly, although\\nyou may have to search for different patterns of behavior than the ones shown here, it\\nis useful knowing that malware commonly gives itself away by taking on sensitive\\nprivileges, engaging in unauthorized network traffic, opening files in odd places, and\\nso on. Whether you are analyzing malicious documents, PE files, or browser exten‐\\nsions, the general principles of using structural, static, and dynamic analysis to gener‐\\nate features are still applicable.44\\nIn this section, we have approached the task of feature generation without consider‐\\ning what we will do with these features, which machine learning algorithms we will\\nuse, or the relevance of each generated feature. Instead, we focused on generating as\\nmany different types of descriptive features as possible from the binaries. Feature\\nrelevance and importance will vary widely depending on what we want to achieve\\nwith machine learning. For instance, if we want to classify malware by family, features\\n170 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 188}, page_content='derived from the decompiled source code will perhaps be much more important than\\ndynamic network behavior, because it takes a lot more effort for malware authors to\\nrewrite source code than to change the URL or IP address of a C&C server. On the\\nother hand, if we simply want to separate malicious binaries from benign binaries,\\njust using syscall n-grams, requested permissions, or statically analyzing for suspi‐\\ncious strings might be more fruitful than looking at source code or assembly-level\\nfeatures.\\nFeature Selection\\nIn most cases, blindly dumping a large number of features into machine learning\\nalgorithms creates noise and is detrimental to model accuracy and performance.\\nThus, it is important to select only the most important and relevant features for use in\\nlearning algorithms. This process is broadly known as feature selection. We can carry\\nout feature selection manually, driven by domain expertise and insights gained from\\nthe data exploration phase, or we can select features automatically using statistical\\nmethods and algorithms. There are also unsupervised feature learning techniques; in\\nparticular, those that make use of deep learning.\\nOne popular way to select features is to use human experience. The guidance that\\nhuman experts can provide to machine learning models comes primarily in the form\\nof manually procured features that are deemed to be important aspects of informa‐\\ntion to feed into the human learning process. For instance, during the training of a\\nbird–mammal binary classification engine, an enormous number of different features\\ncan be generated from each sample (i.e., animal): size, weight, origin, number of legs,\\nand so on. However, any child will be able to tell you that there is a single most\\nimportant feature that can help differentiate birds from mammals—whether it has\\nfeathers. Without this human assistance, the machine learning algorithm might still\\nbe able to come up with a complicated decision boundary in high-dimensional space\\nto achieve good classification accuracy. However, the model with human-assisted fea‐\\nture selection will be a lot simpler and more efficient.\\nStatistically driven feature selection algorithms are popular ways to reduce the\\ndimensionality of datasets, both with and without prior manual feature selection.\\nLet’s discuss these methods by categorizing them into a few families:\\nUnivariate analysis\\nAn intuitive and generalizable way to select a feature is to consider how well the\\nmodel would perform if it took only that feature as input. By iteratively perform‐\\ning univariate statistical tests on each individual feature, we can derive a relative\\nscore of how well each feature fits the training label distribution. Scikit-learn\\nexposes some univariate analysis methods that select only the most descriptive\\nfeatures in the dataset. For instance, the sklearn.feature_selection.SelectKB\\nest class keeps only the highest-scoring features, taking in as an argument a\\nFeature Generation \\n| \\n171'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 189}, page_content='univariate statistical fit scoring function such as the chi-squared test or ANOVA\\n(using the F-value).\\nA common use of feature selection by univariate analysis is to remove features\\nthat don’t vary much between samples. If a feature has the same value in 99% of\\nthe samples, it perhaps isn’t a very helpful feature to include in the analysis. The\\nsklearn.feature_selection.VarianceThreshold class allows you to define a\\nminimum variance threshold for features that you want to keep using.\\nRecursive feature elimination\\nWorking from the opposite direction, recursive feature elimination methods such\\nas sklearn.feature_selection.RFE start with the full feature set and recursively\\nconsider smaller and smaller subsets of features, analyzing how the exclusion of\\nfeatures affects the accuracy of training the estimator model submitted by the\\nresearcher.\\nLatent feature representations\\nMethods such as Singular Value Decomposition (SVD) and Principal Compo‐\\nnent Analysis (PCA) transform high-dimensional data into a lower-dimensional\\ndata space. These algorithms are designed to minimize information loss while\\nreducing the number of features needed for effective machine learning models.\\nThe sklearn.decomposition.PCA class extracts the principal components from\\nthe input features, and then eliminates all but the top components that maximize\\nthe variance capture of the dataset. Note that these methods do not technically\\nperform “feature selection,” because they do not pick out features from the origi‐\\nnal feature set; rather, they output features that are the results of matrix transfor‐\\nmations and do not necessarily correspond to any of the original feature\\ndimensions.\\nModel-speciic feature ranking\\nWhen machine learning algorithms are applied to a dataset, the resulting estima‐\\ntor models can sometimes be expressed as a symbolic combination of the input\\nfeatures. For instance, for a linear regression model in which we are predicting\\nthe value of Y given a three-dimensional dataset (referring to the features as xa,\\nxb, and xc), the regression model can be represented by the equation (ignoring\\nbiases):\\nY = Waxa + Wbxb + Wcxc\\nAfter the training phase, the coefficients (weights) Wa, Wb, and Wc will be\\nassigned some values. For instance:\\nY = 4 . 96xa + 2 . 64xb + 0 . 02xc\\n172 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 190}, page_content='45 Chotirat Ann Ratanamahatana and Dimitrios Gunopulos, “Scaling Up the Naive Bayesian Classifier: Using\\nDecision Trees for Feature Selection,” University of California (2002).\\n46 For a good example of using the SelectFromModel meta-estimator on the sklearn.ensemble.ExtraTree\\nsClassifier to select only the most important features for classification, see the scikit-learn documentation.\\nIn this dummy example, we can quite clearly see that features xa and xb have\\nmuch higher-valued coefficients than xc. Assuming the features are sufficiently\\nnormalized (so that their values are of comparable magnitudes), we can eliminate\\nthe feature xc, knowing that it will not affect the regression model too much. Reg‐\\nularization methods that use the L1 norm will, by the nature of the regularization\\nprocess, have many zero-valued estimated coefficients. Using the sklearn.fea\\nture_selection.SelectFromModel class to eliminate these features from the\\ndataset is a good practice that will make for a more concise and highly perform‐\\ning estimator model. SelectFromModel also works for other machine learning\\nmodels, including tree-based models.45 Tree-based classification models can gen‐\\nerate a metric for the relative importance of each input feature because some\\ninput features can more accurately partition the training data into their correct\\nclass labels than others.46\\nUnsupervised feature learning and deep learning\\nThere is a class of deep neural network algorithms that can automatically learn fea‐\\nture representations, sometimes even from unlabeled data. These algorithms hold out\\nthe tantalizing possibility of significantly reducing the time spent on feature engineer‐\\ning, which is typically one of the most time-consuming steps of machine learning. \\nSpecifically, an autoencoder neural network is an unsupervised learning algorithm that\\nis trained with backpropagation to create a network that learns to replicate the input\\nsample at the output layer. This feat might seem trivial, but by creating a bottlenecked\\nhidden layer in the network, we are essentially training the network to learn an effi‐\\ncient way to compress and reconstruct the input data, minimizing the loss (i.e., differ‐\\nence) between the output and input. Figure 4-8 depicts a simple autoencoder with\\none hidden layer.\\nIn this example, the network is trying to learn, in an unsupervised manner, how to\\ncompress the information required for the reconstruction (at the output layer) of the\\nfive-dimensional input into a three-dimensional set of features in the hidden layer.\\nFeature Generation \\n| \\n173'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 191}, page_content='Figure 4-8. Fully connected 5-3-5 autoencoder network\\nThe data input into neural networks tends to be different from data input to typical\\nmachine learning models. Although algorithms such as random forests and SVMs\\nwork best on well-curated feature sets, deep neural nets work best when given as\\nmany different raw features as can be generated from the data; instead of carefully\\ndesigning features, we let the learning algorithm create the features for us.\\nDeep learning/unsupervised feature learning is an active area of study and one that\\ndiffers significantly from other approaches to machine learning. However, even\\nthough there is a great deal of theoretical work in the area, the method has not yet\\nseen wide use in practice. In this book, we do not go into great detail on deep learn‐\\ning; for more comprehensive coverage, we defer to the many excellent dedicated texts\\non this subject, such as Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron\\nCourville (MIT Press).\\nFrom Features to Classiication\\nAutomating the feature extraction process is a task in and of itself. To generate a fea‐\\nturized dataset from raw data such as binaries, some level of scripting and program‐\\nming is necessary. We do not go into too many specifics here because the task is\\nhighly dependent on the type of data you are working with and the goal of classifica‐\\ntion. Instead, we point you to a couple of excellent examples of tried-and-tested open\\nsource projects that you can look into for further inspiration on the subject:\\n174 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 192}, page_content='47 Inspired by the features proposed in section 2.1.1 of “Deep Neural Network Based Malware Detection Using\\nTwo-Dimensional Binary Program Features” by Joshua Saxe and Konstantin Berlin (MALWARE 2015 confer‐\\nence paper).\\nyouarespecial by Hyrum Anderson, Endgame Inc.\\nThe code in this repository accompanies a talk by Hyrum Anderson, and has\\nsome great feature extraction and deep learning code for malware classification\\nof Windows PE binaries. In particular, the PEFeatureExtractor class extracts a\\ncomprehensive set of static features, including “raw features” that don’t require\\nthe parsing of the PE file such as the following:\\nByte histogram\\nA histogram of the byte value distribution in the binary\\nByte entropy histogram\\nA two-dimensional entropy histogram of bytes, approximating the “joint\\nprobability of byte value and local entropy”47\\nStrings\\nAn array of statistics on strings extracted from the raw byte stream—defined\\nby five-plus consecutive characters that have ASCII values between 0x20\\n(space) and 0x7f (del), or special strings like C:\\\\, HKEY_, http://—such as\\nnumber of strings, average string length, number of C:\\\\ paths, URL instan‐\\nces, registry keys, and string character distribution histogram\\nand “parsed features” such as these:\\nGeneral ile info\\nHigh-level details on the PE file such as if it was compiled with debug sym‐\\nbols, the number of exported/imported functions, etc.\\nHeader ile info\\nDetails obtainable from the header section of the PE file relating to the\\nmachine, architecture, OS, linker, and so on\\nSection info\\nInformation about the binary’s section names, sizes, and entropy\\nImports info\\nInformation about imported libraries and functions that can be used by the\\nPE file\\nExports info\\nInformation about the PE file’s exported functions\\nFrom Features to Classiication \\n| \\n175'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 193}, page_content='Feature Hashing\\nNote that some features in the youarespecial project—for example, section info—\\nmake use of feature hashing to encode extracted features in a vectorized form. This is\\nalso known as the hashing trick because it is a quick and space-efficient way of vecto‐\\nrizing features. Scikit-learn has an implementation of feature hashing provided as\\nsklearn.feature_extraction.FeatureHasher.\\nFeature hashing works by applying a hash function to the feature name and using the\\nobtained hash value as the vector index for storing the corresponding feature value.\\nBy storing these values at the corresponding indices in a sparse matrix and controlling\\nthe number of unique values the hash function can produce, we can place a hard limit\\non the length of the feature matrix. For example, consider the following list of features\\nand their corresponding values:\\nFeature name\\nFeature value\\nFUNCTION_READFILE_CNT_CODE\\n67\\nFUNCTION_READFILE_ENTROPY\\n0.33\\nFUNCTION_READFILE_NUM_IO\\n453\\nFUNCTION_VALIDATECONFIG_CNT_CODE\\n54\\nFUNCTION_VALIDATECONFIG_ENTROPY\\n0.97\\nFUNCTION_VALIDATECONFIG_NUM_IO\\n24587\\nIn feature hashing, we put the feature names through a hash function that returns a\\nhash value between 0 and 99 and get something like this:\\nFeature name\\nHash value\\nFUNCTION_READFILE_CNT_CODE\\n32\\nFUNCTION_READFILE_ENTROPY\\n64\\nFUNCTION_READFILE_NUM_IO\\n39\\nFUNCTION_VALIDATECONFIG_CNT_CODE\\n90\\nFUNCTION_VALIDATECONFIG_ENTROPY\\n33\\nFUNCTION_VALIDATECONFIG_NUM_IO\\n4\\nThen, we encode the features in a sparse vector, using the feature hash value as the\\nindex for storing the feature value:\\nindex\\n4\\n...\\n32\\n33\\n...\\n39\\n...\\n64\\n...\\n90\\nvalue\\n24587\\n-\\n67\\n0.97\\n-\\n453\\n-\\n0.33\\n-\\n54\\n176 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 194}, page_content=\"48 Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola, and Josh Attenberg, “Feature Hashing for\\nLarge Scale Multitask Learning,” Proc. ICML (2009).\\nYou might notice that this technique is susceptible to hash collisions, which would\\ncause two or more feature values to be indexed at the same location, resulting in over‐\\nwriting, a loss of information, and the wrong value being used for a feature. Collisions\\ncan cause varying degrees of damage depending on the size of the dataset and\\nwhether the values are normalized. However, there are several solutions for counter‐\\ning the effects of hash collisions, such as using additional hash functions.48\\nFeature hashing is appealing when you have a large or potentially unbounded number\\nof features in the dataset. This is commonly the case in text classification when creat‐\\ning term-document matrices, and is also prevalent when dealing with highly complex\\nraw data such as binaries from which hundreds of thousands of features can be\\nextracted.\\nHere’s a short code snippet that demonstrates how you can easily use PEFeatureEx\\ntractor to generate a list of relevant features that describe the PE file:\\nimport os\\nfrom pefeatures import PEFeatureExtractor\\nextractor = PEFeatureExtractor()\\nbytez = open(\\n    'VirusShare_00233/VirusShare_fff8d8b91ec865ebe4a960a0ad3c470d,\\n    'rb').read()\\nfeature_vector = extractor.extract(bytez)\\nprint(feature_vector)\\n> [  1.02268000e+05   3.94473345e-01   1.79919427e-03 ...,\\n     0.00000000e+00   0.00000000e+00   0.00000000e+00]\\nApkFile by Caleb Fenton\\nApkFile is a Java library that does for APK files what PEFeatureExtractor does\\nfor PE files. It provides a “robust way to inspect hostile malware samples,” con‐\\nveniently exposing static information from various levels such as the mani‐\\nfest, .dex structure, and decompiled code. Similar to the previous example, the\\nlibrary’s API allows for easy scripting and automation for extracting a feature\\nvector from a large library of APK files.\\nLIEF by Quarkslab\\nPEFeatureExtractor uses LIEF (Library to Instrument Executable Formats)\\nunder the hood to parse PE files. LIEF is a much more powerful and flexible\\nlibrary that parses, modifies, and abstracts ELF, PE, and MachO formats. With\\nminimal effort, you can edit PEFeatureExtractor and create your own ELFFea\\nFrom Features to Classiication \\n| \\n177\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 195}, page_content='tureExtractor just by replacing the lief.PE API usages with lief.ELF APIs\\nthat the library exposes.\\nHow to Get Malware Samples and Labels\\nGetting samples of binaries/executables to train classifiers can be a challenging task.\\nJohn Seymour (@_delta_zero) compiled a great short list of malware datasets that can\\nbe used for training classifiers:\\n• VirusTotal is a very popular source of malware samples and structured analysis,\\nand offers a range of products from on-demand virus analysis to an API for\\nobtaining information about a piece of malware based on the hash of the binary.\\nAccess to most of the services requires a private API key (which costs money),\\nand samples/labels come with licensing clauses.\\n• Malware-Traic-Analysis.net is a small dataset containing 600 heavily analyzed\\nmalware samples and PCAP files. The dataset size is a little too small for training\\na machine learning classifier, but this is a good resource for experimenting with\\nfeatures and learning about malware.\\n• VirusShare.com is a huge (~30 million samples at the time of writing) and free\\nmalware repository that provides live samples (distributed via Torrent) to secu‐\\nrity researchers. Access to the samples is only granted via invitation, but you can\\nrequest one by emailing the site admins. John Seymour and the MLSec Project\\nlead an effort that consistently labels VirusShare samples with detailed informa‐\\ntion about each file, releasing these labels in a batched resource that can be linked\\nfrom SecRepo.com (Samples of Security Related Data—another great resource\\nfor security datasets).\\n• VX Heaven, a dataset popular in academic contexts, contains about 270,000 mal‐\\nware samples categorized into about 40 classes. Samples haven’t been updated in\\nabout 10 years, so don’t expect it to be representative of modern malware.\\n• Kaggle and Microsoft ran a Malware Classiication Challenge in 2015, and made\\nabout 10,000 PE malware samples (PE headers removed so the samples are not\\nlive) available to participants. The samples are still available at the time of writ‐\\ning, but Kaggle terms restrict the use of the dataset strictly to that particular com‐\\npetition.\\nThere are many nuances in creating a good dataset for malware classification that are\\nbeyond the scope of this book. We highly recommend referring to the resources\\nreleased by John Seymour, Hyrum Anderson, Joshua Saxe, and Konstantin Berlin to\\nget more depth on this material.\\n178 \\n| \\nChapter 4: Malware Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 196}, page_content='Conclusion\\nFeature engineering is one of the most important yet frustrating and time-consuming\\nparts of developing machine learning solutions. To engineer effective features from a\\nraw data source, it is not enough to just be a data science or machine learning special‐\\nist. Ample expertise in the application domain is a valuable and even crucial require‐\\nment that can make or break attempts at developing machine learning solutions for a\\nparticular problem. In the security space, where many application areas can benefit\\nfrom machine learning, each area requires a different set of domain expertise to\\ntackle. In this chapter, we analyzed feature engineering for security applications of\\nmachine learning. Diving deep into binary malware analysis and reverse engineering\\nas a driving example for feature extraction, we developed a general set of principles\\nthat we can apply to other applications that use machine learning for security.\\nIn Chapter 5, we look at how we can use a set of extracted features to perform classifi‐\\ncation and clustering.\\nConclusion \\n| \\n179'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 197}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 198}, page_content='1 For the purposes of our discussion, we restrict the definition of “network” to be a system of connections that\\nallows for the transmission of data between connected nodes. There is an enormous range of data transmis‐\\nsion mediums, communication protocols, network topologies, and infrastructure setups that will affect any\\ndetailed discussion of network security, and we do not cover all this ground. Instead, we use a few important\\nand common scenarios to drive the discussion. You will find that you can apply many of the general concepts\\nand techniques discussed here to specific use cases and scenarios, even if there are some differences in the\\nenvironment or protocols.\\nCHAPTER 5\\nNetwork Traic Analysis\\nThe most likely way that attackers will gain entry to your infrastructure is through the\\nnetwork. Network security is the broad practice of protecting computer networks and\\nnetwork-accessible endpoints from malice, misuse, and denial.1 Firewalls are perhaps\\nthe best-known network defense systems, enforcing access policies and filtering\\nunauthorized traffic between artifacts in the network. However, network defense is\\nabout more than just firewalls.\\nIn this chapter, we look at techniques for classifying network traffic. We begin by\\nbuilding a model of network defense upon which we will base our discussions. Then,\\nwe dive into selected verticals within network security that have benefited from devel‐\\nopments in artificial intelligence and machine learning. In the second part of this\\nchapter, we work through an example of using machine learning to find patterns and\\ndiscover correlations in network data. Using data science as an investigation tool, we\\ndiscover how to apply classification on complex datasets to uncover attackers within\\nthe network.\\nOur discussion of network security is limited to packet-based information transmis‐\\nsion. In packet-based transmission, a data stream is segmented into smaller units,\\neach of which contains some metadata about the transmission origin, destination,\\nand content. Each packet is transmitted over the network layer and formatted in an\\nappropriate protocol by the transport layer, with the reconstruction of the informa‐\\n181'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 199}, page_content='tion stream from individual packets occurring at the session layer or above. The secu‐\\nrity of the network, transport, and session layers (layers 3, 4, and 5 of the OSI model,\\nrespectively) are the focus of this chapter.\\nThe OSI Model\\nThroughout this chapter, we refer to different parts of a typical networking stack\\nusing the well-known Open Systems Interconnection (OSI) model. The OSI model\\ncontains seven layers (see also Figure 5-1):\\nLayer 1: physical layer\\nConverts digital data to electrical or mechanical signals that can be transmitted\\nover the network, and converts signals received over the network to digital data\\nLayer 2: data link layer\\nDrives data transfer between adjacent nodes in a physical network\\nLayer 3: network layer\\nRoutes packets and performs flow control between two points on a network\\nLayer 4: transport layer\\nProvides host-to-host communication, dictates the quality and reliability of data\\ntransmission\\nLayer 5: session layer\\nInitiates, maintains, and closes sessions between application processes\\nLayer 6: presentation layer\\nTranslates binary data into formats understandable by applications\\nLayer 7: application layer\\nDisplays data received from the network to users\\n182 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 200}, page_content='Figure 5-1. OSI seven-layer networking stack\\nAs discussed in earlier chapters, attackers target networks mostly as a means to ach‐\\nieving the larger goals of espionage, data exfiltration, mischief, and more. Because of\\nthe complexity and ubiquity of connectivity between computer systems, attackers can\\nfrequently find ways to gain access into even the most carefully designed systems. We\\ntherefore focus our study of network security on scenarios that assume that the\\nattacker has already breached the perimeter and is actively attacking the network\\nfrom within.\\nTheory of Network Defense\\nNetworks have a complicated defense model because of the broad range of attack sur‐\\nfaces and threat vectors. As is the case when defending any complicated system,\\nadministrators need to engage with attackers on multiple fronts and must make no\\nassumptions about the reliability of any one component of the solution.\\nAccess Control and Authentication\\nA client’s interaction with a network begins with the access control layer. Access con‐\\ntrol is a form of authorization by which you can control which users, roles, or hosts in\\nthe organization can access each segment of the network. Firewalls are a means of\\naccess control, enforcing predefined policies for how hosts in the network are\\nallowed to communicate with one another. The Linux kernel includes a built-in fire‐\\nTheory of Network Defense \\n| \\n183'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 201}, page_content='2 We use CIDR notation to refer to IP subnets.\\nwall, iptables, which enforces an IP-level ruleset that dictates the ingress and egress\\ncapabilities of a host, configurable on the command line. For instance, a system\\nadministrator who wants to configure iptables to allow only incoming Secure Shell\\n(SSH) connections (over port 22) from a specific subnet, 192.168.100.0/24,2 might\\nissue the following commands:\\n# ACCEPT inbound TCP connections from 192.168.100.0/24 to port 22\\niptables --append INPUT --protocol tcp --source 192.168.100.0/24\\n         --dport 22 --jump ACCEPT\\n# DROP all other inbound TCP connections to port 22\\niptables --append INPUT --protocol tcp --dport 22 --jump DROP\\nJust like locks on the doors of a building, access control policies are important to\\nensure that only end users who are granted access (a physical key to a locked door)\\ncan enter the network. However, just as a lock can be breached by thieves who steal\\nthe key or break a window, passive access control systems can be circumvented. An\\nattacker who gains control of a server in the 192.169.100.0/24 subnet can access the\\nserver because this passive authentication method relies on only a single property—\\nthe connection’s origin—to grant or deny access.\\nActive authentication methods gather more information about the connecting client,\\noften using cryptographic methods, private knowledge, or distributed mechanisms to\\nachieve more reliable client identity attestation. For instance, in addition to using the\\nconnection origin as a signal, the system administrator might require an SSH key\\nand/or authentication credentials to allow a connection request. In some cases, multi‐\\nfactor authentication (MFA) can be a suitable method for raising the bar for attackers\\nwanting to break in. MFA breaks up the authentication into multiple parts, causing\\nattackers to have to exploit multiple schemes or devices to get both parts of the key to\\ngain the desired access.\\nIntrusion Detection\\nWe discussed intrusion detection systems in detail in Chapter 3. Intrusion detection\\nsystems go beyond the initial access control barriers to detect attempted or successful\\nbreaches of a network by making passive observations. Intrusion prevention systems\\nare marketed as an improvement to passive intrusion detection systems, having the\\nability to intercept the direct line of communication between the source and destina‐\\ntion and automatically act on detected anomalies. Real-time packet sniing is a\\nrequirement for any intrusion detection or prevention system; it provides both a layer\\nof visibility for content flowing through a network’s perimeter and data on which\\nthreat detection can be carried out.\\n184 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 202}, page_content='Detecting In-Network Attackers\\nAssuming that attackers can get past access control mechanisms and avoid detection\\nby intrusion detection systems, they will have penetrated the network perimeter and\\nbe operating within the trusted bounds of your infrastructure. Well-designed systems\\nshould assume that this is always the case and work on detecting in-network attack‐\\ners. Regardless of whether these attackers are intruders or corrupted insiders, system\\nadministrators need to aggressively instrument their infrastructure with monitors\\nand logging to increase visibility within and between servers. Just protecting the\\nperimeter is not sufficient, given that an attacker who spends enough time and\\nresources on breaching the perimeter will often be successful.\\nProper segmentation of a network can help limit the damage caused by in-network\\nattackers. By separating public-facing systems from high-valued central information\\nservers and allowing only closely guarded and monitored API access between sepa‐\\nrate network segments, administrators narrow the channels available for attackers to\\npivot, allowing greater visibility and the ability to audit traffic flowing between nodes. \\nMicrosegmentation is the practice of segmenting a network into various sections\\nbased on each element’s logical function. Proper microsegmentation can simplify the\\nnetwork and the management of security policies, but its continued effectiveness is\\ncontingent on having stringent infrastructure change processes. Changes in the net‐\\nwork must be accurately reflected in the segmentation schemes, which can be chal‐\\nlenging to manage as the complexity of systems increase. Nevertheless, network\\nsegmentation allows administrators an opportunity to enforce strict control on the\\nnumber of possible paths between node A and node B on a network, and also pro‐\\nvides added visibility to enable the use of data science to detect attackers.\\nData-Centric Security\\nWhen the perimeter is compromised, any data stored within the network is at risk of\\nbeing stolen. Attackers who gain access to a network segment containing user creden‐\\ntials have unfettered access to the information stored within, and the only way to\\nlimit the damage is to employ a data-centric view of security. Data-centric security\\nemphasizes the security of the data itself, meaning that even if a database is breached,\\nthe data might not be of much value to an attacker. Encrypting stored data is a way to\\nachieve data-centric security, and it has been a standard practice to salt and hash\\nstored passwords—as implemented in Unix operating systems—so that attackers can‐\\nnot easily make use of stolen credentials to take over user accounts. Nevertheless,\\nencryption of stored data is not suitable for all contexts and environments. For data‐\\nsets that are actively used in analysis and/or need to be frequently used in unencryp‐\\nted form, continuously encrypting and decrypting the data can come with\\nunrealistically high resource requirements.\\nTheory of Network Defense \\n| \\n185'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 203}, page_content='3 David Wu, “Fully Homomorphic Encryption: Cryptography’s Holy Grail,” XRDS: Crossroads, he ACM Maga‐\\nzine for Students 21:3 (2015): 24–29.\\n4 Zvika Brakerski, Craig Gentry, and Vinod Vaikuntanathan, “Fully Homomorphic Encryption Without Boot‐\\nstrapping,” Proceedings of the 3rd Innovations in heoretical Computer Science Conference (2012): 309–325.\\nPerforming data analysis on encrypted data is a goal that the security and data mining\\nresearch communities have been working toward for a long time, and is sometimes\\neven seen as the holy grail of cryptography.3 Homomorphic encryption presents itself\\nas the most promising technique that allows for this. You can use a fully homomor‐\\nphic encryption scheme such as the Brakerski-Gentry-Vaikuntanathan (BGV)\\nscheme4 to perform computation without first decrypting the data. This allows differ‐\\nent data processing services that work on the same piece of data to pass an encrypted\\nversion of the data to each other potentially without ever having to decrypt the data.\\nEven though homomorphic encryption schemes are not yet practical at large scale,\\nimproving their performance is an active area of research. HElib is an efficiently\\nimplemented library for performing homomorphic encryption using low-level func‐\\ntions and the BGV encryption scheme.\\nHoneypots\\nHoneypots are decoys intended for gathering information about attackers. There are\\nmany creative ways to set up honeypot servers or networks (also referred to as honey‐\\nnets), but the general goals of these components are to learn about attack methodolo‐\\ngies and goals as well as to gather forensic information for performing analysis on the\\nattacker’s actions. Honeypots present interfaces that mimic the real systems, and can\\nsometimes be very successful in tricking attackers into revealing characteristics of\\ntheir attack that can help with offline data analysis or active countermeasures. Honey‐\\npots strategically placed in environments that experience a sizable volume of attacks\\ncan be useful for collecting labeled training data for research and improving attack\\ndetection models.\\nSummary\\nSo far in this chapter, we have provided a 10,000-foot view of network security, select‐\\ning a few highlights appropriate for the context of using machine learning for secu‐\\nrity. There are entire fields of study dedicated solely to network security and defense\\nmethodologies. As such, it is impossible to comprehensively cover the complexities of\\nthis topic in just a few paragraphs. In the remainder of this chapter, we dive deep into\\nmore specific attacks and methods of extracting security intelligence from network\\ndata using data science and machine learning.\\n186 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 204}, page_content='5 Packet analyzers exist in both hardware and software form and can capture either packet headers only or full\\ncontents.\\nMachine Learning and Network Security\\nPattern mining is one of the primary strengths of machine learning, and there are\\nmany inherent patterns to be discovered in network traffic data. At first glance, the\\ndata in network packet captures might seem sporadic and random, but most commu‐\\nnication streams follow a strict network protocol. For instance, when inspecting net‐\\nwork packet captures, we can observe the TCP three-way handshake occurring, as\\nshown in Figure 5-2.\\nFigure 5-2. TCP three-way handshake (source: Wireshark screen capture)\\nAfter identifying the handshake that marks the start of a TCP connection, we can iso‐\\nlate the rest of the corresponding TCP session. Identifying TCP sessions is not a par‐\\nticularly complex task, but it drives home the point that network traffic is strictly\\ngoverned by a set of protocols that result in structures and patterns in the data. We\\ncan also find malicious activity in networks by mining for patterns and drawing cor‐\\nrelations in the data, especially for attacks that rely on volume and/or iteration such\\nas network scanning and denial of service (DoS) attacks.\\nFrom Captures to Features\\nCapturing live network data is the primary way of recording network activity for\\nonline or offline analysis. Like a video surveillance camera at a traffic intersection,\\npacket analyzers (also known as packet/network/protocol snifers) intercept and log\\ntraffic in the network. These logs are useful not only for security investigations, but\\nalso for debugging, performance studies, and operational monitoring. When situated\\nin the right places in networks,5 and with network switches and interfaces correctly\\nconfigured, packet analyzers can be a valuable tool for generating detailed datasets\\nthat give you a complete picture of everything that is going on in the network. As you\\ncan imagine, this data can be overwhelming. In complex networking environments,\\neven simple tasks like tracing a TCP session, as we just did, will not be easy. With\\naccess to information-rich raw data, the next step will be to generate useful features\\nfor data analysis.\\nMachine Learning and Network Security \\n| \\n187'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 205}, page_content='Automatic Feature Learning\\nNot all data mining or machine learning techniques require manual feature engineer‐\\ning. Unsupervised feature learning and deep learning algorithms can automatically\\nlearn feature representations from either labeled or unlabeled data, allowing practi‐\\ntioners to avoid spending substantial effort on feature engineering and selection. Note\\nthat “unsupervised feature learning” is different from “unsupervised learning”—the\\nformer refers to automatically generating features from the raw data, whereas the lat‐\\nter refers to machine learning using unlabeled data. In any application of machine\\nlearning to data analysis, it is important to consider and compare the results of tech‐\\nniques that require feature engineering to those that use unsupervised feature learn‐\\ning. The question of which models and algorithms perform better on a dataset is\\nnuanced and highly dependent on the nature of the data.\\nLet’s now look at some specific methods to capture data and generate features from\\nnetwork traffic.\\nTcpdump is a command-line packet analyzer that is ubiquitous in modern Unix-like\\noperating systems. Captures are made in the libpcap file format (.pcap), which is a\\nfairly universal and portable format for the captured network data. The following is\\nan example of using tcpdump to capture three TCP packets from all network\\ninterfaces:\\n# tcpdump -i any -c 3 tcp\\n3 packets captured\\n3 packets received by filter\\n0 packets dropped by kernel\\n12:58:03.231757 IP (tos 0x0, ttl 64, id 49793, offset 0,\\n        flags [DF], proto TCP (6), length 436)\\n    192.168.0.112.60071 > 93.184.216.34.http: Flags [P.],\\ncksum 0x184a (correct), seq 1:385, ack 1, win 4117,\\noptions [nop,nop,TS val 519806276 ecr 1306086754],\\nlength 384: HTTP, length: 384\\n    GET / HTTP/1.1\\n    Host: www.example.com\\n    Connection: keep-alive\\n    Upgrade-Insecure-Requests: 1\\n    User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3)\\n        AppleWebKit/537.36 (KHTML, like Gecko)\\n        Chrome/56.0.2924.87 Safari/537.36\\n    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,\\n        */*;q=0.8\\n    Accept-Encoding: gzip, deflate, sdch\\n    Accept-Language: en-US,en;q=0.8\\n188 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 206}, page_content='12:58:03.296316 IP (tos 0x0, ttl 49, id 54207, offset 0, flags [DF],\\n        proto TCP (6), length 52)\\n    93.184.216.34.http > 192.168.0.112.60071: Flags [.],\\ncksum 0x8aa4 (correct), seq 1, ack 385, win 285,\\noptions [nop,nop,TS val 1306086770 ecr 519806276], length 0\\n12:58:03.300785 IP (tos 0x0, ttl 49, id 54208, offset 0, flags [DF],\\n        proto TCP (6), length 1009)\\n    93.184.216.34.http > 192.168.0.112.60071: Flags [P.],\\ncksum 0xdf99 (correct), seq 1:958, ack 385, win 285,\\noptions [nop,nop,TS val 1306086770 ecr 519806276],\\nlength 957: HTTP, length: 957\\n    HTTP/1.1 200 OK\\n    Content-Encoding: gzip\\n    Accept-Ranges: bytes\\n    Cache-Control: max-age=604800\\n    Content-Type: text/html\\n    Date: Sat, 04 Mar 2017 20:58:03 GMT\\n    Etag: \"359670651+ident\"\\n    Expires: Sat, 11 Mar 2017 20:58:03 GMT\\n    Last-Modified: Fri, 09 Aug 2013 23:54:35 GMT\\n    Server: ECS (fty/2FA4)\\n    Vary: Accept-Encoding\\n    X-Cache: HIT\\n    Content-Length: 606\\nThese three packets were sent between the home/private IP address 192.168.0.112\\nand a remote HTTP server at IP address 93.184.216.34. The first packet contains a\\nGET request to the HTTP server, the second packet is the HTTP server acknowledg‐\\ning the packet, and the third is the server’s HTTP response. Although tcpdump is a\\npowerful tool that allows you to capture, parse, filter, decrypt, and search through\\nnetwork packets, Wireshark is a capable alternative that provides a graphical user\\ninterface and has some additional features. It supports the standard libpcap file for‐\\nmat, but by default captures packets in the PCAP Next Generation (.pcapng) format.\\nTransport Layer Security (TLS)—frequently referred to by its predecessor’s name,\\nSecure Sockets Layer (SSL)—is a protocol that provides data integrity and privacy\\nbetween two communicating applications. TLS encapsulation is great for network\\nsecurity because an unauthorized packet sniffer in the network path between two\\napplications can obtain only encrypted packets that don’t reveal useful information.\\nFor legitimate network analysts trying to extract information from TLS encrypted\\ntraffic, an extra step needs to be performed to decrypt the packets. Administrators\\ncan decrypt TLS/SSL traffic (frequently referred to as “terminating SSL”) as long as\\nthey have access to the private key used to encrypt the data, and the capture includes\\nthe initial TLS/SSL session establishment, according to the TLS Handshake Protocol,\\nwhere session secrets, among other parameters, are shared. Most modern packet ana‐\\nlyzers have the ability to decrypt TLS/SSL packets. Tcpdump does not provide this\\nfunctionality, but ssldump does. Wireshark also provides a very simple interface that\\nMachine Learning and Network Security \\n| \\n189'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 207}, page_content='6 See snakeoil2_070531.tgz, available at https://wiki.wireshark.org/SampleCaptures#Sample_Captures.\\n7 R.L. Rivest, A. Shamir, and L. Adleman, “A Method for Obtaining Digital Signatures and Public-Key Crypto‐\\nsystems,” Communications of the ACM 21 (1978): 120–126.\\nautomatically converts all encrypted packets when you provide the private key and\\nencryption scheme. Let’s look at an example of a decrypted TCP packet’s content\\nfrom a network capture containing TLS/SSL encrypted HTTPS traffic6 using the RSA\\nencryption scheme:7\\ndissect_ssl enter frame #19 (first time)\\npacket_from_server: is from server - TRUE\\n  conversation = 0x1189c06c0, ssl_session = 0x1189c1090\\n  record: offset = 0, reported_length_remaining = 5690\\ndissect_ssl3_record: content_type 23 Application Data\\ndecrypt_ssl3_record: app_data len 360, ssl state 0x23F\\npacket_from_server: is from server - TRUE\\ndecrypt_ssl3_record: using server decoder\\nssl_decrypt_record ciphertext len 360\\nCiphertext[360]:\\ndK.-&..R....yn....,.=....,.I2R.-...K..M.!G..<..ZT..]\"..V_....\\'.;..e.\\nc\\'^T....A.@pz......MLBH.?.:\\\\.)..C...z5v..........F.w..]A...n........\\n.w.@.%....I..gy.........c.pf...W.....Xt..?Q.....J.Iix!..O.XZ.G.i/..I\\nk.*`...z.C.t..|.....$...EX6g.8.......U..\"...o.t...9{..X{ZS..NF.....w\\nt..T.[|[...9{g.;@.!.2..B[.{..j.....;i.w..fE...;.......d..F....4.....\\nW.....+xhp....p..(-L\\nPlaintext[360]:\\nHTTP/1.1 200 OK..Date: Mon, 24 Apr 2006 09:04:18 GMT..Server: Apache\\n/2.0.55 (Debian) mod_ssl/2.0.55 OpenSSL/0.9.8a..Last-Modified: Mon,\\n27 Mar 2006 12:39:09 GMT..ETag: \"14ec6-14ae-42cf5540\"..Accept-Ranges\\n: bytes..Content-Length: 5294..Keep-Alive: timeout=15, max=100..Conn\\nection: Keep-Alive..Content-Type: text/html; charset=UTF-8.....&..FS\\n...k.r8.Z#[.TfC.....\\nssl_decrypt_record found padding 5 final len 354\\nchecking mac (len 334, version 300, ct 23 seq 1)\\nssl_decrypt_record: mac ok\\nWithout the RSA private key, the only thing that a packet sniffer sees is the ciphertext,\\nwhich reveals no information about the actual contents of the message—an HTTP\\n200 OK response.\\nWe now look at an example that shows how we can extract common features from\\nraw network packet captures. We assume that you have some familiarity with the fea‐\\nture generation process; for a detailed discussion, see Chapter 4. In this example, we\\nlook at a dummy attacker’s TCP session that remotely performs an exploit of a sys‐\\ntem, as illustrated in Figure 5-3.\\n190 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 208}, page_content='Figure 5-3. Attacker’s TCP session (source: Wireshark screen capture)\\nWe can immediately extract basic information about the session, such as the\\nfollowing:\\n• Session duration: 4.971 secs\\n• Total session packets: 10\\n• Protocol: TCP\\n• Total bytes from source to destination:\\n62 + 54 + 616 + 54 + 54 + 54 = 894 bytes\\n• Total bytes from destination to source:\\n62 + 887 + 60 + 60 = 1069 bytes\\n• Successful TCP handshake: true\\n• Network service on the destination: HTTP\\n• Number of ACK packets: 4\\nAggregating patterns across large sequences of packets can allow you to generate\\nmore useful information from the data than analyzing single packets. For instance,\\ntrying to detect SQL injections over the network by doing analysis on the packet level\\nwill cause you to look at a lot of useless packets due to protocol communication over‐\\nhead. On the other hand, trying to detect Internet Control Message Protocol (ICMP)\\nflooding DoS attacks requires analysis on the packet level because there are no ses‐\\nsions to speak of.\\nOther application-specific features can be extracted from network packet captures.\\nFor instance, you can extract messages issued over the Telnet protocol, as demon‐\\nstrated in Figure 5-4.\\nMachine Learning and Network Security \\n| \\n191'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 209}, page_content='8 In fact, many operating systems are still distributed with Telnet installed and activated by default. Administra‐\\ntors who intend to protect systems against Telnet attacks must explicitly disable the service or filter out Telnet\\ntraffic.\\nFigure 5-4. Data section of Telnet packet (source: Wireshark screen capture)\\nIn this Telnet data packet, we see a password prompt. Telnet is a protocol designed for\\nbidirectional interaction between two hosts with a virtual terminal connection. All\\nTelnet is sent in the clear over the network, which is a huge security risk. In the early\\ndays of computer networking, this was not such a big concern. As security became a\\nbigger issue, the SSH protocol eventually rose to replace Telnet. SSH implements\\nstrong encryption protocols that prevent interhost communication from being snoo‐\\nped on or hijacked. Nevertheless, Telnet, along with other unencrypted interhost\\ncommunication protocols, remains in use within private networks, where security is\\nassumed to be less of a concern.8 Application-level features extracted from known\\nprotocols such as Telnet can be very powerful for packet capture data analysis. Even\\nin the case of encrypted communications, it can be worthwhile to decrypt the packets\\nfor feature extraction (using similar methods to terminating TLS/SSL, as we\\ndescribed earlier). Here are some examples of features that you can extract:\\n• Application protocol (e.g., Telnet, HTTP, FTP, or SMTP)\\n• Encrypted\\n• Failed login attempt\\n• Successful login attempt\\n• Root access attempted (e.g., su root command issued)\\n• Root access granted\\n• Is guest login\\n• curl/wget command attempted\\n• File creation operation made\\n192 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 210}, page_content='As discussed in previous chapters, the continuous or discrete features that you extract\\ncan be represented in feature vectors and conveniently used in data analysis and\\nmachine learning algorithms for information extraction.\\nThreats in the Network\\nBefore we look at an example of network data analysis, it is important to discuss the\\nthreat model. As mentioned earlier, we will analyze attacks relevant to only the net‐\\nwork, transport, and session layers (OSI layers 3, 4, and 5, respectively). Even though\\nphysical layer (layer 1 [L1]) and data link layer (layer 2 [L2]) attacks are important to\\nconsider in general discussions of network security, we omit them in our current\\nanalysis because the implementation and security of L1 and L2 fall outside the scope\\nof application developers and security engineers. As such, implementing defenses on\\nthose layers is typically unfeasible unless you specialize in designing and developing\\nnetwork devices or software.\\nWe broadly categorize threats into passive and active attacks, and further break down\\nactive attacks into four classes: breaches, spooing, pivoting (“lateral movement”), and\\ndenial of service (DoS).\\nPassive attacks\\nPassive network attacks do not initiate communication with nodes in the network\\nand do not interact with or modify network data. Attackers typically use passive tech‐\\nniques for information gathering and reconnaissance activity. Port scanning is a pas‐\\nsive network attack that bad actors use to probe for open ports to identify services\\nrunning on servers. Given knowledge of certain services’ or applications’ default\\nports, an adversary can learn what a server is running just based on its open ports; for\\nexample, an open port 27017 suggests a running MongoDB instance. Internet wire‐\\ntapping (explained in the following sidebar) is a form of passive attack that manifests\\nitself on the physical layer.\\nAttacks on the Physical Layer\\nPhysical layer attacks, such as those on 802.3 Ethernet, 802.11 WiFi, and Bluetooth,\\nare frequently discussed in network security publications because they are very com‐\\nmon. Beyond physical destruction of network devices or plugging electronic sniffers\\ninto network segments, attacks on wireless transmission mechanisms like WiFi and\\nBluetooth are particularly relevant. Aircrack-ng is an example of WiFi cracking soft‐\\nware that automates the circumventing of certain weak security protocols protecting\\nWiFi networks. MAC looding is an example of a data link layer attack that floods the\\nMAC tables in network switches to replace legitimate entries with illegitimate ones,\\ncausing network packets to be sent to unintended parts of the network.\\nMachine Learning and Network Security \\n| \\n193'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 211}, page_content='Internet wiretapping is a form of passive network attack on the physical layer. It\\ninvolves the interception of network traffic at some point in the transmission, convey‐\\ning it to the infiltrator without knowledge of the network users. Man-in-the-middle\\nattacks are often used to achieve internet wiretapping and allow attackers to view con‐\\nfidential traffic between hosts and/or human users.\\nActive attacks\\nActive attacks are much more varied and can be further categorized into the\\nfollowing:\\nBreaches\\nNetwork breaches are perhaps the most prolific network attacks. The term\\n“breach” can refer to either a hole in the internal network’s perimeter or the act of\\nan attacker exploiting such a hole to gain unauthorized access to private systems.\\nFor many server infrastructures, network nodes lie at the perimeter; routers,\\nproxies, firewalls, switches, and load balancers are examples of such nodes. Intru‐\\nsion detection systems are a form of perimeter defense that attempts to detect\\nwhen an attacker is actively exploiting perimeter vulnerabilities to gain access to\\nthe network. As discussed in Chapter 3, intrusion detection systems are a com‐\\nmon use case for anomaly detection.\\nAttackers can force their way into networks after performing passive information\\ngathering and reconnaissance, finding vulnerabilities in publicly accessible end‐\\npoints that allow them shell or root access to systems. Commands issued over the\\nnetwork that attempt to exploit application vulnerabilities can be detected by\\ninspecting communications between servers, which is why remote application\\nattacks are sometimes classified as network breach attacks. For instance, buffer or\\nheap overflow attacks, SQL injections, and cross-site scripting (XSS) attacks are\\nnot fundamentally caused by problems with the network; however, by inspecting\\ntraffic between hosts, network security systems can potentially detect such\\nattempts to breach servers within the network. For example, basic remote buffer\\noverflow attempts can be detected by inspecting network packet content for par‐\\nticular attack signatures and blocking or putting suspicious packets into quaran‐\\ntine. Nevertheless, polymorphism in such remotely launched attacks has\\nrendered the method of checking attack signatures essentially useless. This is an\\narea in which employing machine learning for fuzzy matching can help to change\\nthe game.\\nData breaches by insiders also pose a significant network threat. Insider threat\\ndetection aims to detect when legitimate human actors within a system compro‐\\nmise that system (e.g., a corrupt employee trying to sell business secrets to com‐\\npetitors). Insider threats are a particularly tricky problem because system\\nadministrators typically have unfettered access to the infrastructure and can also\\n194 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 212}, page_content='be in control of security systems that prevent illegitimate attempts to access val‐\\nuable data. We can reduce the attack surface by setting up proper role-based\\naccess control policies and a system of checks and balances for controlling and\\nauditing internal security systems as well as encrypting stored data. Approaching\\nthe problem with data science, we can also view detecting insider threats as a\\nclassification or anomaly detection problem, looking for inconsistencies in access\\npatterns to detect when a trusted user might be compromised.\\nSpooing\\nAttackers use spooing (i.e., sending falsified data) as a mechanism for installing\\ntheir presence in the middle of a trusted communications channel between two\\nentities. DNS spooing and ARP spooing (also known as cache poisoning) misuse\\nnetwork caching mechanisms to force the client to engage in communications\\nwith a spoofed entity instead of the intended entity. By pretending to be the\\nintended receiving party, attackers can then engage in passive wiretapping attacks\\nto exfiltrate information from otherwise confidential communications.\\nDNS servers translate human-readable domains (e.g., www.example.com) to\\nserver IP addresses via the DNS resolution protocol. A network attacker can poi‐\\nson the client’s DNS cache by temporarily directing the client to an illegitimate\\nDNS server which responds to the DNS resolution request with a malicious IP\\naddress. DNSSEC was introduced to guarantee authentication and integrity in\\nthe DNS resolution process, which prevents most DNS spoofing attacks.\\nPivoting\\nPivoting is the technique of moving between servers in a network after an\\nattacker has gained access to an entry point. Infrastructures in which the bound‐\\naries between services are improperly designed or configured are particularly\\nsusceptible to such attacks. Many high-profile data breaches have involved\\nattackers pivoting through the network after gaining access to a low-value host.\\nLow-value hosts are hosts within the network that don’t provide much informa‐\\ntion to the attackers even when breached. These are usually outward-facing sys‐\\ntems such as web servers or point-of-sale terminals. By design, these systems do\\nnot store information that would be of value to attackers. Consequently, the secu‐\\nrity barriers around them are usually more relaxed compared to high-value sys‐\\ntems such as business logic or customer databases.\\nIn a well-designed secure network, communications between low-value hosts\\nand high-value hosts should only be allowed through a small and controlled set\\nof channels. However, many networks are not perfectly segmented, and contain\\nblind spots that allow attackers to move from one virtual local area network\\n(VLAN) to another, eventually finding their way to a high-value host. Techniques\\nsuch as switch spooing and double tagging allow attackers to perform VLAN hop‐\\nping on inadequately configured VLAN interfaces. Attackers can also use a\\nMachine Learning and Network Security \\n| \\n195'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 213}, page_content='9 RFC 4987 describes SYN flooding attacks and recommends countermeasures to circumvent them.\\n10 Generating artificial clicks on an advertisement hosted on a website with the intention of generating fraudu‐\\nlent revenue for the host website and/or draining advertising budget from the advertiser.\\ncompromised low-value host to perform brute-force attacks, fuzzing, or port\\nscanning on the rest of the network in order to find their next hop within the\\nnetwork. Meterpreter is a tool designed to automate the network pivoting pro‐\\ncess; you can use it in penetration testing to find pivoting vulnerabilities in your\\nnetwork.\\nDoS\\nDenial-of-service (DoS) attacks target the general availability of a system, disrupt‐\\ning access to it by intended users. There are many flavors of DoS attacks, includ‐\\ning the distributed DoS (DDoS) attack, which refers to the use of multiple IP\\naddresses that might span a large range of geolocations to attack a service.\\nSYN flooding is a method of DoS that misuses the TCP handshake mechanism\\nand exploits carelessly implemented endpoints. In the TCP three-way handshake\\nprocess, every new TCP connection begins with the client sending a SYN packet\\nto the server. The server responds to the client with a SYN-ACK packet and waits\\nfor a certain period of time for an ACK response from the client. The server must\\nmaintain a half-open connection while waiting for the ACK packet from the cli‐\\nent, given that a delay in receiving packets could be due to a variety of reasons\\nsuch as network connectivity or congestion issues. Maintaining these half-open\\nconnections consumes system resources for a certain period of time. Malicious\\nclients can continually initiate TCP connections by flooding the server with SYN\\npackets and not respond with ACKs, eventually draining the server of its finite\\nresources and preventing legitimate clients from initiating connections.9 There\\nare many other flavors of DoS attacks that similarly drain servers of available\\nresources in order to interrupt service availability.\\nA botnet is a network of compromised privately owned computers that are infec‐\\nted (without the owners’ knowledge) with malicious software and used for\\nremote access. Botnets have multiple uses, including sending spam, performing\\nclick fraud,10 and scraping web content, but a common use is to launch DDoS\\nattacks. The importance of botnets is such that we will use the next section to\\nexamine them in greater detail.\\n196 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 214}, page_content='11 Leyla Bilge et al., “EXPOSURE: A Passive DNS Analysis Service to Detect and Report Malicious Domains,”\\nACM Transactions on Information and System Security 16:4 (2014).\\nBotnets and You\\nHalf of all web traffic is generated by bots. Bots take on many forms, sometimes as\\nsimple as a Bash script consisting of curl commands; sometimes as a scripted headless\\nbrowser such as PhantomJS; or sometimes even as a large-scale distributed web\\ncrawler powered by a framework like Apache Nutch. These bots are sometimes doc‐\\nile, crawling websites to index a search engine and abiding by the rules defined in a\\nsite’s robots.txt file. Other bots are not as respectful, and can even have malicious\\nintent. One study concludes that 28.9% of all internet traffic can be attributed to mali‐\\ncious bots, though this number comes with a large margin of error. Bad bots perform\\nillegitimate scraping of web content, stuff stolen credentials into login forms, engage\\nin DDoS attacks, send spam and phishing emails, and more. As discussed in previous\\nchapters, zombie machines in botnets (i.e., machines controlled remotely through the\\nuse of malware) are also referred to as bots, and they almost always have malicious\\nintent. Large-scale botnets can enslave internet-connected computers around the\\nworld, allowing malicious controllers to amplify their activity without correspond‐\\ningly scaling up their operational costs. Should distributed attacks originate from\\n“bulletproof hosting services” located in jurisdictions historically involved with high\\nlevels of malicious traffic, web administrators can make a simple decision to block\\nthese low-reputation IP addresses or internet providers. However, botnets made up of\\nhome personal computers, from which large volumes of legitimate traffic can origi‐\\nnate, can make the task of separating malicious and benign traffic much more diffi‐\\ncult.\\nThe importance of understanding botnets\\nIt is important to know about botnets because of the large security risk they pose to\\nenterprise networks and organizations. Zombies that are part of a network might not\\nbe considered active network attackers, but can have equally damaging consequences\\nwhen the botnet is activated. Similar to APT attackers and network intruders, botnet\\nzombies can launch insider attacks that leak important information, degrade system\\nintegrity, and wreak havoc in your environment. Learning about botnet topology and\\nhow bots work can help you to understand what to look for when trying to find infec‐\\nted hosts in your network.\\nEven though we will not discuss specific botnet detection techniques in this book,\\nmachine learning and statistical methods have played an important role in the fight\\nagainst bots. You can use DNS query analysis11 or pattern mining to look for charac‐\\nteristics of network traffic that indicate autonomous bot behavior. Bots that use fast\\nMachine Learning and Network Security \\n| \\n197'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 215}, page_content='12 Z. Berkay Celik and Serna Oktug, “Detection of Fast-Flux Networks Using Various DNS Feature Sets,” IEEE\\nSymposium on Computers and Communications (2013).\\n13 Guofei Gu et al., “BotMiner: Clustering Analysis of Network Traffic for Protocol- and Structure-Independent\\nBotnet Detection”, Proceedings of the 17th USENIX Security symposium (2008): 139–154.\\n14 Florian Tegeler et al., “BotFinder: Finding Bots in Network Traffic Without Deep Packet Inspection”, Proceed‐\\nings of the 8th International Conference on Emerging Networking Experiments and Technologies (2012):\\n349–360.\\n15 Examples of some IRC daemons are https://www.unrealircd.org/ and http://www.inspircd.org/.\\n16 Example botnet commands from Agobot, a popular IRC botnet, are described in “The Evolution of Malicious\\nIRC Bots” by John Canavan of Symantec Security Response.\\nlux networks to mask command-and-control (C&C) servers can also be detected\\nwith machine learning.12 Additionally, clustering techniques have been applied to net‐\\nwork traffic captures to detect zombie-to-C&C communications based on knowledge\\nof botnet topologies.13,14\\nHow do botnets work?\\nBotnets are distributed systems through and through. Because of the high monetary\\nstakes, these systems often have elegant, fault-tolerant, and highly available architec‐\\ntures that can stand up to any do-gooders trying to shut them down. Zombie\\nmachines in the botnets (i.e., the bots) are typically controlled by task delegators\\n(C&C servers). When a computer is infected by botnet malware, one of the first\\nthings that happens is the installation of some hidden daemon process that awaits\\ninstructions from a C&C server. In many ways, this process is coherent with modern\\nserver orchestration architectures. The first botnets made use of Internet Relay Chat\\n(IRC) protocols to communicate with the C&C. Upon infection, an IRC daemon\\n(IRCd) server15 process would be spun up, awaiting instructions on a predetermined\\nchannel. The botnet administrator could then issue commands on these channels,\\nalong the lines of the following:16\\n> ddos.synflood [host] [time] [delay] [port]\\n> (execute|e) [path]\\n> cvar.set spam_maxthreads [8]cvar\\n> spam.start\\nIRC was an easy choice in the early days of botnets because of its ubiquity and ease of\\ndeployment. In addition, it was a technology with which botnet miscreants were\\nfamiliar, as a large amount of underground activity happens in IRC channels. The\\nevolution of botnet topologies over time demonstrates how architectures can\\nimprove their fault tolerance and resilience. In general, there are four categories of\\nC&C architectures:\\n198 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 216}, page_content='17 Christian Dietrich et al. “On Botnets That Use DNS for Command and Control,” Proceedings of the 7th Euro‐\\npean Conference on Computer Network Defense (2011): 9–16.\\nStar/centralized networks\\nThe traditional method of botnet C&C (Figure 5-5) uses the simplest architecture\\nin the playbook: a single centralized C&C server issuing commands to all zom‐\\nbies. This topology, called the star topology, allows for the most direct communi‐\\ncations with zombies, but is obviously brittle because there is a single point of\\nfailure in the system. If the C&C server were to be taken down, the administra‐\\ntors would no longer have access to the zombies. Zombies in this configuration\\ncommonly use DNS as a mechanism for finding their C&C server, because the\\nC&C addresses have to be hardcoded into the botnet application, and using a\\nDNS name instead of an IP address allows for another layer of indirection (i.e.,\\nflexibility) in this frequently changing system.\\nFigure 5-5. Star/centralized botnet C&C network diagram\\nSecurity researchers began detecting botnet zombies within the network by look‐\\ning for suspicious-looking DNS queries.17 If you saw the following DNS query\\nrequest served to the local DNS resolver, you might be tipped off to a problem:\\nDomain Name System (query)\\n    Questions: 1\\n    Answer RRs: 0\\n    Authority RRs: 0\\n    Additional RRs: 0\\n    Queries\\n        botnet-cnc-server.com: type A, class IN\\n            Name: botnet-cnc-server.com\\nMachine Learning and Network Security \\n| \\n199'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 217}, page_content='18 Phillip Porras, Hassen Saidi, and Vinod Yegneswaran, “An Analysis of Conficker’s Logic and Rendezvous\\nPoints,” SRI International Technical Report (2009).\\n19 Sandeep Yadav et al., “Detecting Algorithmically Generated Malicious Domain Names,” Proceedings of the\\n10th ACM SIGCOMM Conference on Internet Measurement (2010): 48–61.\\n20 Hyrum S. Anderson, Jonathan Woodbridge, and Bobby Filar, “DeepDGA: Adversarially-Tuned Domain Gen‐\\neration and Detection,” Proceedings of the 2016 ACM Workshop on Artiicial Intelligence and Security (2016):\\n13–21.\\n            Type: A (Host address)\\n            Class: IN (0x0001)\\nAs with families of malware that “phone home” to a central server, botnets had to\\nadopt domain generation algorithms18 (DGAs) to obfuscate the DNS queries,\\nmaking a resolution request instead to a DNS name like pmdhf98asdfn.com,\\nwhich is more difficult to accurately flag as suspicious. Of course, security\\nresearchers then began to develop heuristics19 and statistical/machine learning\\nmodels20 to detect these artificially generated DNS names, while botnet authors\\ncontinued to try to make these domains look as innocuous as possible. This is\\nanother example of the typical cat-and-mouse game playing out.\\nMultileader networks\\nThe multileader botnet topology is quite similar to the centralized C&C topology,\\nbut is specifically engineered to remove the single point of failure. As we can see\\nin Figure 5-6, this topology significantly increases the level of complexity of the\\nnetwork: C&C servers must frequently communicate between one another, syn‐\\nchronization becomes an issue, and coordination in general requires more effort.\\nOn the other hand, the multileader topology can also alleviate problems arising\\nfrom physical distance. For botnets that span large geographical regions, having\\nzombies that are constantly communicating with a C&C server halfway around\\nthe world is a source of inefficiency and increases the chance of detection because\\neach communication consumes more system resources. Distributing C&C\\nservers around the globe, as content delivery networks do with web assets, is a\\ngood way to remedy this problem. Yet, there still has to be some kind of DNS or\\nserver load balancing for zombies to communicate with the C&C cluster. Fur‐\\nthermore, this topology does not solve the problem of each zombie having to\\ncommunicate with central command.\\n200 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 218}, page_content='Figure 5-6. Multileader botnet C&C network diagram\\nHierarchical networks\\nHierarchical C&C topologies were specifically designed to solve the problem of\\ncentralized command. As depicted in Figure 5-7, zombies are no longer just lis‐\\nteners, but can now also act as relays for upstream commands received. Botnet\\nadministrators can administer commands to a small group of directly connected\\nzombies, which will then in turn propagate them to their child zombies, spread‐\\ning the commands throughout the network. As you can imagine, tracing the\\nsource of commands is a gargantuan task, and this topology makes it very\\nunlikely that the central C&C server(s) can be revealed. Nevertheless, because\\ncommands take time to propagate through the network, the topology might be\\nunsuitable for activities that demand real-time reactions or responses. Further‐\\nmore, taking out a single zombie that happens to be high up in the propagation\\nhierarchy can render a significant portion of the network unreachable by botnet\\nadministrators.\\nMachine Learning and Network Security \\n| \\n201'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 219}, page_content='21 Ping Wanget al., “A Systematic Study on Peer-to-Peer Botnets,” Proceedings of the 18th International Confer‐\\nence on Computer Communications and Networks (2009): 1–8.\\nFigure 5-7. Hierarchical botnet C&C network diagram\\nRandomized P2P networks\\nThe next evolutionary step in botnet topology is a fully decentralized system of\\nzombies, reminiscent of a peer-to-peer (P2P) network21 (see Figure 5-8). This\\ntopology removes any kind of central C&C mechanism and takes the concept of\\ncommand relay to the extreme. Botnet administrators can issue commands to\\nany bot or bots in the network and these commands are then propagated\\nthroughout the network, multicast style. This setup results in a highly resilient\\nsystem because taking down an individual bot does not affect other bots in the\\nnetwork. That said, this topology does come with its fair share of complexities.\\nThe problem of command propagation latency is not solved, and it can be diffi‐\\ncult to ensure that commands have been issued and acknowledged by all bots in\\nthe network because there is no centralized command or formal information\\nflow protocol. In addition, botnet authors must design their command-issuing\\nmechanism in a way that prevents their botnets from being taken over by rogue\\nthird parties. Because commands to control the botnet can be issued to any indi‐\\nvidual bot, including ones that might be located in unfavorable or untrusted exe‐\\ncution environments (from the point of view of botnet administrators), a robust\\nmechanism for ensuring the authenticity of the issued commands is important. A\\ncommon way that this is achieved in modern P2P botnets is for administrators to\\nsign commands with asymmetric cryptography, so authentication of commands\\ncan be performed in a decentralized and secure manner.\\n202 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 220}, page_content='22 Mahbod Tavallaee et al., “A Detailed Analysis of the KDD CUP 99 Data Set,” Proceedings of the 2nd IEEE Sym‐\\nposium on Computational Intelligence in Security and Defense Applications (2009): 53–58.\\n23 This is provided to you in chapter5/datasets in our code repository.\\nFigure 5-8. Randomized/P2P botnet C&C network diagram\\nBuilding a Predictive Model to Classify Network Attacks\\nIn the remainder of this chapter, we demonstrate how to build a network attack clas‐\\nsifier from scratch using machine learning. The dataset that we will use is the NSL-\\nKDD dataset,22 which is an improvement to a classic network intrusion detection\\ndataset used widely by security data science professionals.23 The original 1999 KDD\\nCup dataset was created for the DARPA Intrusion Detection Evaluation Program,\\nprepared and managed by MIT Lincoln Laboratory. The data was collected over nine\\nweeks and consists of raw tcpdump traffic in a local area network (LAN) that simu‐\\nlates the environment of a typical United States Air Force LAN. Some network attacks\\nwere deliberately carried out during the recording period. There were 38 different\\ntypes of attacks, but only 24 are available in the training set. These attacks belong to\\nfour general categories:\\ndos\\nDenial of service\\nr2l\\nUnauthorized accesses from remote servers\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n203'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 221}, page_content='24 An oracle machine is defined in complexity and computability theory as an abstract entity that is able to solve\\nproblems with definitive correctness in a single operation.\\n25 The ImageNet deep neural network classifier has seen many successful applications using it as a base for\\ntransfer learning. For an exploration of what features about ImageNet make it so successful for this purpose,\\nsee Minyoung Huh, Pulkit Agrawal, and Alexei E. Efros, “What Makes ImageNet Good for Transfer Learn‐\\ning,” Berkeley Artificial Intelligence Laboratory, UC Berkeley (2016).\\nu2r\\nPrivilege escalation attempts\\nprobe\\nBrute-force probing attacks\\nThis dataset is somewhat artificial since is a labeled dataset consisting of pregenerated\\nfeature vectors. In many real scenarios, relevant labeled data might be difficult to\\ncome across, and engineering numerical features from the raw data will take up most\\nof your effort.\\nObtaining good training data is a perennial problem when using machine learning\\nfor security. Classifiers are only as good as the data used to train them, and reliably\\nlabeled data is especially important in supervised machine learning. Most organiza‐\\ntions don’t have exposure to a large amount and wide variation of attack traffic, and\\nmust therefore figure out how to deal with the class imbalance problem. Data must be\\nlabeled by an oracle24 that can accurately classify a sample. In some cases, this labeling\\ncan be satisfied by operators without any special skills; for instance, labeling pictures\\nof animals or sentiments of sentences. In the case of classifying network traffic, the\\ntask often must be carried out by experienced security analysts with investigative and\\nforensic skills. The output of security operations centers can often be converted into\\nsome form of training data, but this process is very time consuming. In addition to\\nusing supervised learning methods to train our classifier, we will also experiment\\nwith using unsupervised methods, ignoring the training labels provided in the\\ndataset.\\nWith no good way to generate training data originating from the same source as the\\ntest data, another alternative is to train the classifier on a comparable dataset, often\\nobtained from another source or an academic study. This method might perform well\\nin some cases, but won’t in many. Transfer learning, or inductive transfer, is the pro‐\\ncess of taking a model trained on one dataset and then customizing it for another\\nrelated problem. For example, transfer learning can take a generic image classifier25\\nthat can distinguish a dress from a bag, and alter it to produce a classifier that can\\nrecognize different types of dresses. Transfer learning is currently an active research\\n204 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 222}, page_content='26 Chuong Do and Andrew Ng, “Transfer Learning for Text Classification,” Proceedings of the 18th International\\nConference on Neural Information Processing Systems (2005): 299–306.\\n27 Steffen Bickel, “ECML-PKDD Discovery Challenge 2006 Overview,” Proceedings of the ECML-PKDD Discov‐\\nery Challenge Workshop (2006): 1–9.\\n28 Alexandru Niculescu-Mizil and Rich Caruana, “Inductive Transfer for Bayesian Network Structure Learning,”\\nProceedings of the 11th International Conference on Artiicial Intelligence and Statistics (2007): 339–346.\\narea, and there have been many successful applications of it in text classification,26\\nspam filtering,27 and Bayesian networks.28\\nAs discussed in earlier chapters, building high-performing machine learning systems\\nis a process filled with exploration and experimentation. In the next few sections, we\\nwalk through the process of understanding a dataset and preparing it for processing.\\nThen, we present a few classification algorithms that we can apply to the problem.\\nThe focus of this exercise is not to bring you to the finish line of the task; rather, it is\\nto get you through the heats and qualifiers, helping you get in shape to run the race.\\nExploring the Data\\nLet’s begin by getting more intimate with the data on hand. The labeled training data\\nas comma-separated values (CSV) looks like this:\\n0,tcp,ftp_data,SF,491,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0.00,0.00,\\n0.00,0.00,1.00,0.00,0.00,150,25,0.17,0.03,0.17,0.00,0.00,0.00,0.05,\\n0.00,normal,20\\n0,icmp,eco_i,SF,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,21,0.00,0.00,\\n0.00,0.00,1.00,0.00,1.00,2,60,1.00,0.00,1.00,0.50,0.00,0.00,0.00,\\n0.00,ipsweep,17\\nThe last value in each CSV record is an artifact of the NSL-KDD improvement that\\nwe can ignore. The class label is the second-to-last value in each record, and the other\\n41 values correspond to these features:\\n1\\nduration\\n2\\nprotocol_type\\n3\\nservice\\n4\\nflag\\n5\\nsrc_bytes\\n6\\ndst_bytes\\n7\\nland\\n8\\nwrong_fragment\\n9\\nurgent\\n10\\nhot\\n11\\nnum_failed_logins\\n12\\nlogged_in\\n13\\nnum_compromised\\n14\\nroot_shell\\n15\\nsu_attempted\\n16\\nnum_root\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n205'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 223}, page_content=\"29 This file is not included as part of the NSL-KDD dataset but is included in the original KDD 1999 dataset.\\n30 The code for the full example is provided as a Python Jupyter notebook at chapter5/nsl-kdd-\\nclassiication.ipynb in our code repository.\\n17\\nnum_file_creations\\n18\\nnum_shells\\n19\\nnum_access_files\\n20\\nnum_outbound_cmds\\n21\\nis_host_login\\n22\\nis_guest_login\\n23\\ncount\\n24\\nsrv_count\\n25\\nserror_rate\\n26\\nsrv_serror_rate\\n27\\nrerror_rate\\n28\\nsrv_rerror_rate\\n29\\nsame_srv_rate\\n30\\ndiff_srv_rate\\n31\\nsrv_diff_host_rate\\n32\\ndst_host_count\\n33\\ndst_host_srv_count\\n34\\ndst_host_same_srv_rate\\n35\\ndst_host_diff_srv_rate\\n36\\ndst_host_same_src_port_rate\\n37\\ndst_host_srv_diff_host_rate\\n38\\ndst_host_serror_rate\\n39\\ndst_host_srv_serror_rate\\n40\\ndst_host_rerror_rate\\n41\\ndst_host_srv_rerror_rate\\nOur task is to devise a general classifier that categorizes each individual sample as one\\nof five classes: benign, dos, r2l, u2r, or probe. The training dataset contains samples\\nthat are labeled with the specific attack: ftp_write and guess_passwd attacks corre‐\\nspond to the r2l category, smurf and udpstorm correspond to the dos category, and\\nso on. The mapping from attack labels to attack categories is specified in the file train‐\\ning_attack_types.txt.29 Let’s do some preliminary data exploration to find out more\\nabout these labels. First, let’s take a look at the category distribution:30\\nfrom collections import defaultdict\\n# The directory containing all of the relevant data files\\ndataset_root = 'datasets/nsl-kdd'\\ncategory = defaultdict(list)\\ncategory['benign'].append('normal')\\nwith open(dataset_root + 'training_attack_types.txt', 'r') as f:\\n    for line in f.readlines():\\n        attack, cat = line.strip().split(' ')\\n        category[cat].append(attack)\\n206 \\n| \\nChapter 5: Network Traic Analysis\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 224}, page_content=\"Here’s what we find upon inspecting the contents of category:\\n    {\\n        'benign': ['normal'],\\n        'probe':  ['nmap', 'ipsweep', 'portsweep', 'satan',\\n                   'mscan', 'saint', 'worm'],\\n        'r2l':    ['ftp_write', 'guess_passwd', 'snmpguess',\\n                   'imap', 'spy', 'warezclient', 'warezmaster',\\n                   'multihop', 'phf', 'imap', 'named', 'sendmail',\\n                   'xlock', 'xsnoop', 'worm'],\\n        'u2r':    ['ps', 'buffer_overflow', 'perl', 'rootkit',\\n                   'loadmodule', 'xterm', 'sqlattack', 'httptunnel'],\\n        'dos':    ['apache2', 'back', 'mailbomb', 'processtable',\\n                   'snmpgetattack', 'teardrop', 'smurf', 'land',\\n                   'neptune', 'pod', 'udpstorm']\\n    }\\nWe find that there are 41 attack types specified. This data structure is not very conve‐\\nnient for us to perform the mappings from attack labels to attack categories, so let’s\\ninvert this dictionary in preparation for data crunching:\\nattack_mapping = dict((v,k) for k in category for v in category[k])\\nNow attack_mapping looks like this:\\n    {\\n        'apache2': 'dos',\\n        'back': 'dos',\\n        'guess_passwd': 'r2l',\\n        'httptunnel': 'u2r',\\n        'imap': 'r2l',\\n        ...\\n    }\\nHere is the data that we are using:\\ntrain_file = os.path.join(dataset_root, 'KDDTrain+.txt')\\ntest_file = os.path.join(dataset_root, 'KDDTest+.txt')\\nIt is always important to consider the class distribution within the training data and\\ntest data. In some scenarios, it can be difficult to accurately predict the class distribu‐\\ntion of real-life data, but it is useful to have a general idea of what is expected. For\\ninstance, when designing a network attack classifier for deployment on a network\\nthat does not contain any database servers, we might expect to see very little\\nsqlattack traffic. We can make this conjecture through educated guessing or based\\non past experience. In this particular example, we have access to the test data, so we\\ncan consume the data to get its distribution:\\nimport pandas as pd\\n# header_names is a list of feature names in the same order as the data\\n# where the label (second-to-last value of the CSV) is named attack_type,\\n# and the last value in the CSV is named success_pred\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n207\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 225}, page_content=\"# Read training data\\ntrain_df = pd.read_csv(train_file, names=header_names)\\ntrain_df['attack_category'] = train_df['attack_type'] \\\\\\n        .map(lambda x: attack_mapping[x])\\ntrain_df.drop(['success_pred'], axis=1, inplace=True)\\n# Read test data\\ntest_df = pd.read_csv(train_file, names=header_names)\\ntest_df['attack_category'] = test_df['attack_type'] \\\\\\n        .map(lambda x: attack_mapping[x])\\ntest_df.drop(['success_pred'], axis=1, inplace=True)\\nNow let’s look at the attack_type and attack_category distributions:\\nimport matplotlib.pyplot as plt\\ntrain_attack_types = train_df['attack_type'].value_counts()\\ntrain_attack_cats = train_df['attack_category'].value_counts()\\ntrain_attack_types.plot(kind='barh')\\ntrain_attack_cats.plot(kind='barh')\\nFigures 5-9 and 5-10 depict the training data class distributions.\\nFigure 5-9. Training data class distribution (ive-category breakdown)\\n208 \\n| \\nChapter 5: Network Traic Analysis\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 226}, page_content='Figure 5-10. Training data class distribution (22-category breakdown)\\nThe training data contains 22 types of attack traffic and the test data contains 37 types\\nof attack traffic. The additional 15 types of attack traffic are not present in the train‐\\ning data. The dataset was designed in this way to test how well the trained classifier\\ngeneralizes the training data. For example, let’s say that the classifier is able to cor‐\\nrectly classify the worm attack into the r2l category even though the training data\\ncontained no worm attack samples. This means that this hypothetical classifier suc‐\\ncessfully learned some generalizable properties of the r2l category that allowed it to\\ncorrectly classify previously unseen attack types belonging to this category.\\nOne obvious observation is that the classes are tremendously imbalanced in both\\ndatasets. For instance, the u2r class is smaller than the dos class by three orders of\\nmagnitude in the training set. If we ignore this class imbalance and use the training\\ndata as is, there is a chance that the model will learn a lot more about the benign and\\ndos classes compared to the u2r and r2l classes, which can result in an undesirable\\nbias in the classifier. This is a very common problem in machine learning, and there\\nare a few different ways to approach it. We will keep this drastic class imbalance in\\nmind and address it later.\\nThe original 1999 KDD Cup dataset was once widely used in network security and\\nintrusion detection research but has since seen harsh criticism from researchers that\\nfound problems in using it for evaluating algorithms. Among these problems is the\\nissue of high redundancy in the training and test datasets, causing artificially high\\naccuracies in evaluating algorithms using this data. The NSL-KDD dataset that we are\\nusing addresses this issue. Another criticism is that this dataset is not a realistic repre‐\\nsentation of network traffic, so you should not use it for evaluating algorithms\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n209'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 227}, page_content=\"31 John McHugh, “Testing Intrusion Detection Systems: A Critique of the 1998 and 1999 DARPA Intrusion\\nDetection System Evaluations as Performed by Lincoln Laboratory,” ACM Transactions on Information and\\nSystem Security 3 (2000): 262–294.\\n32 The kddcup.names file is not included in the NSL-KDD dataset, but only in the original KDD 1999 dataset.\\ndesigned to be deployed in real network environments;31 the NSL-KDD dataset does\\nnot address this issue. For the purposes of this example, we are not concerned with\\nhow realistic this dataset is, because we are not evaluating algorithms to measure their\\neffectiveness for use in real networks. The NSL-KDD dataset is a useful dataset for\\neducation and experimentation with data exploration and machine learning classifi‐\\ncation because it strikes a balance between simplicity and sophistication. The classifi‐\\ncation results that we get from the NSL-KDD dataset will not be as good as results\\nthat other publications using the original KDD dataset achieve (>90% classification\\naccuracy).\\nData Preparation\\nLet’s begin by splitting the test and training DataFrames into data and labels:\\ntrain_Y = train_df['attack_category']\\ntrain_x_raw = train_df.drop(['attack_category','attack_type'], axis=1)\\ntest_Y = test_df['attack_category']\\ntest_x_raw = test_df.drop(['attack_category','attack_type'], axis=1)\\nBefore we can apply any algorithms to the data, we need to prepare the data for con‐\\nsumption. Let’s first encode the categorical/dummy variables (referred to in the data‐\\nset as symbolic variables). For convenience, let’s generate the list of categorical\\nvariable names and a list of continuous variable names:32\\nfeature_names = defaultdict(list)\\nwith open(data_dir + 'kddcup.names', 'r') as f:\\n    for line in f.readlines()[1:]:\\n        name, nature = line.strip()[:-1].split(': ')\\n        feature_names[nature].append(name)\\nThis gives us a dictionary containing two keys, continuous and symbolic, each map‐\\nping to a list of feature names:\\n{\\n    continuous: [ duration, src_bytes, dst_bytes, wrong_fragment, ... ]\\n    symbolic:   [ protocol_type, service, flag, land, logged_in, ... ]\\n}\\nWe’ll further split the symbolic variables into nominal (categorical) and binary types\\nbecause we will preprocess them differently.\\n210 \\n| \\nChapter 5: Network Traic Analysis\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 228}, page_content=\"33 We remove root_shell from the list of continuous features because this is an error in the dataset. The\\nkddcup.names file wrongly marks “root_shell” as a continuous feature, whereas the dataset documentation\\nclearly states that it is a binary feature. Furthermore, it is clear from exploring the data that this feature does\\nnot take on values other than 0 and 1. Hence, we treat this feature as a binary feature throughout this\\nexample.\\nThen, we use the pandas.get_dummies() function to convert the nominal variables\\ninto dummy variables. We combine train_x_raw and test_x_raw, run the dataset\\nthrough this function, and then separate it into training and test sets again. This is\\nnecessary because there might be some symbolic variable values that appear in one\\ndataset and not the other, and separately generating dummy variables for them would\\nresult in inconsistencies in the columns of both datasets.\\nIt is typically not okay to perform preprocessing actions on a combination of training\\nand test data, but it is acceptable in this scenario. We are neither doing anything that\\nwill prejudice the algorithm, nor mixing elements of the training and test sets. In typ‐\\nical cases, we will have full knowledge of all categorical variables either because we\\ndefined them or because the dataset provided this information. In our case, the data‐\\nset did not come with a list of possible values of each categorical variable, so we can\\npreprocess as follows:33\\n# Concatenate DataFrames\\ncombined_df_raw = pd.concat([train_x_raw, test_x_raw])\\n# Keep track of continuous, binary, and nominal features\\ncontinuous_features = feature_names['continuous']\\ncontinuous_features.remove('root_shell')\\nbinary_features = ['land','logged_in','root_shell',\\n                   'su_attempted','is_host_login',\\n                   'is_guest_login']\\nnominal_features = list(\\n    set(feature_names['symbolic']) - set(binary_features)\\n)\\n# Generate dummy variables\\ncombined_df = pd.get_dummies(combined_df_raw, \\\\\\n    columns=feature_names['symbolic'], \\\\\\n    drop_first=True)\\n# Separate into training and test sets again\\ntrain_x = combined_df[:len(train_x_raw)]\\ntest_x = combined_df[len(train_x_raw):]\\n# Keep track of dummy variables\\ndummy_variables = list(set(train_x)-set(combined_df_raw))\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n211\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 229}, page_content=\"The function pd.get_dummies() applies one-hot encoding (discussed in Chapter 2)\\nto categorical (nominal) variables such as flag, creating multiple binary variables for\\neach possible value of flag that appears in the dataset. For instance, if a sample has\\nvalue flag=S2, its dummy variable representation (for flag) will be:\\n# flag_S0, flag_S1, flag_S2, flag_S3, flag_SF, flag_SH\\n[    0,       0,       1,       0,       0,       0    ]\\nFor each sample, only one of these variables can have the value 1; hence the name\\n“one-hot.” As mentioned in Chapter 2, the drop_first parameter is set to True to\\nprevent perfect multicollinearity from occurring in the variables (the dummy variable\\ntrap) by removing one variable from the generated dummy variables.\\nLooking at the distribution of our training set features, we notice something that is\\npotentially worrying:\\ntrain_x.describe()\\nduration\\nsrc_bytes\\n… hot\\nnum_failed_logins\\nnum_compromised\\nmean\\n287.14465\\n4.556674e+04\\n0.204409\\n0.001222\\n0.279250\\nstd\\n2604.51531\\n5.870331e+06\\n2.149968\\n0.045239\\n23.942042\\nmin\\n0.00000\\n0.000000e+00\\n0.000000\\n0.000000\\n0.000000\\n…\\n…\\n…\\n…\\n…\\n…\\nmax\\n42908.00000 1.379964e+09\\n77.000000\\n5.000000\\n7479.000000\\nThe distributions of each feature vary widely, which will affect our results if we use\\nany distance-based methods for classification. For instance, the mean of src_bytes is\\nlarger than the mean of num_failed_logins by seven orders of magnitude, and its\\nstandard deviation is larger by eight orders of magnitude. Without performing fea‐\\nture value standardization/normalization, the src_bytes feature would dominate,\\ncausing the model to miss out on potentially important information in the\\nnum_failed_logins feature.\\nStandardization is a process that rescales a data series to have a mean of 0 and a stan‐\\ndard deviation of 1 (unit variance). It is a common, but frequently overlooked,\\nrequirement for many machine learning algorithms, and useful whenever features in\\nthe training data vary widely in their distribution characteristics. The scikit-learn\\nlibrary includes the sklearn.preprocessing.StandardScaler class that provides\\nthis functionality. For example, let’s standardize the duration feature. As we just saw,\\nthe descriptive statistics for the duration feature are as follows:\\n> train_x['duration'].describe()\\ncount    125973.00000\\nmean        287.14465\\nstd        2604.51531\\n212 \\n| \\nChapter 5: Network Traic Analysis\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 230}, page_content=\"min           0.00000\\n25%           0.00000\\n50%           0.00000\\n75%           0.00000\\nmax       42908.00000\\nLet’s apply standard scaling on it:\\nfrom sklearn.preprocessing import StandardScaler\\n# Reshape to signal to scaler that this is a single feature\\ndurations = train_x['duration'].reshape(-1, 1)\\nstandard_scaler = StandardScaler().fit(durations)\\nstandard_scaled_durations = standard_scaler.transform(durations)\\npd.Series(standard_scaled_durations.flatten()).describe()\\n> # Output:\\ncount    1.259730e+05\\nmean     2.549477e-17\\nstd      1.000004e+00\\nmin     −1.102492e-01\\n25%     −1.102492e-01\\n50%     −1.102492e-01\\n75%     −1.102492e-01\\nmax      1.636428e+01\\nNow, we see that the series has been scaled to have a mean of 0 (close enough:\\n2.549477 × 10−17) and standard deviation (std) of 1 (close enough: 1.000004).\\nAn alternative to standardization is normalization, which rescales the data to a given\\nrange—frequently [0,1] or [−1,1]. The sklearn.preprocessing.MinMaxScaler class\\nscales a feature from its original range to [min, max]. (The defaults are min=0, max=1\\nif not specified.) You might choose to use MinMaxScaler over StandardScaler if you\\nwant the scaling operation to preserve small standard deviations of the original series,\\nor if you want to preserve zero entries in sparse data. This is how MinMaxScaler\\ntransforms the duration feature:\\nfrom sklearn.preprocessing import MinMaxScaler\\nmin_max_scaler = MinMaxScaler().fit(durations)\\nmin_max_scaled_durations = min_max_scaler.transform(durations)\\npd.Series(min_max_scaled_duration.flatten()).describe()\\n> # Output:\\ncount    125973.000000\\nmean          0.006692\\nstd           0.060700\\nmin           0.000000\\n25%           0.000000\\n50%           0.000000\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n213\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 231}, page_content='75%           0.000000\\nmax           1.000000\\nOutliers in your data can severely and negatively skew standard scaling and normal‐\\nization results. If the data contains outliers, sklearn.preprocessing.RobustScaler\\nwill be more suitable for the job. RobustScaler uses robust estimates such as the\\nmedian and quantile ranges, so it will not be affected as much by outliers.\\nWhenever performing standardization or normalization of the data, you must apply\\nconsistent transformations to both the training and test sets (i.e., using the same\\nmean, std, etc. to scale the data). Fitting a single Scaler to both test and training sets\\nor having separate Scalers for test data and training data is incorrect, and will opti‐\\nmistically bias your classification results. When performing any data preprocessing,\\nyou should pay careful attention to leaking information about the test set at any point\\nin time. Using test data to scale training data will leak information about the test set\\nto the training operation and cause test results to be unreliable. Scikit-learn provides\\na convenient way to do proper normalization for cross-validation processes—after\\ncreating the Scaler object and fitting it to the training data, you can simply reuse the\\nsame object to transform the test data.\\nWe finish off the data preprocessing phase by standardizing the training and test data:\\nfrom sklearn.preprocessing import StandardScaler\\n# Fit StandardScaler to the training data\\nstandard_scaler = StandardScaler().fit(train_x[continuous_features])\\n# Standardize training data\\ntrain_x[continuous_features] = \\\\\\n    standard_scaler.transform(train_x[continuous_features])\\n# Standardize test data with scaler fitted to training data\\ntest_x[continuous_features] = \\\\\\n    standard_scaler.transform(test_x[continuous_features])\\nClassiication\\nNow that the data is prepared and ready to go, let’s look at a few different options for\\nactually classifying attacks. To review, we have a five-class classification problem in\\nwhich each sample belongs to one of the following classes: benign, u2r, r2l, dos,\\nprobe. There are many different classification algorithms suitable for a problem like\\nthis, and many different ways to approach the problem of multiclass classification.\\nMany classification algorithms inherently support multiclass data (e.g., decision trees,\\nnearest neighbors, Naive Bayes, multinomial logistic regression), whereas others do\\nnot (e.g., support vector machines). Even if our algorithm of choice does not inher‐\\nently support multiple classes, there are some clever techniques for effectively achiev‐\\ning multiclass classification.\\n214 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 232}, page_content='Choosing a suitable classifier for the task can be one of the more challenging parts of\\nmachine learning. For any one task, there are dozens of classifiers that could be a\\ngood choice, and the optimal one might not be obvious. In general, practitioners\\nshould not spend too much time deliberating over optimal algorithm choice. Devel‐\\noping machine learning solutions is an iterative process. Spending time and effort to\\niterate on a rough initial solution will almost always bring about surprising learnings\\nand results. Knowledge and experience with different algorithms can help you to\\ndevelop better intuition to cut down the iteration process, but it is rare, even for expe‐\\nrienced practitioners, to immediately select the optimal algorithm, parameters, and\\ntraining setup for arbitrary machine learning tasks. Scikit-learn provides a nifty\\nmachine learning algorithm cheatsheet gives a good overview of how to choose a\\nmachine learning algorithm.] that, though not complete, provides some intuition on\\nalgorithm selection. In general, here are some questions you should ask yourself\\nwhen faced with machine learning algorithm selection:\\n• What is the size of your training set?\\n• Are you predicting a sample’s category or a quantitative value?\\n• Do you have labeled data? How much labeled data do you have?\\n• Do you know the number of result categories?\\n• How much time and resources do you have to train the model?\\n• How much time and resources do you have to make predictions?\\nEssentially, a multiclass classification problem can be split into multiple binary classi‐\\nfication problems. A strategy known as one-versus-all, also called the binary relevance\\nmethod, fits one classifier per class, with data belonging to the class fitted against the\\naggregate of all other classes. Another less commonly used strategy is one-versus-one,\\nin which there are n_classes * (n_classes – 1) / 2 classifiers constructed, one for each\\nunique pair of classes. In this case, during the prediction phase, each sample is run\\nthrough all the classifiers, and the classification confidences for each of the classes are\\ntallied. The class with the highest aggregate confidence is selected as the prediction\\nresult.\\nOne-versus-all scales linearly with the number of classes and, in general, has better\\nmodel interpretability because each class is only represented by one classifier (as\\nopposed to each class being represented by n_classes – 1 classifiers for one-versus-\\none). In contrast, the one-versus-one strategy does not scale well with the number of\\nclasses because of its polynomial complexity. However, one-versus-one might per‐\\nform better than one-versus-all with a classifier that doesn’t scale well with the num‐\\nber of samples, because each pairwise classifier contains a smaller number of samples.\\nIn one-versus-all, all classifiers each must deal with the entire dataset.\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n215'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 233}, page_content='34 A good reference is he Elements of Statistical Learning, 2nd ed., by Trevor Hastie, Robert Tibshirani, and\\nJerome Friedman (Springer).\\nBesides its ability to deal with multiclass data, there are many other possible consider‐\\nations when selecting a classifier for the task at hand, but we will leave it to other pub‐\\nlications34 to go into these details. Having some intuition for matching algorithms to\\nproblems can help to greatly reduce the time spent searching for a good solution and\\noptimizing for better results. In the rest of this section, we will give examples of\\napplying different classification algorithms to our example. Even though it is difficult\\nto make broad generalizations about when and how to use one algorithm over\\nanother, we will discuss some important considerations to have when evaluating these\\nalgorithms. By applying default or initial best-guess parameters to the algorithm, we\\ncan quickly obtain initial classification results. Even though these results might not be\\nclose to our target accuracy, they will usually give us a rough indication of the algo‐\\nrithm’s potential.\\nWe first consider scenarios in which we have access to labeled training data and can\\nuse supervised classification methods. Then, we look at a semi-supervised and unsu‐\\npervised classification methods, which are applicable whether or not we have labeled\\ndata.\\nSupervised Learning\\nGiven that we have access to roughly 126,000 labeled training samples, supervised\\ntraining methods seem like a good place to begin. In practical scenarios, model accu‐\\nracy is not the only factor for which you need to account. With a large training set,\\ntraining efficiency and runtime is also a big factor—you don’t want to find yourself\\nspending too much time waiting for initial model experiment results. Decision trees\\nor random forests are good places to begin because they are invariant to scaling of the\\ndata (preprocessing) and are relatively robust to uninformative features, and hence\\nusually give good training performance.\\nIf your data has hundreds of dimensions, using random forests can be much more\\nefficient than other algorithms because of how well the model scales with high-\\ndimensional data. Just to get a rough feel for how the algorithm does, we will look at\\nthe confusion matrix, using sklearn.metrics.confusion_matrix, and error rate,\\nusing sklearn.metrics.zero_one_loss. Let’s begin by throwing our data into a sim‐\\nple decision tree classifier, sklearn.tree.DecisionTreeClassifier:\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.metrics import confusion_matrix, zero_one_loss\\nclassifier = DecisionTreeClassifier(random_state=0)\\nclassifier.fit(train_x, train_Y)\\n216 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 234}, page_content='pred_y = classifier.predict(test_x)\\nresults = confusion_matrix(test_Y, pred_y)\\nerror = zero_one_loss(test_Y, pred_y)\\n> # Confusion matrix:\\n[[9357   59  291    3    1]\\n [1467 6071   98    0    0]\\n [ 696  214 1511    0    0]\\n [2325    4   16  219   12]\\n [ 176    0    2    7   15]]\\n> # Error:\\n0.238245209368\\nWith just a few lines of code and no tuning at all, a 76.2% classification accuracy (1 –\\nerror rate) in a five-class classification problem is not too shabby. However, this num‐\\nber is quite meaningless without considering the distribution of the test set\\n(Figure 5-11).\\nFigure 5-11. Test data class distribution (ive-category breakdown)\\nThe 5 × 5 confusion matrix might seem intimidating, but understanding it is well\\nworth the effort. In a confusion matrix, the diagonal values (from the upper left to\\nlower right) are the counts of the correctly classified samples. All the values in the\\nmatrix add up to 22,544, which is the size of the test set. Each row represents the true\\nclass, and each column represents the predicted class. For instance, the number in the\\nfirst row and fifth column represents the number of samples that are actually of class\\n0 that were classified as class 4. (For symbolic labels like ours, sklearn assigns num‐\\nbers in sorted ascending order: benign = 0, dos = 1, probe = 2, r2l = 3, and u2r = 4.)\\nSimilar to the training set, the sample distribution is not balanced across categories:\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n217'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 235}, page_content='> test_Y.value_counts().apply(lambda x: x/float(len(test_Y)))\\nbenign    0.430758\\ndos       0.338715\\nr2l       0.114265\\nprobe     0.107390\\nu2r       0.008872\\nWe see that 43% of the test data belongs to the benign class, whereas only 0.8% of the\\ndata belongs to the u2r class. The confusion matrix shows us that although only 3.7%\\nof benign test samples were wrongly classified, 62% of all test samples were classified\\nas benign. Could we have trained a classifier that is just more likely to classify sam‐\\nples into the benign class? In the r2l and u2r rows, we see the problem in a more\\npronounced form: more samples were classified as benign than all other samples in\\nthose classes. Why could that be? Going back to look at our earlier analysis, we see\\nthat only 0.7% of the training data is r2l, and 0.04% is u2r. Compared with the 53.5%\\nbenign, 36.5% dos, and 9.3% probe, it seems unlikely that there would have been\\nenough information for the trained model to learn enough information from the u2r\\nand r2l classes to correctly identify them. To see whether this problem might be\\ncaused by the choice of the decision tree classifier, let’s look at how the k-nearest\\nneighbors classifier, sklearn.neighbors.KNeighborsClassifier, does:\\nfrom sklearn.neighbors import KNeighborsClassifier\\nclassifier = KNeighborsClassifier(n_neighbors=1, n_jobs=-1)\\nclassifier.fit(train_x, train_Y)\\npred_y = classifier.predict(test_x)\\nresults = confusion_matrix(test_Y, pred_y)\\nerror = zero_one_loss(test_Y, pred_y)\\n> # Confusion matrix:\\n[[9455   57  193    2    4]\\n [1675 5894   67    0    0]\\n [ 668  156 1597    0    0]\\n [2346    2   37  151   40]\\n [ 177    0    4    6   13]]\\n> # Error:\\n0.240951029099\\nAnd here are the results for a linear support vector classifier, sklearn.svm.Line\\narSVC:\\nfrom sklearn.svm import LinearSVC\\nclassifier = LinearSVC()\\nclassifier.fit(train_x, train_Y)\\npred_y = classifier.predict(test_x)\\nresults = confusion_matrix(test_Y, pred_y)\\n218 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 236}, page_content='35 Ivan Tomek, “Two Modifications of CNN,” IEEE Transactions on Systems, Man, and Cybernetics 6 (1976): 769–\\n772.\\nerror = zero_one_loss(test_Y, pred_y)\\n> # Confusion matrix:\\n[[9006  294  405    3    3]\\n [1966 5660   10    0    0]\\n [ 714  122 1497   88    0]\\n [2464    2    1  109    0]\\n [ 175    1    0    8   16]]\\n> # Error:\\n0.278167139815\\nThe error rates are in the same ballpark, and the resulting confusion matrices show\\nvery similar characteristics to what we saw with the decision tree classifier results. At\\nthis point, it should be clear that continuing to experiment with classification algo‐\\nrithms might not be productive. What we can try to do is to remedy the class imbal‐\\nance problem in the training data in hopes that resulting models will not be overly\\nskewed to the dominant classes.\\nClass imbalance\\nDealing with imbalanced classes is an art in and of itself. In general, there are two\\nclasses of remedies:\\nUndersampling\\nUndersampling refers to sampling the overrepresented class(es) to reduce the\\nnumber of samples. Undersampling strategies can be as simple as randomly\\nselecting a fraction of samples, but this can cause information loss in certain\\ndatasets. In such cases, the sampling strategy should prioritize the removal of\\nsamples that are very similar to other samples that will remain in the dataset. For\\ninstance, the strategy might involve performing k-means clustering on the major‐\\nity class and removing data points from high-density centroids. Other more\\nsophisticated methods like removing Tomek’s links35 achieve a similar result. As\\nwith all data manipulations, be cautious of the side effects and implications of\\nundersampling, and look out for potential effects of too much undersampling if\\nyou see prediction accuracies of the majority classes decrease significantly.\\nOversampling\\nOversampling, which refers to intelligently generating synthetic data points for\\nminority classes, is another method to decrease the class size disparity. Oversam‐\\npling is essentially the opposite of undersampling, but is not as simple as arbitrar‐\\nily generating artificial data and assigning it to the minority class. We want to be\\ncautious of unintentionally imparting class characteristics that can misdirect the\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n219'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 237}, page_content=\"36 N.V. Chawla et al., “SMOTE: Synthetic Minority Over-Sampling Technique,” Journal of Artiicial Intelligence\\nResearch (2002): 321–357.\\n37 Haibo He et al., “ADASYN: Adaptive Synthetic Sampling Approach for Imbalanced Learning,” Proceedings of\\nthe IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelli‐\\ngence) (2008): 1322–1328.\\nlearning. For example, a naive way to oversample is to add random samples to\\nthe dataset. This would likely pollute the dataset and incorrectly influence the\\ndistribution. SMOTE36 and ADASYN37 are clever algorithms that attempt to gen‐\\nerate synthetic data in a way that does not contaminate the original characteris‐\\ntics of the minority class.\\nOf course, you can apply combinations of oversampling and undersampling as\\ndesired, to mute the negative effects of each. A popular method is to first oversample\\nthe minority class and then undersample to tighten the class distribution discrepancy.\\nClass imbalance is such a ubiquitous problem that there are software libraries dedica‐\\nted to it. Imbalanced-learn offers a wide range of data resampling techniques for dif‐\\nferent problems. Similar to classifiers, different resampling techniques have different\\ncharacteristics and will vary in their suitability for different problems. Diving in and\\ntrying things out is a good strategy here. Note that some of the techniques offered in\\nthe imbalanced-learn library are not directly applicable to multiclass problems. Let’s\\nfirst oversample using the imblearn.over_sampling.SMOTE class:\\n> print(pd.Series(train_Y).value_counts())\\n    > # Original training data class distribution:\\n        benign    67343\\n        dos       45927\\n        probe     11656\\n        r2l         995\\n        u2r          52\\nfrom imblearn.over_sampling import SMOTE\\n# Apply SMOTE oversampling to the training data\\nsm = SMOTE(ratio='auto', random_state=0)\\ntrain_x_sm, train_Y_sm = sm.fit_sample(train_x, train_Y)\\nprint(pd.Series(train_Y_sm).value_counts())\\n    > # Training data class distribution after first SMOTE:\\n        benign    67343\\n        dos       67343\\n        probe     67343\\n        u2r       67343\\n        r2l       67343\\n220 \\n| \\nChapter 5: Network Traic Analysis\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 238}, page_content=\"The ratio='auto' parameter passed into the imblearn.over_sampling.SMOTE con‐\\nstructor represents the strategy of oversampling all nonmajority classes to be the\\nsame size as the majority class.\\nWith some experimentation, we find that random undersampling of our training data\\ngives the best validation results. The imblearn.under_sampling.RandomUnderSam\\npler class can help us out with this:\\nfrom imblearn.under_sampling import RandomUnderSampler\\nmean_class_size = int(pd.Series(train_Y).value_counts().sum()/5)\\nratio = {'benign': mean_class_size,\\n         'dos': mean_class_size,\\n         'probe': mean_class_size,\\n         'r2l': mean_class_size,\\n         'u2r': mean_class_size}\\nrus = RandomUnderSampler(ratio=ratio, random_state=0)\\ntrain_x_rus, train_Y_rus = rus.fit_sample(train_x, train_Y)\\n    > Original training data class distribution:\\n          benign    67343\\n          dos       45927\\n          probe     11656\\n          r2l         995\\n          u2r          52\\n    > After RandomUnderSampler training data class distribution:\\n          dos       25194\\n          r2l       25194\\n          benign    25194\\n          probe     25194\\n          u2r       25194\\nNote that we calculated the mean class size across all 5 classes of samples and used\\nthat as the target size for undersampling. Now, let’s train the decision tree classifier\\nwith this resampled training data and see how it performs:\\nclassifier = DecisionTreeClassifier(random_state=17)\\nclassifier.fit(train_x_rus, train_Y_rus)\\npred_y = classifier.predict(test_x)\\nresults = confusion_matrix(test_Y, pred_y)\\nerror = zero_one_loss(test_Y, pred_y)\\n> Confusion matrix:\\n      [[9369   73  258    6    5]\\n       [1221 5768  647    0    0]\\n       [ 270  170 1980    1    2]\\n       [1829    2  369  369    5]\\n       [  62    0  108   21    9]]\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n221\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 239}, page_content='38 Yan Zhou, Murat Kantarcioglu, and Bhavani Thuraisingham, “Self-Training with Selection-by-Rejection,” Pro‐\\nceedings of the IEEE 12th International Conference on Data Mining (2012): 795–803.\\n> Error: 0.223962029808\\nResampling helped us get from 76.2% accuracy to 77.6% accuracy. It’s not a huge\\nimprovement, but significant considering we haven’t started doing any parameter\\ntuning or extensive experimentation yet.\\nMatching your task to the ideal classifier is sometimes tedious, but can also be fun.\\nThrough the process of experimentation, you will almost always find something\\nunexpected and learn something new about your data, the classifier, or the task itself.\\nHowever, iterating with different parameters and classifiers will not help if the dataset\\nhas fundamental limitations, such as a dearth of informative features.\\nAs discussed earlier, labeled training data is expensive to generate because it typically\\nrequires the involvement of human experts or physical actions. Thus, it is very com‐\\nmon for datasets to be unlabeled or consist only of a tiny fraction of labeled data. In\\nsuch cases, supervised learning might work if you choose a classifier with high bias,\\nsuch as Naive Bayes. However, your mileage will vary because high-bias algorithms\\nare by definition susceptible to underfitting. You might then need to look to semi-\\nsupervised or fully unsupervised methods.\\nSemi-Supervised Learning\\nSemi-supervised learning is a class of supervised machine learning algorithms and\\ntraining methods that are designed to work with very small sets of labeled training\\ndata. Self-training38 is a good example that we can use to illustrate semi-supervised\\ntechniques. In a nutshell, these algorithms go through an inductive training process,\\nfirst training an initial estimator with the small set of training data, and then running\\nit over unlabeled data. From these initial results, the highest confidence predictions\\nare extracted and added to the training set, labeled with the results from the previous\\nround of prediction. This process is then repeated until the training set contains a sat‐\\nisfactory number of samples.\\nSelf-training produces a reasonably sized training set that often turns out to perform\\nquite well. Some other semi-supervised learning techniques rely on generative\\napproaches to create artificial labeled data from existing samples (the same idea as in\\noversampling, discussed earlier), or on density- and graph-based methods for learning\\nthe data manifold. These techniques infer labels for initially unlabeled data points\\nwith a reasonable degree of confidence.\\n222 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 240}, page_content='39 We won’t be using semi-supervised learning in this example because it typically involves a lengthy process of\\nanalyzing similarities between clusters that is very specific to the dataset in use. For more details on semi-\\nsupervised learning, we highly recommend looking into Semi-Supervised Learning by Olivier Chapelle, Bern‐\\nhard Schölkopf, and Alexander Zien (MIT Press).\\n40 Refer to Chapter 2 for more details. See also Martin Ester et al., “A Density-Based Algorithm for Discovering\\nClusters in Large Spatial Databases with Noise,” Proceedings of the 2nd ACM SIGKDD International Conference\\non Knowledge Discovery and Data Mining (1996): 226–231.\\nScikit-learn \\nprovides \\nthe \\nsklearn.semi_supervised.LabelPropagation \\nand\\nsklearn.semi_supervised.LabelSpreading classes that can help you implement\\nsemi-supervised learning solutions.39\\nUnsupervised Learning\\nWhat if you have no labeled data at all? Especially in some use cases in security,\\nlabeled training data can be prohibitively difficult to generate (e.g., binary analysis\\nrequiring hours of fingerprinting and study per sample, or incident investigation\\nrequiring huge resources and bureaucratic layers to triage). In these cases, unsuper‐\\nvised learning is the only suitable option. This powerful statistical method infers hid‐\\nden latent structure from unlabeled training data. In the classification space, the\\noverwhelmingly dominant class of methods for unsupervised learning is clustering.\\nAs we have discussed in earlier chapters, clustering refers to techniques that group\\nsimilar data samples together, by some definition of similarity. Each group of similar\\npoints is called a cluster, and each cluster represents the learned model of a category.\\nThere are dozens of clustering models that might each be suitable in different scenar‐\\nios. Some methods require you to know the number of classes or centroids ahead of\\ntime (e.g., k-means clustering, Gaussian mixture models), whereas others don’t (e.g.,\\nmean shift clustering). This distinction is the most important factor to consider when\\nchoosing which clustering method to use.\\nGoing through a brief exercise of performing clustering on the NSL-KDD dataset will\\nquickly allow us to see how clustering is different from the supervised techniques that\\nwe saw before. In our example, we know that our data contains five categories of sam‐\\nples, so we will choose the k-means clustering algorithm for the task with k (the num‐\\nber of clusters) equal to 5. (DBSCAN40 is another highly popular choice for clustering\\nbut is more suited for data containing clusters of similar density and hence is unsuita‐\\nble for this task.) Note that k-means works only with continuous features (see Chap‐\\nter 2 for details), so we use only the continuous features in our dataset. We use the\\nsklearn.cluster.KMeans class:\\nfrom sklearn.cluster import KMeans\\nkmeans = KMeans(n_clusters=5).fit(train_x)\\npred_y = kmeans.predict(test_x)\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n223'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 241}, page_content=\"# Inspect the clustering results\\nprint(pd.Series(pred_y).value_counts())\\n>\\n1    15262\\n2     5211\\n0     2069\\n3        2\\nThe results are visibly different from what we got with supervised techniques. What\\nwe get as a result of k-means clustering is a certain number of clusters, where each\\ncluster is labeled with an arbitrary index. In this particular case, notice that the test\\nset contains only four clusters even though we specified n_clusters=5. It seems that\\nthe last cluster did not gain membership of any of the test data points, which is\\nunsurprising given our earlier discussion of class imbalance. What is more interesting\\nis how we evaluate the results of clustering algorithms. None of the clusters have\\nlabels associated with them because we didn’t—and never needed to—pass in any\\nlabel information to the algorithm. Thus, evaluating results of clustering is not as\\nsimple as just comparing expected and predicted labels.\\nTo evaluate our model, we compute how many benign samples are grouped into the\\nsame cluster, and how many samples of other classes are grouped into that cluster. \\nSpecifically, we compute two metrics, the completeness score and the homogeneity\\nscore. A cluster is complete (has completeness score 1) if all data points belonging to\\nthe same class (i.e., with the same class label) are clustered together. On the other\\nhand, a cluster is homogeneous (has homogeneity score 1) if all data points that are\\nclustered together belong to the same class. The V-measure, defined to be the har‐\\nmonic mean of homogeneity and completeness, provides a convenient single metric\\nfor evaluation:\\nv_measure_score = 2 * (homogeneity * completeness) / (homogeneity + completeness)\\nWe generate the evaluation scores for our k-means clustering applied to the NSL-\\nKDD dataset as follows:\\nfrom sklearn.metrics import completeness_score,\\\\\\n    homogeneity_score, v_measure_score\\nprint('Completeness: {}'.format(completeness_score(test_Y, pred_y)))\\nprint('Homogeneity: {}'.format(homogeneity_score(test_Y, pred_y)))\\nprint('V-measure: {}'.format(v_measure_score(test_Y, pred_y)))\\n> Completeness: 0.403815151707\\n> Homogeneity: 0.263893938589\\n> V-measure: 0.319194009471\\nA V-measure score of 0.32 is a really bad result. It looks like the data in its current\\nstate is not suitable for unsupervised classification. Indeed, class imbalance is\\n224 \\n| \\nChapter 5: Network Traic Analysis\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 242}, page_content=\"41 Svante Wold, Kim Esbensen, and Paul Geladi, “Principal Component Analysis,” Chemometrics and Intelligent\\nLaboratory Systems 2 (1987): 37–52.\\nproblematic in clustering, where algorithms rely on shared properties of data points\\nto form (in the ideal case) tight clusters of similar points. The lack of information\\nabout minority classes can lead to minority clusters not being correctly formed at all,\\ninstead resulting in “rogue” clusters siphoning away membership from otherwise\\nwell-formed clusters.\\nExperimenting with data resampling methods can help solve these problems, but it is\\nimportant to note that some classes of problems are fundamentally unsuitable for\\nunsupervised learning. If the data does not contain clearly separable clusters of sam‐\\nples, clustering will be an uphill task. How can we find out? Visualization is always\\nuseful for getting an intuition for the data, and is especially useful for clustering. We\\nwant to plot the samples in some space and visually observe the clusters formed.\\nBefore we attempt to plot our data on a chart, let’s check how many dimensions/\\nfeatures we have:\\n> print('Total number of features: {}'.format(len(train_x.columns)))\\nTotal number of features: 119\\nWe can’t possibly plot all 119 dimensions, so we will perform dimensionality reduction\\nto reduce the data to a more palatable set of two dimensions for representation on\\ntwo-dimensional Cartesian axes. Principal component analysis41 (PCA) is one com‐\\nmon dimensionality reduction method. It is difficult to explain this process accu‐\\nrately without diving into its mathematical formulation, but what PCA effectively\\ndoes is find a set of axes (principal components) in high-dimensional space that are\\nordered by the amount of variance in the data that they explain, from greatest var‐\\niance to smallest. It follows that projecting the dataset onto the first few axes captures\\nmost of the information in the dataset.\\nPerforming dimensionality reduction after PCA is then as simple as picking out the\\ntop n principal components and representing your data in those n dimensions. In\\nmost cases, when performing PCA for the purposes of dimensionality reduction for\\ndownstream classification or processing, you should select a sufficient number of\\nprincipal components to capture a large proportion of the variance in your data. For\\nplotting purposes, however, choosing the top two principal components will often be\\nsufficient to give a good representation for understanding the data. We use\\nsklearn.decomposition.PCA on our training dataset, labeling data points with\\nground truth labels (see Figure 5-12):\\nfrom sklearn.decomposition import PCA\\npca = PCA(n_components=2)\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n225\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 243}, page_content=\"train_x_pca = pca.fit_transform(train_x)\\nplt.figure()\\ncolors = ['navy', 'turquoise', 'darkorange', 'red', 'purple']\\nfor color, cat in zip(colors, category.keys()):\\n    plt.scatter(train_x_pca[train_Y==cat, 0],\\n   train_x_pca[train_Y==cat, 1],\\n                color=color, alpha=.8, lw=2, label=cat)\\nplt.legend(loc='best', shadow=False, scatterpoints=1)\\nplt.show()\\nFigure 5-12. Scatter plot of training data with ground truth labels (transformed with\\nPCA)\\nThe first principal component is represented on the horizontal axis, and the second is\\nrepresented on the vertical axis. It is easy to see that this dataset is not very suitable\\nfor clustering. The probe, dos, and r2l samples are scattered unpredictably, and do\\nnot form any strong clusters. Because there are few u2r samples, it is difficult to\\nobserve this class on the plot and it does not form any visible clusters. Only benign\\nsamples seem to form a strong cluster. To satisfy our curiosity, let’s plot these same\\npoints with the labels assigned after fitting them to the k-means clustering algorithm\\nthat we used earlier:\\nfrom sklearn.cluster import KMeans\\n226 \\n| \\nChapter 5: Network Traic Analysis\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 244}, page_content=\"# Fit the training data to a k-means clustering estimator model\\nkmeans = KMeans(n_clusters=5, random_state=17).fit(train_x)\\n# Retrieve the labels assigned to each training sample\\nkmeans_y = kmeans.labels_\\n# Plot in 2d with train_x_pca_cont\\nplt.figure()\\ncolors = ['navy', 'turquoise', 'darkorange', 'red', 'purple']\\nfor color, cat in zip(colors, range(5)):\\n    plt.scatter(train_x_pca_cont[kmeans_y==cat, 0],\\n                train_x_pca_cont[kmeans_y==cat, 1],\\n                color=color, alpha=.8, lw=2, label=cat)\\nplt.legend(loc='best', shadow=False, scatterpoints=1)\\nplt.show()\\nFigure 5-13 shows the result.\\nFigure 5-13. Scatter plot of training data with k-means predicted classes (k=5)\\nNow, remember that the k-means algorithm is unsupervised, so it is not aware of\\nwhich label each formed cluster corresponds to. Immediately, in Figure 5-13, we can\\nobserve significant differences in the clusters formed by k-means and the ground\\ntruth clusters. The algorithm performs well in grouping certain sections of the data\\ntogether, but it fails to group together clusters of the dos label and wrongly classifies a\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n227\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 245}, page_content='42 We do not go into all the details of ensembling techniques here. For a great reference on this subject, refer to\\nEnsemble Machine Learning: Methods and Applications by Cha Zhang and Yunqian Ma (Springer Publishing).\\nlarge section of “benign” traffic as attack traffic (the upper-left section of Figure 5-13).\\nTuning and experimenting with the value of k can help with this, but from this brief\\nvisual analysis, we see that there might be some fundamental problems with using\\nonly clustering methods to classify network attacks in this data.\\nEven when we are just using continuous features, we are still dealing with a dataset\\ncomprising 34 dimensions. Recall from Chapter 2 that k-means loses effectiveness in\\nhigh dimensions. This is a problem that we can solve by feeding the algorithm with\\ndimensionality-reduced (e.g., with PCA) data. However, something that is more diffi‐\\ncult to solve is the inherent distribution characteristics. In Chapter 2, we also men‐\\ntioned that k-means does not work well on nonspherical distributions. From\\nFigure 5-12, it is difficult to argue that any of the classes have a spherical distribution.\\nNo wonder k-means does not work well here!\\nAdvanced Ensembling\\nk-means works relatively well in assigning labels to some contiguous clusters of data.\\nTrying out k-means with k=8, we get the result illustrated in Figure 5-14.\\nComparing this plot with the ground truth labels in Figure 5-12, we notice that some\\nclusters of data do mostly belong to the same class. Other clusters, such as cluster 2,\\nseem to be made up of a mix of benign and probe traffic. If there were a way to per‐\\nform further classification within clusters, we might be able to achieve better results.\\nThis intuition is leading us to a well-known class of techniques known as ensembling.\\nEnsembling techniques (or ensemble models) refer to the combination of two or more\\nmachine learning models (they could use the same underlying algorithm or alto‐\\ngether different algorithms) to form a single system.42 The goal is to combine the\\nresults of multiple weak models to form a single stronger learner.\\n228 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 246}, page_content=\"43 Hee-su Chae and Sang Hyun Choi, “Feature Selection for Efficient Intrusion Detection Using Attribute Ratio,”\\nInternational Journal of Computers and Communications 8 (2014): 134–139.\\n44 Complete implementation of the attribute ratio calculation is provided in the Using “Attribute Ratio” (AR) fea‐\\nture selection section of the Python Jupyter notebook found at chapter5/nsl-kdd-classiication.ipynb in our\\ncode repository.\\nFigure 5-14. Scatter plot of training data with k-means predicted classes (k=8)\\nIn our example, we are trying to perform further classification separately on some\\nclusters that contain mixed labels, attempting to partition these clusters better than k-\\nmeans would have been able to. To simplify the problem, let’s attempt to classify this\\nnetwork traffic into just the two classes that matter most: attack and benign traffic.\\nWe reduce the dimensionality of the problem by using a method of ranking features\\ncalled the attribute ratio.43 We do not go into further detail here,44 but we used this\\nfeature ranking method to select the features with an attribute ratio greater than 0.01,\\nwhich reduces the number of features we will use to 31. Let’s first define the labels for\\nour task:\\ntrain_Y_bin = train_Y.apply(lambda x: 'benign' if x == 'benign' else 'attack')\\nThen, we select the subset of important features, apply k-means on it with k=8, and\\nobserve the cross-tabulation of the eight k-means clusters and the ground truth\\nbinary labels (Table 5-1):\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n229\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 247}, page_content='kmeans = KMeans(n_clusters=8, random_state=17).fit(\\n    train_df_ar_trimmed[continuous_features_trimmed])\\nkmeans_train_y = kmeans.labels_\\npd.crosstab(kmeans_train_y, train_Y_bin)\\nTable 5-1. Cross-tabulation of k-means predicted clusters versus training data ground truth\\nattack category\\nattack benign\\n0\\n6457\\n63569\\n1\\n11443\\n2784\\n2\\n34700\\n126\\n3\\n0\\n1\\n4\\n4335\\n628\\n5\\n757\\n167\\n6\\n884\\n0\\n7\\n54\\n68\\nLooking at Table 5-1, we must consider how we want to deal with each cluster. Notice\\nhow clusters 2 and 6 have a very clear majority of attack traffic, clusters 3 and 7 seem\\nto contain only low levels of noise, and the rest of the clusters are quite mixed. Devel‐\\noping a suitable result aggregation strategy from the training data is a crucial step in\\nensembling, and it is worthwhile spending time to experiment with which approach\\nworks best. For this example, we devise a three-path strategy for dealing with each\\ncluster:\\n1. For clusters that have an aggregate size of fewer than 200 samples, we consider\\nthem outliers and assign them the attack label.\\n2. For clusters with more than 99% of samples belonging to a single class (either\\nattack or benign), we assign the dominant label to the entire cluster.\\n3. For each of the remaining clusters, we train a separate decision tree classiier.\\nAccording to this strategy, clusters 3 and 7 will be considered “noise” and be assigned\\nthe attack label. Clusters 2 and 6 both have more than 99% of the traffic classified as\\nattacks so that label propagates to the entire cluster. We will train decision tree clas‐\\nsifiers for each of clusters 0, 1, 4, and 5.\\nWe evaluate our method by first running the test samples through the k-means model\\nto obtain the test clusters. Then, all the test samples assigned to clusters 2, 3, 6, and 7\\nwill immediately be labeled as attack. Test samples assigned to cluster 0 will be put\\nthrough the decision tree classifiers trained on cluster 0 from the training set, and so\\non.\\n230 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 248}, page_content=\"As an example, here is how we train cluster 4’s decision tree classifier and make pre‐\\ndictions on test cluster 4’s samples:\\ntrain_y4 = train_df[train_df.kmeans_y == 4]\\ntest_y4 = test_df[test_df.kmeans_y == 4]\\ndfc4 = DecisionTreeClassifier(random_state=17)\\n.fit(train_y4.drop(['kmeans_y'], axis=1),train_y4['labels2'])\\ndtc4_pred_y = dtc4.predict(test_y4.drop(['kmeans_y'], axis=1))\\nFollowing our aggregation strategy, Table 5-2 lists the combined test set confusion\\nmatrices for all eight clusters.\\nTable 5-2. Confusion matrix for combined ensemble model\\nPredicted benign\\nPredicted attack\\nActual benign\\n9,418\\n293\\nActual attack\\n4,020\\n8,813\\nAnalyzing the classification report, we see the results listed in Table 5-3.\\nTable 5-3. Statistics for ensemble classiication model\\nPrecision\\nRecall\\nF1 score Support\\nbenign 0.70\\n0.97\\n0.81\\n9711\\nattack\\n0.97\\n0.69\\n0.80\\n12833\\nWhere:\\nPrecision = True Positives / (True Positives + True Negatives)\\nRecall = True Positives/ (True Positives + False Negatives)\\nIn other words, precision is the proportion of the predicted items that are relevant,\\nand recall is the proportion of the relevant items that are correctly predicted.\\nWe see that the precision for predicted attacks is 97%. This means that if the classifier\\npredicts that a sample is an attack, there is a 97% chance that it actually is an attack.\\nThe recall for benign traic is also 97%, which means that 97% of all actual benign\\ntraffic is correctly predicted as benign traffic.\\nThe problematic parts of the results are the comparatively low precision for the\\nbenign traffic and low recall for attack traffic. In fact, 30% of the traffic that this clas‐\\nsifier classifies as benign is actually an attack.\\nBuilding a Predictive Model to Classify Network Attacks \\n| \\n231\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 249}, page_content='45 We acknowledge that there are also significant differences in the label distributions of clusters 5, 6, and 7, but\\nthe number of samples involved is relatively small compared with the size of the dataset. Hence, these discrep‐\\nancies can be explained by noise in the dataset.\\nHow can we explain these bad results for benign predictions? Let’s look at the k-\\nmeans cross-tabulation for the test dataset and compare it with that of the training\\ndata:\\n# kmeans_test_y is clusters predicted by k-means\\npd.crosstab(kmeans_test_y, test_Y_bin)\\nTable 5-4 shows the results.\\nTable 5-4. Cross-tabulation of k-means predicted clusters versus test data ground truth\\nattack category\\nattack\\nbenign\\n0\\n9,515\\n4,795\\n1\\n87\\n5131\\n2\\n6\\n1,997\\n3\\n0\\n0\\n4\\n51\\n427\\n5\\n10\\n1\\n6\\n37\\n8\\n7\\n5\\n474\\nIf we compare Table 5-1 to Table 5-4, we see that the biggest discrepancies between\\nthe attack/benign distributions within a single cluster come from cluster 0.45 In the\\ntraining data, cluster 0 contains just 9% attack traffic, whereas in the test data, cluster\\n0 contains 66% attack traffic! It seems like the information that is captured by the k-\\nmeans model for cluster 0 is insufficient to generalize to the test data. Let’s confirm\\nthis hypothesis by examining the confusion matrix for cluster 0’s decision tree classi‐\\nfier predictions, as shown in Table 5-5.\\nTable 5-5. Confusion matrix for only cluster 0 (decision tree classiier)\\nPredicted benign\\nPredicted attack\\nActual benign\\n9,352\\n163\\nActual attack\\n3,062\\n1,733\\nComparing Table 5-2 and Table 5-5, notice that 76% (3,062 out of 4,020) of the total\\nfalse negative (predicted benign + actual attack) predictions made by the ensemble\\nare caused by cluster 0’s decision tree classifier. If we could make cluster 0’s classifier\\nbetter, we would greatly improve the ensemble classifier’s overall performance.\\n232 \\n| \\nChapter 5: Network Traic Analysis'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 250}, page_content='Now, you might be tempted to use these specific test results to improve your model.\\nPerhaps you would be able to improve results by using a different algorithm just for\\ncluster 0? In most cases, this kind of customization would be the cardinal sin of\\nmachine learning. You should be careful never to make adjustments to your model\\nbased on results from the test set.\\nHowever, consider the following scenario: suppose that you have this model in pro‐\\nduction for a month, and you observe that cluster 0’s decision tree classifier is consis‐\\ntently underperforming. Making changes to your model based on this information is\\nokay—in fact, it is highly encouraged!\\nHow is this different? Notice that in the latter case, you have expanded your training\\nset to the data you have collected (and perhaps also labeled) over the course of the\\nmonth. You can now use this newly defined training set to develop the next version of\\nthe classifier. However, note that you will also need to generate a test set correspond‐\\ning to this new training set.\\nConclusion\\nHaving worked through the task in this chapter, it should be clear that machine learn‐\\ning—specifically, data correlation and classification—is about more than just choos‐\\ning the right classifier and knowing about algorithms. Spending time to explore and\\nunderstand the data is key, and can help save you precious time in getting to a desired\\nclassification accuracy. The security space provides some unique challenges when\\napplying machine learning. More often than not, you will be faced with class imbal‐\\nance and lack of training data. Sometimes, continuing to tune algorithms or the\\nlearning process may not be the answer—collecting more data, generating more\\ndescriptive features, changing class/category definitions, adjusting the learning goals,\\nor all of the above might be what you need to obtain better results.\\nConclusion \\n| \\n233'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 251}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 252}, page_content='CHAPTER 6\\nProtecting the Consumer Web\\nMost of our discussion so far has focused on preventing hackers from getting into a\\ncomputer or network, detecting them after they’ve achieved a breach, and mitigating\\neffects of the breach. However, it is not necessary for an attacker to breach a network\\nin order to gain economically. In this chapter we consider attackers who use a\\nconsumer-facing website or app’s functionality to achieve their goals.\\nWhen referring to the “consumer web,” we mean any service accessible over the pub‐\\nlic internet that provides a product to individual consumers; the service can be free or\\nfee-based. We distinguish the consumer web from enterprise services provided to an\\norganization, and from internal networks within a company.\\nThe consumer web has many different attack surfaces; these include account access,\\npayment interfaces, and content generation. Social networks provide another dimen‐\\nsion of vulnerability, as attackers can take advantage of the social graph to achieve\\ntheir goals.\\nHowever, the consumer web also has some built-in properties that work to the\\ndefender’s advantage. The foremost of these is scale: any site that is subject to attack is\\nalso subject to a much larger amount of legitimate traffic. This means that when\\nbuilding your defense, you have a large database of legitimate patterns you can use to\\ntrain your algorithms. Anomaly detection, as discussed in Chapter 3, can be appro‐\\npriate here, especially if you don’t have a lot of labeled data. On the other hand, if you\\nare considering building defenses into your product, it’s probably because your web‐\\nsite or app has already undergone an attack—in which case you probably have\\nenough labeled data to build a supervised classifier.\\nIn the subsequent sections, we consider various attack vectors and how machine\\nlearning can help distinguish legitimate activity from malicious activity in each case.\\nBecause open source consumer fraud data is scarce, we will focus primarily on\\n235'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 253}, page_content='principles behind feature generation and algorithm selection for each problem;\\ntoward the end of the chapter, we will use a concrete example to illustrate approaches\\nto clustering.\\nEven though the title of this chapter is “Protecting the Consumer Web,” everything\\nwe discuss applies equally to websites accessed via a browser and apps that get their\\ndata from an internet-facing API. In the following sections we will consider some of\\nthe differences in attack surface and features available to the defender.\\nMonetizing the Consumer Web\\nMany consumer-facing websites make it possible for hackers to monetize directly\\nsimply by gaining access to an account. Financial institutions are the most obvious\\nexample, but online marketplaces, ride-sharing services, ad networks, and even hotel\\nor airline rewards programs also facilitate direct transfers of currency to essentially\\narbitrary recipients. Hackers need only compromise a few high-value accounts to\\nmake the investment worthwhile. Protecting accounts on such a service is thus para‐\\nmount for the site’s continued existence.\\nFraud is another key concern for many consumer-facing websites. Most online serv‐\\nices accept credit cards for payment, and thus bad actors can use stolen credit cards to\\npay for whatever the sites offer. For sites that offer consumer goods directly this is\\nparticularly dangerous, as the stolen goods can then be resold on the black market for\\na fraction of their retail price. Even sites that offer digital goods are susceptible to\\nfraud; digital goods can be resold, or premium accounts on a service can be used to\\naccelerate other types of abuse on that service.\\nFraud encompasses much more than payments. Click fraud consists of bots or other\\nautomated tools clicking links for the sole purpose of increasing click counts. The\\nmost prominent use case is in advertising, either to bolster one’s own revenue or to\\ndeplete competitors’ budgets; however, click fraud can appear anywhere where counts\\ninfluence ranking or revenue, such as number of views of a video or number of “likes”\\nof a user’s post. We also consider review fraud, whereby users leave biased reviews of a\\nproduct to artificially inflate or deflate that product’s rating. For example, a restaurant\\nowner might leave (or pay others to leave) fake five-star reviews of their restaurant on\\na dining site to attract more customers.\\nEven if a hacker can’t monetize directly, there are a large number of sites that provide\\nindirect means to monetization. Spam is the most obvious—any site or app that pro‐\\nvides a messaging interface can be used to send out scams, malware, or phishing mes‐\\nsages. We discussed text classification of spam messages in Chapter 1 and thus won’t\\ngo into further detail here; however, we will discuss behavior-based detection of\\nspammers. More generally, any site that allows users to generate content can be used\\nto generate spammy content; if this content is in broadcast form rather than user-to-\\n236 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 254}, page_content='1 Anupam Das et al., “The Tangled Web of Password Reuse,” Proceedings of the 21st Annual Network and Dis‐\\ntributed System Security Symposium (2014).\\nuser messaging, other fraud or search engine optimization (SEO) techniques can\\nexpose the spam to a broad audience. The attacker can even take advantage of social\\nsignals: if popular content is ranked more highly, fake likes or shares allow spammers\\nto promote their message.\\nThis list of activities covers most of the abuse on the consumer web but is far from\\nexhaustive. For further information, we recommend the Automated hreat Handbook\\nfrom the Open Web Application Security Project (OWAS) as a good resource that\\ndescribes a large variety of different types of abuse.\\nTypes of Abuse and the Data That Can Stop Them\\nLet’s now examine in more depth some of the different ways in which attackers can\\ntry to take advantage of consumer websites. In particular, we will look at account\\ntakeover, account creation, financial fraud, and bot activity. For each of these attack\\nvectors we will discuss the data that needs to be collected and the signals that can be\\nused to block the attack.\\nAuthentication and Account Takeover\\nAny website or app that only serves content does not need to make any distinction\\nbetween users. However, when your site needs to differentiate the experience for dif‐\\nferent users—for example, by allowing users to create content or make payments—\\nyou need to be able to determine which user is making each request, which requires\\nsome form of user authentication.\\nAuthentication on the internet today overwhelmingly takes the form of passwords. \\nPasswords have many useful properties, the foremost of which is that due to their\\nprevalence, nearly everyone knows how to use them. In the ideal situation, passwords\\nserve to identify a user by verifying a snippet of information that is known only to\\nthat user. In practice, however, passwords suffer from many flaws:\\n• Users choose passwords that are easy to remember but also easy to guess. (The\\nmost common password seen in most data breaches is “password.”)\\n• Because it is nearly impossible to remember a unique, secure password for each\\nsite, people reuse passwords across multiple sites; research has shown that nearly\\nhalf of all internet users reuse credentials.1 This means that when a site is\\nbreached, up to half of its users are vulnerable to compromise on other unrelated\\nsites.\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n237'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 255}, page_content='• Users are vulnerable to “phishing” campaigns, in which a malicious email or\\nwebsite takes on the appearance of a legitimate login form, and tricks users into\\nrevealing their credentials.\\n• Users might write down passwords where they can be easily read or share them\\nwith friends, family, or colleagues.\\nWhat are websites to do in the face of these weaknesses? How can you ever be sure\\nthat the person logging in is the actual account owner?\\nOne line of research has focused on developing alternative authentication mecha‐\\nnisms that can replace passwords entirely. Biometric identifiers such as fingerprint or\\niris scans have been shown to be uniquely identifying, and behavioral patterns such as\\ntyping dynamics have also shown success in small studies. However, biometrics lack\\nrevocability and are inherently unchangeable. Because current sensors are susceptible\\nto being tricked, this brittleness makes for an unacceptable system from a security\\nstandpoint, even leaving aside the difficult task of getting users to switch away from\\nthe well-known password paradigm.\\nA more common pattern is to require a second factor for login. This second factor can\\nbe deployed all the time (e.g., on a high-value site such as a bank), on an opt-in basis\\n(e.g., for email or social sites), or when the site itself detects that the login looks suspi‐\\ncious. Second factors typically rely on either additional information that the user\\nknows or an additional account or physical item that the user possesses. Common\\nsecond-factor authentication patterns include:\\n• Confirming ownership of an email account (via code or link)\\n• Entering a code sent via SMS to a mobile phone\\n• Entering a code generated by a hardware token (such as those provided by RSA\\nor Symantec)\\n• Entering a code generated by a software app (such as Google Authenticator or\\nMicrosoft Authenticator)\\n• Answering security questions (e.g., “What month is your best friend’s birthday?”)\\n• Verifying social information (e.g., Facebook’s “photo CAPTCHA”)\\nOf course, all of these second factors themselves have drawbacks:\\n• Email accounts are themselves protected by passwords, so using email as a sec‐\\nond factor just pushes the problem to the email provider (especially if email can\\nbe used to reset the password on the account).\\n• SMS codes are vulnerable to man-in-the-middle or phone-porting attacks.\\n• Hardware and software tokens are secure but the user must have the token or app\\nwith them to log in, and the token must be physically protected.\\n238 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 256}, page_content='2 Because best practice is for passwords to be hashed and salted, a secure site will not know the distribution of\\nits own passwords. Popularity rank can be estimated using publicly leaked lists.\\n• Answers to security questions can be easily guessed.\\n• Social details can often be guessed or found on the internet; or the questions\\nmight be unanswerable even by the person owning the account, depending on\\nthe information requested.\\nIn the most extreme case, the website might simply lock an account believed to be\\ncompromised, which requires the owner to contact customer support and prove their\\nownership of the account via an offline mechanism such as verifying a photo ID.\\nRegardless of the recovery mechanism used, a website that wants to protect its users\\nfrom account takeover must implement some mechanism to distinguish legitimate\\nlogins from illegitimate ones. This is where machine learning and statistical analysis\\ncome in.\\nFeatures used to classify login attempts\\nGiven the aforementioned weaknesses of passwords, a password alone is not enough\\nto verify an account holder’s identity. Thus, if we want to keep attackers out of\\naccounts that they do not own, whenever we see a correct username–password pair\\nwe must run some additional logic that decides whether to require further verifica‐\\ntion before letting the request through. This logic must run in a blocking manner and\\nuse only data that can be collected from the login form. It must also attempt to detect\\nall of the types of attacks discussed earlier. Thus, the main classes of signals we want\\nto collect are as follows:\\n• Signals indicating a brute-force attack on a single account:\\n— Velocity of login attempts on the account—simple rate limiting can often be\\neffective\\n— Popularity rank of attempted passwords—attackers will try common pass‐\\nwords2\\n— Distribution of password attempts on the account—real users will attempt the\\nsame password or similar passwords\\n• Signals indicating a deviation from this user’s established patterns of login:\\n— Geographic displacement from previous logins (larger distances being more\\nsuspicious)\\n— Using a browser, app, or OS not previously used by the account\\n— Appearing at an unusual time of day or unusual day of the week\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n239'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 257}, page_content='— Unusual frequency of logins or inter-login time\\n— Unusual sequence of requests prior to login\\n• Signals indicating large-scale automation of login:\\n— High volume of requests per IP address, user agent, or any other key extracted\\nfrom request data\\n— Unusually high number of invalid credentials across the site\\n— Requests from a hosting provider or other suspicious IP addresses\\n— Browser-based telemetry indicating nonhuman activity—e.g., keystroke tim‐\\ning or device-class fingerprinting\\nEngineering all of these features is a nontrivial task; for example, to capture devia‐\\ntions from established patterns, you will need a data store that captures these patterns\\n(e.g., all IP addresses an account has used). But let’s assume you have the ability to\\ncollect some or all of these features. Now what?\\nFirst of all, let’s consider brute-force protection. In most cases a simple rate limit on\\nfailed login attempts will suffice; you could block after a certain threshold is reached\\nor require exponentially increasing delays between attempts. However, some services\\n(e.g., email) might have apps logging in automatically at regular intervals, and some\\nevents (e.g., password change) can cause these automated logins to begin to fail, so\\nyou might want to discount attempts coming from a known device.\\nDepending on your system’s security requirements you might or might not be able to\\nget some data on the passwords being entered. If you can get a short-term store of\\npassword hashes in order to count unique passwords attempted, you can rate limit on\\nthat feature, instead. You might also want to lock an account for which many pass‐\\nwords attempted appear in lists obtained from breaches.\\nNow we consider attacks in which the attacker has the password. The next step\\ndepends on the labeled data you have available.\\nLabeling account compromise is an imprecise science. You will probably have a set of\\naccount owners who have reached out complaining of their accounts being taken\\nover; these can be labeled as positives. But assuming there is some (perhaps heuristic)\\ndefense mechanism already in place, how do you know which accounts you stopped\\nfrom logging in were truly malicious, as opposed to those with legitimate owners who\\ncouldn’t (or didn’t bother to) get through the additional friction you placed on the\\naccount? And how do you find the false negatives—accounts taken over but not yet\\nreported as such?\\nLet’s assume you don’t have any labeled data. How do you use the signals described\\nhere to detect suspicious logins?\\n240 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 258}, page_content='The first technique you might try is to set thresholds on each of the aforementioned\\nfeatures. For example, you could require extra verification if a user logs in more than\\n10 times in one hour, or more than 500 miles from any location at which they were\\npreviously observed, or using an operating system they haven’t previously used. Each\\nof these thresholds must be set using some heuristic; for example, if only 0.1% of\\nusers log in more than 10 times per hour, you might decide that this is an acceptable\\nproportion of users to whom to apply more friction. But there is a lot of guesswork\\nhere, and retuning the thresholds as user behavior changes is a difficult task.\\nHow about a more principled, statistical approach? Let’s take a step back and think\\nabout what we want to estimate: the probability that the person logging in is the\\naccount owner. How can we estimate this probability?\\nLet’s begin by estimating an easier quantity from the login data: the probability that\\nthe account owner will log in from the particular IP address in the request. Let u\\ndenote the user in question and x denote the IP address. Here is the most basic esti‐\\nmate of the probability:\\nPr IP = x ∣User = u = # logins with IP = x and User = u\\n# logins with User = u\\nSuppose that we have a user, u, who has the following pageview history:\\nDate\\nIP address\\nCountry\\n1-Jul\\n1.2.3.4\\nUS\\n2-Jul\\n1.2.3.4\\nUS\\n3-Jul\\n5.6.7.8\\nUS\\n4-Jul\\n1.2.3.4\\nUS\\n5-Jul\\n5.6.7.8\\nUS\\n6-Jul\\n1.2.3.4\\nUS\\n7-Jul\\n1.2.3.45\\nUS\\n8-Jul\\n98.76.54.32\\nFR\\nFor the login on July 6, we can compute the following:\\nPr IP = 1.2.3.4 User = u = 0.6\\nBut what do we do with the login on July 7? If we do the same calculation, we end up\\nwith a probability estimate of zero. If the probability of user u logging in from IP x is\\nzero, this login must be an attack. Thus, if we took this calculation at face value, we\\nwould need to regard every login from a new IP address as suspicious. Depending on\\nthe attacks to which your system is exposed and how secure you want your logins to\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n241'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 259}, page_content='3 For an alternative smoothing technique using the fact that IP addresses reside in hierarchies (e.g., IP → ISP →\\nCountry), see D. Freeman et al., “Who Are You? A Statistical Approach to Measuring User Authenticity,” Pro‐\\nceedings of the 23rd Annual Network and Distributed System Security Symposium (2016).\\nbe, you might be willing to make this assumption and require extra verification from\\nevery user who changes IP addresses. (This will be particularly annoying to users who\\ncome from dynamically assigned IPs.) However, most administrators will want to\\nfind some middle ground.\\nTo avoid the issue of zero probabilities, we can smooth by adding “phantom” logins to\\nthe user’s history. Specifically, we add β login events, α of which are from the IP\\naddress in question:\\nPr IP = x ∣User = u = # logins with IP = x and User = u + α\\n# logins with User = u + β\\nThe precise values of α and β can be chosen based on how suspicious we expect a new\\nIP address to be, or, in statistical terms, what the prior probability is. One way to esti‐\\nmate the prior is to use the data: if 20% of all logins come from IP addresses not pre‐\\nviously used by that user, values of α = .2 and β = 1 are reasonable.3 With these values,\\nthe logins from our imaginary user on July 6 and 7 get probability estimates of,\\nrespectively:\\nPr IP = 1.2.3.4 User = u = 3 + 0.2 / 5 + 1 = 0.53,\\nPr IP = 1.2.3.45 User = u = 0 + 0.2 / 6 + 1 = 0.03,\\nNote that if we just look at IP addresses, the logins on July 7 and 8 are about equally\\nsuspicious (P = 0.03 for both). However, it is clear from the table that the July 8 login\\nshould be treated with more suspicion because it’s from a country not previously vis‐\\nited by that user. This distinction becomes clear if we do the same calculation for\\ncountry as we did for IP address—if we let α = .9 and β = 1 for the smoothing factors,\\nthe logins on July 7 and 8 have, respectively, probability estimates of:\\nPr country = US User = u = 6 + 0.9 / 6 + 1 = 0.99,\\nPr country = FR User = u = 0 + 0.9 / 7 + 1 = 0.13,\\nThis is a significant difference. We can use similar techniques for all of the features\\nlabeled earlier as “signals indicating a deviation from established patterns of login”: in\\neach case, we can compute the proportion of logins from this user that match the\\nspecified attribute, adding appropriate smoothing to avoid zero estimates.\\n242 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 260}, page_content='How about the “large-scale automation” features? To calculate velocity features, we\\nneed to keep rolling counts of requests over time that we can look up on each incom‐\\ning request. For example, we should keep track of the following (among others):\\n• Number of successful/failed login attempts sitewide in the past hour/day\\n• Number of successful/failed login attempts per IP address in the past hour/day\\n• Number of successful/failed login attempts per user agent in the past hour/day\\nTo determine whether there is an unusually high number of invalid credentials across\\nthe site you can do the following: calculate the login success rate for each hour over a\\nsufficiently large historical period, and use this data to compute the mean and stan‐\\ndard deviation of the success rate. Now when a login comes in, you can compute the\\nsuccess rate over the past hour and determine whether this value is acceptably close\\nto the historical mean; if you’re using heuristics, failure rates two or three standard\\ndeviations above the mean should trigger alerts or additional friction. To get a proba‐\\nbility, you can use a t-test to compute a p-value. You can compute similar statistics on\\nfailure rate per IP or failure rate per user agent.\\nFinally, we consider the “requests from a suspicious entity” features. To accurately \\ncapture these features you need reputation systems that assign to each entity (e.g., IP\\naddress) either a label or a score that indicates the prior level of suspicion. (For exam‐\\nple, hosting providers would typically have low scores.) We defer the discussion of\\nhow to build reputation systems to later in this chapter.\\nBuilding your classiier\\nNow that you have all these features, how do you combine them? Without labels, this\\ntask is a difficult one. Each feature you have computed represents a probability, so the\\nnaive approach is to assume that all of the features are independent and simply multi‐\\nply them together to get a total score (equivalently, you can take logs and add). A\\nmore sophisticated approach would be to use one of the anomaly detection techni‐\\nques from Chapter 3, such as a one-class support vector machine, isolation forest, or\\nlocal outlier factor.\\nWith labels, of course, you can train a supervised classifier. Typically, your labels will\\nbe highly unbalanced (there will be very little labeled attack data), so you will want to\\nuse a technique such as undersampling the benign class or adjusting the cost function\\nfor the attack class.\\nAccount Creation\\nEven though getting into a legitimate user’s account might be necessary to steal assets\\nbelonging to that user, attacks such as sending spam or fake content can be carried\\nout from accounts created and owned by the attacker. If attackers can create a large\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n243'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 261}, page_content='number of accounts, your site could potentially be overwhelmed by illegitimate users.\\nThus, protecting the account creation process is essential to creating a secure system.\\nThere are two general approaches to detecting and weeding out fake accounts: scor‐\\ning the account creation request to prevent fake accounts from being created at all,\\nand scoring existing accounts in order to delete, lock, or otherwise restrict the fake\\nones. Blocking during the creation process prevents attackers from doing any damage\\nat all, and also keeps the size of your account database under control; however, scor‐\\ning after the fact allows greater precision and recall, due to the fact that more infor‐\\nmation is available about the accounts.\\nThe following (simplistic) example illustrates this trade-off. Suppose that you have\\nconcluded from your data that if more than 20 new accounts are created from the\\nsame IP address in the same hour, these accounts are certain to be fake. If you score at\\naccount creation time, you can count creation attempts per IP address in the past\\nhour and block (or perhaps show a CAPTCHA or other challenge) whenever this\\ncounter is greater than 20. (See the following subsection for details on rolling coun‐\\nters.) However, for any particular attack, there will still be 20 fake accounts that got\\nthrough and are free to send spam. On the other hand, if you score newly created\\naccounts once per hour and take down any group of more than 20 from the same IP\\naddress, you will block all the spammers but still give them each one hour to wreak\\nhavoc.\\nClearly a robust approach combines instances of both techniques. In this section, we\\nconsider a scoring model that runs at account creation time. The features that go into\\nsuch a model fall into two categories: velocity features and reputation scores.\\nVelocity features\\nWhen an attacker is flooding your system with account creation requests, you don’t\\nwant to build a complicated machine learning model—you just want to block the\\noffending IP address. But then the attacker will find a new IP address, and now it\\nbecomes a game of whack-a-mole. To avoid this game and create a robust, automated\\ndefense, we use velocity features.\\nThe basic building block of a velocity feature is a rolling counter. A rolling counter\\ndivides time into k buckets (e.g., each hour of the day) and for each key in a keyspace\\n(e.g., the set of all IP addresses) maintains the count of events for that key in each\\nbucket. At set intervals (e.g., on every hour), the oldest bucket is cleared and a fresh\\nbucket is created. At any point we can query the counter to get the number of events\\nfor a given key in the past t buckets (if t ≤ k).\\nHowever, since each bucket will hold roughly the same number of keys, having many\\nfine-grained buckets could lead to an explosion in your storage requirements (e.g., if\\nyou have 1-minute counters, your hourly count will be more accurate than if you had\\n10-minute counters).\\n244 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 262}, page_content='4 Michael Noll gives a good implementation of a rolling counter algorithm in his blog.\\nAfter you have rolling counters,4 you can begin counting account creation attempts\\nby any number of different keys, at one or more granularities of time. Key types that\\nyou might want to count on include the following:\\n• IP address or IP subnet\\n• Geolocation features (city, country, etc.)\\n• Browser type or version\\n• Operating system and version\\n• Success/failure of account creation\\n• Features of the account username (e.g., substrings of email address or phone\\nnumber)\\n• Landing page in the account creation flow (e.g., mobile versus desktop)\\n• API endpoint used\\n• Any other property of the registration request\\nYou can also cross features: for example, successful desktop registrations per IP\\naddress. The only limits are your imagination and the allowable write throughput of\\nyour counter system.\\nNow that you’ve implemented counters, you can compute velocity features. Simple\\nvelocities are straightforward: just retrieve the counts from a certain number of buck‐\\nets, sum them up, and divide by the number of buckets (perhaps with a conversion to\\nyour preferred unit). If you have a global rate limit on any feature, it’s easy to check,\\non any request, whether the current rate is above your limit.\\nOf course, global rates can go only so far. Most likely you have a small fraction of\\nusers on Linux and a much larger fraction on macOS. If you had a global limit on\\naccounts created per OS per hour, this limit would need to be large enough to accom‐\\nmodate the macOS registrations, and a spike in the number of accounts created from\\nLinux would go unnoticed.\\nTo get around this problem, you can use historical data to detect unusual numbers of\\nrequests on any key. The rolling counter itself provides some historical data—for\\nexample, if you have counts of requests per hour for the past 24 hours, you can com‐\\npute the quantity as follows:\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n245'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 263}, page_content='Equation 6-1. Computing recent spikes\\n# requests from now to k hours ago\\n# requests from k hours ago to 24 hours ago + 1\\nk\\n24\\nThis formula gives you a “spike magnitude” of the past k hours compared with the\\nprevious 24 – k hours. (The +1 in the denominator is smoothing that prevents divi‐\\nsion by zero.) To find a reasonable threshold you should log or simulate the rolling\\ncounters on historical data and determine at what level you can safely block requests.\\nUsing recent data to detect spikes will work only if there is enough of it. A more\\nrobust measurement will use historical data, computed from offline logs or long-term\\npersistent counters, to establish a baseline of activity per key, per day, and then use a\\nformula analogous to Equation 6-1 to determine when a quantity spikes. You must\\nstill take care to handle unseen or rare keys; smoothing the counts (as discussed in\\n“Features used to classify login attempts” on page 239) can help here.\\nDetecting spikes is an example of a more general principle: velocities can be very\\neffective when combined into ratios. Spike detection on a single key uses the ratio of\\nrecent requests to older requests. But any of the following ratios should have a “typi‐\\ncal” value:\\n• Ratio of success to failure on login or registration (failure spikes are suspicious)\\n• Ratio of API requests to page requests (the API being hit without a correspond‐\\ning page request suggests automation, at least when the user agent claims to be a\\nbrowser)\\n• Ratio of mobile requests to desktop requests\\n• Ratio of errors (i.e., 4xx response codes) to successful requests (200 response\\ncode)\\nYou can use rolling counters to compute these ratios in real time and therefore incor‐\\nporate them as features in your classifier.\\nReputation scores\\nVelocity features are good at catching high-volume attacks, but what if the attacker\\nslows down and/or diversifies their keys to the point where the requests are coming\\nin below the threshold for any given key? How can we make a decision on a single\\nrequest?\\nThe foundation here is the concept of reputation. Reputation quantifies the knowl‐\\nedge we have about a given key (e.g., IP address) either from our own data or from\\n246 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 264}, page_content='third parties, and gives us a starting point (or more formally, a prior) for assessing\\nwhether a request from this key is legitimate.\\nLet’s look at the example of IP address. The simplest reputation signal for a registra‐\\ntion defense model is the fraction of accounts on that IP that have been previously\\nlabeled as bad. A more sophisticated system might capture other measures of “bad‐\\nness”: how many account takeover attempts have been seen from the IP, or how much\\nspam has been sent from it. If these labels are not readily available, you can use prox‐\\nies for reputation:\\n• How long ago was the IP first seen? (Older is better.)\\n• How many legitimate accounts are on the IP?\\n• How much revenue comes in from the IP?\\n• How consistent is traffic on the IP? (Spikes are suspicious.)\\n• What’s the ratio of reads to writes on the IP? (More writes = more spam.)\\n• How popular is the IP (as a fraction of all requests)?\\nIn addition to data you collect, there is a great deal of external data that can go into\\nyour reputation system, especially with regard to IP addresses and user agents. You\\ncan subscribe to a database that will inform you as to whether any given IP address\\nbelongs to a hosting provider, is a VPN or anonymous proxy, is a Tor exit node, and\\nso on. Furthermore, there are a number of vendors who monitor large swaths of\\ninternet traffic and compile and sell IP blacklist feeds; these vendors typically will\\nprovide a free data sample so that you can evaluate whether their labels overlap with\\nthe abuse you see on your site.\\nWith regard to user agents, there are published lists of known bot user agents and\\nweb scripting packages. For example, requests from curl, wget, or python-requests\\nshould be treated with extra suspicion. Similarly, if a request advertises itself as Goo‐\\nglebot, it is either the real Googlebot or someone pretending to be Googlebot in the\\nhopes that your thirst for search engine optimization will result in you letting them\\nthrough—but the real Googlebot is not likely to be creating any accounts!\\nNow let’s consider how to combine all of these features into a reputation score, again\\nusing IP address as an example. One question we could answer with such a score is,\\n“What is the probability that this IP address will be used for abuse in the future?” To\\ncast this question as a supervised learning problem we need labels. Your choice of\\nlabels will depend on exactly what you want to defend against, but let’s say for sim‐\\nplicity that an IP address is bad if a fake account is created on it in a period of n days.\\nOur supervised learning problem is now as follows: given the past m days of data for\\nan IP, predict whether there will be a fake account created on it in the next n days.\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n247'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 265}, page_content='To train our supervised classifier, we compute features (starting with those described\\npreviously) for each IP for a period of m days and labels for the n days immediately\\nfollowing. Certain features are properties of the IP, such as “is hosting provider.” Oth‐\\ners are time based, such as “number of legitimate accounts on the IP.” That is to say,\\nwe could compute the number of accounts over the entire n days, or for each of the n\\ndays, or something in between. If there is enough data, we could compute n features,\\none for each day, in order to capture trends; this aspect will require some experimen‐\\ntation.\\nIf you are planning on retraining regularly (e.g., daily), validation on a held-out test\\nset (i.e., a random subset of your data excluded from training) is probably sufficient.\\nIf retraining is sporadic (e.g., less often than every n days), you will want to be sure\\nthat your model is sufficiently predictive, so you should validate your model on the\\nnext n days of your training samples, as demonstrated in Figure 6-1.\\nFigure 6-1. Out-of-time training and validation\\nA final word on reputation: we have for the most part used IP address in this section\\nas our example. However, everything we wrote applies to any of the keys listed in the\\nsection “Velocity features” on page 244 earlier in the chapter. The only limits to you\\ncreating reputation systems for countries, browsers, domains, or anything else are the\\namount of data you have and your creativity.\\nFinancial Fraud\\nIf attackers can obtain your product at no cost, they can resell it for less than your\\nprice and make money. This problem applies not only to physical goods that have a\\nlarge secondhand market (e.g., electronics), but also to services that can be arbitraged\\nin a competitive market (e.g., ride hailing). If your audience is large enough, there\\nwill be some people who try to steal your product regardless of what it is. To stop\\nthese people, you need to determine whether each purchase on your site is legitimate.\\nThe vast majority of financial fraud is conducted using stolen credit cards. Credit\\ncard fraud is older than the internet, and an enormous amount of work has been\\ndone to understand and prevent it. A single credit card transaction passes through\\nmany different entities as it is processed:\\n248 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 266}, page_content='1. The merchant (you)\\n2. A payment processor\\n3. The merchant’s bank\\n4. The card network (Visa/Mastercard/American Express/Discover), which routes\\ninter-bank transactions\\n5. The card issuer’s bank\\nEach of these entities has fraud detection mechanisms in place, and can charge\\nupstream entities for fraudulent transactions that make it to them. Thus, the cost of\\nfraud to you is not just the loss of your product or service, but also fees assessed at\\ndifferent levels of the ecosystem. In extreme cases, the damage to your business’s\\ncredit and reputation may cause some banks or networks to levy heavy fines or even\\nrefuse to do business with you.\\nOf course, credit cards are not the only payment method you might accept on your\\nsite. Direct debit is a popular method in Europe, where credit cards are more difficult\\nto get than in the United States. Many sites accept online payment services such as\\nPayPal, Apple Pay, or Android Pay; in these cases, you will have account data rather\\nthan credit card and bank data. However, the principles of fraud detection are essen‐\\ntially the same across all payment types.\\nAlthough many companies offer fraud detection as a service, you might decide that\\nyou want to do your own fraud detection. Perhaps you can’t send sensitive data to a\\nthird party. Perhaps your product has an unusual payment pattern. Or perhaps you\\nhave calculated that it’s more cost effective to build fraud detection yourself. In any\\ncase, after you have made this decision, you will need to collect features that are indi‐\\ncative of fraud. Some of these include:\\n• Spending profiles of customers:\\n— How many standard deviations from the customer’s average purchase a given\\ntransaction is\\n— Velocity of credit card purchases\\n— Prevalence of the current product or product category in the customer’s\\nhistory\\n— Whether this is a first purchase (e.g., a free user suddenly begins making lots\\nof purchases)\\n— Whether this payment method/card type is typical for the customer\\n— How recently this payment method was added to the account\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n249'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 267}, page_content='• Geographical/time-dependency correlation:\\n— All the correlation signals for authentication (e.g., geographic displacement,\\nIP/browser history)\\n— Geographic velocity (e.g., if a physical credit card transaction was made in\\nLondon at 8:45 PM and in New York at 9:00 PM on the same day, the user’s\\nvelocity is abnormally high)\\n• Data mismatch:\\n— Whether the credit card billing address matches the user’s profile information\\nat the city/state/country level\\n— Mismatch between billing and shipping addresses\\n— Whether the credit card’s bank is in the same country as the user\\n• Account profile:\\n— Age of the user’s account\\n— Reputation from account creation scoring (as just discussed)\\n• Customer interaction statistics:\\n— Number of times the customer goes through the payment flow\\n— Number of credit cards tried\\n— How many times a given card is tried\\n— Number of orders per billing or shipping address\\nIf you want to train a supervised fraud detection algorithm, or, even more basically, if\\nyou want to be able to know how well you’re doing at catching fraud, you will need\\nlabeled data. The “gold standard” for labeled data is chargebacks—purchases declared\\nby the card owner to be fraudulent and rescinded by the bank. However, it usually\\ntakes at least one month for a chargeback to complete, and it can even take up to six\\nmonths in many cases. As a result, chargebacks cannot be used for short-term metrics\\nor to understand how an adversary is adapting to recent changes. Thus, if you want to\\nmeasure and iterate quickly on your fraud models, you will need a supplementary\\nmetric. This could include any of the following:\\n• Customer reports of fraud\\n• Customer refunds\\n• Purchases made by fake or compromised accounts\\nFinally, when building your system, it is important to think carefully about where in\\nthe payment flow you want to integrate. As with other abuse problems, if you wait\\n250 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 268}, page_content='5 This equivalence breaks down if you allow or encourage automated activity; for example, if you have APIs\\nthat can be regularly polled for data.\\nlonger you can collect more data to make a more informed decision but risk more\\ndamage. Here are some possible integration points:\\nPreauthorization\\nYou might want to run at least a minimal scoring before sending any data to the\\ncredit card company; if too many cards are declined, you might accrue fines. Fur‐\\nthermore, preauthorization checks prevent attackers from using your site as a test\\nbed to determine which of their stolen cards work.\\nPost-authorization, prepurchase\\nThis is a typical place to run fraud scoring because it allows you to ignore cards\\nthat are declined by the bank and to avoid chargebacks, given that you won’t take\\nfunds for fraudulent purchases. If your site is set up with auth/capture function‐\\nality, you can let the customer proceed as if the purchase were going through,\\nand collect more data to do further scoring before actually receiving the funds.\\nPost-purchase\\nIf you have a physical good that takes some time to prepare for shipping, or if\\nyou have a virtual service that cannot effect much damage in a short time, you\\ncan let the purchase go through and collect more behavioral signals before mak‐\\ning a decision on the purchase and cancelling/refunding transactions deemed to\\nbe fraudulent. By scoring post-purchase, however, you are exposing yourself to\\nchargebacks in the case that the real owner quickly discovers the fraud.\\nBot Activity\\nIn some cases, attackers can glean a great deal of value from a single victim. A bank\\naccount is an obvious example, but any account that can hold tradable assets is a tar‐\\nget; these include ride- or house-sharing accounts, rewards accounts, or ad publish‐\\ning accounts. For these high-value accounts it makes sense for attackers to work\\nmanually to avoid detection. On the other hand, in many cases the expected value of\\na single victim is very small, and is in fact less than the cost of the human effort\\nrequired to access or use the account; examples include spamming, credential stuff‐\\ning, and data scraping. In these cases, attackers must use automation if they hope to\\nmake a profit. Even in the higher-value cases, human effort can scale only so far, and\\nautomation is likely to provide higher return on investment for attackers.\\nIt follows that finding abuse in many cases is equivalent to finding automated activity\\n(aka bots) on your site or app.5 Bots might try to take any of a number of actions,\\nincluding the following:\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n251'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 269}, page_content='Account creation\\nThis was discussed in depth earlier. These bots can be stopped before or after\\naccount creation.\\nCredential stuing\\nRunning leaked lists of username/password pairs against your login infrastruc‐\\nture to try to compromise accounts. These bots should be stopped before they\\ngain access to the account, ideally without leaking information about whether the\\ncredentials are valid.\\nScraping\\nDownloading your site’s data for arbitrage or other illicit use. Scraping bots must\\nbe stopped before they are served any data, so detection must be synchronous\\nand very fast in order to avoid a big latency hit for legitimate users.\\nClick fraud\\nInflating click counts to bring extra revenue to a site that hosts advertisements, or\\nusing artificial clicks to deplete a competitor’s ad budget. The minimal require‐\\nment here is that advertisers not be billed for fraudulent clicks; this computation\\ncould be in real time or as slow as a monthly or quarterly billing cycle. However,\\nif recent click data is used to determine current ad ranking, fraudulent clicks\\nmust be handled in near real time (though asynchronously).\\nRanking fraud\\nArtificially increasing views, likes, or shares in order to make content reach a\\nwider audience. These fraudulent actions must be discounted soon after they\\noccur.\\nOnline gaming\\nBots can simulate activity that would be tedious or expensive for humans to take,\\nsuch as moving large distances geographically (via spoofed GPS signals) or earn‐\\ning points or other gaming currency via repetitive actions (e.g., battling the same\\nenemy over and over to gain a huge number of experience points).\\nAs with financial fraud, there are entire companies devoted to detecting and stopping\\nbot activity; we give some pointers here for detecting and stopping basic bot attacks.\\nBots come in a wide variety of levels of sophistication and with a wide variety of\\nintents. Many bots are even legitimate: think of search engine crawlers such as\\nGooglebot or Bingbot. These bots will typically advertise themselves as such and will\\nalso honor a robots.txt file you place on your site indicating paths that are off-limits to\\nbots.\\nThe dumbest bots are those that advertise themselves as such in their user agent\\nstring. These include tools such as curl and wget, frameworks such as python-\\nrequests, or scripts pretending to be legitimate crawlers such as Googlebot. (The last\\n252 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 270}, page_content='can be distinguished by the fact that they don’t come from a legitimate crawling IP\\naddress.)\\nAfter you have eliminated the dumb bots, the key to detecting further automated\\nactivity is aggregation—can you group together requests that come from the same\\nentity? If you require users to be logged in to engage in whatever activity the bots are\\ntrying to automate, you will already have a user ID upon which you can aggregate. If\\na user ID is not available, or if you want to aggregate across multiple users, you can\\nlook at one or more of IP addresses, referrers, user agents, mobile app IDs, or other\\ndimensions.\\nNow let’s assume that you have aggregated requests that you believe to be from a sin‐\\ngle entity. How do you determine whether the activity is automated? The key idea\\nhere is that the pattern of requests from bots will be different from the patterns\\ndemonstrated by humans. Specific quantitative signals include the following:\\nVelocity of requests\\nBots will make requests at a faster rate than humans.\\nRegularity of requests, as measured by variance in time between requests\\nBots will make requests at more regular intervals than humans. Even if the bot\\noperator injects randomness into the request time, the distribution of interarrival\\ntimes will still be distinguishable from that of humans.\\nEntropy of paths/pages requested\\nBots will focus on their targets instead of browsing different parts of the site.\\nScraping bots will request each page exactly once, whereas real users will revisit\\npopular pages.\\nRepetitive patterns in requests\\nA bot might repeatedly request page A, then B, then C, in order to automate a\\nflow.\\nUnusual transitions\\nFor example, a bot might post to a content generation endpoint without loading\\nthe page containing the submission form.\\nDiversity of headers\\nBots might rotate IP addresses, user agents, referrers, and other client-site head‐\\ners in order to seem like humans, but the distribution generated by the bot is\\nunlikely to reflect the typical distribution across your site. For example, a bot user\\nmight make exactly the same number of requests from each of several user\\nagents.\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n253'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 271}, page_content='6 Grégoire Jacob et al., “PUBCRAWL: Protecting Users and Businesses from CRAWLers,” Proceedings of the\\n21st USENIX Security Symposium (2012).\\n7 Gang Wang et al., “You Are How You Click: Clickstream Analysis for Sybil Detection,” Proceedings of the 22nd\\nUSENIX Security Symposium (2013): 241–255.\\n8 Elie Bursztein et al., “Picasso: Lightweight Device Class Fingerprinting for Web Clients,” Proceedings of the 6th\\nWorkshop on Security and Privacy in Smartphones and Mobile Devices (2016): 93–102.\\nDiversity of cookies\\nA typical website sets a session cookie and can set other cookies depending on\\nthe flow. Bots might ignore some or all of these set-cookie requests, leading to\\nunusual diversity of cookies.\\nDistribution of response codes\\nA high number of errors, especially 403 or 404, could indicate bot requests whose\\nscripts are based on an older version of the site.\\nSeveral bot detection systems in the literature make use of some or all of these signals.\\nFor example, the PubCrawl system6 incorporates clustering and time series analysis of\\nrequests to detect distributed crawlers, whereas the algorithm of Wang et al.7 clusters\\nsequences of requests based on a similarity metric.\\nSometimes, you will not be able to aggregate requests on user ID or any other key—\\nthat is, you have no reliable way to determine whether any two requests come from\\nthe same actor. This could happen, for example, if the endpoint you want to protect is\\navailable to the public without a login, or if many different accounts act in loose coor‐\\ndination during an attack. In these cases, you will need to use request-based bot detec‐\\ntion; that is, determine whether a request is automated using only data from the\\nrequest itself, without any counters or time series data.\\nUseful data you can collect from the request includes the following:\\n• The client’s ability to run JavaScript. There are various techniques to assess Java‐\\nScript ability, from simple redirects to complex challenge–response flows; these\\ndiffer in latency introduced as well as complexity of bots they can detect.\\n• An HTML5 canvas fingerprint, which can be used to determine whether the user\\nagent is being spoofed.8\\n• Order, casing, and spelling of request headers, which can be compared with legit‐\\nimate requests from the claimed user agent.\\n• The TLS fingerprint, which can be used to identify particular clients.\\n• Spelling and casing of values in HTTP request fields with a finite number of pos‐\\nsibilities (e.g., Accept-Encoding, Content-Type)—scripts might contain a typo or\\nuse unusual values.\\n254 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 272}, page_content='9 For example, the crawler-user-agents repository.\\n• Mobile hardware data (e.g., microphone, accelerometer), which can be used to\\nconfirm that a claimed mobile request is coming from an actual mobile device.\\n• IP address and browser/device info, which you can use to look up precomputed\\nreputation scores.\\nWhen implementing request-based detection, we encounter the typical trade-off\\nbetween preventing abuse and increasing friction for good users. If you give each\\nrequest an interactive CAPTCHA, you will stop the vast majority of bots but will also\\nannoy many of your good users into leaving. As a less extreme example, running\\nJavaScript to collect browser or other information can introduce unacceptable latency\\nin page load times. Ultimately, only you can determine your users’ tolerance for your\\ndata-collection processes.\\nLabeling and metrics\\nLabeling bot requests in order to compute metrics or train supervised models is a dif‐\\nficult endeavor. Unlike spam, which can be given to a human to evaluate, there is no\\nreasonable way to present an individual request to a reviewer and have that person\\nlabel the request as bot or not. We thus must consider some alternatives.\\nThe first set of bot labels you should use is bots that advertise themselves as such in\\ntheir User-Agent header. Both open source9 and proprietary lists are available, and\\ncharacteristics of these bots will still hold for more sophisticated bots.\\nIf your bots are engaging in automated writes (e.g., spam, shares, clicks), you have\\nprobably already received complaints and the bot-produced data has been taken\\ndown. The takedown dataset can provide a good seed for training models or cluster‐\\ning; you can also look at fake accounts with a sufficiently large number of writes.\\nIf your bots are engaging in automated reads (e.g., scraping), you might again be able\\nto identify specific high-volume incidents; for example, from a given IP address or\\nuser agent on a given day. As long as you exclude the feature used to identify a partic‐\\nular event, you can use the rest of the data to train models.\\nThis last point applies more broadly: you should never measure bot activity using the\\nsame signal you use to prevent it. As a naive example, if you counted all the self-\\nidentified bots as bad and then blocked them, you wouldn’t really be solving your bot\\nproblem, even though your bot metric would go to zero—you would just be forcing\\nbots to become more sophisticated.\\nOn the flip side, your measurement flow can be as complex as you are willing to make\\nit because it doesn’t need to conform to the demands of a production environment.\\nTypes of Abuse and the Data That Can Stop Them \\n| \\n255'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 273}, page_content='Thus, you can compute additional aggregates or take asynchronous browser signals\\nthat would be too costly to implement in your online defense mechanism, and use\\nthese to measure your progress against bots. In the extreme, you can train a super‐\\nvised model for measurement, as long as its features are uncorrelated with those that\\nyou use for your detection model.\\nOne final note: it might be that you don’t actually care about the automated activity\\nundertaken by bots, but you do care about the pageviews and other statistics they\\ngenerate. This problem of metrics pollution is a common one; because a majority of all\\ninternet traffic is bots, chances are that your usage metrics will look very different if\\nyou exclude bots. You can solve the metrics pollution problem by using the same\\nmethods as online bot detection and, in particular, using aggregation-based and/or\\nrequest-based scoring. Even better, the solution doesn’t need to be implemented in a\\nreal-time production environment, because the outcome of this bot detection is only\\nto change reported metrics. Thus, latency requirements are much more relaxed or\\neven nonexistent (e.g., if using Hadoop), and you can use more data and/or perform\\nmore expensive computations without jeopardizing the result.\\nSupervised Learning for Abuse Problems\\nAfter you have computed velocity features and reputation scores across many differ‐\\nent keys, you are ready to build your account creation classifier! First, find a set of\\nlabeled good and bad account creation requests, and then compute the features for\\neach request in the set, split into train/test/validate, and apply any of the supervised\\nalgorithms of Chapter 2. Simple, right?\\nWell, not so fast. There are some subtleties that you will need to address in order to\\nachieve good performance. We will use the account creation classifier as an example,\\nbut these considerations apply to any classifier you build when using adversarial data.\\nLabeling Data\\nIn the ideal case, you will have a large set of data that was sampled for this particular\\nproject and manually labeled. If this is the case for your site or app, great! In real life,\\nhowever, hand-labeled data usually isn’t presented to you on a platter. Even if you can\\nget some, it might not be enough to train a robust classifier.\\nAt the other extreme, suppose that you are unable to sample and label any data at all.\\nIs supervised learning useless? Probably not—you must have some accounts that you\\nhave already banned from the site for fraud or spam; if this is not the case, your prob‐\\nlem probably isn’t big enough to justify engineering a large-scale machine learning\\nclassifier. The already banned accounts might have been categorized that way through\\na rules-based system, other machine learning models, or manual intervention due to\\n256 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 274}, page_content='10 We will call bad requests “positive” and good requests “negative.” Whether to label bad requests as 0 or 1 is left\\nto you—just be consistent!\\n11 For details, see Burr Settles, “Active Learning Literature Survey,” Computer Sciences Technical Report 1648,\\nUniversity of Wisconsin–Madison (2010).\\nuser complaints. In any case, you can use these accounts as your positive (i.e., bad)\\nexamples,10 and you can use all accounts not (yet) banned as your negative examples.\\nWhat risks does this approach entail? One risk is blindness: your model learns only\\nwhat you already know about the accounts on your system. Without manual labeling,\\nretraining won’t help the model identify new types of abuse, and you will need to\\nbuild yet another model or add rules to take care of new attacks.\\nAnother risk is feedback loops—your model learning from itself and amplifying\\nerrors. For example, suppose that you erroneously banned some accounts from\\nLiechtenstein. Your model will then learn that accounts from Liechtenstein are pre‐\\ndisposed to be abusive and block them proportionately often. If the model retrains\\nregularly and the false positives are not remediated, this feedback loop could eventu‐\\nally lead to all accounts from Liechtenstein being banned.\\nThere are some steps that you can take to mitigate risk when using imperfectly\\nlabeled data:\\n• Oversample manually labeled examples in your training data.\\n• Oversample false positives from this model when retraining (as in boosting).\\n• Undersample positive examples from previous iterations of this model (or closely\\nrelated models/rules).\\n• If you have resources to sample and manually label some accounts, use them to\\nadjudicate cases near the decision boundary of your model (as in active\\nlearning11).\\nOne final warning when you are training on imperfect data: don’t take too literally the\\nprecision and recall numbers that come out of your validation step. If your model\\ndoes a reasonable job of generalizing from the data you have, it will find errors in\\nyour labeled set. These will be “false positives” and “false negatives” according to your\\nlabels, but in real life they are instances your classifier got correct. Thus, you should\\nexpect the precision when your model is deployed to be higher than that which you\\nobtain in offline experiments. Quantifying this effect can be done only through\\nonline experimentation.\\nSupervised Learning for Abuse Problems \\n| \\n257'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 275}, page_content='Cold Start Versus Warm Start\\nIf you have no scoring at account creation (“cold start”), model training is straightfor‐\\nward: use whatever labels you have to build the model. On the other hand, if there is\\nalready a model running at account creation time and blocking some requests\\n(“warm start”), the only bad accounts that are created are the ones that get through\\nthe existing model (i.e., the false negatives). If you train v2 of your model on only this\\ndata, v2 might “forget” the characteristics of v1.\\nTo illustrate this conundrum with an example, suppose v1 blocks all requests with IP\\nvelocity greater than five per day. Then, the IP velocity of bad accounts used to train\\nthe v2 model will be very low, and this feature will probably not be significant in the\\nv2 model. As a result, if you deploy v2, you run the risk of allowing high-velocity\\nrequests per IP.\\nThere are a few different approaches to avoid this problem:\\nNever throw away training data\\nCollect your data for the v2 model after v1 is deployed, and train on the union of\\nv1 and v2 training data. (If you are facing fast-changing adversaries, consider\\napplying an exponential decay model to weight more recent attacks higher.)\\nRun simultaneous models\\nTrain and deploy the v2 model, but also run the v1 model at the same time. Most\\nlikely the reason you were building v2 in the first place is that the performance of\\nv1 is degrading; in this case you should tune the threshold of v1 to make it more\\naccurate. This approach can lead to an explosion in complexity as you deploy\\nmore and more models.\\nSample positives from the deployed v1 model to augment the v2 training data\\nThe advantage of this approach is that all the training data is recent; the disad‐\\nvantage is that it’s difficult to know what the v1 false positives are (see the follow‐\\ning section).\\nFalse Positives and False Negatives\\nIn theory, false negatives are easy to identify—these are accounts that your model said\\nwere good that you allowed to register but ended up being bad. But in practice, you\\ncan identify false negatives in your model only if they trigger some other model or\\nrule, or prompt user complaints. There will always be bad accounts that get through\\nundetected and are therefore mislabeled. If you have the resources to sample and\\nlabel examples, you will get the most leverage by sampling accounts with scores near\\nyour classification threshold; these are the examples about which your model is most\\nuncertain.\\n258 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 276}, page_content='False positives are also tricky. You blocked them by using the best information you\\nhad at the time, and that’s it—you get no more information with which to refine your\\ndecision. Even worse, a false positive at account creation means you blocked a new\\nuser that didn’t already have an established relationship with your site. Such a user\\nwill most likely give up rather than complain to your support team.\\nOne way to deal with the false positive problem is to let a small fraction of requests\\nscored as bad create accounts anyway, and monitor them for further bad activity. This\\napproach is imperfect because an attacker who gets only five percent of their registra‐\\ntions through might just give up on spamming because it doesn’t scale—your testing\\napproach led the adversary to change their behavior, and thus your test results might\\nbe inconclusive. (This problem exists when A/B testing adversarial models in gen‐\\neral.) You should also monitor such accounts for good activity to find “true false\\npositives.”\\nIdentified false positives and false negatives can be oversampled in your training data\\nwhen you retrain the model using one of the techniques of the previous section.\\nMultiple Responses\\nTypically, an account creation model will have multiple thresholds: block if the score\\nis super bad, let the request through if the score is reasonably good, and present a\\nchallenge (e.g., CAPTCHA or phone verification) to the “gray area” scores. This\\napproach can complicate performance measurement and labeling for retraining: is a\\nbad account that solved a challenge a true positive or a false negative? What about a\\ngood account that received a challenge? Ideally each case can receive a certain cost in\\nyour global cost function; if you’re not using a cost function, you will need to decide\\nwhat your positives and negatives are.\\nLarge Attacks\\nIn either the cold-start scenario or the “sample positives” approach to the warm-start\\nproblem, the following can occur: there was a single unsophisticated attacker who\\nmade so many requests from a single IP that this one attacker was responsible for half\\nthe bad requests in the training data. If you simply train on the distribution as is, your\\nmodel will learn that half of all attacks look like this one—the model will be overfit to\\nthis single event, simply because it was so large (and in the warm-start case, it was\\neven defended).\\nOne approach to solving this problem is to downsample large attacks; for example,\\nfrom an attack with x requests you might sample log(x) requests for the training data.\\nThen, this attack appears large but not overwhelming.\\nThis approach begs the question: how do you identify attacks from a single actor?\\nWe’re glad you asked—this topic is the focus of our next section.\\nSupervised Learning for Abuse Problems \\n| \\n259'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 277}, page_content='12 “No resource should be infinite” is a good principle here. In practice, this means that there should be global\\nbackstops on all types of activity per account—logins, messages, transactions, and even pageviews.\\nClustering Abuse\\nAlthough a single account takeover can be devastating to the victim, a single fake\\naccount is much less likely to wreak widespread havoc, especially if the amount of\\nactivity a single account can do is limited.12 Thus, to scale their fraud, attackers must\\ncreate many accounts. Similarly, because the expected value of a single spam message\\nis low, bad guys must send thousands or even millions of messages in order to get a\\nreasonable payoff. The same argument applies to nearly any type of fraud: it only\\nworks if the attacker can execute a large amount of the fraudulent actions in a reason‐\\nably short time span.\\nFraudulent activity on a site thus differs from legitimate activity in the crucial sense\\nthat it is coordinated between accounts. The more sophisticated fraudsters will try to\\ndisguise their traffic as being legitimate by varying properties of the request, for\\nexample by coming from many different IP addresses scattered around the world. But\\nthey can only vary things so much; there is almost always some property or proper‐\\nties of the fraudulent requests that are “too similar” to one another.\\nThe algorithmic approach to implementing this intuition is clustering: identifying\\ngroups of entities that are similar to one another in some mathematical sense. But\\nmerely separating your accounts or events into groups is not sufficient for fraud\\ndetection—you also need to determine whether each cluster is legitimate or abusive.\\nFinally, you should examine the abusive clusters for false positives—accounts that\\naccidentally were caught in your net.\\nThe clustering process is thus as follows:\\n1. Group your accounts or activity into clusters.\\n2. Determine whether each cluster, as a whole, is legitimate or abusive.\\n3. Within each abusive cluster, find and exclude any legitimate accounts or activity.\\nFor step 1, there are many possible clustering methods, a few of which we explore\\nshortly. Step 2 is a classification step, and thus can be tackled by either supervised or\\nunsupervised techniques, depending on whether you have labeled data. We will not\\nconsider step 3 in detail here; one solution is to apply clustering steps 1 and 2\\nrecursively.\\nNote that there are two important parameter choices that will be highly domain\\ndependent:\\n260 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 278}, page_content='• How large does a cluster need to be to be significant? Most legitimate activity,\\nand some fraudulent activity, will not be coordinated, so you will need to remove\\ndata that doesn’t cluster into a large enough group.\\n• How “bad” does a cluster need to be to be labeled abusive? This is mostly signifi‐\\ncant for the supervised case, in which your algorithm will learn about clusters as\\na whole. In some cases, a single bad entity in a cluster is enough to “taint” the\\nentire cluster. One example is profile photos on a social network; nearly any\\naccount sharing a photo with a bad account will also be bad. In other cases, you\\nwill want a large majority of the activity in the cluster to be bad; an example is\\ngroups of IP addresses where you want to be certain that most of the IPs are serv‐\\ning malicious traffic before labeling the entire cluster as bad.\\nExample: Clustering Spam Domains\\nTo demonstrate both the cluster generation and cluster scoring steps, we will work\\nwith a labeled dataset of internet domain names. The good names are the top 500,000\\nAlexa sites from May 2014, and the bad names are 13,788 “toxic domains” from stop‐\\nforumspam.org. The fraction of positive (i.e., spam) examples in the dataset is 2.7%,\\nwhich is reasonable in terms of order of magnitude for the abuse problems with\\nwhich you will typically contend.\\nThe domain data is not account or activity data, but it does have the property that we\\ncan find clusters of reasonable size. For example, a quick scan of the bad domains in\\nalphabetical order reveals the following clusters of a size of at least 10:\\naewh.info, aewn.info, aewy.info, aexa.info, aexd.info, aexf.info, aexg.info, aexw.info, aexy.info, aeyq.info, aezl.info\\nairjordanoutletcenter.us, airjordanoutletclub.us, airjordanoutletdesign.us, airjordanoutletgroup.us, airjordanoutlethomes.us,\\nairjordanoutletinc.us, airjordanoutletmall.us, airjordanoutletonline.us, airjordanoutletshop.us, airjordanoutletsite.us,\\nairjordanoutletstore.us\\nbhaappy0faiili.ru, bhaappy1loadzzz.ru, bhappy0sagruz.ru, bhappy1fajli.ru, bhappy2loaadz.ru, bhappy3zagruz.ru,\\nbhapy1file.ru, bhapy2iilie.ru, bhapy3fajli.ru\\nfae412wdjjklpp.com, fae42wsdf.com, fae45223wed23.com, fae4523edf.com, fae452we334fvbmaa.com, fae4dew2vb.com,\\nfaea2223dddfvb.com, faea22wsb.com, faea2wsxv.com, faeaswwdf.com\\nmbtshoes32.com, mbtshoesbetter.com, mbtshoesclear.com, mbtshoesclearancehq.com, mbtshoesdepot.co.uk,\\nmbtshoesinder.com, mbtshoeslive.com, mbtshoesmallhq.com, mbtshoeson-deal.com, mbtshoesondeal.co.uk\\ntomshoesonlinestore.com, tomshoesoutletonline.net, tomshoesoutletus.com, tomsoutletsalezt.com, tomsoutletw.com,\\ntomsoutletzt.com, tomsshoeoutletzt.com, tomsshoesonline4.com, tomsshoesonsale4.com, tomsshoesonsale7.com,\\ntomsshoesoutlet2u.com\\nyahaoo.co.uk, yahho.jino.ru, yaho.co.uk, yaho.com, yahobi.com, yahoo.co.au, yahoo.cu.uk, yahoo.us, yahooi.aol, yahoon.com,\\nyahooo.com, yahooo.com.mx, yahooz.com\\n(Apparently selling knockoff shoes is a favorite pastime of spammers.)\\nClustering Abuse \\n| \\n261'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 279}, page_content='Good domains also can appear in clusters, typically around international variants:\\ngigabyte.com, gigabyte.com.au], gigabyte.com.cn, gigabyte.com.mx, gigabyte.com.tr, gigabyte.com.tw, gigabyte.de,\\ngigabyte.eu, gigabyte.fr, gigabyte.in, gigabyte.jp\\nhollywoodhairstyle.org, hollywoodhalfmarathon.com, hollywoodhereiam.com, hollywoodhiccups.com,\\nhollywoodhomestead.com, hollywoodid.com, hollywoodilluminati.com, hollywoodlife.com, hollywoodmegastore.com,\\nhollywoodmoviehd.com, hollywoodnews.com\\npokerstars.com, pokerstars.cz, pokerstars.dk, pokerstars.es, pokerstars.eu, pokerstars.fr, pokerstars.gr, pokerstars.it,\\npokerstars.net, pokerstars.pl, pokerstars.pt\\nBecause many domains, both good and bad, do not appear in clusters, the goal of the\\nexperiments that follow will be to maximize recall on the bad domains while main‐\\ntaining high precision. In particular, we will make the following choices:\\n• Clusters must be of size at least 10 in order to be considered.\\n• Clusters must be at least 75% spam in order to be labeled as bad.\\nThese choices will minimize the chances of good domains getting caught up in clus‐\\nters of mostly bad domains.\\nGenerating Clusters\\nLet’s tackle the first step: separating your set of accounts or actions into groups that\\nare similar to one another. We will consider several different techniques and apply\\nthem to the spam dataset.\\nTo cluster, we must generate features for our domains. These features can be categori‐\\ncal, numerical, or text-based (e.g., bag-of-words). For our example, we use the follow‐\\ning features:\\n• Top-level domain (e.g., “.com”)\\n• Percentage of letters, digits, and vowels in the domain name\\n• Age of the domain in days, according to the whois registration date\\n• The bag of words consisting of n-grams of letters in the domain (e.g., “foo.com”\\nbreaks into the 4-grams [“foo.”,“oo.c”,“o.co”,“.com”]) for n between 3 and 8\\nThis technique is often called shingling. The following Python\\ncode computes n-grams for a string:\\ndef ngram_split(text, n):\\n  ngrams = [text] if len(text) < n else []\\n  for i in range(len(text)-n+1):\\n       ngrams.append(text[i:i+n])\\n  return(ngrams)\\n262 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 280}, page_content='13 This is a categorical feature, as opposed to the n-gram feature, which produces lists of unequal length.\\n14 You might wonder how the sum of TP domains and FP domains can be less than 10 times the number of bad\\nclusters if the minimum cluster size is 10; the answer is that some domains can appear in multiple clusters,\\nand we deduplicate when computing the TP/FP stats.\\n• The first n letters of the domain, for n in (3,5,8)13\\nA good clustering method will produce relatively pure clusters (i.e., predominantly\\ngood or bad rather than mixed). In addition, if your data is heavily skewed, as in our\\nexample, the clustering algorithm should rebalance the classes to some extent. The\\nmain intuition behind clustering is that bad things disproportionately happen in\\nbunches, so if you apply a clustering algorithm and get proportionately more good\\nclusters than bad clusters, clustering hasn’t helped you much.\\nWith these principles in mind, when searching for the best clustering strategy, we\\nneed to consider the proportion of clusters that are labeled bad, the proportion of\\ndomains within the bad clusters that are labeled bad, and the recall of the bad clusters.\\nGrouping\\nGrouping best applies to features that can have many distinct values, but aren’t\\nunique for everyone. In our example, we will consider the n-gram features for group‐\\ning. For each value of n from 3 to 8, we grouped domains on every observed n-gram.\\nTable 6-1 shows our results. (Recall that we are using 10 as a minimum cluster size\\nand 75% spam as a threshold to label a cluster bad.)\\nTable 6-1. Results of grouping the spam domains dataset by n-grams, for various values of n\\nn Bad clusters Good clusters Bad cluster % TP domains FP domains Precision\\nRecall\\n3\\n18\\n16,457\\n0.11%\\n456\\n122\\n0.79\\n0.03\\n4\\n95\\n59,954\\n0.16%\\n1,518\\n256\\n0.86\\n0.11\\n5\\n256\\n72,343\\n0.35%\\n2,240\\n648\\n0.78\\n0.16\\n6\\n323\\n52,752\\n0.61%\\n2,176\\n421\\n0.84\\n0.16\\n7\\n322\\n39,390\\n0.81%\\n1,894\\n291\\n0.87\\n0.14\\n8\\n274\\n28,557\\n0.95%\\n1,524\\n178\\n0.90\\n0.11\\nHere, “TP domains” and “FP domains” refer to the number of unique spam and non‐\\nspam domains within the bad clusters.14\\nThese results show that clustering on n-grams is not likely to help in our particular\\ncase, because bad clusters are underrepresented relative to the population of bad\\ndomains (recall that the bad domains are 2.7% of the total). However, the relatively\\nhigh recall (especially for n = 5,6,7) makes it worth investigating whether we can\\nClustering Abuse \\n| \\n263'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 281}, page_content='15 This module contains our implementation of the MinHash algorithm and can be found at https://github.com/\\noreilly-mlsec/book-resources/tree/master/chapter6.\\nbuild a classifier anyway to detect bad clusters; we will consider n = 7 for our upcom‐\\ning evaluation.\\nWe also note that our particular choice of feature for grouping can lead to domains\\nappearing in multiple clusters. In this case, deduplication is essential for computing\\nstatistics; otherwise, you might overestimate precision and recall. If you are grouping\\non a key that is unique for each element, such as login IP address, deduplication is\\nnot a problem.\\nLocality-sensitive hashing\\nAlthough grouping on a single n-gram guarantees a certain amount of similarity\\nbetween different elements of a cluster, we would like to capture a more robust con‐\\ncept of similarity between elements. Locality-sensitive hashing (LSH) can offer such a\\nresult. Recall from Chapter 2 that LSH approximates the Jaccard similarity between\\ntwo sets. If we let the sets in question be the sets of n-grams in a domain name, the\\nJaccard similarity computes the proportion of n-grams the domains have in common,\\nso domains with matching substrings will have high similarity scores. We can form\\nclusters by grouping together domains that have similarity scores above a certain\\nthreshold.\\nThe main parameter to tune in LSH is the similarity threshold we use to form clus‐\\nters. Here we have a classic precision/recall trade-off: high thresholds will result in\\nonly very similar domains being clustered, whereas lower thresholds will result in\\nmore clusters but with less similar elements inside.\\nWe computed clusters using the minHash algorithm (see Chapter 2) on lists of n-\\ngrams. Specifically, the clustering procedure requires computing digests of each set of\\nn-grams, and then for each domain dom, looking up all the domains whose digests\\nmatch the digest of dom in the required number of places:15\\nimport lsh\\ndef compute_hashes(domains, n, num_perms=32, max_items=100,\\nhash_function=lsh.md5hash):\\n    # domains is a dictionary of domain objects, keyed by domain name\\n    # Create LSH index\\n    hashes = lsh.lsh(num_perms, hash_function)\\n    # Compute minHashes\\n    for dom in domains:\\n        dg = hashes.digest(domains[dom].ngrams[n])\\n        domains[dom].digest = dg\\n264 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 282}, page_content='hashes.insert(dom, dg)\\n    return(hashes)\\ndef compute_lsh_clusters(domains, hashes, min_size=10, threshold=0.5):\\n    # domains is a dictionary of domain objects, keyed by domain name\\n    # hashes is an lsh object created by compute_hashes\\n    clusters = []\\n    for dom in domains:\\n        # Get all domains matching the given digest\\n        # result is a dictionary of {domain : score}\\n        result = hashes.query(domains[dom].digest).\\n        result_domains = {domains[d] : result[d] for d in result\\n                if result[d] >= threshold}\\n        if len(result_domains) >= min_size:\\n            # Create a cluster object with the result data\\n            clusters.append(cluster(dom, result_domains))\\n    return(clusters)\\nhashes = compute_hashes(data, n, 32, 100)\\nclusters = compute_lsh_clusters(data, hashes, 10, threshold)\\nTo save memory, we can set up the hashes data structure so that the number of ele‐\\nments that are stored for a given digest is limited.\\nWe ran the algorithm for n ranging from 3 to 7 and similarity thresholds in (0.3, 0.5,\\n0.7). Table 6-2 presents the results.\\nTable 6-2. Results of LSH clustering algorithm applied to the spam domains dataset, for\\nvarious sizes of n-grams and similarity thresholds.\\nt = 0.3\\nt = 0.5\\nt = 0.7\\nn Bad clusters\\nBad %\\nRecall\\nBad clusters\\nBad %\\nRecall Bad clusters\\nBad %\\nRecall\\n3\\n24\\n2.4%\\n0.002\\n0\\n0.0%\\n0.000\\n0\\n0.0%\\n0.000\\n4\\n106\\n1.5%\\n0.013\\n45\\n12.9%\\n0.004\\n0\\n0.0%\\n0.000\\n5\\n262\\n1.8%\\n0.036\\n48\\n4.4%\\n0.004\\n0\\n0.0%\\n0.000\\n6\\n210\\n0.9%\\n0.027\\n61\\n4.0%\\n0.006\\n10\\n16.1%\\n0.002\\n7\\n242\\n1.0%\\n0.030\\n50\\n2.7%\\n0.004\\n38\\n54.3%\\n0.003\\nWe observe that as the similarity threshold increases, the algorithm discovers fewer\\nclusters, but those that are discovered are worse on average.\\nk-means\\nThe first idea that comes into most people’s heads when they think “clustering” is k-\\nmeans. The k-means algorithm is efficient to compute and easy to understand. How‐\\never, it is usually not a good algorithm for detecting abuse. The principal problem is\\nClustering Abuse \\n| \\n265'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 283}, page_content='that k-means requires fixing in advance the number of clusters, k. Because there is no\\na priori means of knowing how many abusive or legitimate clusters you’re looking\\nfor, the best you can do is to set k to be the number of data points divided by the\\nexpected number of points in a bad cluster, and hope that clusters of the right size\\npop out of the algorithm.\\nA second problem is that every item in your dataset is assigned to a cluster. As a\\nresult, if k is too small, items that are not very similar to one another will be artifi‐\\ncially lumped together into clusters. Conversely, if k is too large, you will end up with\\nmany tiny clusters and thus lose the advantage of clustering. If you use grouping or\\nhashing, on the other hand, many items will simply not be clustered with any other\\nitems, and you can focus on the clusters that do exist.\\nA third problem, mentioned in Chapter 2, is that k-means does not work with catego‐\\nrical features, and only sometimes works with binary features. As a result, if you have\\nmany binary or categorical features in your dataset, you might lose much of the dis‐\\ntinguishing power of the algorithm.\\nTo demonstrate these issues, we ran the k-means algorithm on our spam domains\\ndataset, for various values of k. Because we had to remove categorical features, we\\nwere left with only the percentages of letters, numbers, and digits, and the domain\\nregistration date from whois. Table 6-3 shows that, as expected, we found very few\\nabusive clusters using this method.\\nTable 6-3. Results of k-means clustering of the spam domains dataset\\nk = # clusters Bad clusters\\nTP domains\\nFP domains\\nPrecision\\nRecall\\n100\\n0\\n0\\n0\\n—\\n0\\n500\\n0\\n0\\n0\\n—\\n0\\n1,000\\n1\\n155\\n40\\n0.79\\n0.011\\n5,000\\n4\\n125\\n28\\n0.82\\n0.009\\n10,000\\n10\\n275\\n58\\n0.83\\n0.020\\nFurthermore, we observe that increasing k by an order of magnitude doesn’t seem to\\nincrease differentiation between good and bad clusters—the fraction of bad clusters is\\nconsistently around 0.1% for all the values of k we tried.\\nScoring Clusters\\nIn the previous section, we applied several techniques to find clusters of similar\\ndomains in our dataset. However, the act of clustering doesn’t immediately achieve\\nour goal of finding abuse; it simply reorganizes the data in a way that makes abusive\\nentities more likely to “pop out.” The next step is to look at the clusters and determine\\nwhich ones are abusive and which ones are legitimate.\\n266 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 284}, page_content='In general, when clustering abusive entities, your first instinct might be to say that\\nany cluster of a certain size is automatically bad. Rules like this are a good initial step,\\nbut when you have a popular website with a large amount of data, there are sure to be\\nlegitimate outliers, such as these:\\n• Lots of activity on a single IP address? It could be a mobile gateway.\\n• Lots of accounts sharing a tracking cookie? It could be a public computer.\\n• Lots of registrations in quick succession with email addresses in a certain format?\\nIt could be a training session at a school or company where everyone is asked to\\ncreate an account.\\nHow can we distinguish the legitimate clusters from abusive ones? The answer, as\\nusual, is in the data. Specifically, we want to extract cluster-level features that will\\nallow us to distinguish the two types of clusters. Our intuition here is that if a single\\nactor is responsible for creating a cluster, the data within that cluster will probably\\nhave an unusual distribution in some dimension. As a simple example, if we find a\\nbatch of accounts that all have the same name, this batch is suspicious; if the distribu‐\\ntion of names in the cluster roughly follows the distribution of names across the\\nentire site, this batch is less suspicious (at least along the name dimension).\\nIdeally, we would like to treat the cluster scoring stage as a supervised learning prob‐\\nlem. This means that we must acquire cluster-level labels and compute cluster-level\\nfeatures that we can input to a standard classification algorithm such as logistic\\nregression or random forest. We now briefly summarize this process.\\nLabeling\\nIf you have grouped accounts into clusters but have only account-level labels, you\\nneed to develop a procedure that aggregates the account-level labels into labels for the\\nclusters. The simplest method is majority vote: if more accounts in the cluster are bad\\nthan good, the cluster is bad. As a generalization, you can set any threshold t for\\nlabeling and label a cluster as bad if the percentage of bad accounts in the cluster is\\ngreater than t. In our spam domains example, we choose t = 0.75.\\nThere are some situations in which you want to be even more strict and label the\\ncluster as bad as soon as a single member is bad. For example, if you are grouping ads\\nbased on their landing page, if you find a single fraudulent ad that points to a given\\nlanding page, you will probably want to label all ads pointing to that page as fraudu‐\\nlent.\\nFeature extraction\\nAs we did with labels, we need to aggregate account-level features into cluster-level\\nfeatures so that each cluster is represented by a single numerical vector that can be fed\\nClustering Abuse \\n| \\n267'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 285}, page_content='into a classifier. Because our intuition is that abusive clusters will show less diversity\\nalong certain dimensions, we want to compute features that measure this diversity.\\nFor numerical account-level features, we select nine cluster-level features to compute:\\n• Min, max, median, quartiles\\n• Mean and standard deviation\\n• Percentage of null or zero values\\nFor categorical account-level features, we compute four features:\\n• Number of distinct values\\n• Percentage of values belonging to the mode\\n• Percentage of null values\\n• Entropy\\nLet’s consider some concrete examples of this process, using n-gram clusters that cor‐\\nrespond to examples of good and bad clusters we found earlier. Per our previous\\nanalysis, we will focus on 7-grams. Figure 6-2 shows per-domain features for\\ndomains containing the 7-gram “jordano,” whereas Figure 6-3 shows the same for\\ndomains containing the 7-gram “gabyte.”\\nFigure 6-2. Domains with the 7-gram “jordano”\\n268 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 286}, page_content='Figure 6-3. Domains with the 7-gram “gabyte”\\nExpanding the 5 numerical and 4 categorical features as just described gives a total of\\n65 features. For example, the “whois” domain-level feature (which gives the age of the\\ndomain in days) produces the cluster-level features shown in Figure 6-4.\\nFigure 6-4. Examples of cluster-level features for “whois”\\nWhereas the “top-level domain” feature produces the features in Figure 6-5.\\nFigure 6-5. Examples of cluster-level features for “top-level domain”\\nFrom these two examples, we expect the fact that most whois results return null for\\nthe bad domains and return a wide range of results for the good domains to be a dis‐\\ntinguishing feature. We also expect that high diversity of top-level domains indicates\\na good cluster.\\nClustering Abuse \\n| \\n269'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 287}, page_content=\"Classiication\\nNow let’s attempt to put this intuition into practice by training a classifier. We will use\\na random forest classifier, which is a nonlinear classifier that tends to be effective “out\\nof the box” with little tuning. We downsample the good clusters in the training set in\\norder not to overwhelm the classifier; however, we leave the test set unbiased so that\\nwe get an accurate calculation of precision and recall:\\nfrom sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom random import random\\nimport matplotlib.pyplot as plt\\n# Add a random entry to each row, to be used for sampling\\nR = [random() for i in range(len(ngram_cluster_features))]\\nngram_cluster_features['rand'] = R\\n# Split into 2/3 train, 1/3 test, and downsample good clusters\\ntrain, test = train_test_split(ngram_cluster_features.fillna(value=0),\\n                               test_size=0.33)\\nsample_factor = 0.2\\nsampled_train = train[(train.label == 1) | (train.label == 0) &\\n                      (train.rand < sample_factor)]\\n# Fit and predict\\nfeatures = sampled_train[sampled_train.columns.difference(\\n    ['label','rand','score'])]\\nlabels = sampled_train.label\\nclf = RandomForestClassifier(n_estimators=20)\\nclf.fit(features, labels)\\nprobs = clf.predict_proba(test[train.columns.difference(\\n    ['label','rand','score'])])\\n# Compute and plot P-R curve\\nprecision, recall, thresholds = precision_recall_curve(\\n    test.label, probs[:,1])\\nplt.step(recall, precision, color='b', alpha=0.2, where='post')\\nplt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\\nplt.xlabel('Recall')\\nplt.ylabel('Precision')\\nplt.ylim([0.0, 1.05])\\nplt.xlim([0.0, 1.0])\\nplt.title('Precision-Recall curve for 7-gram groupings')\\nplt.show()\\n# Find threshold for 95% precision\\nm = min([i for i in range(len(precision)) if precision[i] > 0.95])\\np,r,t = precision[m], recall[m], thresholds[m]\\nprint(p,r,t)\\n270 \\n| \\nChapter 6: Protecting the Consumer Web\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 288}, page_content=\"From this calculation and the precision-recall curve for this classifier in Figure 6-6,\\nwe see that we can achieve 61% recall and 95% precision on clusters at a threshold of\\n0.75 (i.e., 15 of the 20 trees in our forest classify the cluster as bad).\\nFigure 6-6. Precision-recall curve for 7-gram groupings for spam domain classiication\\nBut this calculation is at the cluster level—what is our precision and recall on the indi‐\\nvidual domain level? For example, if false positives tended to be larger clusters on\\naverage than true positives, our precision on individual domains would be less than\\non clusters.\\nWe can work out the item-level precision and recall as follows:\\n# Compute item-level precision/recall\\npos = (test.score * test['count'])\\nneg = (1-test.score) * (test['count'])\\ntp = sum(pos[test.label >= t])\\nfp = sum(neg[test.label >= t])\\ntn = sum(neg[test.label < t])\\nfn = sum(pos[test.label < t])\\nitem_precision = 1.0*tp/(tp+fp)\\nitem_recall = 1.0*tp/(tp+fn)\\nIn this example, we find that precision drops slightly to 92%, but recall goes all the\\nway down to 21%. This result makes sense intuitively, given that many bad domains\\nin our dataset are not part of clusters and must thus be detected via some other\\nmeans.\\nFurther Directions in Clustering\\nIn the previous example, we demonstrated how to use various algorithms to generate\\nclusters in our example dataset, and then how to programmatically determine which\\nclusters are abusive from the data. When implementing your own clustering system,\\nthere are several directions in which you could extend this example:\\nFurther Directions in Clustering \\n| \\n271\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 289}, page_content='• Experiment with different clustering methods, such as those discussed in Chap‐\\nter 2.\\n• Experiment with different classifiers and classifier parameters.\\n• Add new features at the item level.\\n• Add new aggregate features at the cluster level.\\n• Sample the data so that “semi-good” clusters (i.e., those whose proportion of bad\\nitems is near the threshold for declaring the cluster bad) have less influence on\\nthe outcome.\\n• Give extra weight to items appearing in multiple good or bad clusters.\\n• Add a second classifier to detect false positive items within a cluster (e.g., if 19 of\\n20 items in the cluster are bad but the 20th is obviously good, can we detect the\\ngood item automatically?).\\nAs in many other aspects of security, the best intuition for further work will come\\nfrom looking at the data: What are the trends you are missing? What features can you\\nuse to identify classifier mistakes? In what way are false positives/false negatives simi‐\\nlar to each other? When you can answer these questions qualitatively, you can use the\\nframework of this chapter to improve your algorithmic solution to the problem.\\nConclusion\\nThe consumer web (and associated apps) provides a vast array of surfaces that bad\\nactors can use to monetize. In most cases the attack will require one or many\\naccounts, so preventing attackers from gaining access to accounts can stop many dif‐\\nferent kinds of attacks. In this chapter, we discussed ways to prevent account takeover\\nand fake account creation, which are the two ways bad guys can get access to the\\naccounts they need. We also considered ways to detect financial fraud and automa‐\\ntion, which are two of the common techniques used to attack almost any product.\\nMachine learning for abuse problems comes with its own set of challenges: getting\\nground truth data is difficult, and models must achieve a delicate balance between\\nfinding what is already known and uncovering new attack techniques. We have con‐\\nsidered some of the pitfalls of machine learning for abuse and offered some sugges‐\\ntions to mitigate them.\\nAlthough supervised learning is very powerful for addressing abuse problems, in\\nmany cases clustering techniques can be used to address attacks at scale. When com‐\\nbined with supervised learning, these techniques might allow you to detect and stop\\nlarge attacks very quickly. We demonstrated some clustering techniques through a\\nworked example of classifying spammy domain names.\\n272 \\n| \\nChapter 6: Protecting the Consumer Web'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 290}, page_content='To this point our discussion has been somewhat academic: collect certain signals,\\nimplement certain algorithms, and detect the bad guys. In real life, however, things\\naren’t so neat. Chapter 7 focuses on the issues that come up when translating the ideas\\ndiscussed so far into a real-world system.\\nConclusion \\n| \\n273'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 291}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 292}, page_content='CHAPTER 7\\nProduction Systems\\nUp to this point in the book, we have focused our discussion on implementing\\nmachine learning algorithms for security in isolated lab environments. After you have\\nproven that the algorithm works, the next step will likely be to get the software ready\\nfor production. Deploying machine learning systems in production comes with an\\nentirely different set of challenges and concerns that you might not have had to deal\\nwith during the experimentation and development phases. What does it take to engi‐\\nneer truly scalable machine learning systems? How do we manage the efficacy, relia‐\\nbility, and relevance of web-scale security services in dynamic environments where\\nchange is constant? This chapter is dedicated to security and data at scale, and we will\\naddress these questions and more.\\nLet’s begin by concretely defining what it means for such systems to be production\\nready, deployable, and scalable.\\nDeining Machine Learning System Maturity and\\nScalability\\nInstead of floating around abstract terms for describing the quality of code in produc‐\\ntion, it will benefit the discussion to detail some characteristics that mature and scala‐\\nble machine learning systems should have. The following list of features describes an\\nideal machine learning system, regardless of whether it is related to security; the\\nitems highlighted in bold are especially important for security machine learning sys‐\\ntems. The list also serves as an outline for the remainder of this chapter, so if there is\\nany item you are particularly curious about, you can jump to the corresponding sec‐\\ntion to learn more. We will examine the following topics:\\n275'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 293}, page_content='• Data Quality\\n— Unbiased data\\n— Veriiable ground truth\\n— Sound treatment of missing data\\n• Model Quality\\n— Eicient hyperparameter optimization\\n— A/B testing of models\\n— Timely feedback loops\\n— Repeatable results\\n— Explainable results\\n• Performance\\n— Low-latency training and predictions\\n— Scalability (i.e., can it handle 10 times the traic?)\\n— Automated and eicient data collection\\n• Maintainability\\n— Checkpointing and versioning of models\\n— Smooth model deployment process\\n— Graceful degradation\\n— Easily tunable and conigurable\\n— Well documented\\n• Monitoring and Alerting\\n— System health/performance monitoring (i.e., is it running?)\\n— System efficacy monitoring (i.e., precision/recall)\\n— Monitoring data distributions (e.g., user behavior changing or adversaries\\nadapting)\\n• Security and Reliability\\n— Robust in adversarial contexts\\n— Data privacy safeguards and guarantees\\nThis is a long list, but not all the listed points are applicable to all types of systems.\\nFor instance, explainable results might not be relevant for an online video recom‐\\nmendation system because there are typically no accountability guarantees and the\\ncost of a missed prediction is low. Systems that do not naturally attract malicious\\n276 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 294}, page_content='tampering might not have a strong incentive to devote resources to making models\\nrobust to adversarial activity.\\nWhat’s Important for Security Machine Learning Systems?\\nSecurity machine learning applications must meet an especially stringent set of\\nrequirements before it makes sense to put them into production. Right from the start,\\nalmost all such systems have high prediction accuracy requirements because of the\\nunusually high cost of getting something wrong. An error rate of 0.001 (99.9% pre‐\\ndiction accuracy) might be good enough for a sales projection model that makes 100\\npredictions per day—on average, only 1 wrong prediction will be made every 10 days.\\nOn the other hand, a network packet classifier that inspects a million TCP packets\\nevery minute will be misclassifying 1,000 of those packets each minute. Without sepa‐\\nrate processes in place to filter out these false positives and false negatives, an error\\nrate of 0.001 is untenable for such a system. If every false positive has to be manually\\ntriaged by a human analyst, the cost of operation will be too high. For every false neg‐\\native, or missed detection, the potential consequences can be dire: the entire system\\ncan be compromised.\\nAll of the properties of mature and scalable machine learning systems that we just lis‐\\nted are important, but the highlighted ones are especially critical to the success of\\nsecurity machine learning systems.\\nLet’s dive into the list of qualities and look at more specific techniques for developing\\nscalable, production-quality security machine learning systems. In the following sec‐\\ntions, we examine each issue that either is commonly overlooked or poses a challenge\\nfor the use of machine learning in security. For each, we first describe the problem or\\ngoal and explain why it is important. Next, we discuss ways to approach system\\ndesign that can help achieve the goal or mitigate the problem.\\nData Quality\\nThe quality of a machine learning system’s input data dictates its success or failure.\\nWhen training an email spam classifier using supervised learning, feeding an algo‐\\nrithm training data that contains only health and medicine advertising spam emails\\nwill not result in a balanced and generalizable model. The resulting system might be\\ngreat at recognizing unsolicited emails promoting weight-loss medication, but it will\\nlikely be unable to detect adult content spam.\\nProblem: Bias in Datasets\\nWell-balanced datasets are scarce, and using unbalanced datasets can result in bias\\nthat is difficult to detect. For example, malware datasets are rarely varied enough to\\ncover all different types of malware that a system might be expected to classify.\\nData Quality \\n| \\n277'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 295}, page_content='1 Note that bias (or algorithmic bias) in statistics and machine learning is also a term used to describe errors in\\nassumptions made by a learning algorithm that can cause algorithms to underit. Our use of the term here is\\ndifferent; we refer to data bias here, which refers to a dataset’s inadequate representation of a population.\\nDepending on what was collected in honeypots, the dates the samples were collected,\\nthe source of nonmalicious binaries, and so on, there is often significant bias in these\\ndatasets.\\nMachine learning algorithms rely on datasets fed into algorithms to execute the learn‐\\ning task. We use the term population to refer to the universe of data whose character‐\\nistics and/or behavior the algorithm should model. For example, suppose that we\\nwant to devise a machine learning algorithm to separate all phishing emails from all\\nbenign emails; in this case, the population refers to all emails that have existed in the\\npast, present, and future.\\nBecause it is typically impossible to collect samples from the entire population, data‐\\nsets are created by drawing from sources that produce samples belonging to the pop‐\\nulation. For example, suppose that a convenient dataset for enterprise X is emails\\nfrom its corporate email server for the month of March. Using this dataset eventually\\nproduces a classifier that performs very well for enterprise X, but there is no guaran‐\\ntee that it will continue to perform well as time progresses or if brought to another\\ncompany. Specifically, the phishing emails received by a different enterprise Y also\\nbelong to the population, but they might have very different characteristics that are\\nnot exhibited in enterprise X, in which case it is unlikely that the classifier will pro‐\\nduce good results on enterprise Y’s emails. Suppose further that the phishing samples\\nwithin the dataset are mostly made up of tax scam and phishing emails, given that\\nMarch and April happen to be tax season in the United States. Unless you take special\\ncare, the model might not learn the characteristics of other types of phishing emails\\nand is not likely to perform well in a general test scenario. Because the goal was to\\nbuild a general phishing classifier that worked well on all emails, the dataset used to\\ntrain it was inadequately drawn from the population. This classifier is a victim of\\nselection bias and exclusion bias1 because of the temporal and contextual effects that\\ncontributed to the selection of the particular dataset used to train the classifier.\\nSelection bias and exclusion bias are common forms of bias that can be caused by\\nflawed data collection flows. These forms of bias are introduced by the systematic and\\nimproper selection or exclusion of data from the population intended to be analyzed,\\nresulting in datasets that have properties and a distribution that are not representative\\nof the population.\\nObserver bias, or the observer-expectancy efect, is another common type of bias\\ncaused by errors in human judgment or human-designed processes. Software binary\\nfeature extraction processes might be biased toward certain behavior exhibited by the\\nbinaries that human analysts have been trained to look out for; for example, DNS\\n278 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 296}, page_content='queries to command-and-control (C&C) servers. As a result, the detection and col‐\\nlection mechanisms in such pipelines might miss out on other equally telling but less\\ncommonly exhibited malicious actions, such as unauthorized direct memory\\naccesses. This bias causes imperfect data and incorrect labels assigned to samples,\\naffecting the accuracy of the system.\\nProblem: Label Inaccuracy\\nWhen doing supervised learning, mislabeled data will cause machine learning algo‐\\nrithms to lose accuracy. The problem is exacerbated if the validation datasets are also\\nwrongly labeled. Development-time validation accuracy can look promising, but the\\nmodel will likely not perform as expected when fed with real data in production. The\\nproblem of inaccurate labels is commonly seen when crowdsourcing is used without\\nproper safeguards. User feedback or experts making decisions on incomplete infor‐\\nmation can also result in mislabeled data. Mislabeled data can seriously interfere with\\nthe learning objectives of algorithms unless you recognize and deal with it.\\nChecking the correctness of labels in a dataset often requires expensive human expert\\nresources. It can take hours for an experienced security professional to check whether\\na binary flagged by your system actually carries out malicious behavior. Even doing\\nrandom subset validation on datasets can still be expensive.\\nSolutions: Data Quality\\nThere are many different causes of data quality problems, and there are few quick and\\neasy remedies. The most critical step in dealing with data quality issues in security\\nmachine learning systems is to recognize that the problem exists. Class imbalance (as\\ndiscussed in Chapter 5) is a manifestation of data bias in which the number of sam‐\\nples of one class of data is vastly smaller (or larger) than the number of samples of\\nanother class. Class imbalance is a fairly obvious problem that we can find during the\\nexploration or training phase and alleviate with oversampling and undersampling, as\\ndiscussed earlier. However, there are other forms of data bias and inaccuracies that\\ncan be subtler yet equally detrimental to model performance. Detecting selection bias\\nand observer bias is challenging, especially when the problem results from imple‐\\nmenters’ and designers’ blind spots. Spending time and resources to understand the\\nexact goals of the problem and the nature of the data is the only way to determine if\\nthere are important aspects of the data that your datasets are unable to capture.\\nIn some cases, you can avoid data quality issues by carefully defining the scope of the\\nproblem. For instance, systems that claim to detect all kinds of phishing emails will\\nhave a challenging time generating a representative training dataset. However, if the\\nscope of the problem is narrowed to the most important problem an organization is\\nData Quality \\n| \\n279'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 297}, page_content='2 Clickjacking is a web attack technique that tricks users into clicking something different from what they per‐\\nceive they are clicking, usually by presenting a false interface on top of the original one. Clickjacking makes\\nusers do something unintended that benefits the attacker, such as revealing private information, granting\\naccess to some resource, or taking a malicious action.\\n3 J.L. Fleiss and J. Cohen, “The Equivalence of Weighted Kappa and the Intraclass Correlation Coefficient as\\nMeasures of Reliability,” Educational and Psychological Measurement 33 (1973): 613–619.\\nfacing—for example, detecting phishing emails that attempt to clickjack2 the user—it\\nwill be easier to gather more focused data for the problem.\\nInaccurate labels caused by errors in human labeling can be made less likely by\\ninvolving multiple independent annotators in the labeling process. You can use statis‐\\ntical measures (such as the Fleiss’ kappa3) to assess the reliability of agreement\\nbetween the annotations of multiple labelers and weed out incorrect labels. Assuming\\nthat labels were not assigned in mischief or malice by the annotators, the level of disa‐\\ngreement between human annotators for a particular sample’s label is also often used\\nas the upper bound of the likelihood a machine learning classifier is able to predict\\nthe correct label for the sample. For example, imagine that two independent annota‐\\ntors label an email as spam, and another two think it is ham. This indicates that the\\nsample might be ambiguous, given that even human experts cannot agree on its label.\\nMachine learning classifiers will not be likely to perform well on such samples, and it\\nis best to exclude such samples from the dataset to avoid confounding the learning\\nobjectives of the algorithm.\\nIf you know that the dataset has noisy labels but it is impossible or too costly to weed\\nout the inaccuracies, increasing regularization parameters to deliberately disincentiv‐\\nize overfitting at the expense of prediction accuracy can be a worthwhile trade-off.\\nOverfitting a model to a noisily labeled dataset can be catastrophic and result in a\\n“garbage-in, garbage-out” scenario.\\nProblem: Missing Data\\nMissing data is one of the most common problems that you will face when working\\nwith machine learning. It is very common for datasets to have rows with missing val‐\\nues. These can be caused by errors in the data collection process, but datasets can also\\ncontain missing data by design. For instance, if a dataset is collected through surveys\\nwith human respondents, there may be some optional questions some people choose\\nnot to answer. This causes null values to end up in the dataset, causing problems\\nwhen it comes time for analysis. Some algorithms will refuse to classify a row with\\nnull values, rendering any such row useless even if it contains valid data in most col‐\\numns. Others will use default values in the input or output, which can lead to errone‐\\nous results.\\n280 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 298}, page_content=\"4 Full code can be found as a Python Jupyter notebook, chapter7/missing-values-imputer.ipynb in our code\\nrepository.\\nA common mistake is to fill in the blanks with sentinel values; that is, dummy data of\\nthe same format/type as the rest of the column that signals to the operator that this\\nvalue was originally blank, such as 0 or −1 for numeric values. Sentinel values pollute\\nthe dataset by inserting data that is not representative of the original population from\\nwhich the samples are drawn. It might be obvious to you that 0 or −1 is not a valid\\nvalue for a particular column, but it will in general not be obvious to your algorithm.\\nThe degree to which sentinel values can negatively affect classification results\\ndepends on the particular machine learning algorithm used.\\nSolutions: Missing Data\\nLet’s illustrate this problem with an example4 and experiment with some solutions.\\nOur example dataset is a database containing records of 1,470 employees in an orga‐\\nnization, past and present. The dataset, presented in Table 7-1, has four columns:\\n“TotalWorkingYears,” “MonthlyIncome,” “Overtime,” and “DailyRate.” The “Label”\\nindicates whether the employee has left the organization (with 0 indicating that the\\nemployee is still around).\\nWhat we are attempting to predict with this dataset is whether an employee has left\\n(or is likely to leave), given the other four features. The “Overtime” feature is binary,\\nand the other three features are numerical. Let’s process the dataset and attempt to\\nclassify it with a decision tree classifier, as we have done in earlier chapters. We first\\ndefine a helper function that builds a model and returns its accuracy on a test set:\\ndef build_model(dataset, test_size=0.3, random_state=17):\\n    # Split data into training and test sets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        dataset.drop('Label', axis=1), dataset.Label,\\n        test_size=test_size, random_state=random_state)\\n    # Fit a decision tree classifier\\n    clf = DecisionTreeClassifier(\\n        random_state=random_state).fit(X_train, y_train)\\n    # Compute the accuracy\\n    y_pred = clf.predict(X_test)\\n    return accuracy_score(y_test, y_pred)\\nNow let’s try building a model on the entire dataset:\\n# Read the data into a DataFrame\\ndf = pd.read_csv('employee_attrition_missing.csv')\\nbuild_model(df)\\nData Quality \\n| \\n281\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 299}, page_content=\"At this point, scikit-learn throws an error:\\n> ValueError: Input contains NaN, infinity or a value too large for\\n      dtype('float32').\\nIt appears that some of the values in this dataset are missing. Let’s inspect the\\nDataFrame:\\ndf.head()\\nTable 7-1. Sample rows drawn from employee attrition dataset\\nTotalWorkingYears\\nMonthlyIncome\\nOvertime\\nDailyRate\\nLabel\\n0 NaN\\n6725\\n0\\n498.0\\n0\\n1 12.0\\n2782\\n0\\nNaN\\n0\\n2 9.0\\n2468\\n0\\nNaN\\n0\\n3 8.0\\n5003\\n0\\n549.0\\n0\\n4 12.0\\n8578\\n0\\nNaN\\n0\\nWe see from Table 7-1 that there are quite a few rows that have “NaN” values for the\\n“TotalWorkingYears” and “DailyRate” columns.\\nThere are five methods that you can use to deal with missing values in datasets:\\n1. Discard rows with any missing values (without replacement).\\n2. Discard columns that have missing values.\\n3. Fill in missing values by collecting more data.\\n4. Fill in missing values with zeroes or some other “indicator” value.\\n5. Impute the missing values.\\nMethod 1 works if not many rows have missing values and you have an abundance of\\ndata points. For example, if only 1% of your samples are missing data, it can be\\nacceptable to completely remove those rows. Method 2 is useful if the features for\\nwhich some rows have missing values are not strong features for learning. For exam‐\\nple, if only the “age” column has missing values in a dataset, and the age feature does\\nnot seem to contribute to the learning algorithm much (i.e., removing the feature\\ndoes not cause a significant decrease in prediction accuracy), it can be acceptable to\\ncompletely exclude the column from the learning process. Methods 1 and 2 are sim‐\\nple, but most operators seldom find themselves in positions in which they have\\nenough data or features that they can discard rows or columns without affecting per‐\\nformance.\\nLet’s see what fraction of our samples have missing data. We can drop rows contain‐\\ning any “NaN” values with the function pandas.DataFrame.dropna():\\n282 \\n| \\nChapter 7: Production Systems\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 300}, page_content=\"num_orig_rows = len(df)\\nnum_full_rows = len(df.dropna())\\n(num_orig_rows - num_full_rows)/float(num_orig_rows)\\n> 0.5653061224489796\\nMore than half of the rows have at least one value missing and two out of four col‐\\numns have values missing—not promising! Let’s see how methods 1 and 2 perform\\non our data:\\ndf_droprows = df.dropna()\\nbuild_model(df_droprows)\\n> 0.75520833333333337\\ndf_dropcols = df[['MonthlyIncome','Overtime','Label']]\\nbuild_model(df_dropcols)\\n> 0.77324263038548757\\nDropping rows with missing values gives a 75.5% classification accuracy, whereas\\ndropping columns with missing values gives an accuracy of 77.3%. Let’s see if we can\\ndo better.\\nMethods 3 and 4 attempt to fill in the gaps instead of discarding the “faulty” rows.\\nMethod 3 gives the highest-quality data, but is often unrealistic and expensive. For\\nthis example, it would be too expensive to chase each employee down just to fill in the\\nmissing entries. We also cannot possibly generate more data unless more employees\\njoin the company.\\nLet’s try method 4, filling in all missing values with a sentinel value of −1 (because all\\nof the data is nonnegative, −1 is a good indicator of missing data):\\n# Fill all NaN values with −1\\ndf_sentinel = df.fillna(value=-1)\\nbuild_model(df_sentinel)\\n> 0.75283446712018143\\nThis approach gives us a 75.3% classification accuracy—worse than simply dropping\\nrows or columns with missing data! We see here the danger of naively inserting val‐\\nues without regard to what they might mean.\\nLet’s compare these results to what method 5 can do. Imputation refers to the act of\\nreplacing missing values with intelligently chosen values that minimize the effect of\\nthis filler data on the dataset’s distribution. In other words, we want to ensure that the\\nvalues that we fill the gaps with do not pollute the data significantly. The best way to\\nselect a value for filling the gaps is typically to use the mean, median, or most fre‐\\nquently appearing value (mode) of the column. Which method to choose depends on\\nData Quality \\n| \\n283\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 301}, page_content=\"5 Most implementations of k-NN algorithms don’t actually store the entire training dataset as the model. For\\nprediction-time efficiency, k-NN implementations commonly make use of data structures such as k-d trees.\\nSee J.L. Bentley, “Multidimensional Binary Search Trees Used for Associative Searching,” Communications of\\nthe ACM 18:9 (1975): 509.\\n6 A.M. Kibriya and E. Frank, “An Empirical Comparison of Exact Nearest Neighbour Algorithms,” Proceedings\\nof the 11th European Conference on Principles and Practice of Knowledge Discovery in Databases (2007): 140–\\n151.\\nthe nature of the dataset. If the dataset contains many outliers—for example, if 99% of\\n“DailyRate” values are below 1,000 and 1% are above 100,000—imputing by mean\\nwould not be suitable.\\nScikit-learn provides a convenient utility for imputing missing values: sklearn.pre\\nprocessing.Imputer. Let’s use this to fill in all the missing values with the respective\\nmeans for each of the columns containing missing data:\\nfrom sklearn.preprocessing import Imputer\\nimp = Imputer(missing_values='NaN', strategy='mean', axis=0)\\n# Create a new DataFrame with the dataset transformed by the imputer\\ndf_imputed = pd.DataFrame(imp.fit_transform(df),\\n                          columns=['TotalWorkingYears', 'MonthlyIncome',\\n                                   'OverTime', 'DailyRate', 'Label'])\\nbuild_model(df_imputed)\\n> 0.79365079365079361\\nInstantly, the classification accuracy increases to 79.4%. As you can guess, imputation\\nis often the best choice for dealing with missing values.\\nModel Quality\\nTrained models form the core intelligence of machine learning systems. But without\\nsafeguards in place to ensure the quality of these models, the results they produce will\\nbe suboptimal. Models can take on different forms depending on the machine learn‐\\ning algorithm used, but they are essentially data structures containing the parameters\\nlearned during the algorithm’s training phase. For instance, a trained decision tree\\nmodel contains all of the splits and values at each node, whereas a trained k-nearest\\nneighbors (k-NN) classification model (naively implemented5 or ball trees6) is in fact\\nthe entire training dataset.\\nModel quality is not only important during the initial training and deployment phase.\\nYou must also take care as your system and the adversarial activity it faces evolve; reg‐\\nular maintenance and reevaluation will ensure that it does not degrade over time.\\n284 \\n| \\nChapter 7: Production Systems\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 302}, page_content=\"Problem: Hyperparameter Optimization\\nHyperparameters are machine learning algorithm parameters that are not learned\\nduring the regular training process. Let’s look at some examples of tunable hyperpara‐\\nmeters for the DecisionTreeClassifier in scikit-learn:\\nfrom sklearn import tree\\nclassifier = tree.DecisionTreeClassifier(max_depth=12,\\n                                         min_samples_leaf=3,\\n                                         max_features='log2')\\nIn the constructor of the classifier, we specify that the max_depth that the tree should\\ngrow to is 12. If this parameter is not specified, the default behavior of this implemen‐\\ntation is to split nodes until all leaves are pure (only contain samples belonging to a\\nsingle class) or, if the min_samples_split parameter is specified, to stop growing the\\ntree when all leaf nodes have fewer than min_samples_split samples in them. We\\nalso specify min_samples_leaf=3, which means that the algorithm should ensure that\\nthere are at least three samples in a leaf node. max_features is set to log2, which\\nindicates to the classifier that the maximum number of features it should consider\\nwhen looking for the best split of a node is the base-2 logarithm of the number of\\nfeatures in the data. If you do not specify max_features, it defaults to the number of\\nfeatures. You can find the full list of tunable hyperparameters for any classifier in the\\ndocumentation. If this looks intimidating to you, you are not alone.\\nHyperparameters typically need to be chosen before commencing the training phase.\\nBut how do you know what to set the learning rate to? Or how many hidden layers in\\na deep neural network will give the best results? Or what value of k to use in k-means\\nclustering? These seemingly arbitrary decisions can have a significant impact on a\\nmodel’s efficacy. Novice practitioners typically try to avoid the complexity by using\\nthe default values provided by the machine learning library. Many mature machine\\nlearning libraries (including scikit-learn) do provide thoughtfully chosen default val‐\\nues that are adequate for the majority of use cases. Nevertheless, it is not possible for a\\nset of hyperparameters to be optimal in all scenarios. A large part of your responsibil‐\\nity as a machine learning engineer is to understand the algorithms you use well\\nenough to find the optimal combination of hyperparameters for the problem at hand.\\nBecause of the huge parameter space, this process can be expensive and slow, even for\\nmachine learning experts.\\nSolutions: Hyperparameter Optimization\\nHyperparameters are a fragile component of machine learning systems because their\\noptimality can be affected by small changes in the input data or other parts of the sys‐\\ntem. The problem can be naively approached in a “brute-force” fashion, by training\\ndifferent models using all different combinations of the algorithm’s hyperparameters,\\nModel Quality \\n| \\n285\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 303}, page_content='and then selecting the set of hyperparameters that results in the best-performing\\nmodel.\\nHyperparameter optimization is most commonly done using a technique called grid\\nsearch, an exhaustive sweep through the hyperparameter space of a machine learning\\nalgorithm. By providing a metric for comparing how well each classifier performs\\nwith different combinations of hyperparameter values, the optimal configuration can\\nbe found. Even though this operation is computationally intensive, it can be easily\\nparallelized because each different configuration of hyperparameter values can be\\nindependently computed and compared. Scikit-learn provides a class called\\nsklearn.model_selection.GridSearchCV that implements this feature.\\nLet’s look at a short example of using a support vector machine to solve a digit classi‐\\nfication problem—but instead of the commonly used MNIST data we’ll use a smaller\\nand less computationally demanding dataset included in the scikit-learn digits data‐\\nset, adapted from the Pen-Based Recognition of Handwritten Digits Data Set. Before\\ndoing any hyperparameter optimization, it is good practice to establish a perfor‐\\nmance baseline with the default hyperparameters:\\nfrom sklearn import svm, metrics\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.datasets import fetch_mldata, load_digits\\n# Read dataset and split into test/train sets\\ndigits = load_digits()\\nn_samples = len(digits.images)\\ndata = digits.images.reshape((n_samples, −1))\\nX_train, X_test, y_train, y_test = train_test_split(\\n    data, digits.target, test_size=0.3, random_state=0)\\n# Train SVC classifier, then get prediction and accuracy\\nclassifier = svm.SVC()\\nclassifier.fit(X_train, y_train)\\npredicted = classifier.predict(X_test)\\nprint(\"Accuracy: %.3f\" % metrics.accuracy_score(y_test, predicted))\\n> Accuracy: 0.472\\nAn accuracy of 47.2% is pretty poor. Let’s see if tuning hyperparameters can give us a\\nboost:\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\n# Define a dictionary containing all hyperparameter values to try\\nhyperparam_grid = {\\n    \\'kernel\\': (\\'linear\\', \\'rbf\\'),\\n    \\'gamma\\': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\\n    \\'C\\': [1, 3, 5, 7, 9]\\n}\\n286 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 304}, page_content='# Perform grid search with desired hyperparameters and classifier\\nclassifier = GridSearchCV(svc, hyperparam_grid)\\nclassifier.fit(X_train, y_train)\\nThe hyperparam_grid dictionary passed into the GridSearchCV constructor along\\nwith the svc estimator object contains all of the hyperparameter values that we want\\nthe grid search algorithm to consider. The algorithm then builds 60 models, one for\\neach possible combination of hyperparameters, and chooses the best one:\\nprint(\\'Best Kernel: %s\\' % classifier.best_estimator_.kernel)\\nprint(\\'Best Gamma: %s\\' % classifier.best_estimator_.gamma)\\nprint(\\'Best C: %s\\' % classifier.best_estimator_.C)\\n> Best Kernel: rbf\\n> Best Gamma:  0.001\\n> Best C:      3\\nThe default values provided by the sklearn.svm.SVC class are kernel=\\'rbf\\',\\ngamma=1/n_features (for this dataset, n_features=64, so gamma=0.015625), and C=1.\\nNote that the gamma and C proposed by GridSearchCV are different from the default\\nvalues. Let’s see how it performs on the test set:\\npredicted = classifier.predict(X_test)\\nprint(\"Accuracy: %.3f\" % metrics.accuracy_score(y_test, predicted))\\n> Accuracy: 0.991\\nWhat a dramatic increase! Support vector machines are quite sensitive to their hyper‐\\nparameters, especially the gamma kernel coefficient, for reasons which we will not go\\ninto here.\\nGridSearchCV can take quite some time to run because it is train‐\\ning a separate SVC classifier for each combination of hyperparame‐\\nter values provided in the grid. Especially when dealing with larger\\ndatasets, this process can be very expensive. Scikit-learn provides\\nmore optimized hyperparameter optimization algorithms such as\\nsklearn.model_selection.RandomizedSearchCV that can return\\nresults more quickly.\\nEven for algorithms that have only a few hyperparameters, grid search is a very time-\\nand resource-intensive way to solve the problem because of combinatorial explosion.\\nTaking this naive approach as a performance baseline, we now consider some ways to\\noptimize this process:\\n1) Understand the algorithm and its parameters well\\nHaving a good understanding of the underlying algorithm and experience in\\nimplementation can guide you through the iterative process of manual hyper‐\\nModel Quality \\n| \\n287'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 305}, page_content=\"7 Yann LeCun, Corinna Cortes, and Christopher Burges, “The MNIST Database of Handwritten Digits” (1998).\\nparameter optimization and help you to avoid dead ends. However, even if you\\nare new to the field, the tuning process does not need to be completely blind. Vis‐\\nualizations of the training results can usually prompt adjustments of hyperpara‐\\nmeters in certain directions and/or in magnitude. Let’s take the classic example of\\na neural network for classifying digits (from 0 to 9) from the MNIST image data‐\\nset7 of individual handwritten digits. The model we are using is a fully connected\\nfive-layer neural network implemented in TensorFlow. Using the visualization\\ntool TensorBoard included in the standard distribution of TensorFlow, we plot a\\ngraph of the cross_entropy loss:\\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(\\n    logits=Ylogits, labels=Y_)\\ncross_entropy = tf.reduce_mean(cross_entropy)*100\\ntf.summary.scalar('cross_entropy', cross_entropy)\\nFigure 7-1 shows the result.\\nFigure 7-1. TensorBoard scalar plot of training and test cross_entropy loss (log scale)\\nObserving the training and test cross_entropy loss over 10,000 epochs in\\nFigure 7-1, we note an interesting dichotomy in the two trends. The training is\\nperformed on 55,000-digit samples and the testing is done on a static set of\\n10,000-digit samples. After each epoch, the cross_entropy loss is separately cal‐\\nculated on the training dataset (used to train the network) and the test dataset\\n(which is not accessible to the network during the training phase). As expected,\\nthe training loss approaches zero over more training epochs, indicating that the\\n288 \\n| \\nChapter 7: Production Systems\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 306}, page_content='8 Nitish Srivastava et al., “Dropout: A Simple Way to Prevent Neural Networks from Overfitting,” Journal of\\nMachine Learning Research 15 (2014): 1929–1958.\\nnetwork gradually performs better as it spends more time learning. The test loss\\ninitially follows a similar pattern to the training loss, but after about 2,000 epochs\\nbegins to trend upward. This is usually a clear sign that the network is overfitting\\nto the training data. If you have dealt with neural networks before, you will know\\nthat dropout8 is the de facto way to perform regularization and deal with overfit‐\\nting. Applying a dropout factor to the network will fix the upward trend of the\\ntest loss. By iteratively selecting different values of dropout on the network, you\\ncan then use this plot to find the hyperparameter value that reduces overfitting\\nwithout sacrificing too much accuracy.\\n2) Mimic similar models\\nAnother common way to solve the hyperparameter cold-start problem is to\\nresearch previous similar work in the area. Even if the problem might not be of\\nexactly the same nature, copying hyperparameters from other work while under‐\\nstanding why those choices were made can save you a lot of time because some‐\\none else has already put in the work to solve a similar problem. For example, it\\nmight take 10 iterations of experimentation to find out that 0.75 is the optimal\\ndropout value to use for your MNIST classifier network, but looking at the values\\nused to solve the MNIST problem in previously published work using a similar\\nneural network could reduce your hyperparameter optimization time.\\n3) Don’t start tuning parameters too early\\nIf you are resource constrained, don’t fret over hyperparameters. Only worry\\nabout the parameters when you suspect that they might be the cause of a problem\\nin your classifier. Starting with the simplest configurations and watching out for\\npotential improvements to make along the way is generally a good practice to\\nfollow.\\nAutoML is a field of research that aims to automate the training\\nand tuning of machine learning systems, including the process of\\nhyperparameter optimization. In principle, AutoML tools can\\nselect the best algorithm for a task, perform an optimal architecture\\nsearch for deep neural nets, and analyze the importance of hyper‐\\nparameters to the prediction result. Though still very much in the\\nresearch phase, AutoML is definitely an area to watch.\\nFeature: Feedback Loops, A/B Testing of Models\\nBecause security machine learning systems have such a low tolerance for inaccura‐\\ncies, every bit of user feedback needs to be taken into account to improve system\\nModel Quality \\n| \\n289'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 307}, page_content='efficacy as much as possible. For example, an anomaly detection system that raises\\ntoo many false positive alerts to security operations personnel should take advantage\\nof the correct labels given by human experts during the alert triaging phase to retrain\\nand improve the model.\\nLong-running machine learning systems often also fall into the predicament of con‐\\ncept drit (also known as “model rot”), in which a model that originally yielded good\\nresults deteriorates over time. This is often an effect of changing properties of the\\ninput data due to external effects, and machine learning systems need to be flexible\\nenough to adapt to such changes.\\nThe first step to system flexibility is to detect model rot before it cripples the system\\nby producing wrong or nonsensical output. Feedback loops are a good way to not\\nonly detect when the model is deteriorating but also gather labeled training data for\\ncontinuously improving the system. Figure 7-2 presents a simple anomaly detection\\nsystem with an integrated feedback loop.\\nFigure 7-2. Anomaly detection system with feedback loop\\nThe dashed line in Figure 7-2 indicates the information channel that security opera‐\\ntions analysts are able to use to give expert feedback to the system. False positives\\nproduced by the detector will be flagged by human experts, who then can make use of\\nthis feedback channel to indicate to the system that it made a mistake. The system\\nthen can convert this feedback into a labeled data point and use it for further training.\\nFeedback loops are immensely valuable because the labeled training samples they\\nproduce represent some of the most difficult predictions that the system has to make,\\nwhich can help ensure that the system does not make similar mistakes in the future.\\nNote that retraining with feedback may cause overfitting; you should take care to\\nintegrate this feedback with appropriate regularization. Feedback loops can also pose\\na security risk if the security operations analysts are not trusted personnel or if the\\n290 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 308}, page_content='9 Burr Settles, “Active Learning Literature Survey,” Computer Sciences Technical Report 1648, University of\\nWisconsin–Madison (2010).\\nsystem is somehow hijacked to provide malicious feedback. This will result in adver‐\\nsarial model poisoning; for example, red herring attacks, which will cause the model\\nto learn from mislabeled data and performance to rapidly degrade. In Chapter 8, we\\ndiscuss mitigation strategies for situations in which trust cannot be guaranteed within\\nthe system.\\nReinforcement Learning Versus Active Learning\\nTwo types of machine learning systems are closely related to online feedback.\\nReinforcement learning (RL) is an approach to machine learning that trains a model\\nthrough Markov processes and a feedback loop. RL algorithms attempt to strike a bal‐\\nance between stochastic exploration (to discover knowledge that the model does not\\nhave) and exploitation (to reinforce previously learned knowledge). By rewarding the\\nmodel when positive feedback is received and punishing the model when negative\\nfeedback is received, the RL models are trained in a radically different way from\\nsupervised learning, in which the “feedback” is provided to algorithms at the outset in\\nthe form of labels.\\nActive learning is a special type of semi-supervised learning in which a trained classi‐\\nfier model gets to pick data points that it is least confident of making predictions on\\nand ask human experts to provide labels for them. Humans provide the labels\\nthrough a feedback loop, which the algorithm will then use to train and improve its\\nmodel. Active learning is useful in the security space because it is well suited to the\\nfact that there is a lack of well-labeled security datasets. There are various strategies\\nfor picking samples to send for human review;9 we do not elaborate on them here, but\\nyou should explore the literature if you are thinking of using active learning to\\nimprove the accuracy of a model.\\nA/B testing, also known as split testing, refers to a randomized controlled experiment\\ndesigned to understand how system variants affect metrics. Most large websites today\\nrun hundreds or even thousands of A/B tests simultaneously, as different product\\ngroups seek to optimize different metrics. The standard procedure for an A/B test is\\nto randomly divide the user population into two groups, A and B and show each\\ngroup a different variant of the system in question (e.g., a spam classifier). Evaluating\\nthe experiment consists of collecting data on the metric to be tested from each group\\nand running a statistical test (usually a t-test or chi-squared test) to determine if the\\nmetric’s difference between the two groups is statistically significant.\\nModel Quality \\n| \\n291'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 309}, page_content='10 Tyler Lu, Dávid Pál, and Martin, Pál, “Contextual Multi-Armed Bandits,” Journal of Machine Learning\\nResearch Proceedings Track 9 (2010): 485–492.\\nA primary challenge in A/B testing is to figure out how much traffic to route through\\nthe new system (A, or the treatment group) and how much to route through the old\\nsystem (B, or the control group). This problem is a variation of the multi-armed bandit\\nproblem in probability theory, in which the solution must strike a balance between\\nexploration and exploitation. We want to be able to learn as much as possible about\\nthe new system by routing more traffic to it (in other words, to gain maximum statis‐\\ntical power for our test), but we don’t want to risk overall metrics degradation because\\nsystem A might have worse performance than the existing system B. One algorithm\\nthat addresses this problem is homson sampling, which involves routing to each var‐\\niant an amount of traffic proportional to the probability that a better result will be\\nyielded, based on prior collected data. Contextual multi-armed bandits10 take this\\napproach a step further and also bring external environmental factors into this\\ndecision-making process.\\nIn the context of machine learning systems, you should always validate and compare\\nnew generations of models against existing production models through A/B testing.\\nWhenever you apply such a test, there needs to be a well-defined metric that the test\\nis seeking to optimize. For instance, such a metric for a spam classifier A/B test could\\nbe the number of spam emails that end up in user email inboxes; you can measure\\nthis metric either via user feedback or via sampling and labeling.\\nA/B testing is critical to machine learning systems because evolutionary updates to\\nlong-running models (e.g., retraining) might not give you the best results that you\\ncan get. Being able to experiment with new models and determine empirically which\\ngives the best performance gives machine learning systems the flexibility required to\\nadapt to the changing landscape of data and algorithms.\\nHowever, you must be careful when running A/B tests in adversarial environments.\\nThe statistical theory behind A/B testing assumes that the underlying input distribu‐\\ntion is identical between the A and B segments. However, the fact that you are putting\\neven a small fraction of traffic through a new model can cause the adversary to\\nchange its behavior. In this case, the A/B testing assumption is violated and your sta‐\\ntistics won’t make sense. In addition, even if the adversary’s traffic is split between\\nsegments, the fact that some traffic now is acted upon differently can cause the adver‐\\nsary to change its behavior or even disappear, and the metric you really care about\\n(how much spam is sent) might not show a statistically significant difference in the\\nA/B test even though the new model was effective. Similarly, if you begin blocking\\n50% of the bad traffic with the new model, the adversary might simply double its\\nrequest rate, and your great model won’t change your overall metrics.\\n292 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 310}, page_content='Feature: Repeatable and Explainable Results\\nSometimes, just getting the right answer is not enough. In many cases, prediction\\nresults need to be reproducible for the purposes of audits, debugging, and appeals. If\\nan online account fraud model flags user accounts as suspicious, it should be consis‐\\ntent in its predictions. Systems need to be able to reproduce results predictably and\\nremove any effects of stochastic variability from the outward-facing decision-making\\nchain.\\nMachine learning systems are frequently evaluated with a single metric: prediction\\naccuracy. However, there are often more important factors in production environ‐\\nments that contribute to the success and adoption of a machine learning system,\\nespecially in the realm of security. The relationship between human and machine is\\nfraught with distrust, and a system that cannot convince a person that it is making\\nsound decisions (especially if at the cost of convenience) will quickly be discarded.\\nFurthermore, security machine learning systems are frequently placed in a path of\\ndirect action with real (potentially costly) consequences. If a malicious DNS classifier\\ndetects a suspicious DNS request made from a user’s machine, a reasonable and sim‐\\nple mitigation strategy might be to block the request. However, this response causes a\\ndisruption in the user’s workflow, which will in many cases trigger costly actions from\\nthe user; for example, a call to IT support. For cases in which the user cannot be con‐\\nvinced that the action has malicious consequences, they might even be tempted to\\nsearch for ways to bypass the detection system (often with success, because it is rare\\nthat all surfaces of exposure are covered).\\nBeyond contributing to the trust between human and machine, an arguably more\\nimportant effect of repeatable and explainable results is that system maintainers and\\nmachine learning engineers will be able to dissect, evaluate, and debug such systems.\\nWithout system introspection, improving such systems would be a very difficult task.\\nRepeatability of machine learning predictions is a simple concept: assuming con‐\\nstantly changing priors in a statistical system (due to continuous adaptation, manual\\nevolution, etc.), we should be able to reproduce any decision made by the system at\\nany reasonable point in its history. For instance, if a continuously adapting malware\\nclassifier used to mark a binary as benign but has now decided that it is malicious, it\\nwill be immensely useful to be able to reproduce past results and compare the system\\nstate (parameters/hyperparameters) over these different points in time. You can ach‐\\nieve this by regularly checkpointing system state and saving a description of the\\nmodel in a restorable location. Another way of reproducing results is to log the model\\nparameters with every decision made by the system.\\nExplainability of machine learning systems is a more complicated concept. What does\\nit mean for a machine learning system to be explainable? If you imagine how difficult\\nit is to explain every decision you make to another person, you begin to realize that\\nthis is not at all a straightforward requirement for machine learning systems. Yet, this\\nModel Quality \\n| \\n293'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 311}, page_content='is such an important area of research that it has attracted interest from all over aca‐\\ndemia, industry, and government. According to DARPA, “the goal of Explainable AI\\n(XAI) is to create a suite of new or modified machine learning techniques that pro‐\\nduce explainable models that, when combined with effective explanation techniques,\\nenable end users to understand, appropriately trust, and effectively manage the\\nemerging generation of AI systems.” This statement sets out a long-term goal, but\\nthere are some concrete things that we can do to improve the explainability of today’s\\nmachine learning systems.\\nExplainability is critical to building trust in your machine learning system. If a fraud\\ndetection system detects a suspicious event, the consequent side effects will likely\\ninvolve a human that may question the validity of the decision. If the alert goes to\\nsecurity operations analysts, they will need to manually check whether fraud is indeed\\nat play. If the reasons for the alert being raised are not obvious, analysts might errone‐\\nously flag the event as a false alarm even if the system was actually correct.\\nIn essence, a system is explainable if it presents enough decision-making information to\\nallow the user to derive an explanation for the decision. Humans have access to a body\\nof cultural and experiential context that enables us to derive explanations for deci‐\\nsions from sparse data points, whereas incorporating such context is difficult for\\n(current) machines to achieve. For example, a “human explanation” for why a binary\\nfile is deemed malicious might be that it installs a keylogger on your machine to\\nattempt to steal credentials for your online accounts. However, users in most contexts\\ndon’t require this much information. If such a system is able to explain that this deci‐\\nsion was made because uncommon system hooks to the keyboard event driver were\\ndetected and this behavior has a strong historical association with malware, it would\\nbe sufficient for a user to understand why the system drew the conclusion.\\nIn some cases, however, explainability and repeatability of results don’t matter so\\nmuch. When Netflix recommends to you a movie on your home screen that you just\\naren’t that into, does it really matter to you? The importance of strong accountability\\nin predictions and recommendations is a function of the importance and effects of\\nsingular decisions made by the system. Each decision in a security machine learning\\nsystem can have large consequences, and hence explainability and repeatability are\\nimportant to consider when taking such systems to production.\\nGenerating explanations with LIME\\nSome current methods approach the explainability problem by finding the localized\\nsegments of input that contribute most to the overall prediction result. Local\\n294 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 312}, page_content='11 Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin, \"Why Should I Trust You?: Explaining the Predic‐\\ntions of Any Classifier,” Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discov‐\\nery and Data Mining (2016): 1135–1144.\\n12 Ryan Turner, “A Model Explanation System,” Black Box Learning and Inference NIPS Workshop (2015).\\n13 Ryan Turner, “A Model Explanation System: Latest Updates and Extensions,” Proceedings of the 2016 ICML\\nWorkshop on Human Interpretability in Machine Learning (2016): 1–5.\\n14 Full code is provided as a Python Jupyter notebook chapter7/lime-explainability-spam-ighting.ipynb in our\\ncode repository.\\nInterpretable Model-Agnostic Explanations (LIME)11 and Turner’s Model Explanation\\nSystem (MES)12,13 both belong to this school of thought. LIME defines explanations as\\nlocal linear approximations of a machine learning model’s behavior: “While the\\nmodel may be very complex globally, it is easier to approximate it around the vicinity\\nof a particular instance.” By repeatedly perturbing localized segments of the input and\\nfeeding it through the model and then comparing the results obtained when certain\\nsegments are omitted or included, LIME can generate linear and localized explana‐\\ntions for the classifier’s decisions. Let’s apply LIME to the multinomial Naive Bayes\\nspam classification example from Chapter 1 to see if we can get some explanations to\\nhelp us understand the system’s decision-making process:14\\nfrom sklearn.pipeline import make_pipeline\\nfrom lime.lime_text import LimeTextExplainer\\n# Define the class_names with positions in the list that\\n# correspond to the label, i.e. \\'Spam\\' -> 0, \\'Ham\\' -> 1\\nclass_names = [\\'Spam\\', \\'Ham\\']\\n# Construct a sklearn pipeline that will first apply the\\n# vectorizer object (CountVectorizer) on the dataset, then\\n# send it through the mnb (MultinomialNB) estimator instance\\nc_mnb = make_pipeline(vectorizer, mnb)\\n# Initialize the LimeTextExplainer object\\nexplainer_mnb = LimeTextExplainer(class_names=[\\'Spam\\', \\'Ham\\'])\\nWe now can use explainer_mnb to generate explanations for individual samples:\\n# Randomly select X_test[11121] as the sample\\n# to generate an explanation for\\nidx = 11121\\n# Use LIME to explain the prediction using at most\\n# 10 features (arbitrarily selected) in the explanation\\nexp_mnb = explainer_mnb.explain_instance(\\n    X_test[idx], c_mnb.predict_proba, num_features=10)\\n# Print prediction results\\nprint(\\'Email file: %s\\' % \\'inmail.\\' + str(idx_test[idx]+1))\\nModel Quality \\n| \\n295'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 313}, page_content=\"print('Probability(Spam) = %.3f' % c_mnb.predict_proba([X_test[idx]])[0,0])\\nprint('True class: %s' % class_names[y_test[idx]])\\n> Email file: inmail.60232\\n> Probability(Spam) = 1.000\\n> True class: Spam\\nLooking at an excerpt of the email subject/body for inmail.60232, it’s quite obvious\\nthat this is indeed spam:\\nBachelor Degree in 4 weeks, Masters Degree in no more than 2 months. University\\nDegree OBTAIN A PROSPEROUS FUTURE, MONEY-EARNING POWER, AND\\nTHE PRESTIGE THAT COMES WITH HAVING THE CAREER POSITION YOUVE\\nALWAYS DREAMED OF. DIPLOMA FROM PRESTIGIOUS NON-ACCREDITED\\nUNVERSITIES BASED ON YOUR PRESENT KNOWLEDGE AND PROFESSIONAL\\nEXPERIENCE.If you qualify …\\nWe can dig deeper and inspect the weighted feature list produced by the explainer.\\nThese weighted features represent a linear model that approximates the behavior of\\nthe multinomial Naive Bayes classifier in the localized region of the selected data\\nsample:\\nexp_mnb.as_list()\\n> [(u'PROSPEROUS', −0.0004273209832636173),\\n   (u'HolidaysTue', −0.00042036070378471198),\\n   (u'DIPLOMA', −0.00041735867961910481),\\n   (u'Confidentiality', −0.00041301526556397427),\\n   (u'Degree', −0.00041140081539794645),\\n   (u'682', −0.0003778027616648757),\\n   (u'00', −0.00036797175961264029),\\n   (u'tests', 4.8654872568674994e−05),\\n   (u'books', −4.0641140958656903e-05),\\n   (u'47', 1.0821887948671182e-05)]\\nFigure 7-3 presents this data in chart form.\\nFigure 7-3. Linear weighted features contributing to MNB prediction\\n296 \\n| \\nChapter 7: Production Systems\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 314}, page_content='Observe that the words “PROSPEROUS,” “HolidaysTue,” “DIPLOMA,” and so on\\ncontribute negatively to the sample being classified as ham. More specifically, remov‐\\ning the word “PROSPEROUS” from the sample would cause the multinomial Naive\\nBayes algorithm to classify this example as spam with 0.0427% less confidence. This\\nexplanation that LIME produces allows an end user to inspect the components that\\ncontribute to a decision that a machine learning algorithm makes. By approximating\\narbitrary machine learning models with a localized and linear substitute model\\n(described by the linear weighted features as illustrated in Figure 7-3), LIME does not\\nrequire any specific model family and can easily be applied to existing systems.\\nPerformance\\nBy nature, many security machine learning systems are in the direct line of traffic,\\nwhere they are forced to make rapid-fire decisions or risk falling behind. Detecting an\\nanomaly 15 minutes after the event is often too late. Systems that have real-time\\nadaptability requirements must also meet a high bar for efficiently implementing con‐\\ntinuous incremental retraining.\\nProduction machine learning systems have much stricter performance requirements\\nthan experimental prototypes. In some cases, prediction latencies that exceed the mil‐\\nlisecond range can cause the downfall of an entire system. Furthermore, systems tend\\nto fail when bombarded with a high load unless they are designed to be fault-tolerant\\nand highly scalable. Let’s look at some ways to achieve low latency and high scalability\\nin machine learning systems.\\nGoal: Low Latency, High Scalability\\nMachine learning, especially on large datasets, is a computationally intensive task.\\nScikit-learn puts out respectable performance numbers by any measure, and contrib‐\\nutors are constantly making performance improvements to the project. Nevertheless,\\nthis performance can still be insufficient for the demands of some applications. For\\nsecurity machine learning systems in critical decision paths, the end user’s tolerance\\nfor high-latency responses might be limited. In such cases, it is often a good design\\nchoice to take machine learning systems out of the main line of interaction between\\nusers and a system.\\nYour security system should make its decisions asynchronously wherever possible,\\nand it should be able to remediate or mitigate threats in a separate and independent\\npath. For example, a web application intrusion detection system (IDS) implemented\\nusing machine learning can be continuously queried with incoming requests. This\\nIDS must make real-time decisions as to whether a request is a threat. The web appli‐\\ncation can choose to let the request pass if it does not receive a reply from the IDS\\nwithin a certain time threshold, so as not to the degrade user experience with unbear‐\\nable wait times when the system is overloaded. When the IDS eventually returns a\\nPerformance \\n| \\n297'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 315}, page_content='15 Parallelism as a method for performance optimization is elaborated on further in “Horizontal Scaling with\\nDistributed Computing Frameworks” on page 300.\\n16 Chih-Chung Chang and Chih-Jen Lin, “LIBSVM: A Library for Support Vector Machines,” Transactions on\\nIntelligent Systems and Technology 2:3 (2011).\\nresult and indicates that that previously passed request was a suspicious entity, it can\\ntrigger a hook within the web application to inform it of this decision. The web appli‐\\ncation can then choose to perform a variety of mitigating actions, such as immedi‐\\nately disallowing further requests made by the user.\\nHowever, such a system design might be unsuitable in some cases. For instance, if a\\nsingle malicious request can cause a significant data breach, the attacker’s objectives\\nmight have already been met by the time the IDS decision is made. Attackers can\\neven bombard the system with dummy requests to cause a slowdown in the IDS and\\nincrease the attack window. In such cases it is worthwhile to invest resources to opti‐\\nmizing the machine learning system to minimize latency, especially when under\\nheavy load. (This scenario can arguably also be solved with tweaks to system design—\\nsingle requests should not be allowed to cause a significant data breach or seriously\\ndamage a system.)\\nPerformance Optimization\\nTo speed up machine learning applications, we can search for performance bottle‐\\nnecks in the program execution framework, find more efficient algorithms, or use\\nparallelism. Let’s consider these different approaches:15\\nProiling and framework optimization\\nSotware proiling is a method of dynamically analyzing the performance of a\\nprogram. We do this instrumenting of the software with a tool called a proiler.\\nThe profiler typically inserts hooks into components, functions, events, code, or\\ninstructions being executed, and does a deep analysis of the time it takes for each\\nindividual component to run. The data collected allows the operator to gain deep\\ninsight into the internal performance characteristics of the software and identify\\nperformance bottlenecks. Profiling is a well-known and general part of the soft‐\\nware developer’s toolkit, and should be actively used by machine learning engi‐\\nneers working on optimizing algorithms or systems for production.\\nCore algorithms in scikit-learn are frequently Cython wrappers around other\\npopular and well-maintained machine learning libraries written in native C\\nor C++ code. For example, the SVM classes in scikit-learn mostly hook into\\nLIBSVM,16 which is written in C++. Furthermore, matrix multiplication (which\\nis a very common operation in machine learning algorithms) and other vector\\ncomputations are usually handled by NumPy, which uses native code and\\n298 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 316}, page_content=\"17 See the recipe “Getting the Best Performance out of NumPy” from Cyrille Rossant’s IPython Interactive Com‐\\nputing and Visualization Cookbook (Packt).\\nmachine-level optimizations to speed up operations.17 Nevertheless, there are\\nalways performance bottlenecks, and performance profiling is a good way to\\nfind them if performance is a problem in your machine learning application. The\\nIPython integrated profiler is a good place to start. When dealing with large data‐\\nsets and memory-intensive models, the program might be memory bound rather\\nthan compute bound. In such cases, a tool like memory_profiler can help to find\\ncertain lines or operations that are memory hogs so that you can remedy the\\nproblem.\\nOptimized Linear Algebra Frameworks\\nScikit-learn and NumPy use highly optimized native linear algebra frameworks\\nsuch as Basic Linear Algebra Subprograms (BLAS) and Linear Algebra PACKage\\n(LAPACK) if the distribution is linked with these libraries. If profiling suggests\\nthat the performance bottleneck lies in matrix multiplication routines, the distri‐\\nbution of scikit-learn you are using may not be compiled to use BLAS, and the\\nmuch slower numpy.dot() function might have been invoked. Adding the follow‐\\ning lines to your scikit-learn application can help warn you when the BLAS pack‐\\nage is not available or if numpy.dot() is suboptimally invoked:\\nimport warnings\\nfrom sklearn.exceptions import NonBLASDotWarning\\nwarnings.simplefilter('always', NonBLASDotWarning)\\nThere is an endless list of framework-level performance optimizations that you\\ncan apply to machine learning applications that we will not go into here. Such\\noptimizations will commonly help algorithms achieve speed increases of two to\\nfive times, but it is rare for major improvements to result from these.\\nAlgorithmic optimization\\nAlgorithmic improvements and picking efficient models can often bring greater\\nperformance improvements. Losing some accuracy for a huge performance\\nimprovement can be a worthwhile trade-off, depending on the context. Because\\nmodel selection is such a context- and application-specific process, there is no\\nhard-and-fast ruleset for how to achieve better performance and scalability by\\nchoosing certain algorithms over others. Nonetheless, here is a teaser list of tips\\nthat might be useful in your decision-making process:\\nPerformance \\n| \\n299\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 317}, page_content='18 This observation comes with hefty caveats: for instance, model size, GPU versus CPU, and so on.\\n19 Stephen Boyd et al., “Distributed Optimization and Statistical Learning via the Alternating Direction Method\\nof Multipliers,” Foundations and Trends in Machine Learning 3 (2011): 1–122.\\n20 Edward Y. Chang et al., “PSVM: Parallelizing Support Vector Machines on Distributed Computers,” Proceed‐\\nings of the 20th International Conference on Neural Information Processing Systems (2007) 257–264.\\n• Having fewer features means having to do fewer arithmetic operations,\\nwhich can improve performance. Applying dimensionality reduction meth‐\\nods to remove useless features from your dataset can improve performance.\\n• Tree-based models (e.g., decision trees, random forests) tend to have very\\ngood prediction performance because every query interacts only with a small\\nportion of the model space (one root-to-leaf path per tree). Depending on\\narchitecture and hyperparameter choices, neural network predictions can\\nsometimes be speedier than random forests.18\\n• Linear models are fast to train and evaluate. Training of linear models can be\\nparallelized with a popular algorithm called the Alternating Direction\\nMethod of Multipliers (ADMM),19 which allows the training of large linear\\nmodels to scale very well.\\n• SVMs suffer from widely known scalability problems. They are one of the\\nslower model families to train and are also very memory intensive. Simple\\nlinear SVMs are usually the only choice for deploying on large datasets.\\nHowever, evaluations can be quite fast if kernel projections are not too com‐\\nplex. It is possible (but complicated) to parallelize SVM training.20\\n• Deep learning algorithms (deep neural nets) are slow to train and quite\\nresource intensive (typically at least millions of matrix multiplications\\ninvolved), but can easily be parallelized with the appropriate hardware—e.g.,\\ngraphics processing units (GPUs)—and modern frameworks such as Tensor‐\\nFlow, Torch, or Caffe.\\n• Approximate nearest neighbor search algorithms such as k-d trees (which we\\nintroduced in Chapter 2) can significantly speed up close-proximity searches\\nin large datasets. In addition, they are generally very fast to train and have\\nvery fast average performance with bounded error. Locality sensitive hashing\\n(LSH, which we used in Chapter 1) is another approximate nearest neighbor\\nsearch method.\\nHorizontal Scaling with Distributed Computing Frameworks\\nParallelization is a key tenet of performance optimization. By distributing a collection\\nof 100 independent compute operations to 100 servers, we can achieve a speedup in\\nprocessing time of up to 100 times (ignoring I/O and shuffling latency). Many steps\\n300 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 318}, page_content=\"21 Jeffrey Dean and Sanjay Ghemawat, “MapReduce: Simplified Data Processing on Large Clusters,” Proceedings\\nof the 6th Symposium on Operating Systems Design and Implementation(2004): 137–150.\\n22 This example uses version 0.2.0 of the spark-sklearn library.\\nof the machine learning process can benefit from parallelism, but many datasets and\\nalgorithms cannot be “blindly distributed” because each unit of operation might not\\nbe independent. For instance, the training of a random forest classifier is embarrass‐\\ningly parallel because each randomized decision tree that makes up the forest is inde‐\\npendently created and can be individually queried for the generation of the final\\nprediction. However, other algorithms (e.g., SVMs) are not so straightforward to par‐\\nallelize, because they require frequent global message passing (between nodes) during\\nthe training and/or prediction phase, which can sometimes incur an exponentially\\nincreasing cost as the degree of distribution increases. We do not go into the theory of\\nparallel machine learning here; instead, let’s look at how to take advantage of frame‐\\nworks to horizontally scale our machine learning systems in the quickest ways\\npossible.\\nDistributed machine learning is not just about training classification or clustering\\nalgorithms on multiple machines. Scikit-learn is designed for single-node execution,\\nbut there are some types of tasks that are better suited for the distributed computing\\nparadigm. For instance, hyperparameter optimization and model search operations\\n(discussed in “Problem: Hyperparameter Optimization” on page 285) create a large\\nnumber of symmetrical tasks with no mutual dependency. These types of embarrass‐\\ningly parallel tasks are well suited for distributed MapReduce21 frameworks such as\\nApache Spark. Spark is an open source distributed computing platform that heavily\\nuses memory-based architectures, lazy evaluation, and computation graph optimiza‐\\ntion to enable high-performance MapReduce-style programs.\\nspark-sklearn is a Python package that integrates the Spark computing framework\\nwith scikit-learn, focused on hyperparameter optimization. Even though there is (as\\nof this writing) quite a limited set of scikit-learn’s functionality implemented in spark-\\nsklearn, the classes that do exist are drop-in replacements into existing scikit-learn\\napplications. Let’s see how the spark_sklearn.GridSearchCV22 class can help with\\nour digit classification Support Vector Classifier hyperparameter search operation\\nfrom the section “Solutions: Hyperparameter Optimization” on page 285:\\nfrom sklearn.svm import SVC\\nimport numpy as np\\nfrom time import time\\nfrom spark_sklearn import GridSearchCV # This is the only changed line\\n# Define a dictionary containing all hyperparameter values to try\\nhyperparam_grid = {\\n    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\\n    'gamma': np.linspace(0.001, 0.01, num=10),\\nPerformance \\n| \\n301\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 319}, page_content=\"23 Eight Intel Broadwell CPUs, 30 GB memory.\\n24 Note that spark-sklearn does not implement individual learning algorithms such as SVMs or k-means. It cur‐\\nrently implements only simple and easily parallelized tasks like grid search cross-validation.\\n    'C': np.linspace(1, 10, num=10),\\n    'tol': np.linspace(0.001, 0.01, 10)\\n}\\nclassifier = GridSearchCV(svc, hyperparam_grid)\\nstart = time()\\nclassifier.fit(X_train, y_train)\\nelapsed = time() – start\\n...\\nprint('elapsed: %.2f seconds' % elapsed)\\n> elapsed: 1759.71 seconds\\n> Best Kernel: rbf\\n> Best Gamma: 0.001\\n> Best C: 2.0\\n> Accuracy: 0.991\\nThe hyperparam_grid passed into GridSearchCV specifies values for four hyperpara‐\\nmeters that the optimization algorithm needs to consider. In total, there are 4,000\\nunique value combinations, which take 1,759.71 seconds to complete on a single\\neight-core23 machine using scikit-learn’s GridSearchCV. If we use the spark-sklearn\\nlibrary’s GridSearchCV instead (as in the preceding code snippet), and run the pro‐\\ngram on a five-node Spark cluster (one master, four workers, all the same machine\\ntype as in the single-machine example), we see an almost linear speedup—the tasks\\nare executed only on the four-worker nodes:\\n> elapsed: 470.05 seconds\\nEven though spark-sklearn is very convenient to use and allows you to parallelize\\nhyperparameter optimization across a cluster of machines with minimal development\\neffort, its feature set is quite small.24 Furthermore, it is intended for datasets that fit in\\nmemory, which limits its usefulness. For more heavyweight production applications, \\nSpark ML offers a respectable set of parallelized algorithms that have been imple‐\\nmented and optimized to run as MapReduce-style jobs on distributed Spark clusters.\\nAs one of the most mature and popular distributed machine learning frameworks,\\nSpark ML goes beyond providing common machine learning algorithms for classifi‐\\ncation and clustering: it also provides for distributed feature extraction and transfor‐\\nmation, allows you to create pipelines for flexible and maintainable processing, and\\nlets you save serialized versions of machine learning objects for checkpointing and\\nmigration.\\n302 \\n| \\nChapter 7: Production Systems\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 320}, page_content=\"25 Full code can be found as a Python Jupyter notebook at chapter7/spark-mllib-spam-ighting.ipynb in our code\\nrepository.\\nLet’s try using some of the Spark ML APIs on the same spam classification dataset\\nthat we used in Chapter 1 as well as earlier in this chapter, in “Generating explana‐\\ntions with LIME” on page 294. In particular, we will focus on using Spark ML pipe‐\\nlines to streamline our development workflow. Similar to scikit-learn pipelines, Spark\\nML pipelines allow you to combine multiple sequential operations into a single logi‐\\ncal stream, facilitated by a unified API interface. Pipelines operate on Spark Data‐\\nFrames, which are optimized columnar-oriented datasets, similar to Pandas\\nDataFrames but supporting Spark transformations. We implement a spam classifica‐\\ntion pipeline using Spark ML, omitting the email parsing and dataset formatting code\\nbecause we can reuse the same code as before:25\\nfrom pyspark.sql.types import *\\nfrom pyspark.ml import Pipeline\\nfrom pyspark.ml.feature import Tokenizer, CountVectorizer\\nfrom pyspark.ml.classification import RandomForestClassifier\\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\\n# Read in the raw data\\nX, y = read_email_files()\\n# Define a DataFrame schema to specify the names and\\n# types of each column in the DataFrame object we will create\\nschema = StructType([\\n            StructField('id', IntegerType(), nullable=False),\\n            StructField('email', StringType(), nullable=False),\\n            StructField('label', DoubleType(), nullable=False)])\\n# Create a Spark DataFrame representation of the data with\\n# three columns, the index, email text, and numerical label\\ndf = spark.createDataFrame(zip(range(len(y)), X, y), schema)\\n# Inspect the schema to ensure that everything went well\\ndf.printSchema()\\n> root\\n  |-- id: integer (nullable = false)\\n  |-- email: string (nullable = false)\\n  |-- label: double (nullable = false)\\nA small quirk of Spark ML is that it requires labels to be of the Double type. (If you\\nfail to specify this, you will run into errors when executing the pipeline.) We created a\\nStructType list in the preceding example, which we passed as the schema into the\\nspark.createDataFrame() function for converting the Python list-type dataset to a\\nSpark DataFrame object. Now that we have our data in a Spark-friendly format, we\\nPerformance \\n| \\n303\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 321}, page_content=\"can define our pipeline (almost all Spark ML classes support the explainParams() or\\nexplainParam(paramName) function, which conveniently prints out the relevant doc‐\\numentation snippets to give you a description of the parameters for this class—a very\\nuseful feature, especially given that Spark ML documentation is sometimes difficult to\\nlocate):\\n# Randomly split the dataset up into training and test sets, where\\n# TRAINING_SET_RATIO=0.7 (seed set for reproducibility)\\ntrain, test = df.randomSplit([TRAINING_SET_RATIO, 1-TRAINING_SET_RATIO], seed=123)\\n# First, tokenize the email string (convert to\\n# lowercase then split by whitespace)\\ntokenizer = Tokenizer()\\n# Second, convert the tokens into count vectors\\nvectorizer = CountVectorizer()\\n# Third, apply the RandomForestClassifier estimator\\nrfc = RandomForestClassifier()\\n# Finally, create the pipeline\\npipeline = Pipeline(stages=[tokenizer, vectorizer, rfc])\\nA convenient feature of ML pipelines is the ability to specify parameters for pipeline\\ncomponents in a parameter dictionary that can be passed into the pipeline upon exe‐\\ncution. This allows for neat separation of application logic and tunable parameters,\\nwhich might seem like a small feature but can make a lot of difference in the main‐\\ntainability of code. Notice that we didn’t specify any parameters when initializing the\\npipeline components (Tokenizer, CountVectorizer, RandomForestClassifier) in\\nthe previous example—if we had specified any, they would just have been overwritten\\nby parameters passed in the call to the pipeline.fit() function, which executes the\\npipeline:\\n# Define a dictionary for specifying pipeline component parameters\\nparamMap = {\\n    tokenizer.inputCol: 'email',\\n    tokenizer.outputCol: 'tokens',\\n    vectorizer.inputCol: 'tokens',\\n    vectorizer.outputCol: 'vectors',\\n    rfc.featuresCol: 'vectors',\\n    rfc.labelCol: 'label',\\n    rfc.numTrees: 500\\n}\\n# Apply all parameters to the pipeline,\\n# execute the pipeline, and fit a model\\nmodel = pipeline.fit(train, params=paramMap)\\n304 \\n| \\nChapter 7: Production Systems\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 322}, page_content=\"26 This example was run on a five-node Spark cluster (one master, four workers) on Google’s DataProc engine.\\n27 For details on all of these, see the documentation.\\nWe now have a trained pipeline model that we can use to make predictions. Let’s run\\na batch prediction on our test set and evaluate it using the BinaryClassificationEva\\nluator object, which automates all of the data wrangling necessary for generating\\nevaluation metrics:\\n# Make predictions on the test set\\nprediction = model.transform(test)\\n# Evaluate results using a convenient Evaluator object\\nevaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction')\\npr_score = evaluator.evaluate(prediction,\\n{evaluator.metricName: 'areaUnderPR'})\\nroc_score = evaluator.evaluate(prediction,\\n{evaluator.metricName: 'areaUnderROC'})\\nprint('Area under ROC curve score: {:.3f}'.format(roc_score))\\nprint('Area under precision/recall curve score: {:.3f}'.format(pr_score))\\n> Area under ROC curve score: 0.971\\n> Area under precision/recall curve score: 0.958\\nWith the help of Spark ML, we have written a concise yet highly scalable piece of code\\nthat can handle a punishing load of data.26 Spark ML pipelines help create elegant\\ncode structure, which can be very helpful as your code base grows. You can also add\\nhyperparameter optimization logic to the pipeline by configuring a ParamGrid\\nBuilder object (for specifying hyperparameter candidates) and a CrossValidator or\\nTrainValidationSplit object (for evaluating hyperparameter/estimator efficacy).27\\nSpark provides convenient ways to use parallelization and cluster computing to ach‐\\nieve lower latencies and higher scalability in machine learning systems. Distributed\\nprogramming can be significantly more complicated than local development in\\nscikit-learn, but the investment in effort will pay dividends over time.\\nUsing Cloud Services\\nThe machine-learning-as-a-service market is predicted to grow to $20 billion by\\n2025. All of the popular public cloud providers have several machine learning and\\ndata infrastructure offerings that you can use to quickly and economically scale your\\noperations. These services relieve organizations of the operational overhead of man‐\\naging a Spark cluster or TensorFlow deployment that requires significant effort to\\nconfigure and maintain.\\nPerformance \\n| \\n305\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 323}, page_content='The largest players in the public cloud arena, such as Amazon Web Services (AWS)\\nand Google Cloud Platform (GCP), provide powerful APIs for video, speech, and\\nimage analysis using pretrained machine learning models. They also provide server‐\\nless interfaces to run experimental or production machine learning jobs, without ever\\nhaving to link via Secure Shell (SSH) into an instance to install dependencies or\\nreboot processes. For example, Google Cloud Dataflow is a fully managed platform\\nthat allows users to execute jobs written in the Apache Beam unified programming\\nmodel, without having to fret over load and performance. Scaling up to 10 times the\\nthroughput will simply be a matter of changing a parameter to launch approximately\\n10 times more instances to deal with the load. Google Cloud Dataproc is a managed\\nSpark and Hadoop service that allows you to spin up large clusters of machines (pre‐\\nloaded and preconfigured with Spark, Hadoop, Pig, Hive, Yarn, and other distributed\\ncomputing tools) in “less than 90 seconds on average.” For instance, setting up a five-\\nnode Spark cluster on Dataproc for running the Spark ML spam classification exam‐\\nple from earlier in this section took less than a minute after running this gcloud\\ncommand on the command line:\\ngcloud dataproc clusters create cluster-01 \\\\\\n    --metadata \"JUPYTER_CONDA_PACKAGES=numpy:pandas:scipy:scikit-learn\" \\\\\\n    --initialization-actions \\\\\\n        gs://dataproc-initialization-actions/jupyter/jupyter.sh \\\\\\n    --zone us-central1-a \\\\\\n    --num-workers 4 \\\\\\n    --worker-machine-type=n1-standard-8 \\\\\\n    --master-machine-type=n1-standard-8\\nThe cluster creation command allows users to specify initialization-actions—a\\nscript for installing custom packages and data/code dependencies that will be exe‐\\ncuted during the provisioning phase of each machine in the cluster. In the preceding\\ncommand, we used an initialization-actions script to install a Jupyter notebook\\nand the Python package dependencies Pandas, SciPy, and so on.\\nAmazon Machine Learning allows even novices to take advantage of machine learn‐\\ning by uploading data to their platforms (e.g., S3 or Redshift) and “creating” a\\nmachine learning model by tweaking some preference settings on a web interface. \\nGoogle Cloud ML Engine allows for much more flexibility, giving users the ability to\\nrun custom TensorFlow model training code on a serverless architecture, and then\\nsave the trained model and expose it through a predictions API. This infrastructure\\nmakes it possible for machine learning engineers to focus solely on the efficacy of\\ntheir algorithms and outsource operational aspects of deploying and scaling a\\nmachine learning system.\\nUsing cloud services can give organizations a lot of flexibility in experimenting with\\nmachine learning solutions. These solutions will often even be more cost effective\\nafter you consider all of the operational and maintenance costs that go into manually\\nmanaging machine learning deployments. For organizations that must deal with\\n306 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 324}, page_content='28 D. Sculley et al., “Hidden Technical Debt in Machine Learning Systems,” Proceedings of the 28th International\\nConference on Neural Information Processing Systems (2015): 2503–2511.\\n29 Joost Visser et al., Building Maintainable Sotware, Java Edition: Ten Guidelines for Future-Proof Code (Sebasto‐\\npol, CA: O’Reilly Media, 2016).\\nvariation in machine learning system implementation and architectures, or operate\\nsystems that will potentially need to scale significantly over a short period of time,\\nusing public cloud offerings such as Google Cloud ML Engine makes a lot of sense.\\nHowever, the availability of such services is entirely dependent on their parent organ‐\\nization’s business needs (i.e., how profitable it is to Amazon, Google, Microsoft, etc.),\\nand building critical security services on top of them might not be a sound strategic\\ndecision for everyone.\\nMaintainability\\nSuccessful machine learning systems in production often outlive their creators\\n(within an organization). As such, these systems must be maintained by engineers\\nwho don’t necessarily understand why certain development choices were made.\\nMaintainability is a software principle that extends beyond security and machine\\nlearning. All software systems should optimize for maintainability, because poorly\\nmaintained systems will eventually be deprecated and killed. Even worse, such sys‐\\ntems can limp along for decades, draining resources from the organization and pre‐\\nventing it from implementing its goals. A recent paper from Google28 argues that due\\nto their complexity and dependence on ever-changing data, machine learning sys‐\\ntems are even more susceptible than other systems to buildup of technical debt.\\nIn this section we briefly touch on a few maintainability concepts. We do not go into\\ngreat detail, because many of these concepts are covered in depth in dedicated\\npublications.29\\nProblem: Checkpointing, Versioning, and Deploying Models\\nIs a machine learning model code or data? Because models are so tightly coupled to\\nthe nature of the data used to generate them, there is an argument that they should be\\ntreated as data, because code should be independent of the data it processes. However,\\nthere is operational value in subjecting models to the same versioning and deploy‐\\nment processes that conventional source code is put through. Our view is that\\nmachine learning models should be treated both as code and data. Storing model\\nparameters/hyperparameters in version-control systems such as Git makes the resto‐\\nration of previous models very convenient when something goes wrong. Storing\\nmodels in databases allows for querying parameters across versions in parallel, which\\ncan be valuable in some contexts.\\nMaintainability \\n| \\n307'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 325}, page_content='30 Alex Guazzelli et al., “PMML: An Open Standard for Sharing Models,” he R Journal 1 (2009): 60–65.\\nFor audit and development purposes, it is good to ensure that any decision that a sys‐\\ntem makes at any point in time can be reproduced. For instance, consider a web\\napplication anomaly detection server that flags a particular user session as anoma‐\\nlous. Because of the high fluctuations in input that web applications can see, this sys‐\\ntem attempts to continuously measure and adapt to the changing traffic through\\ncontinuous and automatic parameter tuning. Furthermore, machine learning models\\nare continuously tuned and improved over time, whether due to automated learning\\nmechanisms or human engineers. Checkpointing and versioning of models enables\\nus to see if this user session would have triggered the model from two months ago.\\nSerializing models for storage can be as simple as using the Python pickle object\\nserialization interface. For space and performance efficiency as well as better portabil‐\\nity, you can use a custom storage format that saves all parameter information\\nrequired to reconstruct a machine learning model. For instance, storing all the feature\\nweights of a trained linear regression model in a JSON file is a platform- and\\nframework-agnostic way to save and reconstruct linear regressors.\\nPredictive Model Markup Language (PMML) is the leading open standard for XML-\\nbased serialization and sharing of predictive data mining models.30 Besides storing\\nmodel parameters, the format can also encode various transformations applied to the\\ndata in preprocessing and postprocessing steps. A convenient feature of the PMML\\nformat is the ability to develop a model using one machine learning framework and\\ndeploy it on a different machine learning framework. As the common denominator\\nbetween different systems, PMML enables developers to compare the performance\\nand accuracy of the same model executed on different machine learning frameworks.\\nThe deployment mechanism for machine learning models should be engineered to be\\nas foolproof as possible. Machine learning systems can be deployed as web services\\n(accessible via REST APIs, for example), or embedded in backend software. Tight\\ncoupling with other systems is discouraged because it causes a lot of friction during\\ndeployment and results in a very inflexible framework. Accessing machine learning\\nsystems through APIs adds a valuable layer of indirection which can lend a lot of flex‐\\nibility during the deployment, A/B testing, and debugging process.\\nGoal: Graceful Degradation\\nSoftware systems should fail gracefully and transparently. If a more advanced and\\ndemanding version of a website does not work on an old browser, a simpler, light‐\\nweight version of the site should be served instead. Machine learning systems are no\\ndifferent. Graceful failure is an important feature for critical systems that have the\\npotential to bring down the availability of other systems. Security systems are\\n308 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 326}, page_content='frequently in the critical path, and there has to be a well-defined policy for how to\\ndeal with failure scenarios.\\nShould security systems fail open (allow requests through if the system fails to\\nrespond) or fail closed (block all requests if the system fails to respond)? This ques‐\\ntion cannot be answered without a comprehensive study of the application, weighing\\nthe risk and cost of an attack versus the cost of denying real users access to an appli‐\\ncation. For example, an authentication system will probably fail closed, because fail‐\\ning open would allow anybody to access the resources in question; an email spam\\ndetection system, on the other hand, will fail open, because blocking everyone’s email\\nis much more costly than letting some spam through. In the general case, the cost of a\\nbreach vastly outweighs the cost of users being denied service, so security systems\\ntypically favor policies that define a fail-closed strategy. In some scenarios, however,\\nthis will make the system vulnerable to denial-of-service attacks, since attackers sim‐\\nply have to take down the security gateway to deny legitimate users access to the\\nentire system.\\nGraceful degradation of security systems can also be achieved by having simpler\\nbackup systems in place. For instance, consider the case in which your website is\\nexperiencing heavy traffic volumes and your machine learning system that differenti‐\\nates real human traffic from bot traffic is at risk of buckling under the stress. It may\\nbe wise to fall back to a more primitive and less resource-intensive strategy of\\nCAPTCHAs until traffic returns to normal.\\nA well-thought-out strategy for ensuring continued system protection when security\\nsolutions fail is important because any loopholes in your security posture (e.g.,\\ndecreased system availability) represent opportunities for attackers to get in.\\nGoal: Easily Tunable and Conigurable\\nReligious separation of code and configuration is a basic requirement for all\\nproduction-quality software. This principle holds especially true for security machine\\nlearning systems. In the world of security operations, configurations to security sys‐\\ntems often have to be tuned by security operations analysts, who don’t necessarily\\nhave a background in software development. Designing software and configuration\\nthat empowers such analysts to tune systems without the involvement of software\\nengineers can significantly reduce the operational costs of such systems and make for\\na more versatile and flexible organization.\\nMaintainability \\n| \\n309'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 327}, page_content='31 “Architecting a Machine Learning System for Risk”, by Naseem Hakim and Aaron Keys, provides an insightful\\nview into how a large company like Airbnb designs real-time security machine learning and risk-scoring\\nframeworks.\\n32 Slawek Ligus, Efective Monitoring and Alerting for Web Operations (Sebastopol, CA: O’Reilly Media, 2012).\\nMonitoring and Alerting\\nSecurity machine learning systems should be fast and robust. Ideally, such systems\\nshould never see any downtime and predictions should be made in near real time.31\\nHowever, the occasional mishap that results in a performance slowdown or system\\noutage is inevitable. Being able to detect such events in a timely fashion allows for\\nmitigations that can limit their detrimental effects, for example by having backup sys‐\\ntems kick in and operational personnel called to investigate the issue.\\nA monitoring framework is a system that aggregates metrics from different sources in\\na central place for manual monitoring and performing anomaly detection. Such sys‐\\ntems are often made up of five distinct components:\\n• Metrics collectors\\n• Time series database\\n• Detection engine\\n• Visualization layer\\n• Alerting mechanism\\nA typical workflow for application monitoring starts when applications periodically\\npublish metrics to a monitoring framework collection point (e.g., a REST endpoint),\\nor when metric collector agents on the endpoints extract metrics from the system.\\nThese metrics are then stored in the time series database, which the detection engine\\ncan query to trigger alerts and the visualization layer can use to generate charts. The\\nalerting mechanism is then in charge of informing relevant stakeholders of notable\\noccurrences automatically detected by the framework.\\nMonitoring and alerting frameworks are often in the predicament of being able to\\nalert administrators when other systems go down but not being able to do so when\\nthey experience downtime themselves. Although it is impossible to completely\\nremove this risk, it is important to design or select monitoring systems that are them‐\\nselves highly available, robust, and scalable. Adding redundancy in monitoring solu‐\\ntions can also decrease the probability of a total loss of visibility when a single\\nmachine goes down. An involved discussion of monitoring is beyond the scope of\\nthis book, but it is worthwhile to invest time and effort to learn more about effective\\nmonitoring and alerting.32 Popular monitoring frameworks such as Prometheus, the\\nTICK stack, Graphite, and Grafana are good candidates for getting started.\\n310 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 328}, page_content='33 A big jump or an anomaly of this sort means something has changed either in the data or in the system. This\\ncould be due to an attack on the login endpoint of your site, or could be due to subtler issues like an incor‐\\nrectly trained or tuned model that is causing a much higher rate of false positives than before.\\nPerformance and availability are not the only system properties that should be moni‐\\ntored. Because these statistical systems consume real-world data that is subject to a\\ncertain degree of unpredictability, it is also important to monitor the general efficacy\\nof the system to ensure that relevant and effective results are consistently produced.\\nThis task is seldom straightforward since measures of efficacy necessarily require\\nhaving access to some way to reliably check if predictions are correct, and often\\ninvolve human labels from feedback loops. A common approximation for measuring\\nchanges in efficacy is to monitor the distribution of system predictions served. For\\ninstance, if a system that typically sees 0.1% of login requests marked as suspicious\\nsees this number suddenly jump to 5%, it’s probably worth looking into.33\\nAnother powerful feature is being able to monitor changes in the input data, inde‐\\npendent of the machine learning system’s output. Data properties such as the statisti‐\\ncal distribution, volume, velocity, and sparseness can have a large effect on the\\nefficacy and performance of machine learning systems. Changes in data distributions\\nover time could be an effect of shifting trends, acquiring new sources of data (e.g., a\\nnew customer or application feeding data to the system), or in rare cases adversarial\\npoisoning (red herring attacks, which we discuss in Chapter 8). Increasing sparseness\\nin incoming data is also a common occurrence that has negative effects on machine\\nlearning systems.\\nData collection and feature extraction pipelines become stale when they don’t keep up\\nwith changing data formats. For instance, a web application feature extractor collect‐\\ning IP addresses from HTTP requests may assume that all IP addresses are in the\\nIPv4 format. When the website starts supporting IPv6, this assumption is then bro‐\\nken and we will observe a higher number of data points with a null IP field. Although\\nit can be difficult to keep up with changing input data formats, monitoring the occur‐\\nrence of missing fields in extracted feature sets makes for a good proxy. A changing\\ntrend in error or exception counts in individual system components (such as in the\\nfeature extraction pipeline) can also be a good early indicator of system failure; these\\ncounts should be a standard metric monitored in mature production systems.\\nSecurity and Reliability\\nWherever security solutions are deployed, malicious activity should be expected. Let’s\\nlook at the security and privacy guarantees that security machine learning systems\\nshould provide.\\nSecurity and Reliability \\n| \\n311'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 329}, page_content='34 Daniel Hsu, “Machine Learning and Privacy”, Columbia University, Department of Computer Science.\\nFeature: Robustness in Adversarial Contexts\\nSecurity systems face a constant risk of adversarial impact. Attackers have constant\\nmotivation to circumvent protective walls put in place because there is, by nature, a\\nlikely payout on the other side. It is hence necessary for production systems to be\\nrobust in the face of malicious activity attempting to bring down the performance,\\navailability, or efficacy of such systems.\\nIt is important to stress the confounding effects that active adversaries can have in\\ninfluencing machine learning models. There is a significant body of research in this\\narea, showing how much adversaries can do with minimal access and information.\\nFor security machine learning systems in particular, it is important to preempt\\nattacker logic and capabilities. You should thus take care to select robust algorithms\\nas well as design systems with the proper checks and balances in place that allow for\\ntampering attempts to be detected and their effects limited.\\nA variety of different statistical attacks can be waged on machine learning systems,\\ncausing them to lose stability and reliability. As designers and implementers of secu‐\\nrity machine learning systems, we are in a unique position to protect these systems\\nfrom adversarial impact. We will dive into a more detailed discussion of adversarial\\nmachine learning in Chapter 8, but it is important to consider whether the security\\nmachine learning systems that you put into production are susceptible to such attacks\\nor not.\\nFeature: Data Privacy Safeguards and Guarantees\\nData privacy is an increasingly relevant area of concern as technology becomes more\\npervasive and invasive. Machine learning systems are usually at odds with privacy\\nprotection because algorithms work well with more descriptive data. For instance,\\nbeing able to access rich audio and camera captures from mobile devices can give us a\\nlot of raw material for classifying the legitimacy of mobile app API requests made to\\nan account login endpoint, but such broad access is typically considered to be a huge\\nprivacy violation and hence is seldom done in practice.\\nIn addition to the privacy issues related to the collection of intrusive data from users\\nand endpoints, there is also the issue of information leakage from trained machine\\nlearning models themselves.34 Some machine learning models generate outputs that\\nallow an external observer to easily infer or reconstruct either the training data that\\nwent into model training or the test data that generated that prediction output. For\\ninstance, the k-NN algorithm and kernel-based support vector machines are particu‐\\n312 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 330}, page_content='35 Zhanglong Ji, Zachary C. Lipton, and Charles Elkan, “Differential Privacy and Machine Learning: A Survey\\nand Review” (2014).\\n36 Cynthia Dwork and Aaron Roth, “The Algorithmic Foundations of Differential Privacy,” Foundations and\\nTrends in heoretical Computer Science 9 (2014): 211–407.\\nlarly susceptible to information leakage because some training data can be inferred\\nfrom density calculations and functions that represent the support vectors.35\\nThe problem of building privacy-preserving machine learning algorithms has spawned\\nan active field of research, and is difficult to solve because attackers often have access\\nto global information. If an attacker has access to a trained machine learning model\\nand to 50% or more of the training data, it will be possible for them to make high-\\nconfidence guesses about the makeup of the other 50%. Diferential privacy36 refers to\\na class of privacy-preserving machine learning solutions that aims to solve this prob‐\\nlem by making it more difficult for an attacker to make high-confidence guesses\\nabout a piece of missing information from his or her point of view.\\nPrivacy in machine learning systems should be a top requirement because privacy\\nviolations and breaches usually have serious and expensive consequences. Production\\nsystems should be able to provide privacy safeguards and guarantees that are based\\non sound theoretical and technical frameworks and limit the harm that attackers can\\ndo to steal private information.\\nFeedback and Usability\\nUser experiences that emphasize communication and collaboration between humans\\nand machines while balancing machine automation and (the perception of) user\\nagency are the true hallmarks of an outstanding security machine learning system.\\nThere is an inherent distrust between humans and machines. Machine learning solu‐\\ntions will not reach their full potential unless the user experience of such systems pro‐\\ngresses along with them. Explainability of results is an important prerequisite for\\ntrust because most users will not trust the results of systems if they don’t understand\\nhow the system arrived at the result. Transparency is key to fully exploiting the power\\nthat machine learning systems can provide. If a fraudulent login detection system\\nuses machine learning to determine that a particular login attempt is suspicious, the\\nsystem should attempt to inform the user of the reasons behind this decision and\\nwhat they can do to remedy the situation.\\nOf course, full explainability is at odds with security principles, which dictate that sys‐\\ntems should reveal as little as possible to potential attackers. Giving attackers a feed‐\\nback channel allows them to iterate quickly and develop exploits that will eventually\\nbe able to fool systems. A potential solution is to scale the transparency of a machine\\nlearning engine’s decisions inversely with how likely it is to be engaging with an\\nFeedback and Usability \\n| \\n313'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 331}, page_content='attacker. If the system is able to classify typical attack behavior with high confidence,\\nand most false positives are not “high-confidence positives,” it can implement a dis‐\\ncriminating transparency policy that keeps obvious attackers from getting any feed‐\\nback. This setup allows for some flexibility in mitigating the negative effects of wrong\\npredictions made by machine learning systems.\\nThe presentation of information in the human-machine interface of machine learn‐\\ning systems is an area of study that is often neglected. Poor management of the bias,\\ntrust, and power dynamics between humans and security machine learning systems\\ncan cause their downfall.\\nConclusion\\nSecurity machine learning systems must be one of the strongest links in a modern\\napplication environment. As such, these systems need to meet quality, scalability, and\\nmaintainability standards that surpass most other components in an operation. In\\nthis chapter, we provided a framework for evaluating a system’s production readiness;\\nit is now your job, as security data scientists and engineers, to ensure that the software\\nyou deploy is truly production ready.\\n314 \\n| \\nChapter 7: Production Systems'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 332}, page_content='1 Weilin Xu, Yanjun Qi, and David Evans, “Automatically Evading Classifiers: A Case Study on PDF Malware\\nClassifiers.” Network and Distributed Systems Symposium 2016, 21–24 February 2016, San Diego, California.\\n2 Blaine Nelson et al., “Exploiting Machine Learning to Subvert Your Spam Filter,” Proceedings of the 1st USE‐\\nNIX Workshop on Large-Scale Exploits and Emergent hreats (2008): 1–9.\\n3 Alexey Kurakin, Ian Goodfellow, and Samy Bengio, “Adversarial Examples in the Physical World” (2016).\\n4 Bin Liang et al., “Deep Text Classification Can Be Fooled” (2017).\\n5 Hossein Hosseini et al., “Deceiving Google’s Perspective API Built for Detecting Toxic Comments” (2017).\\nCHAPTER 8\\nAdversarial Machine Learning\\nAs machine learning begins to be ubiquitously deployed in critical systems, its relia‐\\nbility naturally comes under scrutiny. Although it is important not to be alarmist, the\\nthreat that adversarial agents pose to machine learning systems is real. Much like how\\na hacker might take advantage of a firewall vulnerability to gain access to a web\\nserver, a machine learning system can itself be targeted to serve the goals of an\\nattacker. Hence, before putting such solutions in the line of fire, it is crucial to con‐\\nsider their weaknesses and understand how malleable they are under stress.\\nAdversarial machine learning is the study of machine learning vulnerabilities\\nin adversarial environments. Security and machine learning researchers have pub‐\\nlished research on practical attacks against machine learning antivirus engines,1 spam\\nfilters,2 network intrusion detectors, image classifiers,3 sentiment analyzers,4,5 and\\nmore. This has been an increasingly active area of research in recent times, even\\nthough such attacks have rarely been observed in the wild. When information secu‐\\nrity, national sovereignties, and human lives are at stake, machine learning system\\ndesigners have a responsibility to preempt attacks and build safeguards into these\\nsystems.\\n315'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 333}, page_content='6 Marco Barreno et al., “Can Machine Learning Be Secure?” Proceedings of the 2006 ACM Symposium on Infor‐\\nmation, Computer and Communications Security (2006): 16–25.\\nVulnerabilities in machine learning systems can arise from flawed system design, fun‐\\ndamental algorithmic limitations, or a combination of both. In this chapter, we exam‐\\nine some vulnerabilities in and attacks on machine learning algorithms. We then use\\nthe knowledge gained to motivate system designs that are more resilient to attacks.\\nTerminology\\nEarly research in adversarial machine learning defined a taxonomy for qualitatively\\nanalyzing attacks on machine learning systems based on three dimensions of\\nproperties:6\\nInluence\\nCausative attacks refer to attempts by an adversarial actor to affect the training\\nprocess by tampering with the training data or training phase parameters. \\nBecause it is difficult for an adversary to manipulate an offline curated training\\nset, this type of attack is predominately relevant to online learners. Online learn‐\\ners automatically adapt to changing data distributions by directly exploiting user\\ninteractions or feedback on predictions to update the trained model. By sacrific‐\\ning stationarity for adaptability, such learning systems continuously evolve by\\nincrementally training statistical models with freshly observed data. Typical use\\ncases of online learning include an image classification service that learns from\\nuser corrections and reinforcement, or malicious traffic detection on websites\\nthat frequently experience viral traffic spikes.\\nExploratory attacks are purely based on post–training phase interactions with\\nmachine learning systems. In this mode of attack, actors do not have any influ‐\\nence over the trained data manifold, but instead find and exploit adversarial\\nspace to cause models to make mistakes that they were not designed to make. A\\nnaive example of an exploratory attack is to engage in brute-force fuzzing of a\\nmachine learning classifier’s input space to find samples that are wrongly\\nclassified.\\nSpeciicity\\nTargeted attacks refer to attempts to cause a directed and intentional shift of a\\nmodel’s predictions to an alternate, focused outcome. For instance, a targeted\\nattack of a malware family classifier could cause samples belonging to malware\\nfamily A to be reliably misclassified as malware family B.\\nIndiscriminate attacks are highly unspecific attacks by adversaries who want\\nmodels to make wrong decisions but don’t necessarily care what the eventual\\n316 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 334}, page_content='7 Carbon Black, “Beyond the Hype: Security Experts Weigh in on Artificial Intelligence, Machine Learning and\\nNon-Malware Attacks” (2017).\\noutcome of the system is. An indiscriminate attack on the malware family classi‐\\nfier just mentioned would cause samples belonging to malware family A to be\\nmisclassified as anything but family A.\\nSecurity violation\\nIntegrity attacks on machine learning systems affect only the ability of security\\ndetectors to find attacks; that is, they reduce the true positive rate (i.e., recall). A\\nsuccessful launch of such an attack on a machine learning web application fire‐\\nwall would mean that an adversary can successfully execute attacks that the fire‐\\nwall was specifically designed to detect.\\nAvailability attacks, which are usually the result of indiscriminate attacks,\\ndegrade the usability of a system by reducing the true positive rate and increasing\\nthe false positive rate. When systems fail in this manner, it becomes difficult to\\nreliably act on the results produced and hence the attack is viewed as a reduction\\nin system availability. This type of attack is relevant only to causative attacks\\nbecause it typically involves tampering with an (online) learning agent’s decision\\nfunctions.\\nThe Importance of Adversarial ML\\nMachine learning is quickly becoming a compulsory tool in any security practition‐\\ner’s repertoire, but three out of four researchers still feel that today’s artificial intelli‐\\ngence–driven security solutions are flawed.7 A large part of the lack of confidence in\\nsecurity machine learning solutions stems from the ease with which adversaries can\\nbypass such solutions. The interesting conundrum is that many security professionals\\nalso predict that security solutions of the future will be driven by AI and machine\\nlearning. The need to close the gap between the reality of today and the expectations\\nfor tomorrow explains why adversarial machine learning is important to consider for\\nsecurity contexts.\\nAdversarial machine learning is difficult because most machine learning solutions\\nbehave as black boxes. The lack of transparency into what goes on inside detectors\\nand classifiers makes it difficult for users and practitioners to make sense of model\\npredictions. Furthermore, the lack of explainability of decisions made by these sys‐\\ntems means that users cannot easily detect when a system has been influenced by a\\nmalicious actor. As long as humans cannot be assured of robustness of machine\\nlearning systems, there will be resistance to their adoption and acceptance as a main\\ndriver in security solutions.\\nThe Importance of Adversarial ML \\n| \\n317'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 335}, page_content='8 XSS attacks typically take advantage of a web application vulnerability that allows attackers to inject client-\\nside scripts into web pages viewed by other users.\\nSecurity Vulnerabilities in Machine Learning Algorithms\\nSecurity systems are natural targets for malicious tampering because there are often\\nclear gains for attackers who successfully circumvent them. Systems powered by\\nmachine learning contain a fresh new attack surface that adversaries can exploit when\\nthey are furnished with background knowledge in this space. Hacking system envi‐\\nronments by exploiting design or implementation flaws is nothing new, but fooling\\nstatistical models is another matter altogether. To understand the vulnerabilities of\\nmachine learning algorithms, let’s consider the how the environment in which these\\ntechniques are applied affects their performance. As an analogy, consider a swimmer\\nwho learns and practices swimming in swimming pools their entire life. It is likely\\nthat they will be a strong swimmer in pools, but if they are suddenly thrown into the\\nopen ocean, they might not be equipped with the ability to deal with strong currents\\nand hostile conditions and are likely to struggle.\\nMachine learning techniques are usually developed under the assumptions of data\\nstationarity, feature independence, and weak stochasticity. Training and testing data‐\\nsets are assumed to be drawn from populations whose distributions don’t change over\\ntime, and selected features are assumed to be independently and identically dis‐\\ntributed. Machine learning algorithms are not typically designed to be effective in\\nadversarial environments where these assumptions are shattered. Attempting to fit a\\ndescriptive and lasting model to detect adaptive adversaries that have incentive to\\navoid correct classification is a difficult task. Adversaries will attempt to break any\\nassumptions that practitioners make as long as that is the path of least resistance into\\na system.\\nA large class of machine learning vulnerabilities arise from the fundamental problem\\nof imperfect learning. A machine learning algorithm attempts to fit a hypothesis\\nfunction that maps points drawn from a certain data distribution space into different\\ncategories or onto a numerical spectrum. As a simple thought experiment, suppose\\nthat you want to train a statistical learning agent to recognize cross-site scripting\\n(XSS) attacks8 on web applications. The ideal result is an agent that is able to detect\\nevery possible permutation of XSS input with perfect accuracy and no false positives.\\nIn reality, we will never be able to produce systems with perfect efficacy that solve\\nmeaningfully complex problems because the learner cannot be provided with perfect\\ninformation. We are not able to provide the learner with a dataset drawn from the\\nentire distribution of all possible XSS input. Hence, there exists a segment of the dis‐\\ntribution that we intend for the learner to capture but that we have not actually pro‐\\nvided it sufficient information to learn about. Modeling error is another phenomenon\\nthat contributes to the adversarial space of a statistical learner. Statistical learning\\n318 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 336}, page_content='9 Keinosuke Fukunaga, Introduction to Statistical Pattern Recognition, 2nd ed. (San Diego, CA: Academic Press\\n1990), pp. 3 and 97.\\nforms abstract models that describe real data, and modeling error arises due to natu‐\\nral imperfections that occur in these formed models.\\nEven “perfect learners” can display vulnerabilities because the Bayes error rate9 might\\nbe nonzero. The Bayes error rate is the lower bound on the possible error for a given\\ncombination of a statistical classifier and the set of features used. This error rate is\\nuseful for assessing the quality of a feature set, as well as measuring the effectiveness\\nof a classifier. The Bayes error rate represents a theoretical limit for a classifier’s per‐\\nformance, which means that even when we provide a classifier with a complete repre‐\\nsentation of the data, eliminating any sources of imperfect learning, there still exists a\\nfinite set of adversarial samples that can cause misclassifications.\\nFigure 8-1 illustrates the theoretical data population we want to develop a statistical\\nlearning model for, and its relationships with the training and test data distribution\\nspaces. (Note that we are referring not to the actual datasets, but to the population\\nfrom which these datasets are drawn—there should be no intersection between the\\ntraining and test datasets.)\\nFigure 8-1. Adversarial space as a result of imperfect representation in training data\\nEssentially, the training data we provide a machine learning algorithm is drawn from\\nan incomplete segment of the theoretical distribution space. When the time comes\\nfor evaluation of the model in the lab or in the wild, the test set (drawn from the test\\ndata distribution) could contain a segment of data whose properties are not captured\\nin the training data distribution; we refer to this segment as adversarial space. Attack‐\\ners can exploit pockets of adversarial space between the data manifold fitted by a stat‐\\nistical learning agent and the theoretical distribution space to fool machine learning\\nSecurity Vulnerabilities in Machine Learning Algorithms \\n| \\n319'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 337}, page_content='10 Christian Szegedy et al., “Intriguing Properties of Neural Networks” (2013).\\n11 Ian Goodfellow, Jonathon Shlens, and Christian Szegedy, “Explaining and Harnessing Adversarial Examples”\\n(2014).\\n12 Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow, “Transferability in Machine Learning: From Phe‐\\nnomena to Black-Box Attacks Using Adversarial Samples” (2016).\\nalgorithms. Machine learning practitioners and system designers expect the training\\nand test data to be drawn from the same distribution space, and further assume that\\nall characteristics of the theoretical distribution be covered by the trained model.\\nThese “blind spots” in machine learning algorithms arise because of the discrepancy\\nbetween expectation and reality.\\nMore catastrophically, when attackers are able to influence the training phase, they\\ncan challenge the data stationarity assumptions of machine learning processes. Sys‐\\ntems that perform online learning (i.e., that learn from real-time user feedback) are\\nnot uncommon because of adaptability requirements and the benefits that self-\\nadjusting statistical systems bring. However, online learning introduces a new class of\\nmodel poisoning vulnerabilities that we must consider.\\nStatistical learning models derive intelligence from data fed into them, and vulnera‐\\nbilities of such systems naturally stem from inadequacies in the data. As practitioners,\\nit is important to ensure that the training data is as faithful a representation of the\\nactual distribution as possible. At the same time, we need to continually engage in\\nproactive security defense and be aware of different attack vectors so that we can\\ndesign algorithms and systems that are more resilient to attacks.\\nAttack Transferability\\nThe phenomenon of attack transferability was discovered by researchers who found\\nthat adversarial samples (drawn from adversarial space) that are specifically designed\\nto cause a misclassification in one model are also likely to cause misclassifications in\\nother independently trained models10,11—even when the two models are backed by\\ndistinctly different algorithms or infrastructures.12 It is far from obvious why this\\nshould be the case, given that, for example, the function that a support vector\\nmachine fits to a training data distribution presumably bears little resemblance to the\\nfunction fit by a deep neural network. Put in a different way, the adversarial spaces in\\nthe data manifold of trained machine learning model A have been found to overlap\\nsignificantly with the adversarial spaces of an arbitrary model B.\\nTransferability of adversarial attacks has important consequences for practical attacks\\non machine learning because model parameters are not commonly exposed to users\\ninteracting with a system. Researchers have developed practical adversarial evasion\\nattacks on so-called black-box models; i.e., classifiers for which almost no information\\n320 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 338}, page_content='13 Nicolas Papernot et al., “Practical Black-Box Attacks Against Deep Learning Systems Using Adversarial\\nExamples” (2016).\\n14 Florian Tramèr et al., “The Space of Transferable Adversarial Examples” (2017).\\n15 Ian Goodfellow et al., “Generative Adversarial Nets,” Proceedings of the 27th International Conference on Neu‐\\nral Information Processing Systems (2014): 2672–2680.\\n16 Hyrum S. Anderson, Jonathan Woodbridge, and Bobby Filar, “DeepDGA: Adversarially-Tuned Domain Gen‐\\neration and Detection,” Proceedings of the 2016 ACM Workshop on Artiicial Intelligence and Security (2016):\\n13–21.\\nabout the machine learning technique or model used is known.13 With access only to\\ntest samples and results from the black-box classifier, we can generate a labeled train‐\\ning dataset with which we can train a local substitute model. We then can analyze this\\nlocal substitute model offline to search for samples that belong to adversarial space.\\nSubsequently, attack transferability allows us to use these adversarial samples to fool\\nthe remote black-box model.\\nAttack transferability is an active area of research,14 and this work will continue to\\ninfluence the field of adversarial machine learning in the foreseeable future.\\nGenerative Adversarial Networks\\nYou might have come across the class of deep learning algorithms called Generative\\nAdversarial Nets15 (GANs). These are unsupervised machine learning algorithms that\\nmake use of two “dueling” neural networks in a zero-sum-game framework.\\nTypically, one of the two neural networks acts as the generator and the other acts as\\nthe discriminator. The discriminator is trained as a one-class classifier in the typical\\nfashion, by feeding it labeled samples from a training set until it is able to accurately\\npredict class membership of a test set with some level of accuracy. The generator then\\niteratively attempts to generate samples with the goal of having the discriminator\\nthink that the sample belongs to the original dataset. The entire process then can be\\niterated, terminating either when the performance meets the system requirements or\\nwhen additional iterations don’t improve performance. This back-and-forth training\\nmethod results in a system that has sensationally strong learning capabilities.\\nGANs don’t have any direct relationship with adversarial machine learning, but this\\ntechnique has in fact been used by researchers to generate command-and-control\\ndomain names16 for evasion attacks of machine learning detection models.\\nSecurity Vulnerabilities in Machine Learning Algorithms \\n| \\n321'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 339}, page_content='17 A “red herring” is something that misleads or distracts—fitting for model poisoning attacks, which aim to\\nmislead the learning agent into learning something incorrect and/or unintended.\\n18 Screenshots taken from Google Translate are purely used to illustrate the mechanism for such an attack. Many\\npeople rely on the accuracy of online services such as this and it is not cool to tamper with it without prior\\npermission from the service provider.\\nAttack Technique: Model Poisoning\\nModel poisoning attacks, also known as red herring17 attacks, are realistically observed\\nonly in online learning systems. Online learning systems sacrifice stationarity for\\nadaptability by dynamically retraining machine learning models with fresh user inter‐\\nactions or feedback. Anomaly detection systems use online learning to automatically\\nadjust model parameters over time as they detect changes in normal traffic. In this\\nway, laborious human intervention to continually tune models and adjust thresholds\\ncan be avoided. Nevertheless, online learners come with a set of risks in adversarial\\nenvironments. Especially in systems that are not well designed for resilience to\\nattacker manipulation, it can be trivial for an adversary to confuse machine learning\\nalgorithms by introducing synthetic traffic.\\nBy definition, poisoning attacks are causative in nature and can vary arbitrarily in\\nspecificity and type of security violation. Consider a natural language translation ser‐\\nvice with a naively implemented online user feedback loop that takes in user correc‐\\ntions to continually retrain the machine learning translation engine. Without any\\nform of input filtering, an indiscriminate attack on the system could be as simple as\\nproviding nonsensical garbage feedback, as in Figure 8-2.18 A more targeted attack\\ncould be made to the system by selectively and repeatedly causing the system to\\ntranslate the word “love” in English to “déteste” in French, as shown in Figure 8-3.\\nFigure 8-2. Indiscriminate poisoning of a language translation system\\n322 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 340}, page_content='19 This is assuming that all samples used to train the model are equally weighted and contribute uniformly to the\\ntraining of the model.\\n20 “Chaff” is a term used to refer to attack traffic for poisoning learning machine learning models.\\nFigure 8-3. Targeted poisoning of a language translation system\\nIt is easy to understand how a model can be negatively affected by such input. The\\nworldview of a statistical learning agent is shaped entirely by the training data it\\nreceives and any positive or negative reinforcement of its learned hypotheses. When a\\ntoddler is learning the names of fruits through examples in a picture book, the learn‐\\ning process can similarly be poisoned if the example fruits in the book are incorrectly\\nnamed.\\nIn poisoning attacks, attackers are assumed to have control over a portion of the\\ntraining data used by the learning algorithm. The larger the proportion of training\\ndata that attackers have control over, the more influence they have over the learning\\nobjectives and decision boundaries of the machine learning system.19 An attacker\\nwho has control over 50% of the training set can influence the model to a greater\\nextent than an attacker who has control over only 5%. This implies that more popular\\nservices that see a larger volume of legitimate traffic are more difficult to poison\\nbecause attackers need to inject a lot more chaf20 to have any meaningful impact on\\nthe learning outcome.\\nOf course, system owners can easily detect when an online learner receives a high\\nvolume of garbage training data out of the blue. Simple rules can flag instances of\\nsudden spikes in suspicious or abnormal behavior that can indicate malicious tam‐\\npering. After you detect it, filtering out this traffic is trivial. That said, if attackers\\nthrottle their attack traffic, they can be a lot more difficult to detect. So-called boiling\\nfrog attacks spread out the injection of adversarial training examples over an extended\\nperiod of time so as not to trigger any tripwires. Boiling frog attacks can be made\\nmore effective and less suspicious by introducing chaff traffic in stages that match the\\ngradual shifting of the classifier’s decision boundary.\\nAttack Technique: Model Poisoning \\n| \\n323'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 341}, page_content='21 Battista Biggio, Blaine Nelson, and Pavel Laskov, “Poisoning Attacks Against Support Vector Machines,” Pro‐\\nceedings of the 29th International Conference on Machine Learning (2012): 1467–1474.\\n22 Marius Kloft and Pavel Laskov, “Security Analysis of Online Centroid Anomaly Detection,” Journal of\\nMachine Learning Research 13 (2012): 3647–3690.\\n23 Benjamin I.P. Rubinstein et al., “ANTIDOTE: Understanding and Defending Against Poisoning of Anomaly\\nDetectors,” Proceedings of the 9th ACM SIGCOMM Internet Measurement Conference (2009): 1–14.\\n24 Shike Mei and Xiaojin Zhu, “Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine\\nLearners,” Proceedings of the 29th AAAI Conference on Artiicial Intelligence (2015): 2871–2877.\\n25 Blaine Nelson et al., “Exploiting Machine Learning to Subvert Your Spam Filter,” Proceedings of the 2nd USE‐\\nNIX Workshop on Large-Scale Exploits and Emergent hreats (2008): 1–9.\\n26 Battista Biggio et al., “Poisoning Behavioral Malware Clustering,” Proceedings of the 7th ACM Workshop on\\nArtiicial Intelligence and Security (2014): 27–36.\\n27 Huang Xiao et al., “Is Feature Selection Secure Against Training Data Poisoning?” Proceedings of the 32nd\\nInternational Conference on Machine Learning (2015): 1689–1698.\\n28 Ling Huang et al., “Adversarial machine learning,” Proceedings of the 4th ACM Workshop on Artiicial Intelli‐\\ngence and Security (2011): 43–58.\\n29 Luis Muñoz-González et al., “Towards Poisoning of Deep Learning Algorithms with Back-Gradient Optimi‐\\nzation,” Proceedings of the 10th ACM Workshop on Artiicial Intelligence and Security (2017): 27–38.\\nPoisoning attacks executed gradually over a long period of time can be made to look\\nlike organic drift in the data distributions. For instance, an online learning anomaly\\ndetector that has a decision boundary initially fitted to block at 10 requests per\\nminute (per IP address) would block requests from IPs that make 20 requests per\\nminute. The system would be unlikely to be configured to learn from this traffic\\nbecause the detector would classify this as an anomaly with high confidence. How‐\\never, sticking closer to the decision boundary can cause these systems to “second-\\nguess” the initially fitted hypothesis functions. An attacker that starts by sending 11\\nrequests per minute for one week can have a higher chance of moving the decision\\nboundary from 10 to 11. Repeating this process with the new boundary can help ach‐\\nieve the original goal of significantly altering the decision boundary without raising\\nany alarms. To system administrators, there can be a variety of legitimate reasons for\\nthis movement: increased popularity of a website, increased user retention leading to\\nlonger interactions, introduction of new user flows, and so on.\\nPoisoning attacks have been studied and demonstrated on a variety of different\\nmachine learning techniques and practical systems: SVMs;21 centroid and generic\\nanomaly detection algorithms;22,23 logistic, linear, and ridge regression;24 spam filters;25\\nmalware classifiers;26 feature selection processes;27 PCA;28 and deep learning algo‐\\nrithms.29\\n324 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 342}, page_content='30 For the full code used in this example, refer to the Python Jupyter notebook chapter8/binary-classiier-\\nevasion.ipynb in our repository.\\n31 Note that our choice of classifier here is arbitrary. We chose to use MLP because it is one of the classifiers that\\nimplements the partial_fit() function that we will later use to mimic the incremental training of a model\\nthat online learners perform.\\nExample: Binary Classiier Poisoning Attack\\nTo concretely illustrate poisoning attacks, let’s demonstrate exactly how the decision\\nboundary of a simple machine learning classifier can be manipulated by an attacker\\nwith unbounded query access to system predictions.30 We begin by creating a random\\nsynthetic dataset using the sklearn.datasets.make_classification() utility:\\nfrom sklearn.datasets import make_classification\\nX, y = make_classification(n_samples=200,\\n    n_features=2,\\n    n_informative=2,\\n    n_redundant=0,\\n    weights=[.5, .5],\\n    random_state=17)\\nThis code is a simple two-feature dataset with 200 samples, out of which we will use\\nthe first 100 samples to train the classifier and the next 100 to visually demonstrate\\nthat the classifier is appropriately fitted.\\nFor our example, we fit a multilayer perceptron (MLP) classifier to this dataset.31\\nMLPs are a class of simple feed-forward neural networks that can create nonlinear\\ndecision boundaries. We import the sklearn.neural_network.MLPClassifier class\\nand fit the model to our dataset:\\nfrom sklearn.neural_network import MLPClassifier\\nclf = MLPClassifier(max_iter=600, random_state=123).fit(X[:100], y[:100])\\nTo inspect what’s going on under the hood, let’s generate a visualization of the classi‐\\nfier’s decision function. We create a two-dimensional mesh grid of points in our input\\nspace (X and y values between −3 and 3 with intervals of .01 between each adjacent\\npoint) and then extract prediction probabilities for each of the points in this mesh:\\nimport numpy as np\\nxx, yy = np.mgrid[-3:3:.01, −3:3:.01]\\ngrid = np.c_[xx.ravel(), yy.ravel()]\\nprobs = clf.predict_proba(grid)[:, 1].reshape(xx.shape)\\nThen we generate a contour plot from this information and overlay the test set on the\\nplot, displaying X1 on the vertical axis and X0 on the horizontal axis:\\nAttack Technique: Model Poisoning \\n| \\n325'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 343}, page_content='import matplotlib.pyplot as plt\\nf, ax = plt.subplots(figsize=(12, 9))\\n# Plot the contour background\\ncontour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\\n                      vmin=0, vmax=1)\\nax_c = f.colorbar(contour)\\nax_c.set_label(\"$P(y = 1)$\")\\nax_c.set_ticks([0, .25, .5, .75, 1])\\n# Plot the test set (latter half of X and y)\\nax.scatter(X[100:,0], X[100:, 1], c=y[100:], s=50,\\n           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\\n           edgecolor=\"white\", linewidth=1)\\nax.set(aspect=\"equal\",\\n       xlim=(-3, 3), ylim=(-3, 3))\\nFigure 8-4 shows the result.\\nFigure 8-4. Decision function contour plot of MLP classiier itted to our dataset\\nFigure 8-4 shows that the MLP’s decision function seems to fit quite well to the test\\nset. We use the confidence threshold of 0.5 as our decision boundary. That is, if the\\nclassifier predicts that P(y = 1) > 0.5, the prediction is y = 1; otherwise, the prediction\\n326 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 344}, page_content='32 The implementation of this function can be found in the full code provided at chapter8/binary-classiier-\\nevasion.ipynb in our repository. The function plot_decision_boundary() has the signature plot_deci\\nsion_boundary(X_orig, y_orig, probs_orig, chaff_X=None, chaff_y=None, probs_poisoned=None).\\nis y = 0. We define a utility function plot_decision_boundary() for plotting this\\ndecision boundary along with the same test set:32\\n    plot_decision_boundary(X, y, probs)\\nFigure 8-5 shows the result.\\nFigure 8-5. Decision boundary of MLP classiier itted to our dataset\\nWe then generate five carefully selected chaff points, amounting to just 5% of the\\ntraining dataset. We assign the label y = 1 to these points because that is what the clas‐\\nsifier would predict (given the current decision function):\\nnum_chaff = 5\\nchaff_X = np.array([np.linspace(-2, −1, num_chaff),\\n    np.linspace(0.1, 0.1, num_chaff)]).T\\nchaff_y = np.ones(num_chaff)\\nAttack Technique: Model Poisoning \\n| \\n327'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 345}, page_content='Figure 8-6 illustrates the chaff points (depicted by the star markers), which mostly lie\\nwithin the y = 1 space (y = 1 is depicted by empty circle markers, and y = 0 is depicted\\nby the filled circle markers).\\nFigure 8-6. Chaf points depicted in relation to the test set\\nTo mimic online learners that use newly received data points to dynamically and\\nincrementally train the machine learning model, we are going to use scikit-learn’s par\\ntial_fit() API for incremental learning that some estimators (including MLPClassi\\nfier) implement. We incrementally train our existing classifier by partial-fitting the\\nmodel to the five new chaff points (attack traffic) that we generated:\\nclf.partial_fit(chaff_X, chaff_y)\\nThe classifier is now updated with this new malicious information. Now, let’s see how\\nthe decision boundary has shifted (see Figure 8-7):\\nprobs_poisoned = clf.predict_proba(grid)[:, 1].reshape(xx.shape)\\nplot_decision_boundary(X, y, probs, chaff_X, chaff_y, probs_poisoned)\\n328 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 346}, page_content='Figure 8-7. Shited decision boundary ater 1x partial itting of ive chaf points\\nThe new decision boundary is the darker of the two curves. Notice that the decision\\nboundary has shifted slightly downward, creating a miniscule gap between the two\\ncurves. Any points that lie within this gap would previously have been classified as y\\n= 0, but now would be classified as y = 1. This means that the attacker has been suc‐\\ncessful in causing a targeted misclassification of samples. Repeating the par\\ntial_fit() step iteratively (using the same five chaff points) allows us to observe\\nhow much the decision function shifts as the percentage of chaff traffic increases, as\\ndemonstrated in Figure 8-8.\\nA larger-magnitude shift of the decision boundary represents a larger input space of\\nmisclassified points, which implies a more serious degradation of model\\nperformance.\\nAttack Technique: Model Poisoning \\n| \\n329'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 347}, page_content='Figure 8-8. Shited decision boundaries ater 2x, 3x, 4x, and 5x partial itting of ive\\nchaf points (10%, 15%, 20%, 25% attack traic from upper let to lower right,\\nrespectively)\\nAttacker Knowledge\\nAs you might notice from Figure 8-8, knowledge of the underlying model’s decision\\nfunction is an important factor in poisoning attacks. How does the attacker know\\nhow to select chaff in a way that will cause an effective shift of the decision boundary?\\nThe basic level of access that we assume that any attacker has is the ability to launch\\nan unlimited number of queries to the system and obtain a prediction result. That\\nsaid, the fewer queries made to a system, the less likely an attacker is to trigger trip‐\\nwires and cause suspicion. An attacker who has access not only to the prediction\\nresult but also to the prediction probabilities is in a much more powerful position\\n330 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 348}, page_content='because they can then derive decision function gradients (such as those shown in\\nFigure 8-4) that allow for useful optimizations, especially when selecting chaff points\\non complex decision function surfaces; for example, when the decision function has\\nmultiple local minima or maxima.\\nHowever, even an attacker without access to the prediction probabilities has access to\\ncategorical classification results, which then allows them to infer the decision bound‐\\naries of a model by making queries to points around the boundary line (as shown in\\nFigures 8-5 through 8-8). This information is enough for an attacker to select chaff\\ntraffic that does not arouse suspicion yet can mislead an online learner.\\nOne scenario in which determining chaff placement requires a bit more reverse engi‐\\nneering of the machine learning system is when the input data is transformed before\\nbeing fed into a classifier. For instance, if PCA dimensionality reduction is applied to\\nthe data, how does an attacker know which dimensions of the input to manipulate?\\nSimilarly, if the input goes through some other unknown nonlinear transformation\\nbefore being fed into a classifier, it is a lot less clear how an attacker should map\\nchanges in the raw input to points on the decision surface. As another example, some\\ntypes of user input cannot be easily modified by a user interacting with the system,\\nsuch as when classifier input depends on system state or properties that users have no\\ninfluence over. Finally, determining how much chaff is necessary to cause a meaning‐\\nful shift of the decision boundary can also be challenging.\\nThe aforementioned challenges can mostly be overcome with enough access to the\\nsystem, allowing the attacker to extract as much information from a learner as possi‐\\nble. As defenders, the goal is to make it difficult for attackers to make simple inferen‐\\nces about the system that allow them to engage in attacks on the learner without\\nsacrificing the system’s efficacy.\\nDefense Against Poisoning Attacks\\nThere are some design choices that a machine learning system architect can make\\nthat will make it more difficult for even motivated adversaries to poison models. Does\\nthe system really need real-time, minute-by-minute online learning capabilities, or\\ncan similar value be obtained from a daily scheduled incremental training using the\\nprevious day’s data? There are significant benefits to designing online learning sys‐\\ntems that behave similarly to an offline batch update system:\\n• Having longer periods between retraining gives systems a chance to inspect the\\ndata being fed into the model.\\n• Analyzing a longer period of data gives systems a better chance of detecting boil‐\\ning frog attacks, where chaff is injected gradually over longer periods of time.\\nAggregating a week’s worth of data, as opposed to the past five minutes of data,\\nallows you to detect chaff being injected at a low rate.\\nAttack Technique: Model Poisoning \\n| \\n331'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 349}, page_content='• Attackers thrive on short feedback loops. A detectable shift in the decision\\nboundary as a result of their attack traffic gives them quick positive reinforce‐\\nment and allows them to continue iterating on their method. Having a week-long\\nupdate cycle means that attackers will not know if their attack attempt will have\\nthe positive outcome they are looking for until the following week.\\nIf you have a mechanism for inspecting incremental training data before feeding it\\ninto a partial learning algorithm, there are several ways you can detect poisoning\\nattack attempts:\\n• Identifying abnormal pockets of traffic that originate from a single IP address or\\nautonomous system (ASN), or have unusual common characteristics; for exam‐\\nple, many requests coming in with an abnormal user agent string. You can\\nremove such traffic from the automatic incremental learning mechanism and\\nhave an analyst inspect the traffic for signs of attacks.\\n• Maintaining a calibration set of handcrafted “normal traffic” test data that you\\nrun against the model after each period of retraining. If the classification results\\ndiffer dramatically between previous cycles and the current cycle, there might be\\ntampering involved.\\n• Defining a threshold around the decision boundary and continuously measuring\\nwhat percentage of test data points observed fall in that space. For example, sup‐\\npose that you have a simple linear decision boundary at P(y = 1) = 0.5. If you\\ndefine the decision boundary threshold region to be 0.4 < P(y = 1) < 0.6, you can\\ncount the percentage of test data points observed daily that fall within this region\\nof prediction confidence. If, say, 30% of points fall in this region on average, and\\nyou suddenly have 80% of points falling into this region over the past week, this\\nanomaly might signify a poisoning attack—attackers will try to stick as close to\\nthe decision boundary as possible to maximize the chances of shifting the bound‐\\nary without raising alarms.\\nBecause of the large variety of model poisoning attacks that can be launched on a\\nmachine learning system, there is no hard-and-fast rule for how to definitively secure\\na system on this front. This field is an active area of research, and there continue to be\\nalgorithmic developments in statistical learning techniques that are less susceptible to\\n332 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 350}, page_content='33 Emmanuel J. Candès et al., “Robust Principal Component Analysis?” (2009).\\n34 Mia Hubert, Peter Rousseeuw, and Karlien Vanden Branden, “ROBPCA: A New Approach to Robust Princi‐\\npal Component Analysis,” Technometrics 47 (2005): 64–79.\\n35 S. Charles Brubaker, “Robust PCA and Clustering in Noisy Mixtures,” Proceedings of the 20th Annual ACM-\\nSIAM Symposium on Discrete Algorithms (2009): 1078–1087.\\n36 Peter Rousseeuw and Mia Hubert, “Anomaly Detection by Robust Statistics” (2017).\\n37 Sohil Atul Shah and Vladlen Koltun, “Robust Continuous Clustering,” Proceedings of the National Academy of\\nSciences 114 (2017): 9814–9819.\\n38 Ian Goodfellow, Jonathon Shlens, and Christian Szegedy, “Explaining and Harnessing Adversarial Examples,”\\nICLR 2015 conference paper (2015).\\npoisoning attacks. Robust statistics is frequently cited as a potential solution to make\\nalgorithms more resilient to malicious tampering.33,34,35,36,37\\nAttack Technique: Evasion Attack\\nExploiting adversarial space (illustrated in Figure 8-1) to find adversarial examples\\nthat cause a misclassification in a machine learning classifier is called an evasion\\nattack. Popular media has compared this phenomenon to humans being fooled by\\noptical illusions, mainly because early research in this area demonstrated the concept\\non deep neural net image classifiers.38 For example, Figure 8-9 illustrates how small\\nalterations made to individual pixel intensities can cause a high-performance MNIST\\ndigit classifier to misclassify the 0 as a 6.\\nFigure 8-9. Comparison of the unaltered MNIST handwritten digit of a 0 (let) with the\\nadversarially perturbed version (right)\\nAttack Technique: Evasion Attack \\n| \\n333'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 351}, page_content='39 Alexey Kurakin, Ian Goodfellow, and Samy Bengio, “Adversarial Examples in the Physical World” (2016).\\n40 Anish Athalye et al., “Synthesizing Robust Adversarial Examples” (2017).\\n41 Ivan Evtimov et al., “Robust Physical-World Attacks on Machine Learning Models” (2017).\\n42 Weilin Xu, Yanjun Qi, and David Evans, “Automatically Evading Classifiers: A Case Study on PDF Malware\\nClassifiers,” Proceedings of the 23rd Network and Distributed Systems Symposium (2016).\\nEvasion attacks are worthy of concern because they are more generally applicable\\nthan poisoning attacks. For one, these attacks can affect any classifier, even if the user\\nhas no influence over the training phase. In combination with the phenomenon of\\nadversarial transferability and local substitute model training, the exploratory nature\\nof this technique means that motivated attackers can launch highly targeted attacks\\non the integrity of a large class of machine learning systems. Evasion attacks with\\nadversarial examples have been shown to have a significant impact on both tradi‐\\ntional machine learning models (logistic regression, SVMs, nearest neighbor, decision\\ntrees, etc.) and deep learning models.\\nResearchers have also shown that image misclassifications can have significant real-\\nworld consequences.39 In particular, the development of autonomous vehicles has led\\nresearchers to find adversarial examples that are robust to arbitrary noise and trans‐\\nformations,40 and it has been shown that very small perturbations made to street signs\\ncan cause targeted misclassifications of the images in self-driving cars.41\\nOf course, this type of attack is not limited to image classification systems. Research‐\\ners have demonstrated a similar attack to successfully evade malware classifiers,42\\nwhich has direct consequences on the security industry’s confidence in machine\\nlearning as a driver of threat detection engines. Adversarial perturbations are conve‐\\nnient to apply to image samples because altering a few pixels of an image typically\\ndoes not have obvious visual effects. Applying the same concept to executable binar‐\\nies, on the other hand, requires some hacking and experimentation to ensure that the\\nbits perturbed (or program instructions, lines of code, etc.) will not cause the result‐\\ning binary to be corrupted or lose its original malicious behavior, which would defeat\\nthe entire purpose of evasion.\\nExample: Binary Classiier Evasion Attack\\nLet’s demonstrate the principles of evasion attacks by attempting to find an adversa‐\\nrial example using a rudimentary gradient ascent algorithm. Assuming a perfect-\\nknowledge attacker with full access to the trained machine learning model:\\n1. We begin with an arbitrarily chosen sample and have the model generate predic‐\\ntion probabilities for it.\\n334 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 352}, page_content=\"43 The code and small datasets for training and using the WAF can be found in the chapter8/waf folder of our\\nrepository.\\n44 Full code for this example can be found as the Python Jupyter notebook chapter8/binary-classiier-\\nevasion.ipynb in our repository.\\n2. We dissect the model to find features that are the most strongly weighted in the\\ndirection that we want the misclassification to occur; that is, we find a feature J\\nthat causes the classifier to be less confident in its original prediction.\\n3. We iteratively increase the magnitude of the feature until the prediction probabil‐\\nity crosses the confidence threshold (typically 0.5).\\nThe pretrained machine learning model that we will be working on is a simple web\\napplication firewall (WAF).43 This WAF is a dedicated XSS classifier. Given a string,\\nthe WAF will predict whether the string is an instance of XSS. Give it a spin!\\nEven though real-world attackers will have less than perfect knowledge, assuming a\\nperfect-knowledge attacker enables us to perform a worst-case evaluation of model\\nvulnerabilities and demonstrate some upper bounds on these attacks. In this case, we\\nassume the attacker has access to a serialized scikit-learn Pipeline object and can\\ninspect each stage in the model pipeline.\\nFirst, we load the trained model and see what steps the pipeline contains using the\\nPython built-in vars() function:44\\nimport pickle\\np = pickle.load(open('waf/trained_waf_model'))\\nvars(p)\\n> {'steps': [\\n        ('vectorizer',\\n         TfidfVectorizer(analyzer='char', binary=False,\\n                         decode_error=u'strict',\\n                         dtype=<type 'numpy.int64'>,\\n                         encoding=u'utf-8', input=u'content',\\n                         lowercase=True, max_df=1.0,\\n                         max_features=None, min_df=0.0,\\n                         ngram_range=(1, 3), norm=u'l2',\\n                         preprocessor=None, smooth_idf=True,\\n                         stop_words=None, strip_accents=None,\\n                         sublinear_tf=True,\\n                         token_pattern=u'(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b',\\n                         tokenizer=None, use_idf=True,\\n                         vocabulary=None)\\n        ),\\n        ('classifier',\\n         LogisticRegression(C=1.0, class_weight='balanced',\\n                            dual=False, fit_intercept=True,\\nAttack Technique: Evasion Attack \\n| \\n335\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 353}, page_content=\"intercept_scaling=1, max_iter=100,\\n                            multi_class='ovr', n_jobs=1,\\n                            penalty='l2', random_state=None,\\n                            solver='liblinear', tol=0.0001,\\n                            verbose=0, warm_start=False)\\n        )]}\\nWe see that the Pipeline object contains just two steps: a TfidfVectorizer followed\\nby a LogisticRegression classifier. A successful adversarial example, in this case,\\nshould cause a false negative; specifically, it should be a string that is a valid XSS pay‐\\nload but is classified as a benign string by the classifier.\\nGiven our previous knowledge of text vectorizers, we know that we now need to find\\nthe particular string tokens that can help influence the classifier the most. We can\\ninspect the vectorizer’s token vocabulary by inspecting its vocabulary_ attribute:\\nvec = p.steps[0][1]\\nvec.vocabulary_\\n> {u'\\\\x00\\\\x02': 7,\\n   u'\\\\x00': 0,\\n   u'\\\\x00\\\\x00': 1,\\n   u'\\\\x00\\\\x00\\\\x00': 2,\\n   u'\\\\x00\\\\x00\\\\x02': 3,\\n   u'q-1': 73854,\\n   u'q-0': 73853,\\n   ...\\n  }\\nEach of these tokens is associated with a term weight (the learned inverse document\\nfrequency, or IDF, vector) that is fed into the classifier as a single document’s feature.\\nThe trained LogisticRegression classifier has coefficients that can be accessed\\nthrough its coef_ attribute. Let’s inspect these two arrays and see how we can make\\nsense of them:\\nclf = p.steps[1][1]\\nprint(vec.idf_)\\n> [  9.88191796  13.29416517  13.98731235  ...,\\n    14.39277746  14.39277746  14.39277746]\\nprint(clf.coef_)\\n> [[  3.86345441e+00   2.97867212e-02   1.67598454e-03 ...,\\n      5.48339628e-06   5.48339628e-06   5.48339628e-06]]\\nThe product of the IDF term weights and the LogisticRegression coefficients\\ndetermines exactly how much influence each term has on the overall prediction\\nprobabilities:\\n336 \\n| \\nChapter 8: Adversarial Machine Learning\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 354}, page_content='term_influence = vec.idf_ * clf.coef_\\nprint(term_influence)\\n> [[  3.81783395e+01   3.95989592e-01   2.34425193e-02 ...,\\n      7.89213024e-05   7.89213024e-05   7.89213024e-05]]\\nWe now want to rank the terms by the value of influence. We use the function\\nnumpy.argpartition() to sort the array and convert the values into indices of the\\nvec.idf_ array so that we can find the corresponding token string from the vectoriz‐\\ner’s token dictionary, vec.vocabulary_:\\nprint(np.argpartition(term_influence, 1))\\n> [[81937 92199     2 ..., 97829 97830 97831]]\\nIt looks like the token at index 80832 has the most positive influence on the predic‐\\ntion confidence. Let’s inspect this token string by extracting it from the token\\ndictionary:\\n# First, we create a token vocabulary dictionary so that\\n# we can access tokens by index\\nvocab = dict([(v,k) for k,v in vec.vocabulary_.items()])\\n# Then, we can inspect the token at index 80832\\nprint(vocab[81937])\\n> t/s\\nAppending this token to an XSS input payload should cause the classifier to be\\nslightly less confident in its prediction. Let’s pick an arbitrary payload and verify that\\nthe classifier does indeed correctly classify it as an XSS string (y = 1):\\npayload = \"<script>alert(1)</script>\"\\np.predict([payload])[0]\\n# The classifier correctly predicts that this is an XSS payload\\n> 1\\np.predict_proba([payload])[0]\\n# The classifier is 99.9999997% confident of this prediction\\n> array([  1.86163618e-09,   9.99999998e-01])\\nThen, let’s see how appending the string \"t/s\" to the input affects the prediction\\nprobability:\\np.predict_proba([payload + \\'/\\' + vocab[80832]])[0]\\n> array([  1.83734699e-07,   9.99999816e-01])\\nAttack Technique: Evasion Attack \\n| \\n337'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 355}, page_content=\"45 Ian Goodfellow, Jonathon Shlens, and Christian Szegedy, “Explaining and Harnessing Adversarial Examples,”\\nICLR 2015 conference paper (2015).\\nThe prediction confidence went down from 99.9999998% to 99.9999816%! All we\\nneed to do now is to increase the weight of this feature in this sample. For the Tfidf\\nVectorizer, this simply means increasing the number of times this token appears in\\nthe input string. As we continue to increase the weight of this feature in the sample,\\nwe are ascending the gradient of the classifier’s confidence in the target class; that is,\\nthe classifier is more and more confident that the sample is not XSS.\\nEventually, we get to the point where the prediction probability for class y = 0 sur‐\\npasses that for y = 1:\\np.predict_proba([payload + '/' + vocab[80832]*258])[0]\\n> array([ 0.50142443,  0.49857557])\\nAnd the classifier predicts that this input string is not an XSS string:\\np.predict([payload + '/' + vocab[80832]*258])[0]\\n> 0\\nInspecting the string, we confirm that it is definitely a valid piece of XSS:\\nprint(payload + '/' + vocab[80832]*258)\\n# Output truncated for brevity\\n> <script>alert(1)</script>/t/st/st/st/st/st/st/st/st/s...t/s\\nWe have thus successfully found an adversarial sample that fools this machine learn‐\\ning WAF.\\nThe technique we have demonstrated here works for the very simple linear model of\\nthis example, but it would be extremely inefficient with even slightly more complex\\nmachine learning models. Generating adversarial examples for evasion attacks on\\narbitrary machine learning models requires more efficient algorithms. There are two\\npredominant methods based on the similar concept of gradient ascent:\\nFast Gradient Sign Method (FGSM)45\\nFGSM works by computing the gradient of the classifier’s output with respect to\\nchanges in its input. By finding the direction of perturbation that causes the larg‐\\nest change in the classification result, we can uniformly perturb the entire input\\n(i.e., image) by a small amount in that direction. This method is very efficient,\\nbut usually requires a larger perturbation to the input than is required to cause a\\nmisclassification. For adversarial images, this means that there will appear to be\\nrandom noise that covers the entire image.\\n338 \\n| \\nChapter 8: Adversarial Machine Learning\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 356}, page_content='46 Nicolas Papernot et al., “The Limitations of Deep Learning in Adversarial Settings,” Proceedings of the 1st IEEE\\nEuropean Symposium on Security and Privacy (2016): 372–387.\\nJacobian Saliency Map Approach (JSMA)46\\nThis adversarial sample generation method uses the concept of a saliency map, a\\nmap of relative importance for every feature in the input. For images, this map\\ngives a measure of how much a change to the pixel at each position will affect the\\noverall classification result. We can use the salience map to identify a set of the\\nmost impactful pixels, and we can then use a gradient ascent approach to itera‐\\ntively modify as few pixels as possible to cause a misclassification. This method is\\nmore computationally intensive than FGSM, but results in adversarial examples\\nthat are less likely to be immediately identified by human observers as having\\nbeen tampered with.\\nAs discussed earlier in this chapter, these attacks can be applied to arbitrary machine\\nlearning systems even when attackers have very limited knowledge of the system; in\\nother words, they are black-box attacks.\\nDefense Against Evasion Attacks\\nAs of this writing, there are no robust defenses against adversarial evasion. The\\nresearch so far has shown anything that system designers can do to defend against\\nthis class of attacks can be overcome by an attacker with more time or computational\\nresources.\\nBecause evasion attacks are driven by the concept of gradient ascent to find samples\\nbelonging to adversarial space, the general idea behind defending machine learning\\nmodels against evasion attacks is to make it more difficult for adversaries to get infor‐\\nmation about a model’s decision surface gradients. Here are two proposed defense\\nmethods:\\nAdversarial training\\nIf we train our machine learning model with adversarial samples and their cor‐\\nrect labels, we may be able to minimize the adversarial space available for attack‐\\ners to exploit. This defense method attempts to enumerate all possible inputs to a\\nclassifier by drawing samples belonging to the theoretical input space that are not\\ncovered in the original training data distribution (illustrated in Figure 8-1). By\\nexplicitly training models not to be fooled by these adversarial samples, could we\\nperhaps beat attackers at their own game?\\nAdversarial training has shown promising results, but only solves the problem to\\na degree since the success of this defense technique rests on winning the arms\\nrace between attackers and defenders. Because it is, for most meaningful problem\\nspaces, impossible to exhaustively enumerate the entire theoretical input space,\\nAttack Technique: Evasion Attack \\n| \\n339'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 357}, page_content='47 Geoffrey Hinton, Oriol Vinyals, and Jeff Dean, “Distilling the Knowledge in a Neural Network,” Google Inc.\\n(2015).\\n48 As we discussed earlier in “Security Vulnerabilities in Machine Learning Algorithms” on page 318.\\nan attacker with enough patience and computational resources can always find\\nadversarial samples on which a model hasn’t explicitly been trained.\\nDefensive distillation\\nDistillation was originally designed as a technique for compressing neural net‐\\nwork model sizes and computational requirements so that they can run on\\ndevices with strict resource limitations such as mobile devices or embedded\\nsystems.47 This compression is achieved by training an optimized model by\\nreplacing the categorical class labels from the original training set with the proba‐\\nbility vector outputs of the initial model. The resulting model has a much\\nsmoother decision surface that makes it more difficult for attackers to infer a gra‐\\ndient. As with adversarial training, this method only makes it slower and more\\ndifficult for attackers to discover and exploit adversarial spaces, and hence solves\\nthe problem only against computationally bounded attackers.\\nEvasion attacks are difficult to defend against precisely because of the issue of imper‐\\nfect learning48—the inability of statistical processes to exhaustively capture all possible\\ninputs that belong to a particular category of items that we would like for classifiers to\\ncorrectly classify.\\nAdversarial machine learning researchers have developed Clever‐\\nHans, a library for benchmarking the vulnerability of machine\\nlearning systems to adversarial examples. It has convenient APIs\\nfor applying different types of attacks on arbitrary models, training\\nlocal substitute systems for black-box attacks, and testing the effect\\nof different defenses such as adversarial training.\\nConclusion\\nA prerequisite for machine learning–driven security is for machine learning itself to\\nbe secure and robust. Although both poisoning and evasion attacks are currently the‐\\noretically impossible to perfectly defend against, this should not be seen as a reason\\nfor completely shying away from using machine learning in security in practice.\\nAttacks against machine learning systems often take system designers by surprise\\n(even if they are experienced machine learning practitioners!) because machine\\nlearning can behave in unexpected ways in adversarial environments. Without fully\\nunderstanding why this phenomenon exists, it is easy to misinterpret these results as\\n“failures” of machine learning.\\n340 \\n| \\nChapter 8: Adversarial Machine Learning'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 358}, page_content='Poisoning and evasion attacks don’t demonstrate a “failure” of machine learning but\\nrather indicate an improper calibration of expectations for what machine learning\\ncan do in practical scenarios. Rather than being taken by surprise, machine learning\\nsystem designers should expect that their systems will misbehave when used by mis‐\\nbehaving users. Knowing about the types of vulnerabilities that machine learning\\nfaces in adverse environments can help motivate better system design and can help\\nyou make fewer false assumptions about what machine learning can do for you.\\nConclusion \\n| \\n341'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 359}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 360}, page_content='APPENDIX A\\nSupplemental Material for Chapter 2\\nMore About Metrics\\nIn our discussion of clustering, we primarily used the standard Euclidean distance\\nbetween vectors in a vector space:\\nd x, y = ∑i xi −yi\\n2\\nEuclidean distance is also known as the L2 norm. There are several other metrics that\\nare commonly used in applications:\\n• One variation of Euclidean distance is the L1 norm, also known as Manhattan dis‐\\ntance (because it counts the number of “blocks” between two points on a grid):\\nd x, y = ∑\\ni\\nxi −yi\\n• Another is the L∞ norm, defined as the following:\\nd x, y = max\\ni\\nxi −yi\\n• For vectors of binary values or bits, you can use Hamming distance, which is the\\nnumber of bits in common between x and y. This can be computed as:\\nd x, y = H ¬ x ⊕y\\n343'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 361}, page_content='where H(v) is the Hamming weight; that is, the number of “1” bits in v. If the\\npoints you compare are of different bit length, the shorter one will need to be\\nprepended with zeros.\\n• For lists, you can use the Jaccard similarity:\\nd x, y = x ∩y\\nx ∪y\\nThe Jaccard similarity computes the number of elements in common between x\\nand y, normalized by the total number of elements in the intersection. One useful\\nproperty of Jaccard similarity is that you can use it to compare lists of different\\nlengths.\\nThe L1 and L2 metrics in vector spaces suffer from what is known as the “curse of\\ndimensionality.” This phrase refers to the principle that as the number of dimensions\\nincreases, all points seem to be roughly equally distant from one another. Thus, if you\\nare trying to cluster items in high-dimensional space, you should either reduce the\\nnumber of dimensions or use a different metric, such as the L∞ norm. For a more for‐\\nmal treatment, see section 2.5 of he Elements of Statistical Learning, 2nd ed., by Tre‐\\nvor Hastie, Robert Tibshirani, and Jerome Friedman (Springer).\\nSize of Logistic Regression Models\\nDigging deeper into the contents of the LogisticRegression classifier object, you’ll\\nnotice that all that changed after the call to fit() is the assignment of the three\\nattributes coef_, intercept_, and n_iter_. Let’s inspect these attributes and see what\\na logistic regression classifier model actually is:\\nprint(clf.coef_)\\n> [[-7.44949492  0.26692309  1.39595031 −1.44011704  1.41274547\\n    1.32026309   0.20373255]]\\nprint(clf.intercept_)\\n> [ 2.93674111]\\nprint(clf.n_iter_)\\n> [19]\\nThe n_iter_ attribute is irrelevant because it serves only to tell us the number of iter‐\\nations of some training process that it took to train the classifier to its current state.\\nThis means that the entirety of the information learned from the training set is stored\\nwithin the eight numpy.float64 numbers of coef_ and intercept_. Because each of\\n344 \\n| \\nAppendix A: Supplemental Material for Chapter 2'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 362}, page_content='the eight numpy.float64 objects is 8 bytes in size, the model can be fully represented\\nusing just 64 bytes of storage. The logistic regression model has managed to compress\\nall the information about how to (almost) perfectly identify fraudulent transactions in\\nthis online retailer’s environment from the 26,728 data points in the training set into a\\nmere 64 bytes.\\nImplementing the Logistic Regression Cost Function\\nThe cost function for binary logistic regression is the product of the individual prob‐\\nabilities (or likelihoods) for each class:\\nJ θ = 1\\nm ∑\\ni = 1\\nm\\n−y(i) log (hθ(x(i))) −(1 −y(i)) log (hθ(x(i)))\\nThis formula might look intimidating, but the general concept really isn’t that differ‐\\nent from linear regression. Let’s break it down further.\\nUnlike linear regression, logistic regression is a regression model in which the depen‐\\ndent variable is categorical; that is, the value that we want to predict is discrete in\\nnature. This is convenient for classification tasks because the output we want is one\\nout of the n category labels. For example, the payment fraud classifier that we looked\\nat a moment ago is a binary classifier whose output can be only either 0 or 1.\\nThe error (derived from residuals) for a single point can then be expressed by using\\nthe log-likelihoods of the sigmoid function:\\nErr(hθ(x), y) =\\n−log (1 −hθ(x)) if y = 0\\n−log hθ(x)\\nif y = 1\\nWe can rewrite this expression as the following:\\nErr(hθ(x), y) = −y log (hθ(x)) −(1 −y) log (1 −hθ(x))\\nIf h(x) is very close to 1, the loss is small when the true label is 1 and high when the\\ntrue label is 0.\\nThe cost function is simply the mean of all the errors in the training set:\\nJ(θ) = 1\\nm ∑\\ni = 1\\nm\\nErr (hθ(x(i)), y(i))\\nSupplemental Material for Chapter 2 \\n| \\n345'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 363}, page_content='When expanded, this gives us the aforementioned logistic regression cost function:\\nJ θ = 1\\nm ∑\\ni = 1\\nm\\n−y(i) log (hθ(x(i))) −(1 −y(i)) log (1 −hθ(x(i)))\\nMinimizing the Cost Function\\nAn intuitive way to think about minimizing the cost function is to consider a simpler\\nform of supervised machine learning, linear regression, also known as least squares\\nregression. Given a two-dimensional dataset, we want to fit a regression line (line of\\nbest fit, trend line) to capture the relationship between these two dimensions (on the\\nx- and y-axes of the graph in Figure 2-4).\\nTo do this, we first define a cost function that we will use as the objective in our opti‐\\nmization process. This cost function will give us a quantitative measure of how well\\nthis regression line is able to capture the linear relationship in the data. The cost func‐\\ntion, as defined in the linear regression algorithm, is the sum of the squared residuals\\nfor every point in the dataset. The residual for a data point is the difference between\\nthe predicted and actual y-values, as illustrated in Figure A-1. Summing up all the\\nsquared residuals between a set of data points and a regression line gives us the cost\\nof that particular line. The larger the value of the cost function, the worse the regres‐\\nsion line is at capturing a linear relationship in the dataset. Hence, the optimization\\nobjective is to adjust the parameters of the linear regression model (i.e., the slope and\\nintercept of the line) to minimize this cost function.\\nFigure A-1. Illustration of x- and y-residuals of a regression line for a single training data\\npoint\\n346 \\n| \\nAppendix A: Supplemental Material for Chapter 2'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 364}, page_content='For gradient descent optimization algorithms, we need to find the gradient of this\\ncost function by differentiating with respect to θ:\\n∂J θ\\n∂θj\\n= 1\\nm ∑\\ni = 1\\nm\\nhθ(x(i)) −y i xj\\ni\\nNow that you have some understanding of how the training of a regression model\\nactually works, let’s try to implement our own version of scikit-learn’s fit() function.\\nWe begin by defining the logistic, cost, and gradient functions, as we just stated:\\n# Logistic function, also known as the sigmoid function\\ndef logistic(x):\\n    return 1 / (1 + np.exp(-x))\\n# Logistic regression cost function\\ndef cost(theta, X, y):\\n    X = X.values\\n    y = y.values\\n    # Note that we clip the minimum values to slightly above\\n    # zero to avoid throwing an error when logarithm is applied\\n    log_prob_zero = np.log(\\n        (1 - logistic(np.dot(X, theta))).clip(min=1e-10))\\n    log_prob_one = np.log(\\n        logistic(np.dot(X, theta)).clip(min=1e-10))\\n    # Calculate the log-likelihood terms\\n    zero_likelihood = (1 - y) * log_prob_zero\\n    one_likelihood = -y * log_prob_one\\n    # Sum across all the samples, then take the mean\\n    return np.sum(one_likelihood - zero_likelihood) / (len(X))\\n# Logistic regression gradient function\\ndef gradient(theta, X, y):\\n    X = X.values\\n    y = y.values\\n    num_params = theta.shape[0]\\n    grad = np.zeros(num_params)\\n    err = logistic(np.dot(X, theta)) - y\\n    # Iterate through parameters and calculate\\n    # gradient for each given current error\\n    for i in range(num_params):\\n        term = np.multiply(err, X[:, i])\\n        grad[i] = np.sum(term) / len(X)\\n    return grad\\nSupplemental Material for Chapter 2 \\n| \\n347'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 365}, page_content=\"1 R. Fletcher and C.M. Reeves, “Function Minimization by Conjugate Gradients,” he Computer Journal 7\\n(1964): 149–154.\\nContinuing from the payment fraud detection example in “Machine Learning in\\nPractice: A Worked Example” on page 27 (where the data has already been read and\\nthe training/test sets created), let’s further prepare the data for optimization. Note that\\nwe are trying to optimize eight model parameters. Having k + 1 model parameters,\\nwhere k is the number of features in the training set (in this case, k = 7), is typical for\\nlogistic regression because we have a separate “weight” for each feature plus a “bias”\\nterm. For more convenient matrix multiplication shape-matching, we will insert a\\ncolumn of zeros into X:\\n# Insert column of zeros for more convenient matrix multiplication\\nX_train.insert(0, 'ones', 1)\\nX_test.insert(0, 'ones', 1)\\nNext, we randomly initialize our model parameters in a size-8 array and give it the\\nname theta:\\n# Seed for reproducibility\\nnp.random.seed(17)\\ntheta = np.random.rand(8)\\nAs a baseline, let’s evaluate the cost in the model’s current unoptimized state:\\ncost(theta, X_train, y_train)\\n> 20.38085906649756\\nNow, we use an implementation of the gradient descent algorithm provided by SciPy,\\nscipy.optimize.fmin_tnc. The underlying optimization algorithm is the Newton\\nConjugate-Gradient method,1 an optimized variant of the simple gradient descent\\nthat we described earlier (in scikit-learn, you can use this solver by specifying\\nsolver:'newton-cg'):\\nfrom scipy.optimize import fmin_tnc\\nres = fmin_tnc(func=cost, x0=theta, fprime=gradient,\\n               args=(X_train, y_train))\\nThe results of the gradient descent optimization are stored in the res tuple object.\\nInspecting res (and consulting the function documentation), we see that the zeroth\\nposition in the tuple contains the solution (i.e., our eight trained model parameters),\\nthe first position contains the number of function evaluations, and the second posi‐\\ntion contains a return code:\\n> (array([ 19.25533094, −31.22002744,   0.55258124,   4.05403275,\\n           −3.85452354,  10.60442976,  10.39082921,  12.69257041]), 55, 0)\\n348 \\n| \\nAppendix A: Supplemental Material for Chapter 2\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 366}, page_content='2 Because this logistic regression cost function is convex, we are guaranteed that any local minimum found is\\nalso a global minimum.\\nIt looks like it took 55 iterations of the gradient descent algorithm to successfully\\nreach the local minimum2 (return code 0), and we have our optimized model param‐\\neters. Let’s see what the value of the cost function is now:\\ncost(res[0], X_train, y_train)\\n> 1.3380705016954436e-07\\nThe optimization appears to have been quite successful, bringing down the cost from\\nthe initial value of 20.38 to the current value of 0.0000001338. Let’s evaluate these\\ntrained parameters on the test set and see how well the trained logistic regression\\nmodel actually does. We first define a get_predictions() function, which simply\\ndoes a matrix multiplication of the test data and theta before passing it into the logis‐\\ntic function to get a probability score:\\ndef get_predictions(theta, X):\\n    return [1 if x >= 0.5 else 0 for x in logistic(X.values * theta.T)]\\nThen, let’s run a test by passing in the test data and comparing it to the test labels:\\ny_pred_new = get_predictions(np.matrix(res[0]), X_test)\\nprint(accuracy_score(y_pred_new, y_test.values))\\n> 1.0\\nWe achieved 100% accuracy on the test data! It seems like the optimization worked\\nand we have successfully trained the logistic regression model.\\nSupplemental Material for Chapter 2 \\n| \\n349'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 367}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 368}, page_content='1 Lee Brotherston and Amanda Berlin, Defensive Security Handbook: Best Practices for Securing Infrastructure\\n(Sebastopol, CA: O’Reilly Media, 2017), Chapter 18.\\n2 Robert Layton and Paul Watters, Automating Open Source Intelligence: Algorithms for OSINT (Waltham, MA:\\nSyngress, 2015).\\n3 Sudhanshu Chauhan and Nutan Panda, Hacking Web Intelligence: Open Source Intelligence and Web Reconnais‐\\nsance Concepts and Techniques (Waltham, MA: Syngress, 2015).\\nAPPENDIX B\\nIntegrating Open Source Intelligence\\nThe community of security professionals works tirelessly toward the goals of securing\\nperimeters, preventing breaches, and keeping hackers out. Because of how attackers\\ncommonly target more than one organization at a time, there are significant merits to\\ninformation sharing and fluidity in strengthening the line of defense. Security intelli‐\\ngence sharing has proven to be quite useful in detecting attacks and assessing risk.\\nThe term Open Source Intelligence (OSINT) is used to refer to data that has been col‐\\nlected from various sources (not necessarily in the context of security) and is shared\\nwith other systems that can use it to drive predictions and actions. Let’s take a brief\\nlook at a few different types of open source intelligence and consider its impact in the\\ncontext of security machine learning systems. Our coverage is by no means exhaus‐\\ntive; we refer you to the literature1,2,3 for more information.\\nSecurity Intelligence Feeds\\nThreat intelligence feeds can be a double-edged sword when applied to security\\nmachine learning systems. The most common manifestation of security intelligence is\\nthe real-time IP or email blacklist feed. By collecting the latest attack trends and char‐\\nacteristics from honeypots, crawlers, scanners, and proprietary sources, these feeds\\nprovide an up-to-date list of values that can be used by other systems as a feature for\\nclassifying entities. For instance, the Spamhaus Project tracks spam, malware, and\\n351'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 369}, page_content='4 The word “compounding” is used here in the same way that “compounding interest” is used in the financial\\ncontext. Knowledge bases are frequently compounded in the sense that they are used to build systems that\\ngenerate more knowledge to be fed back into the original knowledge base.\\nphishing vectors around the world, providing real-time feeds of mail server, hijacked\\nserver, and end-user IP addresses that its data and analysts have determined to be\\nconsistently exhibiting bad behavior online. A subscriber to Spamhaus blocklists can\\nquery an endpoint to find out if a request coming into their system has exhibited bad\\nbehavior elsewhere on the internet. The response can then motivate secondary deci‐\\nsions or actions, such as increasing the risk score of this request if it has been marked\\nas originating from a potentially hijacked server.\\nA common problem observed by consumers of threat intelligence feeds is the reliabil‐\\nity and applicability of the feeds across different systems. What has been determined\\nto be a threat in one context might not be a threat in every other context. Further‐\\nmore, how can we guarantee that the feeds are reliable and have not themselves been\\nsubject to poisoning attacks? These are questions that can severely limit the direct\\napplicability of threat intelligence feeds in many systems. The Threat Intelligence\\nQuotient Test is a system (not currently under active development) that allows for the\\n“easy statistical comparison of different threat intelligence indicator sources such as\\nnovelty, overlap, population, aging and uniqueness.” Tools such as this one can help\\nyou to measure and compare the reliability and usefulness of threat feeds.\\nDespite their drawbacks, security intelligence feeds can provide useful features for\\nenriching datasets or for using as a source of confirmation when your security\\nmachine learning system suspects an entity to be malicious.\\nAnother common use of threat intelligence feeds is to fuel entity reputation systems\\nthat keep track of the history of an IP address, domain, or user account’s historical\\nbehavior. Mature organizations typically maintain a compounding4 knowledge base\\nof entities in a system that will contribute to how much trust they place in an entity.\\nFor instance, if an IP address originating from Eastern Europe has consistently been\\nshowing up in threat intelligence feeds as a host potentially hijacked by a botnet, its\\nscore in the IP reputation database will probably be low. When a future request origi‐\\nnating from that IP address exhibits the slightest sign of anomaly, we might go ahead\\nand take action on it, whereas we might give more leeway to an IP address with no\\nhistory of malice.\\nGeolocation\\nThe IP address is the most common unit of threat identification for web applications.\\nBecause every request originates from an IP address and most addresses can be asso‐\\nciated with a set of physical location coordinates, collecting IP addresses enables data\\n352 \\n| \\nAppendix B: Integrating Open Source Intelligence'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 370}, page_content='analysts to obtain information about the initiator of the request and make inferences\\nabout the threat level. In addition to the physical location, IP intelligence feeds com‐\\nmonly also provide the autonomous system number (ASN), internet service provider\\n(ISP), and even device type associated with an IP address. Maxmind is one of the\\nmost popular providers of IP intelligence, providing frequently updated databases\\nand APIs for resolving the location information of an IP address.\\nEven though geolocation is a valuable feature to add to security machine learning sys‐\\ntems, it is important to note that there are some gotchas when considering the IP\\naddresses associated with a web request. These may not be the IP address of the user\\nmaking the request, since your system only sees the address of the last hop in the\\nrequest routing path. For example, if the user is sitting behind a proxy, the IP address\\nseen will be that of the proxy instead of the user. In addition, IP addresses cannot be\\nreliably associated with a single person. Multiple users in a household or large enter‐\\nprise will share the same IP address if they share an internet connection or sit behind\\nthe same proxy service. Many ISPs also provide dynamic IPs, which means that the IP\\naddresses of their end users are rotated regularly. Mobile users on a cellular network\\nwill typically have rotating IP addresses even if they don’t change their physical loca‐\\ntion, because each cell tower has a pool of nonsticky IP addresses that users connec‐\\nted to them share.\\nIntegrating Open Source Intelligence \\n| \\n353'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 371}, page_content=''),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 372}, page_content='Index\\nA\\nA/B model testing, 291\\naccess control\\ndefined, 13\\nnetwork traffic analysis and, 183\\naccount creation, 243-248\\nbots and, 252\\nreputation scores, 246-248\\nvelocity features, 244-246\\naccount takeover (ATO), 4, 237-243\\nactivation functions, 54\\nactive authentication, 184\\nactive learning, 291\\nactive network attacks, 194-196\\nbreaches, 194\\nDoS, 196\\npivoting, 195\\nspoofing, 195\\nadb (Android Debug Bridge), 161\\nADMM (alternating direction method of multi‐\\npliers), 300\\nadvanced persistent threats (APT), 5\\nadversarial examples, 123\\nadversarial machine learning, 11, 315-341\\nattack transferability, 320\\ndefined, 315\\nevasion attacks, 333-340\\ngenerative adversarial nets, 321\\nimportance of, 317\\nmodel poisoning attacks, 322-333\\nsecurity vulnerabilities in machine learning\\nalgorithms, 318-321\\nterminology, 316\\nadversarial space\\nattack transferability, 320\\ndefensive distillation, 340\\ndefined, 319\\nevasion attacks, 333, 339\\nexploratory attacks, 316\\nmodeling error, 318\\nadversarial training, 339\\nadware, 3\\nagglomerative (bottom-up) hierarchical cluster‐\\ning, 68\\nAI (artificial intelligence), 10-11\\nAircrack-ng, 193\\nalerting\\nanomaly detection, 84\\nproduction systems, 310-311\\nalgorithms\\ndefined, 26\\nloss functions, 35\\nmodel families, 33-35\\noptimization, 36-40, 299\\npractical considerations in classification,\\n55-64\\nsecurity vulnerabilities, 318-321\\nsupervised classification algorithms, 40-55\\ntraining to learn, 32-40\\nalternating direction method of multipliers\\n(ADMM), 300\\nAmazon Machine Learning, 306\\nAmazon Web Services (AWS), 306\\nAndroid\\nbehavioral analysis, 160-168\\ndebugging, 168\\ndynamic instrumentation, 169\\nJava and Android Runtime, 150\\n355'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 373}, page_content=\"malware analysis, 148-171\\npacking for obfuscation, 160\\nstatic analysis, 154-160\\nstructural analysis, 150-154\\nAndroid Debug Bridge (adb), 161\\nAndroid Package Kit (APK), 150\\nAndroid Runtime (ART), 150\\nANN (artificial neural networks) (see neural\\nnetworks)\\nanomaly detection, 12, 79-124\\nchallenges of using machine learning, 119\\ndata and algorithms, 93-119\\ndata-driven methods, 82-85\\ndeep packet inspection, 90-91\\ndefined, 27\\ndensity-based methods, 116-118\\nfeature engineering, 85-93\\nfeedback loops, 289-291\\nforecasting, 95-105\\ngoodness-of-fit tests, 107-112\\nhost intrusion detection, 85-88\\nintegrating human feedback in systems, 123\\nintrusion detection with heuristics, 81\\nisolation forests, 115-116\\nlocal outlier factor, 117-118\\nmaintainability of systems, 123\\nmitigating adversarial effects, 123\\nnetwork intrusion detection, 89-92\\none-class Support Vector Machines,\\n112-115\\nonline learning and, 322\\noptimizing system for explainability, 121\\noutlier detection vs., 79\\nperformance and scalability in real-time\\nstreaming applications, 122\\npractical system design concerns, 121-123\\nresponse and mitigation, 120\\nstatistical metrics, 106-107\\nsupervised learning vs., 80\\nunsupervised machine learning algorithms,\\n112-116\\nweb application intrusion detection, 92-93\\nAPK (Android Package Kit), 150\\nApkFile tool, 177\\napplication sandbox, 161\\nAPT (advanced persistent threats), 5\\narea under the curve (AUC), 63\\nARIMA (autoregressive integrated moving\\naverage), 96-101\\nART (Android Runtime), 150\\nartificial intelligence (AI), 10-11\\nartificial neural networks (ANN) (see neural\\nnetworks)\\nATO (account takeover), 4, 237-243\\nattack transferability, 320\\nAUC (area under the curve), 63\\nauthentication, 237-243\\nclassifier construction, 243\\nfeatures used to classify login attempts,\\n239-243\\nnetwork traffic analysis, 183\\npattern recognition vs. anomaly detection,\\n13\\nautocorrelation, 96\\nautoencoder neural network, 173\\nAutoML, 289\\nautoregressive integrated moving average\\n(ARIMA), 96-101\\nautoregressive models, 96-101\\navailability attacks, 317\\nAWS (Amazon Web Services), 306\\nB\\nbackdoor, 4\\nbackpropagation, 54\\nbag-of-words representation, 21, 70\\nBayes error rate, 319\\nBayes' Theorem, 50\\nbehavioral analysis, 13, 160-168\\nbias, in datasets, 147, 277-279\\nbinary classifier evasion attack, 334-339\\nbinary classifier poisoning attack, 325-331\\nbinary data, 126, 145\\nbinary relevance method, 215\\nbinary trees, 72-75, 300\\n(see also decision trees)\\nblack-box models, 320\\nblindness, 257\\nboiling frog attacks, 323\\nbot (defined), 4\\nbot requests\\nconsumer web fraud, 251-256\\nlabeling and metrics, 255\\nbotnet\\ndefined, 4, 196\\ndetection, 13\\nhierarchical, 201\\nmechanism of operation, 198-202\\n356 \\n| \\nIndex\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 374}, page_content='multileader networks, 200\\nnetwork traffic analysis, 197-202\\nrandomized P2P networks, 202\\nrentals, 8\\nsecurity risk posed by, 197\\nstar topology, 199\\nbreaches, network, 194\\nBro, 90\\nbrute-force attacks, 239\\nC\\nC, compiled code execution in, 134-139\\nCalinski-Harabaz (C-H) index, 77\\nCapstone, 157\\ncategorical variable, 29\\ncausative attacks, 316\\nchaff\\nand poisoning attacks, 327-329\\ndefined, 323\\ncheckpointing, 307\\nclass imbalance, 219-222, 279\\nclassification\\nadvanced ensembling, 228-233\\nauthentication abuse and, 243\\ndefined, 9\\nimbalanced classes, 219-222\\nnetwork attacks, 214-216\\npractical considerations, 55-64\\npredictive models, 203-233\\nscoring of clusters, 270\\nsemi-supervised learning, 222\\nsupervised learning, 40-55, 216-222\\ntraining a classifier, 270\\nunsupervised learning, 223-228\\ncleverhans library, 340\\nclick fraud, 236, 252\\nclickjacking, 280\\ncloud services, 305\\nclustering, 65-77, 271\\nabuse, 260-271\\nalgorithms for, 65-72\\nDBSCAN, 73-75\\nevaluating results, 75-77\\nfor network attack classification, 223-228\\ngenerating clusters, 262\\ngrouping method, 65, 263\\nhierarchical, 68-69\\nk-d trees, 72-75\\nk-means (see k-means clustering)\\nlocality-sensitive hashing, 68-69, 264-265\\nmetrics, 343\\nscoring, 266-271\\nspam domains, 261-262\\ncode execution\\ncompiled, 134-139\\ninterpreted, 139-143\\nmodern processes, 132-143\\ncold start, 256\\ncollaborative filtering, 18\\ncompiled code execution, 134-139\\ncompleteness score, 75, 224\\nconcept drift, 290\\nConficker worm, 128, 130\\nconfiguration, tunability and, 309\\nconfusion matrix, 18, 216-219\\nconsumer web abuse, 235-272\\nabuse types, 237-256\\naccount creation, 243-248\\nauthentication and account takeover,\\n237-243\\nbot activity, 251-256\\nclustering of, 260-271\\nclustering spam domains, 261-262\\ncold start vs. warm start for supervised\\nlearning, 256\\ndefined, 235\\nfalse positives/negatives for abuse problems,\\n258\\nfinancial fraud protection, 248-251\\ngenerating clusters of abuse, 262\\nlabeling data, 256\\nlarge attacks and supervised learning, 259\\nmonetizing by hackers, 236\\nmultiple responses for supervised learning,\\n259\\nscoring clusters, 266-271\\nsupervised learning for detecting, 256-259\\ncontextual multi-armed bandits, 292\\nconventional validation, 15\\ncost functions, 35\\nimplementing, 345\\nminimizing, 346-349\\ncovariance, 111\\ncovariance estimate fitting (elliptic envelope fit‐\\nting), 108-112\\ncredential stuffing, 252\\ncredit cards, 8, 248\\ncross-site scripting (XSS) attacks, 318, 335-338\\nIndex \\n| \\n357'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 375}, page_content='cross-validation, 15, 56\\ncurse of dimensionality, 67, 344\\ncyber attacks\\neconomy of, 7\\nindirect monetization, 8\\nmarketplace for hacking skills, 7\\nprincipal threats, 3-5\\ncycles (defined), 95\\nD\\nDalvik, 150\\ndarknet, 7\\ndata\\nanomaly detection with, 93-119\\nbias, 278\\ncollection for feature generation, 146-147\\nfor network attack classifier, 205-214\\nunbalanced, 57\\ndata privacy safeguards/guarantees, 312\\ndata quality, 277-284\\nbias in datasets, 277-279\\nlabel inaccuracy problems, 279\\nmissing data, 280-284\\nsolutions, 279\\ndata validation, 147\\ndata-centric security, 185\\nDataFrame, 29\\ndatasets\\nbias, 277-279\\nfeaturized, 174-178\\ndatasketch, 19\\nDBSCAN (Density-Based Spatial Clustering of\\nApplications with Noise), 73-75\\nDDoS (distributed denial-of-service) attacks, 5,\\n196\\ndebugging, for Android malware analysis, 168\\ndecision boundary, 33, 324-333\\ndecision forests, 45\\ndecision trees, 42-45\\nalgorithmic optimization, 300\\nensembles (see decision forests)\\nlimitations, 44\\ndeep learning, 11, 173-174\\ndeep neural network algorithms\\nfeature representations, 173-174\\noptimization, 300\\ndeep packet inspection (DPI), 90-91\\ndefensive distillation, 339\\ndendrogram, 69\\ndenial-of-service (DoS) attacks, 5, 196\\ndensity-based anomaly detection, 116-118\\nDensity-Based Spatial Clustering of Applica‐\\ntions with Noise (DBSCAN), 73-75\\ndifferential privacy, 313\\ndiscriminator (neural network), 321\\ndistance metrics\\nHamming, 343\\nL-infinity, 67\\nL1, 343\\ndistillation, 339\\ndistributed computing, horizontal scaling with,\\n300-305\\ndistributed denial-of-service (DDoS) attacks, 5,\\n196\\ndivisive (top-down) hierarchical clustering, 68\\nDoS (denial-of-service) attacks, 5, 196\\ndummy variables, 30\\ndynamic (behavioral) analysis, 13, 160-168\\ndynamic instrumentation, 169\\ndynamic IPs, 353\\nE\\nelliptic envelope fitting (covariance estimate fit‐\\nting), 108-112\\nemail filters, 1\\nembarrassingly parallel problems, 301\\nensemble/ensembling\\ndefined, 23, 45, 228\\nfor network attack classification, 228-233\\nEuclidean distance, 343\\nevasion attacks, 333-340\\nbinary classifier attack, 334-339\\ndefense against, 339\\nwith adversarial examples, 123\\nexclusion bias, 278\\nexplainability, 293-297\\nexploit (defined), 4\\nexploratory attacks, 316\\nF\\nF-score, 64\\nfailures (graceful degradation), 308\\nfalse negatives/false positives\\nfor consumer web supervised learning, 258\\nwith anomaly detection, 82\\nFast Gradient Sign Method (FGSM), 338\\nfeature engineering, 145-178\\nfor anomaly detection, 85-93\\n358 \\n| \\nIndex'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 376}, page_content=\"for cluster scoring, 267-269\\ndata collection, 146-147\\ndeep packet inspection, 90-91\\ndefined, 126\\nhost intrusion detection, 85-88\\nfor network defense, 187-193\\nnetwork intrusion detection, 89-92\\nunsupervised feature learning, 188\\nvelocity features as account creation\\ndefense, 244-246\\nweb application intrusion detection, 92-93\\nfeature extraction\\ndefined, 126\\n(see also feature engineering)\\nfeature generation (see feature engineering)\\nfeature hashing, 176\\nfeature selection, 59-60\\nlatent feature representations, 172\\nmalware analysis, 171-174\\nmodel-specific feature ranking, 172\\nrecursive feature elimination, 172\\nunivariate analysis, 171\\nunsupervised feature learning and deep\\nlearning, 173-174\\nfeatures\\nalgorithmic optimization, 300\\nmissing, 58\\nfeaturized datasets, 174-178\\nfeedback loops\\nas risk in supervised learning, 257\\nfor models, 289-291\\nin anomaly detection systems, 123\\nin production systems, 313\\nFGSM (Fast Gradient Sign Method), 338\\nfinancial fraud, 248-251\\nfirst-order optimization algorithms, 37\\nforecasting\\nanomaly detection, 95-105\\nARIMA, 96-101\\nartificial neural networks, 102-105\\nfuzzing, 13, 167\\nfuzzy hashing, 19\\nfuzzy matching, 130\\nG\\ngames, online, 252\\nGaussian distribution, 84\\nGBDT (gradient-boosted decision trees), 46\\nGCP (Google Cloud Platform), 306\\ngenerative adversarial nets (GANs), 321\\ngenerator (neural network), 321\\ngeolocation, 352\\nGini impurity, 42\\ngoodness-of-fit tests\\nelliptic envelope fitting, 108-112\\nfor anomaly detection, 107-112\\nGoogle Cloud ML Engine, 306\\nGoogle Cloud Platform (GCP), 306\\ngradient descent optimization algorithms, 38\\ngradient-boosted decision trees (GBDT), 46\\ngreedy training, 45\\ngrid search, 286-287\\ngrouping (clustering method), 65, 263\\nGrubbs' outlier test, 107\\nH\\nhacking, commoditization of, 7\\nHamming distance, 343\\nhashing trick, 176\\nhashing, locality-sensitive, 68-69\\nheuristics, intrusion detection with, 81\\nHex-Rays IDA, 157\\nhierarchical botnets, 201\\nhierarchical clustering, 68-69\\nhinge loss, 47\\nhomogeneity score, 75, 224\\nhomomorphic encryption, 186\\nhoneypots, 186\\nhost intrusion detection\\nanomaly detection, 85-88\\nosquery and, 86-88\\nhyperparameter optimization, 285-289\\nI\\nIDS (see intrusion detection systems)\\nimbalanced classes, 219-222\\nimperfect learning, 318, 340\\nimputation, 58, 283\\nincendiary speech, 5\\nincident response, anomaly detection and, 120\\nindiscriminate attacks, 316\\ninductive transfer, 204\\ninformation gain, 43\\ninsider threat detection, 194\\nintegrity attacks, 317\\nInternet Relay Chat (IRC) protocol, 198\\nInternet wiretapping, 193\\ninterpreted code execution, 139-143\\nIndex \\n| \\n359\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 377}, page_content='intrusion detection systems (IDS)\\nand asynchronous decision-making, 297\\nnetwork traffic analysis and, 184\\nwith heuristics, 81\\nIP addresses\\nreputation scoring, 246-248\\nthreat identification, 352\\nIRC (Internet Relay Chat) protocol, 198\\nisland hopping, 91\\nisolation forests, 115-116\\nJ\\nJaccard similarity, 70, 344\\nJacobian Saliency Map Approach (JSMA), 339\\nJava, 150\\njust-in-time (JIT) compilation, 133\\nK\\nk-dimensional (k-d) trees, 72-75, 300\\nk-means clustering, 65-67, 265\\nand advanced ensembling, 228-233\\ndensity-based clustering and, 117\\nfor network traffic analysis, 223, 228-233\\nhierarchical clustering vs., 68-69\\nlocality-sensitive hashing vs., 69\\nk-nearest neighbors (k-NN) algorithms, 52, 117\\nKDD Cup, 91\\n(see also NSL-KDD dataset)\\nkernel (defined), 84\\nkernel trick, 48\\nkeyloggers, 4\\nKnowledge Discovery and Data Mining Special\\nInterest Group (SIGKDD), 91\\nL\\nL-infinity distance, 67\\nlabeling\\nbot requests, 255\\nfor consumer web abuse problems, 256\\nfor scoring clusters, 267\\ninaccuracy problems, 279\\nlast hop, 353\\nlatency, production system, 297-300\\nlatent feature representations, 172\\nlazy-learning algorithms, 52\\nleast squares regression, 346\\nLIBLINEAR, 37\\nLIEF project, 177\\nlinear models, 300\\nlinear regression, 40, 346\\nLocal Interpretable Model-Agnostic Explana‐\\ntions (LIME), 294-297\\nlocal outlier factor (LOF), 117-118\\nlocal substitute model, 321\\nlocality-sensitive hashing (LSH), 19, 68-69, 71,\\n264-265\\nlog odds, 40\\nlogin attacks, 4\\n(see also authentication)\\nlogistic function, 34\\nlogistic regression, 30\\ncost functions, 35, 345-349\\nnegative log likelihood, 36\\nsize of models, 344\\nsupervised learning algorithms, 40-42\\nlong short-term memory (LSTM) networks,\\n102-105\\nloss functions, 35\\nlow-value hosts, 195\\nLSH (see locality-sensitive hashing)\\nM\\nMAC flooding, 193\\nmachine learning (generally)\\nadversaries using, 11\\n(see also adversarial machine learning)\\nAI and, 10-11\\nanomaly detection, 119\\nbasics, 9-12\\ndefined, 9, 26\\nlimitations, 23\\nmalware classification, 129-131\\nnetwork security and, 187-202\\nonline purchase transaction data example,\\n27-32\\nproblems and approaches, 25-27\\nproduction systems (see production sys‐\\ntems)\\nreal-world security uses, 12-14\\nsupervised vs. unsupervised, 9\\ntraining algorithms to learn, 32-40\\nMAD (median absolute deviation), 106\\nmaintainability, production system, 307-309\\ncheckpointing, versioning, and deployment\\nof models, 307\\nconfiguration and tuning, 309\\ngraceful degradation, 308\\n360 \\n| \\nIndex'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 378}, page_content='malware (defined), 3\\nmalware analysis, 125-179\\nAndroid, 148-171\\ndata collection for feature generation,\\n146-147\\ndefinitions for malware classification,\\n128-131\\ndetection, 13\\nfeature generation, 145-178\\nfeature hashing, 176\\nfeature selection, 171-174\\nfeaturized dataset generation, 174-178\\ngetting malware samples/labels, 178\\nmachine learning in malware classification,\\n129-131\\nmalware attack flow, 143\\nmalware basics, 126-145\\nmalware behaviors, 144\\nmalware economy, 131\\nmodern code execution processes, 132-143\\nMalware Classification Challenge, 178\\nmalware-traffic-analysis.net, 178\\nman-in-the-middle attacks, 194\\nManhattan distance (L1 distance), 343\\nmasquerading (phishing), 4\\nmaximum likelihood estimate, 51\\nmaximum-margin hyperplane, 47\\nMaxmind, 353\\nMCD (Minimum Covariance Determinant),\\n111\\nmedian absolute deviation (MAD), 106\\nmetamorphic malware, 129\\nmetrics pollution, 256\\nmetrics, clustering, 65, 343\\nMFA (multifactor authentication), 184\\nmicrosegmentation, 185\\nMinHash, 70\\nMinimum Covariance Determinant (MCD),\\n111\\nmisclassification, attack transferability and, 320\\nmissing data, 280-284\\nmissing features, 58\\nMLP (multilayer perceptron), 325\\nmodel families, 33-35\\nmodel poisoning attacks (see poisoning attacks)\\nmodel rot, 290\\nmodeling error, 318\\nmodels\\nA/B testing, 291\\ncheckpointing/versioning/deployment, 307\\ncomparing, 62-64\\ndefined, 32\\nfeedback loops, 289-291\\nfor production systems, 284-297\\nhyperparameter optimization, 285-289\\nrepeatable and explainable results, 293-297\\nmomentum, 38\\nmonitoring, production system, 310-311\\nmoving average, 106\\nmulti-armed bandit problem, 292\\nmultifactor authentication (MFA), 184\\nmultilayer perceptron (MLP), 325\\nmultileader botnets, 200\\nN\\nn-grams, 263-265, 268-269\\nNaive Bayes classifiers, 49-51\\nNatural Language Toolkit (NLTK), 15\\nnegative log likelihood, 36\\nnetwork breaches, 194\\nnetwork traffic analysis, 181-233\\naccess control and authentication, 183\\nactive attacks, 194-196\\nadvanced ensembling, 228-233\\nand class imbalance, 219-222\\nattack classification, 214-216\\nbotnets, 197-202\\ncapturing live network data for feature gen‐\\neration, 187-193\\ndata exploration/preparation, 205-210\\ndata-centric security, 185\\ndeep packet inspection, 90-91\\ndetecting in-network attackers, 185\\nfeatures for, 91\\nhoneypots, 186\\nintrusion detection, 89-92, 184\\nmachine learning and network security,\\n187-202\\nnetwork defense theory, 183-186\\nOSI model, 182\\noutlier detection, 13\\npassive attacks, 193\\nphysical layer attacks, 193\\npredictive model to classify attacks, 203-233\\nsemi-supervised learning for, 222\\nsupervised learning for network attack clas‐\\nsification, 216-222\\nthreats in the network, 193-196\\nIndex \\n| \\n361'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 379}, page_content='unsupervised feature learning, 188\\nunsupervised learning, 223-228\\nneural networks, 11, 53, 102-105, 173-174, 300\\nNLTK (Natural Language Toolkit), 15\\nnormalization of data, 213\\nnovelty detection, 94\\nNSL-KDD dataset, 203, 209\\nNumPy, linear algebra frameworks with, 299\\nO\\nobjective functions, 35, 320\\n(see also loss functions)\\nobserver bias (observer-expectancy effect), 278\\none-class Support Vector Machines, 112-115\\none-hot encoding, 30\\none-versus-all strategy, 215\\none-versus-one strategy, 215\\nonline gaming, 252\\nonline learning\\ncausative attacks and, 316\\nmodel poisoning and, 320, 322-333\\n(see also poisoning attacks)\\nopen source intelligence (OSINT), 351-353\\ngeolocation, 352\\nsecurity intelligence feeds, 351\\nOpen Systems Interconnection (OSI) model,\\n182\\noptimization algorithms, 36-40\\nfirst-order, 37\\ngradient descent, 38\\nsecond-order, 37\\nselecting, 39\\noptimized linear algebra frameworks, 299\\nOSI (Open Systems Interconnection) model,\\n182\\nOSINT (see open source intelligence)\\nosquery, 86-88\\nout-of-time validation, 57\\noutlier detection, 13, 79, 94\\noverfitting, 24, 44, 61-62\\noversampling, 219\\nP\\npackers, 160\\npacket sniffing, 184\\nparallelization, 122, 300\\npassive attacks, 193\\npasswords, 237, 239\\npattern mining, 187\\npattern recognition, 12\\npay-per-install (PPI) marketplace, 8\\nPCA (Principal Component Analysis), 172, 225\\nperceptron, 54\\nperformance optimization, 297-307\\ncloud services for, 305\\nhorizontal scaling with distributed comput‐\\ning frameworks, 300-305\\nlatency reduction, 297-300\\nphishing, 4\\nphysical layer attacks, 193\\npivoting, 91, 195\\npoisoning attacks, 291, 322-333\\nattacker knowledge of decision function,\\n330\\nbinary classifier attack, 325-329\\nchaff and, 123, 327-329\\ndefense against, 331-331\\npolymorphic malware, 129\\npolynomial factor differencing, 97\\npopulation, 278\\nport scanning, 193\\nPPI (pay-per-install) marketplace, 8\\nPrincipal Component Analysis (PCA), 172, 225\\nprivacy-preserving machine learning, 313\\nproduction systems, 275-314\\nA/B testing of models, 291\\ncloud services for, 305\\nconfiguration and tunability, 309\\ndata quality, 277-284\\nfeedback, 313\\nfeedback loops, 289-291\\ngraceful degradation, 308\\nhorizontal scaling with distributed comput‐\\ning frameworks, 300-305\\nhyperparameter optimization, 285-289\\nlatency optimization, 297-300\\nmaintainability, 307-309\\nmature/scalable system characteristics,\\n275-277\\nmodel checkpointing/versioning/deploy‐\\nment, 307\\nmodel quality, 284-297\\nmonitoring and alerting, 310-311\\nperformance optimization, 297-307\\nperformance requirements, 277\\nrepeatable/explainable results, 293-297\\nscalability, 297-300\\nsecurity and reliability, 311-313\\n362 \\n| \\nIndex'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 380}, page_content='usability, 313\\nprofilers, 298\\nprotectors, 160\\nproxies, 353\\nPython, interpreted code execution example,\\n139-143\\nQ\\nquery packs, 87\\nR\\nRadare2, 156-157\\nradial basis function, 49\\nrandom forests, 45\\nalgorithmic optimization, 300\\nclassifier training, 270\\nisolation forests, 115-116\\nrandomized P2P botnets, 202\\nranking fraud, 252\\nransomware, 3, 132\\nreceiver operating characteristic (ROC), 63\\nrecommendation systems, 119\\nrecursive feature elimination, 172\\nred herring attacks, 291\\n(see also poisoning attacks)\\nregression, 9, 27\\nregular data, 80\\nregularization, 61\\nreinforcement learning (RL), 291\\nreliability, production system, 311-313\\ndata privacy safeguards/guarantees, 312\\nrobustness in adversarial contexts, 312\\nrepeatability of machine learning predictions,\\n293\\nreputation scores, 246-248\\nreputation systems, 243\\nresidual, 346\\nreverse engineering, 127\\nreview fraud, 236\\nRL (reinforcement learning), 291\\nROC (receiver operating characteristic), 63\\nrolling counter, 244\\nrootkit, 3\\nS\\nscalability\\nhorizontal scaling with distributed comput‐\\ning frameworks, 300-305\\nproduction systems, 275-277, 297-300\\nreal-time streaming applications, 122\\nscanning attacks, 4\\nscikit-learn\\nand semi-supervised learning, 223\\nand spark-sklearn, 301\\nfeature hashing, 176\\nfeature selection, 60\\nhyperparameter optimization, 285-289\\nimputing missing values, 284\\nincorrect handling of categorical variables,\\n42\\nlinear algebra frameworks, 299\\nLOF generation, 117\\nmachine learning algorithm cheat-sheet,\\n215\\nnative linear algebra frameworks, 299\\nnormalization for cross-validation, 214\\nunivariate analysis methods, 171\\nscoring of clusters, 266-271\\nclassification, 270\\nfeature extraction, 267-269\\nlabeling, 267\\nscraping, 252, 255\\nseasonality, 83\\nseasons (defined), 95\\nsecond factor authentication, 238\\nsecond-order optimization algorithms, 37\\nsecurity information and event management\\n(SIEM), 120\\nsecurity intelligence feeds, 351\\nsecurity, production system, 311-313\\ndata privacy safeguards/guarantees, 312\\nrobustness in adversarial contexts, 312\\nselection bias, 278\\nsemantic gap, 119\\nsemi-supervised learning\\nactive learning, 291\\nfor network attack classification, 222\\nsentinel values, 281\\nSGD (Stochastic Gradient Descent), 38\\nshingling, 70\\nSIEM (security information and event manage‐\\nment), 120\\nSIGKDD (Knowledge Discovery and Data\\nMining Special Interest Group), 91\\nsigmoid function, 34\\nSilhouette coefficient, 76\\nSingular Value Decomposition (SVD), 172\\nIndex \\n| \\n363'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 381}, page_content=\"smoothing, 51\\nsniffing, 4\\nSnort, 89\\nsocial engineering, 5\\nsoftware profiling, 298\\nsoftware reverse engineering, 127\\nsource code, binaries and, 126\\nspam\\ndefined, 4\\ndetection, 13\\niterative approach to fighting, 14-23\\norigins, 1\\nspam domains, 261-262\\nSpamhaus Project, 351\\nSpark ML, 302-305\\nspark-sklearn, 301\\nspear phishing, 5\\nSPI (stateful packet inspection), 89\\nsplit testing, 291\\nspoofing, 195\\nspyware, 3, 8\\nstacked generalization, 23\\nstandardization of data series, 212\\nstar/centralized botnets, 199\\nstateful packet inspection (SPI), 89\\nstatic analysis, 154-160\\nstatistical analysis, 11\\nstatistical tests\\nfor anomaly detection, 106-107\\nGrubbs' outlier test, 107\\nmedian absolute deviation, 106\\nstealth banning, 121\\nstemming, 15\\nStochastic Gradient Descent (SGD), 38\\nstop words, 15\\nstructural analysis, 150-154\\nStuxnet worm, 125\\nsupervised learning, 9\\nanomaly detection vs., 80\\ncold start vs. warm start, 256\\nconsumer web abuse detection, 256-259\\ndefined, 27\\nfalse positives/negatives, 258\\nforecasting, 95-105\\nlabeling data, 256\\nlarge attacks on consumer web, 259\\nmultiple responses for consumer web abu‐\\nses, 259\\nnetwork attack classification, 216-222\\nsupervised learning algorithms, 40-55\\nchoosing thresholds and comparing models,\\n62-64\\ndecision trees, 42-45\\nfeature selection, 59-60\\nk-nearest neighbors, 52\\nlogistic regression, 40-42, 344\\n(see also logistic regression)\\nmodel family selection, 55\\nNaive Bayes classifiers, 49-51\\nneural networks, 53\\noverfitting/underfitting, 61-62\\npractical considerations, 55-64\\nsupport vector machines, 47-49\\ntraining data construction, 56-59\\nsupport vector machines (SVMs), 47-49\\nalgorithmic optimization, 300\\nand hyperparameters, 287\\none-class, 112-115\\nsupport vectors, 48\\nSVD (Singular Value Decomposition), 172\\nSYN flooding, 196\\nT\\ntargeted attacks, 316\\ntcpdump, 188\\nThomson sampling, 292\\nthreat intelligence feeds, 351\\nThreat Intelligence Quotient Test, 352\\nthreat mitigation, anomaly detection and, 120\\nthresholds, choosing, 62-64\\ntime series\\ndefined, 80\\ntrends, seasons, and cycles, 95\\ntime series analysis, 27\\nTLS (Transport Layer Security), 189\\ntrained models, 284-297\\n(see also models)\\ntraining data construction\\nattacker evolution, 58\\nlarge events, 58\\nmissing features, 58\\nnetwork attack classifier, 205-214\\nunbalanced data, 57\\ntransfer learning, 204\\nTransport Layer Security (TLS), 189\\nTREC Public Spam Corpus, 15\\ntree-based models, 300\\n(see also decision trees)\\n364 \\n| \\nIndex\"),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 382}, page_content='trends (defined), 95\\nTrojan, 3\\ntunability, 309\\nU\\nunbalanced data, 57\\nunderfitting, 61\\nundersampling, 219\\nunivariate analysis, 171\\nunsupervised feature learning, 54, 173-174, 188\\nunsupervised learning\\nalgorithms, 112-116, 321\\ndefined, 9, 27\\ngenerative adversarial nets, 321\\nisolation forests, 115-116\\nnetwork attack classification, 223-228\\none-class Support Vector Machines,\\n112-115\\nunsupervised feature learning vs., 54, 188\\nuser authentication (see authentication)\\nV\\nV-measure, 75, 224\\nvalidation, 147\\nvariance reduction, 43\\nvelocity features, 244-246\\nversioning, 307\\nvirus (defined), 3\\nVirusShare.com, 178\\nVirusTotal, 178\\nVX Heaven, 178\\nW\\nwarm start, 256\\nweb application firewall (WAF), 335-338\\nweb application intrusion detection, 92-93\\nworm (defined), 3\\nX\\nXGBoost, 47\\nXSS (cross-site scripting) attacks, 318, 335-338\\nY\\nyouarespecial project, 175-177\\nZ\\nzero-day vulnerability\\ndefined, 5\\nmarketplace for, 7\\nIndex \\n| \\n365'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 383}, page_content='About the Authors\\nClarence Chio is an engineer and entrepreneur who has given talks, workshops, and\\ntraining courses on machine learning and security at DEF CON and other security/\\nsoftware engineering conferences and meetups across more than a dozen countries.\\nHe was previously a member of the security research team at Shape Security, a com‐\\nmunity speaker with Intel, and a security consultant for Oracle. Clarence advises a\\nhandful of startups on security data science, and is the founder and organizer of the\\nData Mining for Cyber Security meetup group, the largest gathering of security data\\nscientists in the San Francisco Bay area. He holds a BS and MS in computer science\\nfrom Stanford University, specializing in data mining and artificial intelligence.\\nDavid Freeman is a research scientist/engineer at Facebook working on spam and\\nabuse problems. He previously led anti-abuse engineering and data science teams at\\nLinkedIn, where he built statistical models to detect fraud and abuse and worked with\\nthe larger machine learning community at LinkedIn to build scalable modeling and\\nscoring infrastructure. He is an author, presenter, and organizer at international con‐\\nferences on machine learning and security, such as NDSS, WWW, and AISec, and has\\npublished more than twenty academic papers on mathematical and statistical aspects\\nof computer security. He holds a PhD in mathematics from UC Berkeley and did\\npostdoctoral research in cryptography and security at CWI and Stanford University.\\nColophon\\nThe animal on the cover of Machine Learning and Security is a Siberian pit viper\\n(Gloydius halys), also known as a halys viper. It lives throughout a wide segment of\\nAsia east of the Ural Mountains, including parts of Russia and China. This snake is\\nvenomous and part of the pit viper family. Pit vipers are so named for a specialized\\nheat-sensing organ in a deep pit on their snout. This pit organ helps in finding\\nwarmer or cooler places as needed for temperature regulation, as well as sensing and\\nstriking prey. Most pit viper species also give birth to live young rather than laying\\neggs.\\nThe Siberian pit viper grows to a length of around 21–23 inches; females of the spe‐\\ncies are slightly longer than males. It has a slightly upturned snout, and the skin is\\npatterned with large dark crossbars alternating with a lighter color (varying from gray\\nto light brown or yellow, depending on the subspecies).\\nThis snake hunts with an ambush method, where it remains still on the ground and\\nwaits for prey (such as a bird or small mammal) to pass close enough to strike. The\\nvenom will paralyze or kill its victim, which the viper then swallows whole. Like most\\nsnakes, Siberian pit vipers generally keep to themselves and will only bite humans if\\nthey feel threatened.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.15', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': \"D:20180126221952Z00'00'\", 'source': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'file_path': '..\\\\data\\\\pdf\\\\machine learing and security.pdf', 'total_pages': 385, 'format': 'PDF 1.5', 'title': 'Machine Learning and Security', 'author': 'Chio, Clarence;freeman, David', 'subject': '', 'keywords': '', 'moddate': \"D:20180126221952Z00'00'\", 'trapped': '', 'modDate': \"D:20180126221952Z00'00'\", 'creationDate': \"D:20180126221952Z00'00'\", 'page': 384}, page_content='The cover image is from Lydekker’s Royal Natural History. The cover fonts are URW\\nTypewriter and Guardian Sans. The text font is Adobe Minion Pro; the heading font\\nis Adobe Myriad Condensed; and the code font is Dalton Maag’s Ubuntu Mono.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install pymupdf\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/pdf\",\n",
    "    glob=\"**/*.pdf\", ## Pattern to match files  \n",
    "    loader_cls= PyMuPDFLoader, ##loader class to use\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "pdf_documents=dir_loader.load()\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf183bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_documents[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
